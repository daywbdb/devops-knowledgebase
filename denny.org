-*- mode:org; fill-column:70; coding:utf-8; -*-
* org-mode configuration
#+STARTUP: overview customtime noalign logdone hidestars
#+TAGS: ARCHIVE(a) WORK(w) LIFE(l) EMACS(e) IMPORTANT(i) Debug(d) Communication(c) RECOMMENDATE(r) Tool(t) Habit(h) noexport(n) Share (s) BLOG(b) Problem(p)
#+SEQ_TODO: TODO HALF ASSIGN | DONE BYPASS DELEGATE CANCELED DEFERRED
#+DRAWERS: HIDDEN CODE CONF EMAIL WEBPAGE SNIP
#+PRIORITIES: A D C
#+ARCHIVE: %s_done::** Finished Tasks
#+AUTHOR: dennyzhang.com (denny.zhang001@gmail.com)
#+OPTIONS: toc:2 \n:t ^:nil creator:nil d:nil
* What value DevOps Consultant Provides
- Code Build
- CI
- Automation to Push prod env
- Monitoring system
- Backup
- Autoscale
- Auto failover
- Trouble shooting

* DevOps Library
- nagios: https://github.com/DennyZhang/enforce_all_nagios_check
- chef: https://supermarket.chef.io/users/dennyzhang001
* [#A] How To Bill Customers Properly
| Task                  | Category | Summary                                                                        |
|-----------------------+----------+--------------------------------------------------------------------------------|
| CI maintain           | Routine  | Watch failed Jenkins Jobs; Do basic trouble shooting and reproduce; escalation |
| Operate prod env      | Routine  | Watch monitoring alerts; handle emergency; trouble shooting/escalation         |
|-----------------------+----------+--------------------------------------------------------------------------------|
| AIO Chef cookbooks    | Dev      | Backbone cookbooks; all-in-one cookbooks                                       |
| Metric visualization  | Dev      | Generate key metrics and graph                                                 |
|-----------------------+----------+--------------------------------------------------------------------------------|
| Backup Chef cookbooks | Dev      | Backup and recovery rehearsal                                                  |
| Negative Test         | Dev      | Restart test, reboot and chaos monkey                                          |
| Log management        | Debug    | offline trouble shooting                                                       |
|-----------------------+----------+--------------------------------------------------------------------------------|
|-----------------------+----------+--------------------------------------------------------------------------------|
| Auto diagnostic       | Debug    | Business related Trouble shooting                                              |
| Clustering            | Dev      |                                                                                |
| Track prod env issue  | Prod env | Trouble shooting                                                               |
|-----------------------+----------+--------------------------------------------------------------------------------|
| Security              | Risk     |                                                                                |
| Identity risks        | Risk     |                                                                                |

* Consultant Facility
** TODO VPN disconnect issue: simple configure for client; resilient for network turbulence

** TODO Ruilin: how Don managed without ruilin facing customers directly
** TODO Ruilin: how to allow you using emails, without communication overhead
** TODO Jay: how to split the profit within the team?
** TODO Jay & Don: allow DevOps team to work from home
* [#A] [Doc] DevOps related documentation requirement
| Name                               | Summary                                                              |
|------------------------------------+----------------------------------------------------------------------|
| Issues Contact                     | For different issues, know escalate to whom                          |
| Aggregation for useful links       | Jenkins url, nagios url, prod env url                                |
| Document template for issue report | Avoid false alarm and describe issue clearly with less communication |
| Track issues of prod env           | Learn from history                                                   |
| Jenkins jobs introduction          | GUI for the visualized Ops                                           |
| metric introduction                | What does each metric mean                                           |
|------------------------------------+----------------------------------------------------------------------|
| handy commands                     | useful commands related to current projects                          | 

** template for common pages

https://totvslab.atlassian.net/wiki/display/MDMP/Tech+Ops
https://totvslab.atlassian.net/wiki/display/TECH/TechOps+Home

Environments
DigiticalOcean Env
How-To Manage Prod envs
Contact List For Emergencies
How To Backup and Restore An Env
How To Deploy Prod Env
How To Monitor Prod Env
How To Push Prod Env
Maintainance History Of Prod Env
How-To Use DevKit
How To Build Code
How To Setup Sandbox
How To Trouble Shooting
** Easily to get a list of open OPS tickets and history
#+BEGIN_EXAMPLE
[2/5/15, 4:51:51 PM] John Kaplan: yes…
[2/5/15, 4:52:08 PM] John Kaplan: https://totvslab.atlassian.net/secure/RapidBoard.jspa?rapidView=37&view=detail
[2/5/15, 4:52:26 PM] John Kaplan: this is the sprint board
[2/5/15, 4:52:52 PM] John Kaplan: click on “Ops” in the top menu
[2/5/15, 4:53:24 PM] John Kaplan: and click on ICM 1.4.5 Labs in the top to see the work for just the labs sprint
[2/5/15, 4:53:49 PM] John Kaplan: You are the “Big D”
[2/5/15, 5:02:48 PM] denny: Thanks!
#+END_EXAMPLE
** Don't write document which will easily change: You will need waste time to do the cleanup
** TODO Wiki: split test env into sections
** [Documentation] Document the major change before push or hotfix
#+BEGIN_EXAMPLE
[2/9/15, 3:38:59 PM] John Kaplan: we can send an email alert to customerfi admins about the proposed update and ask for any blackout schedule
[2/9/15, 4:24:33 PM] Vicente Goetten: Any risk for this deployment?
[2/9/15, 4:25:11 PM] Suresh Sathyanarayan: From QA perspective, no risk Vicente.
[2/9/15, 4:26:56 PM] denny: Maybe we can maintain a wiki page as a team effort, whenever we do a push/hotfix
- first make notes for major changes there
- Draft evaluation for the risk and change

What do you think, Lucas/Vicente
#+END_EXAMPLE
** TODO mail: FW: Cloud Env. :: Report                             :noexport:
[[gnus:mail.misc#EF9859611DA81140B2B29B02EC8AD6EAF8F427@helios.mex01.local][Email from Denny Zhang (Mon, 26 Jan 2015 21:56:24 +0000): FW: Cloud Env. :: Report]]
#+begin_example
From: Denny Zhang <denny.zhang@totvs.com>
Subject: FW: Cloud Env. :: Report
To: "filebat.mark@gmail.com" <filebat.mark@gmail.com>
Date: Mon, 26 Jan 2015 15:56:24 -0600

---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Monday, January 26, 2015 3:55 PM
To: Lucas Vinicius Schiochet
Cc: John Kaplan; Suresh Sathyanarayan; Kung Wang
Subject: RE: Cloud Env. :: Report

Hi Lucas

I've crossed out all VMs which are not mandatory. Also added a column "Location" for all VMs, which
tell whether it's in Nimvbs, EC2 or digital ocean.

Regards,
Denny
---------------------------------------------------------------------------------------------------
From: Lucas Vinicius Schiochet
Sent: Monday, January 26, 2015 3:18 PM
To: Denny Zhang
Cc: John Kaplan; Suresh Sathyanarayan
Subject: Cloud Env. :: Report

Hi Denny,

I am looking the documentation available in:

  * https://totvslab.atlassian.net/wiki/display/TECH/Fluig+Testbed+Env
  * https://totvslab.atlassian.net/wiki/display/TECH/Fluig+Amazon+AWS+Env
  * https://totvslab.atlassian.net/wiki/display/TECH/Fluig+DigitialOcean+Env

But I don’t know which servers are mandatory like customerfi.com and which one we does not need
anymore like denny-chef-ubuntu-10.
Also I don’t know which server are at Nimbvs and which is in thirty party clouds.

The list are up to date? Can you update the list to I create a report of machine migration?

Regards,
Lucas Schiochet

#+end_example
** Improve doc about Apache certificate
*** mail: RE: Security Certificate                                 :noexport:
[[gnus:mail.misc#EF9859611DA81140B2B29B02EC8AD6EAF95C76@helios.mex01.local][Email from Denny Zhang (Mon, 2 Feb 2015 16:08:37 -0600): RE: Security Certificate]]
#+begin_example
From: Denny Zhang <denny.zhang@totvs.com>
Subject: RE: Security Certificate
To: Julio Cesar Negri <julio.negri@totvs.com.br>, Suresh Sathyanarayan
        <Suresh@totvs.com>, Shivang Shah <shivang.shah@totvs.com>
CC: Denny Zhang <denny.zhang@totvs.com>
Date: Mon, 02 Feb 2015 16:08:37 -0600

Hi Julio

How are you? Long time to see you.

Is the certificate self-signed? If so, that's the standard behavior.

Check related wiki for more.
https://totvslab.atlassian.net/wiki/display/TECH/FAQ+Of+Certificate

In case you can't access the url, I've taken a screenshot for you.

[cid]

Regards,

Denny
---------------------------------------------------------------------------------------------------
From: Julio Cesar Negri
Sent: Monday, February 02, 2015 2:55 PM
To: Suresh Sathyanarayan; Shivang Shah
Cc: Denny Zhang
Subject: Security Certificate

Hi guys!

A long long time ago I sent an email to Labs’ team about message below (asking certificate):

[cid]

What could we do to eliminate this message?

I remember that Denny sent me 2 files, ssl.crt and ssl.key.

This files have relationship with this issue?

[cid]

Thanks a lot!!!

TOTVS PRIVATE           Julio César Négri
                        Serviços Grandes Contas
                        julio.negri@totvs.com.br
                        Cel +55 11 99199-3503

#+end_example
** [#A] People don't want to check wiki, simply ask personally    :IMPORTANT:
*** Kung ask me questions about qafluigidentity
#+BEGIN_EXAMPLE
[2/5/15, 11:51:36 AM] kungchaowang: Denny, can we deploy 1.4.4, with new change to #cache_type=none on it?
[2/5/15, 11:51:43 AM] kungchaowang: it’s still old conf
[2/5/15, 11:51:56 AM] kungchaowang: I can change it, but I think it’s better for you to do it
[2/5/15, 11:52:58 AM] denny: Kung, chef has already changed that file to “#cache_type=none”.

Do you mean the change is not reflected?
[2/5/15, 11:53:12 AM] kungchaowang: no
[2/5/15, 11:53:45 AM] kungchaowang: may be we did not deploy to qafluigidentity
[2/5/15, 11:54:29 AM] denny: I didn’t operate that env. Maybe we can reach John/Suresh
[2/5/15, 11:54:45 AM] denny: It should have been changed.

Let me check 3 critical envs
[2/5/15, 11:54:59 AM] denny: I’m on call showing Lucas team about enterprise upgrade
[2/5/15, 11:55:01 AM] kungchaowang: yes, you can ask them to do jenkins deploy
#+END_EXAMPLE
** DONE move on-premise env from github to wiki
  CLOSED: [2015-03-19 Thu 10:27]
#+BEGIN_EXAMPLE
macs-MacBook-Air:deployment mac$ git status
On branch master
Your branch is up-to-date with 'origin/master'.

Changes not staged for commit:
  (use "git add/rm <file>..." to update what will be committed)
  (use "git checkout -- <file>..." to discard changes in working directory)

	deleted:    on_premise/on_premise_blanver_prod.sh
	deleted:    on_premise/on_premise_blanver_test.sh
	deleted:    on_premise/on_premise_bradesco_redhat_prod.sh
	deleted:    on_premise/on_premise_bradesco_redhat_test.sh
	deleted:    on_premise/on_premise_brazil_insurance_prod.sh
	deleted:    on_premise/on_premise_brazil_insurance_test.sh
	deleted:    on_premise/on_premise_resource_prod.sh
	modified:   ../../cookbooks/all-in-one/.kitchen.yml
	modified:   ../../cookbooks/fluig-cluster/.kitchen.yml

no changes added to commit (use "git add" and/or "git commit -a")
macs-MacBook-Air:deployment mac$ git pull
Already up-to-date.
macs-MacBook-Air:deployment mac$ git commit -am "move on-premise env from github to wiki"
[master 5e1c68a] move on-premise env from github to wiki
 9 files changed, 9 insertions(+), 343 deletions(-)
 delete mode 100644 cmd/deployment/on_premise/on_premise_blanver_prod.sh
 delete mode 100644 cmd/deployment/on_premise/on_premise_blanver_test.sh
 delete mode 100644 cmd/deployment/on_premise/on_premise_bradesco_redhat_prod.sh
 delete mode 100644 cmd/deployment/on_premise/on_premise_bradesco_redhat_test.sh
 delete mode 100644 cmd/deployment/on_premise/on_premise_brazil_insurance_prod.sh
 delete mode 100644 cmd/deployment/on_premise/on_premise_brazil_insurance_test.sh
 delete mode 100644 cmd/deployment/on_premise/on_premise_resource_prod.sh
 mode change 100644 => 100755 cookbooks/all-in-one/.kitchen.yml
#+END_EXAMPLE
** SSH common problem
*** Can't ssh: ~/.ssh/id_rsa.pub doesn't match /root/.ssh/authorized_keys
*** How to update local key pair of id_rsa.pub and id_rsa
*** ~/.ssh/known_hosts is changed, thus ssh give some error
*** ssh to the machine need VPN

* #  --8<-------------------------- separator ------------------------>8--
* DevOps interview Questions
** CI: Speed up the code build logic
** backup: what if transfering backup set fails
** monitoring: how to do GUI simulated test
** configuration management tool
** ruby skills
** linux: service tomcat7 status: initscript difference between upstart, initscript, systemd
** linux: how to change dameon process to service
** linux: write linux debian and rpm packages
** #  --8<-------------------------- separator ------------------------>8--
** bash: sed
From string of "a=1, b=2, c = 3", get value of b.
** bash: When scripts fails, how trap exit
** #  --8<-------------------------- separator ------------------------>8--
** toolkits: Jenkins, nagios, chef
** Any questions for me?
* DevOps Principle
** DONE Principle: don't use anything specific to your name: like denny git branch; denny public repo
   CLOSED: [2015-07-22 Wed 13:59]
* [#A] Principle to Track issues and learn from history           :IMPORTANT:
** [#A] Principle: File tickets for any major issue of prod env, group them as subtask of one ticket
http://totvslab.atlassian.net/browse/CLOUDPASS-6890
CP-6890: On Demand OPS Support In 1.4.4

http://totvslab.atlassian.net/browse/CLOUDPASS-6946
CP-6946: On Demand OPS Support In 1.4.5
** Principle: Track every maintaince record for prod env
- What's the change, bug list, what unexpected issue happened

https://totvslab.atlassian.net/wiki/pages/viewpage.action?pageId=48463913
Changeset for Upgrading/Patching prod env

https://totvslab.atlassian.net/wiki/pages/viewpage.action?pageId=50167890
Maintenance History Of All Enterprise Identity Envs.
** Principle: confirm change with developers each time
*** TODO make sure chef has updated neo4j configuration
#+BEGIN_EXAMPLE
[2/5/15, 12:02:27 PM] denny: Just checked psfluigidentity, which is upgraded by chef last night.
[2/5/15, 12:02:32 PM] denny: It’s done indeed.

root@fluig-id-dev-03:/opt/neo4j-server/conf# grep -C 3 'cache_type=none' /opt/neo4j-server/conf -r
<eo4j-server/conf# grep -C 3 'cache_type=none' /opt/neo4j-server/conf -r
/opt/neo4j-server/conf/neo4j.properties-remote_shell_port=1337
/opt/neo4j-server/conf/neo4j.properties-
/opt/neo4j-server/conf/neo4j.properties-# change internal cache type
/opt/neo4j-server/conf/neo4j.properties:#cache_type=none
[2/5/15, 12:02:43 PM] denny: Let’s double confirm in qafluigidentity, after the push
[2/5/15, 12:02:54 PM] denny: I mean Suresh’s upgrade
#+END_EXAMPLE
** File a story for routine task: put effort in measurable goals
** TODO [#A] Make invisible work visible.
Make invisible work visible.

Record what you and your colleagues do to support cross-functional
collaboration. If members of the dev and ops teams work together to
solve a problem in the development environment, make sure to record
and recognize what made that possible: an ops colleague taking an
extra on-call shift, or an assistant ordering food for a working
session. These are non-trivial contributions, and may be required for
successful collaboration.
** TODO File ticket for the special use case
#+BEGIN_EXAMPLE
[11/26/14, 12:31:46 PM] denny: denny added John Kaplan, Shivang to this conversation
[11/26/14, 12:32:12 PM] denny: Hi Shivang, same question: why ad won’t work on redhat on-premise env?

Because it’s self signed?
[11/26/14, 12:40:33 PM] Shivang: because the company domain name
[11/26/14, 12:40:37 PM] Shivang: is probably not set correctly
[11/26/14, 12:40:40 PM] Shivang: when activating the company
[11/26/14, 12:40:51 PM] Shivang: did you ask the customer what their VM is going to be recognized as
[11/26/14, 12:40:52 PM] Shivang: inside the
[11/26/14, 12:41:00 PM] Shivang: network before putting the company domain ?
[11/26/14, 12:41:20 PM] John Kaplan: Shivang is this a general VM issue, or particular to this install?
[11/26/14, 12:43:12 PM] Shivang: this problem was there with clayton as well
[11/26/14, 12:43:20 PM] Shivang: but no one really go tback to me as to what we did for that solution
[11/26/14, 12:43:43 PM] Shivang: and this will keep happening till the time we don't get the information from the customer BEFORE we start deploying on-premises
[11/26/14, 12:46:22 PM] Shivang: anyways .. we will see what happens
[11/26/14, 12:46:29 PM] Shivang: if they complain AD doesn't work
[11/26/14, 12:46:33 PM] Shivang: we get to it when we get to ti
[11/26/14, 12:52:10 PM] denny: Do you mean the info we used to register the company registration is inaccurate?
[11/26/14, 12:52:24 PM] Shivang: possible
[11/26/14, 12:52:34 PM] Shivang: what did we put in the company domain field?
[11/26/14, 12:53:00 PM] denny: John, would you ask shivang to help to review the info we used to create that company?
[11/26/14, 12:53:38 PM] Shivang: normally it shouldn't come from john .. it should come from the company admin .. the person who is going to install the VM on customer site
[11/26/14, 12:53:39 PM] denny: If it's wrong, we can create a new one with right info. And I will do the registration again.
[11/26/14, 12:53:51 PM] Shivang: what are they going to call the domain
[11/26/14, 12:53:57 PM] Shivang: inside the copany network?
[11/26/14, 12:54:02 PM] John Kaplan: oh we don’t get the domain name from SaaS?
[11/26/14, 12:54:06 PM] Shivang: that should be the name of the domain
[11/26/14, 12:54:07 PM] Shivang: no
[11/26/14, 12:54:27 PM] Shivang: if they ever open their network .. their domain names will have conflicts
[11/26/14, 12:54:40 PM] John Kaplan: If we just use the on prem domain it should work, no?
[11/26/14, 12:54:47 PM] Shivang: company domain is the name of the VM as to hwo its going to be recognized INSIDE the network
[11/26/14, 12:55:00 PM] John Kaplan: ah
[11/26/14, 2:31:52 PM] Shivang: someone noting down all these usecases?
[11/26/14, 2:32:03 PM] Shivang: of what customers CAN and WILL do for on premises deplouyment?
[11/26/14, 2:32:14 PM] Shivang: so that we can add them to our test cases?
[11/26/14, 2:33:44 PM] John Kaplan: I have not been tracking the deployment issues
[11/26/14, 2:36:19 PM] Shivang: no not deployment
[11/26/14, 2:36:29 PM] Shivang: these are the usecases that customers will try
[11/26/14, 2:36:31 PM] Shivang: for example
[11/26/14, 2:36:33 PM] denny: Yes, agree,, shivang. their use case is quite different from normal one. This result in many new question, which we didn't take into consideration during developing and test
[11/26/14, 2:36:34 PM] Shivang: moving VMs
[11/26/14, 2:37:30 PM] Shivang: changing ips
[11/26/14, 2:37:40 PM] Shivang: proxy
[11/26/14, 2:37:45 PM] Shivang: not opening ports
[11/26/14, 2:37:55 PM] Shivang: strangling fluig identity deployment
[11/26/14, 2:38:01 PM] Shivang: all these test cases
[11/26/14, 2:40:20 PM] John Kaplan: yeah I think we did some code upgrades to try to account for deployment strangling, but not for post deploy options
[11/26/14, 2:42:36 PM] John Kaplan: Did we want to restart and try the mail server settings, or are there other changes to take care of?
[11/26/14, 2:42:40 PM] Shivang: yes .. i think we should note these usecases somewhere atleast
[11/26/14, 2:42:59 PM] Shivang: and circle back to them as either dev requriements OR on-premises prereqs from customers
[11/26/14, 2:43:45 PM] John Kaplan: I have just to topics you mentioned here saved.
[11/26/14, 2:47:31 PM] Shivang: that should be good enogu for now
[11/26/14, 2:47:42 PM] John Kaplan: ok
#+END_EXAMPLE
* [#A] [Process] Refine work process
** [#A] Principle: spend 5 min before take off everyday, review all your today's skype and email
- Now what's blocked on me, then improve it.
- Identity what's tasks with high value and low value
- How to make things better
** [#A] Avoid overcommit: don't reply messages at nights          :IMPORTANT:
*** TODO Avoid working at nights
#+BEGIN_EXAMPLE
[1/20/15, 8:53:38 PM] denny: Could anyone narrow down which jar?
[1/20/15, 8:53:54 PM] denny: front end engineer?
[1/20/15, 8:53:55 PM] Shivang: i am about to check # 1 right now (pushed a small code change)
[1/20/15, 8:54:20 PM] Shivang: if it still doesn't fix than it's probably # 2
[1/20/15, 8:54:29 PM] Shivang: i will ping you as soon as i can test it ..
[1/20/15, 8:55:31 PM] denny: Yes, let me know.

I will check this issue tomorrow morning.

Right now I’m working on something else, and getting late here.
[1/20/15, 8:55:38 PM] Shivang: no problem
[1/20/15, 8:55:39 PM] Shivang: thanks
[1/20/15, 8:55:56 PM] denny: BTW, how is everything going within the LAB
#+END_EXAMPLE
** [#A] Principle: A successful Devops implementation will measure everything which matters :IMPORTANT:
https://www.chef.io/blog/2010/07/16/what-devops-means-to-me/
Measurement
If you can’t measure, you can’t improve.  A successful Devops implementation will measure everything it can as often as it can… performance metrics, process metrics, and even people metrics.
** Principle: 避免好大喜功的内心倾向
** #  --8<-------------------------- separator ------------------------>8--
** TODO Identity what takes your resource, how to prevent?
** TODO People ask for questions of env parameters
#+BEGIN_EXAMPLE
[2/4/15, 4:22:13 PM] Suresh Sathyanarayan: The selenium script is running on that machine right ?
[2/4/15, 4:22:48 PM] denny: You mean the selenium script of nagios check, or the jenkins run?
[2/4/15, 4:22:55 PM] Suresh Sathyanarayan: the jenkins run
[2/4/15, 4:23:01 PM] denny: Wait 5 min
[2/4/15, 4:23:06 PM] Suresh Sathyanarayan: ok
[2/4/15, 4:23:38 PM] denny: root/Totvs123abc
[2/4/15, 4:23:48 PM] Suresh Sathyanarayan: ok let me ry
[2/4/15, 4:23:51 PM] Suresh Sathyanarayan: *try
[2/4/15, 4:24:37 PM] Suresh Sathyanarayan: ok i am in. now where would i find the selenium script
[2/4/15, 4:24:38 PM] Suresh Sathyanarayan: ?
[2/4/15, 4:25:09 PM] denny: /var/lib/jenkins/smoke_test/code
#+END_EXAMPLE
** TODO People ask me to get a file
** Idetity useless communication and avoid it by better way
*** wiki for env support, to avoid TOI style questions
https://totvslab.atlassian.net/wiki/display/TECH/Fluig+Env+List
#+BEGIN_EXAMPLE
Skip to content
Skip to breadcrumbs
Skip to header menu
Skip to action menu
Skip to quick search
Linked Applications
Confluence
Spaces
People
 Create
Quick Search
0


TechOps
Configure
 Edit  Watch  Share
Pages  TechOps Home  Environments
Skip to end of banner
Go to start of banner
Fluig Env List
Skip to end of metadata
Created by Denny Zhang, last modified just a moment ago Go to start of metadata
Summary
Link
Server page for Prod env of Fluig Identity	BR-FI-SERVERS: Prod env
Server page for Dev/QA	Fluig Testbed Env
Server page In Digital Ocean	Fluig DigitialOcean Env
Server page for Amazon AWS	Fluig Amazon AWS Env
FAQ:
Question: For a given cluster env, how to find out the IP where a specific service component is deployed? Say where is couchbase deployed for the qafluigidentity env?
Answer: From "Env List" wiki above, we can easily locate the info for the given env.
Then check "COMPONENTS" column for how different services are deployed.  "EXTERNAL-IP/INTERNAL-IP" column tells the IP.

Question: How to add my ssh key, so that I can ssh to the machines?
Answer: Anyone who can login that machine is capable to do that.
Get your ssh private of my computer, and append it to ~/.ssh/authorized_keys in the server. Here is an example.
   echo "ssh-rsa AAAAB3NzaC... ...Gyurx4kxxMb45yzuKCzQjgI3F denny.zhang@totvs.com" >> ~/.ssh/authorized_keys
Question: How can I login to check log files for a given machine
Answer: All machines come up with a readonly OS user, thus people can login and check if necessary.
To get the password of QA env, please turn to QA lead. For prod env, please turn to DevOps Lead.

Question: Where are the log files? How I can check service status?
Answer: Please check the trouble shooting wiki: How To Trouble Shooting All-in-one Identity Envs

Question: How to do ssh tunnel?
           Answer: This question rise in this scenario: e.g, firewall don't allow request to port 8091 of QA1B env, which is couchbase webUI.
             But I need to access that webUI, to check or modify some data. Thus we need ssh tunnel, to map server's port to my local port by ssh protocol.
             First make sure, you can "ssh root@qa1b" with no problem. Then run this: "ssh -N -p 22 -f root@qa1b -L 8091:localhost:8091 -n /bin/bash".
             Now when you visit: http://localhost:8091, you're actually visiting http://qa1b:8091
             ssh tunnel is a common technology, google it to learn more.
Question: Why I can't ssh servers?
For the security concern, any critical machine is configured to only allow remote ssh login from certain range of IP address. So we will need VPN first.
Some QA test machines in public cloud, say digital ocean or EC2, are not that critical. Thus they come up with public IP, and people can't ssh without VPN.

Question: I can't ping a given machine, so the server is down?
The answer is maybe. Some machines has configured to disallowed ICMP request, thus ping is prohibited.
But mostly ssh request is allowed, if you have enough privilege. So try "ssh $username@$vm_ip" or "telnet $vm_ip 22", to double confirm first.
LikeBe the first to like this
No labels Edit Labels
User icon: Denny
Write a comment…
Powered by Atlassian | Terms of Use | Answers | Maintenance Schedule

#+END_EXAMPLE
*** Mark skype status as "Away": when people ping you for non-critical questions or things should go to you
** TODO [#A] Track meantime of error recovery or system push
- It's better done automatically
** TODO mail: Stop sending out Denny's Weekly Status Update        :noexport:
[[gnus:mail.misc#EF9859611DA81140B2B29B02EC8AD6EAFB1419@helios.mex01.local][Email from Denny Zhang (Fri, 13 Feb 2015 13:36:47 -0600): Stop sending out Denny's Weekl]]
#+begin_example
From: Denny Zhang <denny.zhang@totvs.com>
Subject: Stop sending out Denny's Weekly Status Update
To: Kung Wang <kung.wang@totvs.com>, Vicente Goetten <goetten@totvs.com>
CC: John Kaplan <john.kaplan@totvs.com>, Lucas Vinicius Schiochet
        <lucas.schiochet@fluig.com>, Denny Zhang <denny.zhang@totvs.com>
Date: Fri, 13 Feb 2015 13:36:47 -0600

Hi Guys

Just let you know. I will stop sending out the weekly status update email, after discussing with
Kung.

The alternative would be:
- Update as much as possible in JIRA system
- Send out monthly work review for lesson learned and improvement points from my side.

I have a habit of diary everyday, so I will keep logging my daily work locally.
Just don't want to spam you guys' email inbox.

Any more suggestions to my work, do let me know.

Cheers,
Denny
---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Sunday, February 08, 2015 9:03 PM
To: Kung Wang; Vicente Goetten
Cc: John Kaplan; Lucas Vinicius Schiochet
Subject: RE: Denny's Weekly Status Update

Hi all

Enclose is my weekly update. Archive can be found in below:
https://totvslab.atlassian.net/wiki/display/~Denny/Denny%27s+Weekly+Status+Report

This week's review:
- [40%] Ops effort
  Upgrade 3 critical envs 3 times
  Handle/Report issues found
- [30%] Dev effort
  Chef update for 1.4.4: hornetq conf, ssversion
  CP-6807: deploy and data backup/restore for new customerfi
- [20%] Knowledge transfer
  Enterprise upgrade workshop to Lucas for Blanver
  Doc improvement for backup, nagios and apache certificate.
- [10%] research for related technology
  Chef testkitchen
  ELK: logstash+elastic search+kibana.

Next week's plan:
- Knowledge transfer to BR DevOps
- My tickets of 1.4.5 sprint

Regards,
Denny
---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Monday, February 02, 2015 9:39 AM
To: Kung Wang; Vicente Goetten
Cc: John Kaplan; Lucas Vinicius Schiochet; Denny Zhang
Subject: RE: Denny's Weekly Status Update

Hi all

Enclose is my weekly update. Archive can be found in below:
https://totvslab.atlassian.net/wiki/display/~Denny/Denny%27s+Weekly+Status+Report

This week's review:
- [40%] Documentation
  CP-6755 Documentation for all critical actions of day-to-day support.
- [40%] Ops effort
  CP-6807: coorindate for customerfi upgrade, and deploy new customerfi cluster
  CP-6731: Need to log rotate huge files under in /data/fluigidentity-logs
  CP-6681: On-demand support for enterprise deployment solution
  Change chef for Identity-1.4.4 and test cluster deployment
- [20%] Adhoc support
  Support misc request/questions for people from Skype.
  Explore related technical: chef coding style check; chef supermarket

Next week's plan:
- On-demand upgrade for qafluigidentity/customerfi/psfliugidentity of 1.4.4
- On-demand update for wiki
- Migrate data of customerfi to new env
- Explore technology of: chef kitchen, chef rspec, log analysis, etc.

Regards,
Denny

---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Monday, January 19, 2015 8:32 AM
To: Kung Wang; Vicente Goetten
Cc: John Kaplan; Denny Zhang
Subject: RE: Denny's Weekly Status Update

Hi all

Enclose is my weekly update. Archive can be found in below:
https://totvslab.atlassian.net/wiki/display/~Denny/Denny%27s+Weekly+Status+Report

This week's review:
- [50%] Env Support
  Upgrade 3 prod envs to patched 1.4.3 three times
  Issue support: search service fail to restart;
- [30%] Coding and bug fixing
  TECH-75: nagios avoid false alarm of checking log
   CP-6682: auto assign company racagent
- [20%] Doc and training
  wiki for all envs and VMs in digital ocean, EC2 and data center
  Knowledge transfer and live demo to Lucas for Identity Enterprise deployment

Next week's plan:
- Document the common procedure for upgrade
- Review env issues/escalations for the past 6 months
- Chef bug fixing and improvement.

Regards,
Denny
---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Sunday, January 11, 2015 7:39 PM
To: Kung Wang; Vicente Goetten
Cc: John Kaplan; Denny Zhang
Subject: RE: Denny's Weekly Status Update

Hi all

Enclose is my weekly update. Archive can be found in below:
https://totvslab.atlassian.net/wiki/display/~Denny/Denny%27s+Weekly+Status+Report

This week's review:
- [30%] Upgrade prod env/customerfi/psfluigidentity to 1.4.3. And issue supporting.
  network issue, search high CPU, rmi fd
- [30%] On-premise testing, bug fixing and provide internal technical doc
- [20%] Brazil Insurance on-premise support: upgrade to 1.4.2.1; Test env deployment
- [20%] QA env issue support, chef improvement, etc.

Next week's plan:
- On-premise solution improvement
- Chef improvement based on various OPS requests.
- Misc on-demand tasks

Regards,
Denny
---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Sunday, January 04, 2015 11:50 PM
To: Kung Wang; Vicente Goetten
Cc: John Kaplan
Subject: RE: Denny's Weekly Status Update

Hi all

Enclose is my weekly update. Archive can be found in below:
https://totvslab.atlassian.net/wiki/display/~Denny/Denny%27s+Weekly+Status+Report

This week's review:

Worked for 1 day(Friday), 2 days shift for Thanks giving days(Monday/Tuesday),
1 day off (Wednesday), 1 national holiday(Thursday)

Fixed/Resolved below on Friday:
- TECH-75: collect all noticable exceptions in all critical logfiles
- JIRA-6664: automate the change of mix panel for prod env
- JIRA-6676: Discuss prod env issue: RMI in app02 is opening too many file handlers
- Misc communications and tasks.

Next week's plan:
- Coordinate to finish on-premise solution
- Upgrade all prod envs for the new release
- Resolve/Coordinate to resolve all opening issues on various prod envs.
- Misc on-demands

Regards,
Denny
---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Sunday, December 28, 2014 9:37 PM
To: Kung Wang; Vicente Goetten
Cc: John Kaplan; Denny Zhang
Subject: RE: Denny's Weekly Status Update

Hi all

Enclose is my weekly update. Archive can be found in below:
https://totvslab.atlassian.net/wiki/display/~Denny/Denny%27s+Weekly+Status+Report

This week's review:
- [50% Nagios Improvement By Chef]
  Critical log files of all related services are monitored closely
  Monitor count of opened file handlers for all critical services
  Monitor neo4j services in nagios

- [40% Chef Development]
  JIRA 6571: On-premise deploy, given the OS installed
  Tech-71: Update java lib problem by cksum.
  Tech-47: Refactor/Rewrite initscript of all services

- [10% Misc]
  Update and discussion for Brazil Insurance; BR data team communication; Routine check of prod
envs, etc.

Next week's plan:
- On Vacation with limited Internet

Regards,
Denny
---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Monday, December 22, 2014 10:35 AM
To: Kung Wang; Vicente Goetten
Cc: John Kaplan; Denny Zhang
Subject: RE: Denny's Weekly Status Update

Hi all

Enclose is my weekly update. Archive can be found in below:
https://totvslab.atlassian.net/wiki/display/~Denny/Denny%27s+Weekly+Status+Report

This week's review:
- [50% Env Support]
  Upgrade 2 Bradesco envs from 1.4 to 1.4.2; then to 1.4.2.1
  Upgrade prod env from 1.4.2 to 1.4.2.1
  Upgrade customerfi/psfluigidentity from 1.4.1 to 1.4.2.1

- [30% Prod env Escalation]
  RMI using exclusive network file handler
  Neo4j machine run out of disk, which result in whole system down.
  Hornetq configuration hot fix

- [20% Misc]
  Chef développement for 1.4.2.1 change.
  Interview BR DevOps
  Nagios improvement for fd checks, process resource utilization, etc.

Next week's plan:
- JIRA 6571/6572: Chef change to support On-premise as a solution
- On-demand tasks and escalation for 3 prod envs and 2 on-premise envs.
- Nagios improvement: log file check

Note: During Christmas, I will take some days off. Detail will be send out in another email.

Regards,
Denny
---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Sunday, December 14, 2014 10:44 PM
To: Kung Wang; Vicente Goetten
Cc: John Kaplan; Denny Zhang
Subject: RE: Denny's Weekly Status Update

Hi all

Enclose is my weekly update. Archive can be found in below:
https://totvslab.atlassian.net/wiki/display/~Denny/Denny%27s+Weekly+Status+Report

This week's review:
- [50% Chef]  New logic and bug fixing
  search.yml schema change for 1.4.2
  TECH-69: neo4j avoid being downloaded over and over again
  JIRA 6549: Configure 404 error page

- [20% Prod env Support]
  Upgrade env from 1.41. to 1.4.2
  Tech-61: Mirgate nagios of prod env to the nagios of chef

- [30% Misc]
  Tech-68 Enabled daily remote backup for all prod envs
  On-premise support of document and demo setup

Next week's plan:
- Enable mail sending for critical failure of Jenkins, backup, misc
- Bug fixing of Chef code: http proxy support, package updating
- Upgrade all prod envs and on-premise envs to 1.4.2, on demand

Regards,
Denny
---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Monday, December 08, 2014 12:31 AM
To: Kung Wang; Vicente Goetten
Cc: John Kaplan; Denny Zhang
Subject: RE: Denny's Weekly Status Update

Hi all

Enclose is my weekly update. Archive can be found in below:
https://totvslab.atlassian.net/wiki/display/~Denny/Denny%27s+Weekly+Status+Report

This week's review:
- [40% Redhat On-premise]  Support test env Bradesco and Deploy prod env
  Coordinate/Resolve issues: email sending problem; http proxy problems
  Chef improvement to work with limited network
- [40% Prod env Support]
  Upgrade prod env from 1.4 to 1.4.1
  Chef bug fixing and improvements for problems found
  Support customerfi and psfluigidentity
- [20% Backup logic] Improvement backup logic, Show on-premise Demo, etc.

Next week's plan:
- TECH-63: Workout backup and restore plan, by simulating the same env of prod env in digital ocean
- TECH-68: Remote copy for critical backup set on different env
- TECH-61: Upgrade existing nagios to the one of chef and bug fixing

Regards,
Denny
---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Sunday, November 30, 2014 9:28 PM
To: Kung Wang; Vicente Goetten
Cc: John Kaplan; Shivang Shah; Reinaldo Oliveira Machado Junior; Denny Zhang
Subject: RE: Denny's Weekly Status Update

Hi all

Enclose is my weekly update. Archive can be found in below:
https://totvslab.atlassian.net/wiki/display/~Denny/Denny%27s+Weekly+Status+Report

This week's review:
- [40% Redhat On-premise]  Deploy redhat on-premise and handling issue escalated
  Things done:
        - Preparation: Identity firewall rules, and negotiate with customer to register redhat
license.
       - Installation: Deploy by chef, after working around restricted firewall
       - Registration: company activating fail, due to java program doesn't recognize http proxy
       - Bug fixing: RMI lock issue
        - Bug fixing: Java programs of Fluig identity doesn't recognize http proxy: CLOUDPASS-6533
        - Bug fixing: neo4j was listening on 127.0.0.1:7474, instead of *:7474
        - Bug fixing: external call fails, by working around couch base
  Open issues:
       - Email sending fails: First need support engineer to test customer's mail server with "auth
on".
         Later we may need to change code to use customers' mail server.
       - Application sync fail: Not sure about the root cause, and where we stand
        - rest 404 exception:  Not sure about the root cause, and where we stand
        - Bug: initscript of tomcat has bugs on redhat, it may result in multiple tomcat instances.
I'm following on this.
        - Not sure how far we're for the whole integration process.

- [20% Prod Env Upgrade] Migrate prod env to be managed by Chef finnally
  Test and simulate the change; Perform the migration; Upgrade nagios system of prod env

- [30% customerfi/psfluigidentity Env] Upgrade envs to 1.4.1, and support escalated issues.
  Things done: Upgrade to 1.4.1; Neo4j upgrade; known issue of RMI lock;

  Open issues: company sync fail in customer side; company group not found in neo4j; rest service
report function not found.

Next week's plan:
- Redhat On-premise env Support
- customerfi/psfluigidentity env Support
- Upgrade prod env to 1.4.1

Problems highlighted:
- Need a project contact to follow issues of redhat on-premise for TOTVS Lab's side.
  Currently people in redhat on-premise thread seems to see me as the contact of this project.
  But to answer or dig deeper for most issues escalated, we need understanding of the features and
backend logic.
  Those are missing for me, which result in my low productivities for this support.

- Identity-1.4.1 looks like not stable enough, from the experience of customerfi/psfluigidentity/
redhat on-premise.

Regards,
Denny
---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Sunday, November 16, 2014 3:03 PM
To: Kung Wang; Vicente Goetten
Cc: John Kaplan
Subject: RE: Denny's Weekly Status Update

Hi all

Enclose is my weekly update. Archive can be found in below:
https://totvslab.atlassian.net/wiki/display/~Denny/Denny%27s+Weekly+Status+Report

This week's review:
- [Backup] Make sure prod env and all envs managed by chef are properly backup, as we discussed
- [Deployment Logic] Handle deployment refactor logic.
  Major parts are Shivang's cleanup branch and Kung's neo4j
- [Env Support] Bug fixing and env support
  AWS dns configuration issues; Jenkins bug for racagent;

Next week's plan:
- Redhat On-premise deployment
- Identity-1.4.1 branch support and bug fixing
- Upgrade prod env to be managed by chef
- [Maybe] Upgrade prod env to Identity-1.4.1

Regards,
Denny
---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Monday, November 10, 2014 12:42 AM
To: Kung Wang; Vicente Goetten
Cc: John Kaplan; Denny Zhang
Subject: RE: Denny's Weekly Status Update

Hi all

Enclose is my weekly update. Archive can be found in below:
https://totvslab.atlassian.net/wiki/display/~Denny/Denny%27s+Weekly+Status+Report

This week's review:
- [80% -- 100% QA env support]
   Provide a one-click jenkins job to upgrade all QA envs for any given branch name.
   Migrate QA env(psfluigidentity/customerfi) to be managed by chef, and handle escalated issues
- [50% -- 90% Backup logic]
  Enable auto backup logic for all QA envs.
  Improve backup logic, and prepare to enable new backup logic for prod env.
- 2 Days chef training on SFO
- [0% -- 80% Handle new deployment logic of master branch]
  Implemented new logic and verified multiple times in cluster deployment test
Next week's plan:
- Enable new backup logic for prod env
- Migrate prod env and QA1B to be managed by chef

Regards,
Denny
---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Sunday, November 02, 2014 4:03 PM
To: Kung Wang; Vicente Goetten
Cc: John Kaplan; Denny Zhang
Subject: RE: Denny's Weekly Status Update

Hi all

Enclose is my weekly update. Archive can be found in below:
https://totvslab.atlassian.net/wiki/display/~Denny/Denny%27s+Weekly+Status+Report

This week's review:
- [40% Env Support]
   Prod env: Upgrade prod env and support escalated issues
   On-premise env: support 2 customer cases of on-premise escalated issues.
   QA env: On-demand upgrade and trouble shooting for QA env.
- [60% ] fluig-cluster: Improvement for cluster deployment by chef.
  It works and verified in multiple tests. Need some time to polish that.
  Hopefully, it can be delivered as a solution next week.
Next week's plan:
- Chef training and on site visit
- Provide QA a jenkins job, which can deploy and upgrade QA env easily
- Migrate existing env to be managed by Chef gradually
- Support escalated issues for different envs.

Regards,
Denny
---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Sunday, October 26, 2014 8:06 AM
To: Kung Wang; Vicente Goetten
Cc: Denny Zhang; John Kaplan
Subject: RE: Denny's Weekly Status Update

Hi all

Enclose is my weekly update. Archive can be found in below:
https://totvslab.atlassian.net/wiki/display/~Denny/Denny%27s+Weekly+Status+Report

This week's review:
- [Env Support] Maintain QA env.
  Redeploy the cluster by Chef;  Perform upgrade on demand;  Fix several notorious problem like
keystore corrupted, mismatched version of smartsync, etc
- [0% - 80% ] fluig-cluster: Dynamically configure nagios checks.
  Now we're capable to deploy fluig cluster by chef. It shall take another one or two week to
stabilize it.
- [70% - 100%]  fluig-backup: Enable proper backup for all envs managed by chef.
Next week's plan:
- Bug fix and improvement for fluig-cluster
- Enable fluig cluster to be properly monitored
- Migrate existing env to be managed by Chef gradually
- Support escalated issues for different envs.

Regards,
Denny
---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Saturday, October 18, 2014 11:43 PM
To: Kung Wang; Vicente Goetten
Cc: Denny Zhang
Subject: RE: Denny's Weekly Status Update

Hi all

Enclose is my weekly update. Archive can be found in below:
https://totvslab.atlassian.net/wiki/display/~Denny/Denny%27s+Weekly+Status+Report

This week's review:
- Knowledge Transfer from Bill, and support internal request
- [0% - 70%]  fluig-backup: Rewrite backup logic for all fluig services.
  Need more tests, especially for multi-node deployment env. And apply new process to prod env.
- [70% - 90%] Jenkins improvement: Support more test cases and bug fixing.
  Currently develop cycle is done, need support John/Suresh to use new process.
- [40% - 70% ] fluig-nagios: Dynamically configure nagios checks.
  Currently all-in-one env works, need support multi-node deployment.
Next week's plan:
- Understand details info/knowledge to support all QA and prod env.
- Enable Chef to support multi-node deployment

Regards,
Denny
---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Sunday, October 12, 2014 10:44 AM
To: Kung Wang; Vicente Goetten
Cc: Bill Nguyen; Denny Zhang
Subject: RE: Denny's Weekly Status Update

Hi all

Enclose is my weekly update. Archive can be found in below:
https://totvslab.atlassian.net/wiki/display/~Denny/Denny%27s+Weekly+Status+Report

This week's review:
- [70% -- 100%] VMApp project(CentOS).
- [60% -- 80%] VMApp project(Redhat).
  Missing part is bootstrap Redhat to deploy Reinaldo's webapp.
- [60% - 70%] Jenkins improvement: Integrate smoke test into Jenkins.
- [0% - 40%] fluig-nagios: enable all envs to be properly monitored by nagios..
Next week's plan:
- Backup: enable all envs to be properly backup by Chef.
- Finish VMApp Project for Redhat
- Keep improving Jenkins

Regards,
Denny
---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Monday, October 06, 2014 9:04 AM
To: Kung Wang; Vicente Goetten
Cc: Bill Nguyen
Subject: RE: Denny's Weekly Status Update

Hi all

Enclose is my weekly update. Archive can be found in below:
https://totvslab.atlassian.net/wiki/display/~Denny/Denny%27s+Weekly+Status+Report

This week's review:
- [90% -- 100%] VMApp project(ubuntu): Phase #1 is done.
  There're several future improvements points tracked in phase #2
- [30% -- 60%] Jenkins improvement: Fundamental parts are ready
  With only one command, users can deploy fluig jenkins.
  With only one click, users can build any branch and deploy it in all-in-one env.
- [60% -- 70%] VMApp Project(Redhat/CentOS)
  Some improvement and bug fix.
  Next step is to bootstrap Redhat VM, improve liveCD of CentOS.
Next week's plan:
- Finish VMApp Project for Redhat/CentOS
- Keep improving Jenkins

Regards,
Denny
---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Sunday, September 28, 2014 11:12 PM
To: Kung Wang; Vicente Goetten
Cc: Bill Nguyen; Don Hu; Reinaldo Oliveira Machado Junior
Subject: RE: [09/13] Denny's Weekly Status Update

Hi all

Enclose is my weekly update. Archive can be found in below:
https://totvslab.atlassian.net/wiki/display/~Denny/Denny%27s+Weekly+Status+Report

This week's review:
- [60% -- 90%] VMApp project(ubuntu)
  Hacked integration test has passed. Some known issues and more tests are needed.
- [0% -- 60%] VMApp Project(Redhat/CentOS)
  Chef can deploy all-in-one env on Redhat/CentOS;  LiveCD of CentOS is done.
- [0% -- 30%] Jenkins improvement
  To deploy and config fluig jenkins system, only need to run one command.
  Jenkins can build different code branches now.

Next week's plan:
- Finish integration test of VMApp Project of Ubuntu
- Finish VMApp project for CentOS
- Keep working on Jenkins improvement.

Need for discussion:
- To build Redhat LiveCD/image, need subscribe to Rehat service or pay some fee. Need some research
on this.

Regards,
Denny

---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Saturday, September 13, 2014 3:36 PM
To: Kung Wang; Vicente Goetten
Cc: Bill Nguyen; Don Hu; Denny Zhang
Subject: [09/13] Denny's Weekly Status Update

Hi all

Enclose is my weekly update. Archive can be found in below:
https://totvslab.atlassian.net/wiki/display/~Denny/Denny%27s+Weekly+Status+Report

This week's review:
- [70%] Finish original goal of Chef Ubuntu Deployment
- [10%] Supporting Issues of QA1B/Prod env
- [20%] Adhoc tasks: Code review; Redhat chef

Next week's plan:
- Chef Redhat deployment or VMApp Project?

Regards,
Denny

#+end_example
** [#A] File a ticket for any new escalation issue: Think how to detect it automatically next time
** TODO [#A] Detect visibility of low efficiency or potential problems
http://blog.flux7.com/blogs/devops/devops-saves-healthcaregov
The goal of DevOps is to gain greater visibility, and earlier
visibility, into the innards of software development and easing the
communication of that information to the parties involved. With the
launch of healthcare.gov, we saw the complete lack of communication
and visibility and then, again, we see how the problems were fixed by
providing tremendous amounts of visibility.
** TODO [#A] Ask the team what's there tedious manual steps everyday?
** [#A] Communication: What part I'm doing is too pushing??
** TODO People from different sites, can't ssh to the machine
#+BEGIN_EXAMPLE
[3/10/15, 3:15:12 PM] denny: Would you like to check the nagios server for 4 critical envs?
[3/10/15, 3:16:04 PM] denny: nagios http://172.20.16.13/nagios3/ nagiosadmin/hi2.Nagios6
[3/10/15, 3:16:49 PM] Meken Santos Gonçalves: haven't access to http://172.20.16.13/nagios3/
[3/10/15, 3:17:15 PM] Malucelli: for me it's ok
[3/10/15, 3:17:33 PM] denny: We need VPN to login all critical env.
[3/10/15, 3:17:38 PM] denny: Do you have that, Meken?
[3/10/15, 3:17:48 PM] Meken Santos Gonçalves: I don't have
[3/10/15, 3:18:01 PM] Meken Santos Gonçalves: what vpn do you Use?
[3/10/15, 3:18:13 PM] Meken Santos Gonçalves: vpn.totvs.com.br?
[3/10/15, 3:18:29 PM] denny: I’m using vpnusa.totvs.com.
[3/10/15, 3:18:35 PM] Meken Santos Gonçalves: ok
[3/10/15, 3:18:40 PM] Meken Santos Gonçalves: I don1t have
[3/10/15, 3:18:44 PM] Meken Santos Gonçalves: don't
[3/10/15, 3:18:54 PM] denny: Alex, do you have any sharing for how we can help Meken on this?
[3/10/15, 3:20:25 PM] Malucelli: I don't access any vpn, I guess there's a direct route for me
[3/10/15, 3:21:04 PM] denny: Yes, it looks so.

Meken can you ssh to any machine for below?
https://totvslab.atlassian.net/wiki/display/TECH/Prod+Envs+And+Critical+Identity+Envs
#+END_EXAMPLE
* [#A] [TroubleShooting] App layer problems
** Principle: 故障排除时先由快速简单的测试开始，尽量避免慢并复杂的测试; unit test should be fast
** #  --8<-------------------------- separator ------------------------>8--
** TODO neo4j exception
*** error log
#+BEGIN_EXAMPLE
[12/3/14, 9:23:14 AM] denny: Kung, just confirmed for neo4j log

1. All errors in /opt/neo4j-server/data/log/console.log
indicates:
      8:[03 Dec 2014;14:16:35.489] - [ERROR] [FluigUserBoImpl:79] - ensure uniqueKey for FluigUser in error: org.neo4j.graphdb.ConstraintViolationException: Unable to create CONSTRAINT ON ( fluiguser:FluigUser ) ASSERT fluiguser.uniqueKey IS UNIQUE:

2. All exceptions in /data/totvslabs/scim/neo4j/embedded/messages.log
indicates
root@fluig-id-messaging-01:/data/totvslabs/scim# tail -n 2000 /data/totvslabs/scim/neo4j/embedded/messages.log
< -n 2000 /data/totvslabs/scim/neo4j/embedded/messages.log
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_17]
	at java.lang.Thread.run(Thread.java:722) [na:1.7.0_17]
2014-12-03 14:09:46.897+0000 INFO  [o.n.k.i.a.i.IndexPopulationJob]: Index population started: [:FluigUser(uniqueKey) [provider: {key=lucene, version=1.0}]]
2014-12-03 14:09:54.277+0000 ERROR [o.n.k.i.a.i.IndexPopulationJob]: Failed to populate index: [:FluigUser(uniqueKey) [provider: {key=lucene, version=1.0}]]
org.neo4j.kernel.impl.nioneo.store.InvalidRecordException: DynamicRecord Not in use, blockId[1642342]
	at org.neo4j.kernel.impl.nioneo.store.AbstractDynamicStore.getRecord(AbstractDynamicStore.java:371) ~[neo4j-kernel-2.1.6.jar:2.1.6]
	at org.neo4j.kernel.impl.nioneo.store.AbstractDynamicStore.getLightRecords(AbstractDynamicStore.java:305) ~[neo4j-kernel-2.1.6.jar:2.1.6]
	at org.neo4j.kernel.impl.nioneo.store.PropertyStore.ensureHeavy(PropertyStore.java:303) ~[neo4j-kernel-2.1.6.jar:2.1.6]
	at org.neo4j.kernel.impl.nioneo.xa.NeoStoreIndexStoreView.valueOf(NeoStoreIndexStoreView.java:210) ~[neo4j-kernel-2.1.6.jar:2.1.6]
	at org.neo4j.kernel.impl.nioneo.xa.NeoStoreIndexStoreView.access$400(NeoStoreIndexStoreView.java:55) ~[neo4j-kernel-2.1.6.jar:2.1.6]
	at org.neo4j.kernel.impl.nioneo.xa.NeoStoreIndexStoreView$1.read(NeoStoreIndexStoreView.java:94) ~[neo4j-kernel-2.1.6.jar:2.1.6]
	at org.neo4j.kernel.impl.nioneo.xa.NeoStoreIndexStoreView$1.read(NeoStoreIndexStoreView.java:80) ~[neo4j-kernel-2.1.6.jar:2.1.6]
	at org.neo4j.kernel.impl.nioneo.xa.NeoStoreIndexStoreView$NodeStoreScan.run(NeoStoreIndexStoreView.java:330) ~[neo4j-kernel-2.1.6.jar:2.1.6]
	at org.neo4j.kernel.impl.api.index.IndexPopulationJob.indexAllNodes(IndexPopulationJob.java:212) ~[neo4j-kernel-2.1.6.jar:2.1.6]
	at org.neo4j.kernel.impl.api.index.IndexPopulationJob.run(IndexPopulationJob.java:107) ~[neo4j-kernel-2.1.6.jar:2.1.6]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_17]
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334) [na:1.7.0_17]
	at java.util.concurrent.FutureTask.run(FutureTask.java:166) [na:1.7.0_17]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_17]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_17]
	at java.lang.Thread.run(Thread.java:722) [na:1.7.0_17]
[12/3/14, 9:23:46 AM] kungchaowang: because the data corruption, so index failed to createroot@fluig-id-messaging-01:/data/totvslabs/scim# tail -n 2000 /data/totvslabs/scim/neo4j/embedded/messages.log
< -n 2000 /data/totvslabs/scim/neo4j/embedded/messages.log
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_17]
	at java.lang.Thread.run(Thread.java:722) [na:1.7.0_17]
2014-12-03 14:09:46.897+0000 INFO  [o.n.k.i.a.i.IndexPopulationJob]: Index population started: [:FluigUser(uniqueKey) [provider: {key=lucene, version=1.0}]]
2014-12-03 14:09:54.277+0000 ERROR [o.n.k.i.a.i.IndexPopulationJob]: Failed to populate index: [:FluigUser(uniqueKey) [provider: {key=lucene, version=1.0}]]
org.neo4j.kernel.impl.nioneo.store.InvalidRecordException: DynamicRecord Not in use, blockId[1642342]
	at org.neo4j.kernel.impl.nioneo.store.AbstractDynamicStore.getRecord(AbstractDynamicStore.java:371) ~[neo4j-kernel-2.1.6.jar:2.1.6]
	at org.neo4j.kernel.impl.nioneo.store.AbstractDynamicStore.getLightRecords(AbstractDynamicStore.java:305) ~[neo4j-kernel-2.1.6.jar:2.1.6]
	at org.neo4j.kernel.impl.nioneo.store.PropertyStore.ensureHeavy(PropertyStore.java:303) ~[neo4j-kernel-2.1.6.jar:2.1.6]
	at org.neo4j.kernel.impl.nioneo.xa.NeoStoreIndexStoreView.valueOf(NeoStoreIndexStoreView.java:210) ~[neo4j-kernel-2.1.6.jar:2.1.6]
	at org.neo4j.kernel.impl.nioneo.xa.NeoStoreIndexStoreView.access$400(NeoStoreIndexStoreView.java:55) ~[neo4j-kernel-2.1.6.jar:2.1.6]
	at org.neo4j.kernel.impl.nioneo.xa.NeoStoreIndexStoreView$1.read(NeoStoreIndexStoreView.java:94) ~[neo4j-kernel-2.1.6.jar:2.1.6]
	at org.neo4j.kernel.impl.nioneo.xa.NeoStoreIndexStoreView$1.read(NeoStoreIndexStoreView.java:80) ~[neo4j-kernel-2.1.6.jar:2.1.6]
	at org.neo4j.kernel.impl.nioneo.xa.NeoStoreIndexStoreView$NodeStoreScan.run(NeoStoreIndexStoreView.java:330) ~[neo4j-kernel-2.1.6.jar:2.1.6]
	at org.neo4j.kernel.impl.api.index.IndexPopulationJob.indexAllNodes(IndexPopulationJob.java:212) ~[neo4j-kernel-2.1.6.jar:2.1.6]
	at org.neo4j.kernel.impl.api.index.IndexPopulationJob.run(IndexPopulationJob.java:107) ~[neo4j-kernel-2.1.6.jar:2.1.6]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_17]
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334) [na:1.7.0_17]
	at java.util.concurrent.FutureTask.run(FutureTask.java:166) [na:1.7.0_17]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_17]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_17]
	at java.lang.Thread.run(Thread.java:722) [na:1.7.0_17]
2014-12-03 14:09:55.361+0000 INFO  [o.n.k.i.a.i.IndexPopulationJob]: Index population started: [:FluigUser(uniqueKey) [provider: {key=lucene, version=1.0}]]
2014-12-03 14:10:02.708+0000 ERROR [o.n.k.i.a.i.IndexPopulationJob]: Failed to populate index: [:FluigUser(uniqueKey) [provider: {key=lucene, version=1.0}]]
org.neo4j.kernel.impl.nioneo.store.InvalidRecordException: DynamicRecord Not in use, blockId[1642342]
	at org.neo4j.kernel.impl.nioneo.store.AbstractDynamicStore.getRecord(AbstractDynamicStore.java:371) ~[neo4j-kernel-2.1.6.jar:2.1.6]
	at org.neo4j.kernel.impl.nioneo.store.AbstractDynamicStore.getLightRecords(AbstractDynamicStore.java:305) ~[neo4j-kernel-2.1.6.jar:2.1.6]
	at org.neo4j.kernel.impl.nioneo.store.PropertyStore.ensureHeavy(PropertyStore.java:303) ~[neo4j-kernel-2.1.6.jar:2.1.6]
	at org.neo4j.kernel.impl.nioneo.xa.NeoStoreIndexStoreView.valueOf(NeoStoreIndexStoreView.java:210) ~[neo4j-kernel-2.1.6.jar:2.1.6]
	at org.neo4j.kernel.impl.nioneo.xa.NeoStoreIndexStoreView.access$400(NeoStoreIndexStoreView.java:55) ~[neo4j-kernel-2.1.6.jar:2.1.6]
#+END_EXAMPLE
** TODO learn to configure RM, in order to test sync operation
#+BEGIN_EXAMPLE
[12/3/14, 10:27:00 AM] denny: Hi Vicente & John

Tesing sync operation looks crucial to the functionality of identity system.

The ideal way for testing is developing mockup ERP system, and perform the sync.

But we are short of resource for this.

I’m thinking whether we can get enough knowledge about installing and using an existing one, say RM or Protheus.

Thus we can easily sync feature much deeply, and tremendously reduce the communication effort.
[12/3/14, 10:28:19 AM] denny: ============================
To be more specific:
- Do you think it’s necessary that we learn how to install and configure RM to perform the sync, for the in-house test?
[12/3/14, 10:29:09 AM] denny: denny set topic to “Learn RM for in-house test”
[12/3/14, 10:30:56 AM] Vicente Goetten: Denny
[12/3/14, 10:31:09 AM] Vicente Goetten: we already have Protheus, Logix, Datasul and RM connected to our QA environment
[12/3/14, 10:31:17 AM] Vicente Goetten: and I think Andre knows how to use it
[12/3/14, 10:31:33 AM] Vicente Goetten: John, please make sure that you guys also know how to configure and perform a sync for all these 4 apps
[12/3/14, 10:31:37 AM] Vicente Goetten: I'm leaving this thread
[12/3/14, 10:31:43 AM] Vicente Goetten: Vicente Goetten has left the conversation
[12/3/14, 10:32:48 AM] denny: OK!  John, I’m setting up a test env, would you please help or show me how to configure ERP part to trigger the sync operation?
#+END_EXAMPLE
** TODO Shivang: Can we do couchbase rebalance after rmi purge?
** TODO Understand AD server
https://totvslab.atlassian.net/wiki/display/QF/AD+Test+Environments
** TODO Test Desktop SSO
#+begin_example
[10/31/14, 6:43:22] Fellipe Augusto da Silva: hi Denny
[10/31/14, 6:44:10] denny: [10/31/14, 6:42:16] Fellipe Augusto da Silva: looks like it was a problem in Desktop SSO, and not manual login as we tested
[10/31/14, 6:42:41] Fellipe Augusto da Silva: Jonathan pushed the change on 1.4 branch

How can I test it?
[10/31/14, 6:44:25] Fellipe Augusto da Silva: it's complicated, we need a IIS server and some confs
[10/31/14, 6:44:34] Fellipe Augusto da Silva: not sure if we have an env with that
[10/31/14, 6:45:18] denny: I see, that's fine.

Thanks a lot, Fellipe
#+end_example
** TODO [#A] CP-6994: In prod env, search service is using 4Gb resident memory :IMPORTANT:
https://totvslab.atlassian.net/browse/CLOUDPASS-6994
** caculate the FD count for different type
#+BEGIN_EXAMPLE
[2/2/15, 12:53:55 PM] kungchaowang: thank you, let me get it
[2/2/15, 12:56:58 PM] kungchaowang: from that fd.txt got from 6 days ago, I have:

Kung-at-Totvslabs:tmp kungwang$ grep ".jar" fd.txt | wc -l
     598
Kung-at-Totvslabs:tmp kungwang$ grep lucene fd.txt | wc -l
    2266

now I got:

root@fluig-id-cust-01:/data/totvslabs/scim# lsof -p 6492 | grep ".jar" | wc -l
598
root@fluig-id-cust-01:/data/totvslabs/scim# lsof -p 6492 | grep "lucene" | wc -l
161
[2/2/15, 12:57:12 PM] kungchaowang: so, the lucene file handle is reduced
[2/2/15, 12:57:31 PM] kungchaowang: we still have to open that many jar file anyway to support the app
[2/2/15, 12:57:54 PM] kungchaowang: I think we are good for now
#+END_EXAMPLE
** How to detect disk is becoming slow?
** TODO detect load SAML request is slow:
tail /var/log/tomcat/cloudpass.log
#+BEGIN_EXAMPLE
<saml2p:AuthnRequest AssertionConsumerServiceURL="https://suporte.totvs.com/group/portaldocliente" Destination="https://totvs.fluigidentity.com/cloudpass/SPInitPost/receiveSSORequest/zf0y84vo717g8hjx/y6k661wf5a5vh9u11405012401405" ID="_11e4d5523473b115cebded4e5f437549" IssueInstant="2015-03-09T19:04:51.772Z" ProtocolBinding="urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST" ProviderName="TotvsLabs" Version="2.0" xmlns:saml2p="urn:oasis:names:tc:SAML:2.0:protocol"><saml2:Issuer Format="urn:oasis:names:tc:SAML:2.0:nameid-format:entity" xmlns:saml2="urn:oasis:names:tc:SAML:2.0:assertion">TotvsLabs</saml2:Issuer><saml2p:NameIDPolicy Format="urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress"/></saml2p:AuthnRequest>
2015-03-09 19:06:08,458 [ajp-bio-8009-exec-54746] INFO  binding.AuthnRequestProcessor  - SAML Request is valid....will be processed
2015-03-09 19:06:08,579 [ajp-bio-8009-exec-54746] INFO  binding.SSOHandler  - SAML User ID: juarez.marques@doitsistemas.com.br
2015-03-09 19:06:08,587 [ajp-bio-8009-exec-54746] INFO  binding.SSOHandler  - Generate success repsonse
2015-03-09 19:06:08,587 [ajp-bio-8009-exec-54746] INFO  assertion.SucessResponseGenerator  - Subject was successfully authenticated...create success response
2015-03-09 19:06:08,588 [ajp-bio-8009-exec-54746] INFO  assertion.AssertionGenerator  - Signing assertion...
2015-03-09 19:06:08,591 [ajp-bio-8009-exec-54746] INFO  assertion.AssertionGenerator  - Assertion signed.
2015-03-09 19:06:08,592 [ajp-bio-8009-exec-54746] INFO  binding.SSOHandler  - Send response
2015-03-09 19:06:08,592 [ajp-bio-8009-exec-54746] INFO  binding.SSOHandler  - Send saml response
2015-03-09 19:06:08,593 [ajp-bio-8009-exec-54746] INFO  binding.HttpPostBindingAdapter  - Encoding...
2015-03-09 19:06:08,606 [ajp-bio-8009-exec-54746] DEBUG PROTOCOL_MESSAGE  -
<?xml version="1.0" encoding="UTF-8"?>
<saml2p:Response
    Destination="https://suporte.totvs.com/group/portaldocliente"
    ID="_1cd60921a9b3a5b3528a564c1ca91040"
    InResponseTo="_11e4d5523473b115cebded4e5f437549"
    IssueInstant="2015-03-09T19:06:08.587Z" Version="2.0"
    xmlns:saml2p="urn:oasis:names:tc:SAML:2.0:protocol" xmlns:xs="http://www.w3.org/2001/XMLSchema">
    <saml2:Issuer
        Format="urn:oasis:names:tc:SAML:2.0:nameid-format:entity" xmlns:saml2="urn:oasis:names:tc:SAML:2.0:assertion">TotvsLabs</saml2:Issuer>
    <ds:Signature xmlns:ds="http://www.w3.org/2000/09/xmldsig#">
        <ds:SignedInfo>
            <ds:CanonicalizationMethod Algorithm="http://www.w3.org/2001/10/xml-exc-c14n#"/>
            <ds:SignatureMethod Algorithm="http://www.w3.org/2000/09/xmldsig#rsa-sha1"/>
            <ds:Reference URI="#_1cd60921a9b3a5b3528a564c1ca91040">
                <ds:Transforms>
                    <ds:Transform Algorithm="http://www.w3.org/2000/09/xmldsig#enveloped-signature"/>
                    <ds:Transform Algorithm="http://www.w3.org/2001/10/xml-exc-c14n#">
                        <ec:InclusiveNamespaces PrefixList="xs" xmlns:ec="http://www.w3.org/2001/10/xml-exc-c14n#"/>
                    </ds:Transform>
                </ds:Transforms>
                <ds:DigestMethod Algorithm="http://www.w3.org/2000/09/xmldsig#sha1"/>
                <ds:DigestValue>eTd3RNh9VjEYBHWlkdEQUv6IPz0=</ds:DigestValue>
            </ds:Reference>
        </ds:SignedInfo>
        <ds:SignatureValue>USePx/GGwob/ziFJ95Lr4xwY44zwLtw66rFby9K500TTUVoh39m3W+0hqvxDZ8+AFplb3Adn/gzOssB/yU5jWHcW+HKJYdYC2M+IwMps9rn1obmYb3X228mkgkxbgfDYPD9AdniDbW/hrep7gAycaTvUx5NjhYjarfuwxFOspFU=</ds:SignatureValue>
        <ds:KeyInfo>
            <ds:X509Data>
                <ds:X509Certificate>MIICBjCCAW8CBgFA0ZsrITANBgkqhkiG9w0BAQsFADBJMSYwJAYDVQQLEx1Ub3R2c0xhYnMgUHJp
bWFyeSBDZXJ0aWZpY2F0ZTESMBAGA1UEChMJVG90dnNMYWJzMQswCQYDVQQGEwJVUzAeFw0xMzA4
MzAyMzQyMjFaFw0xODA4MjkyMzQyMjFaMEkxJjAkBgNVBAsTHVRvdHZzTGFicyBQcmltYXJ5IENl
cnRpZmljYXRlMRIwEAYDVQQKEwlUb3R2c0xhYnMxCzAJBgNVBAYTAlVTMIGfMA0GCSqGSIb3DQEB
AQUAA4GNADCBiQKBgQCSTmcVLlj7K58TlSqCG6m51mSQlH0hPN5z0T2iMs/d30f8udnm75nla2OJ
ktdDu8Jm8/XcCFoMfyKnkZojZgRPaFOqWjhh9/nYCcm8wGGFko3WYqrzmKzVtiJZ1+PfQdd5yXCe
ao8Gevt46Ssfh7mLWSU4c+DcB5wWr9jM4ejVeQIDAQABMA0GCSqGSIb3DQEBCwUAA4GBAGBWsiJO
QJcB2apM2gAT4x3y7ZBvxnY8CA4A7pUUNMaTwDqk19LwGzuohcY2mkB4Rq7tx3NcEMfT/tZbvPhy
XpJcjWbfDJPM6kjCPCwTxUzQWvFbl1GDMO5+8nll//8QgjwMbTI6pMcdhxcDvhSpSXF9P02lKKBf
Ve453KKeFSW+</ds:X509Certificate>
            </ds:X509Data>
        </ds:KeyInfo>
    </ds:Signature>
    <saml2p:Status xmlns:saml2p="urn:oasis:names:tc:SAML:2.0:protocol">
        <saml2p:StatusCode Value="urn:oasis:names:tc:SAML:2.0:status:Success"/>
    </saml2p:Status>
    <saml2:Assertion ID="_d6feb5f895b07cb84864045a6b714af0"
        IssueInstant="2015-03-09T19:06:08.587Z" Version="2.0"
        xmlns:saml2="urn:oasis:names:tc:SAML:2.0:assertion" xmlns:xs="http://www.w3.org/2001/XMLSchema">
        <saml2:Issuer Format="urn:oasis:names:tc:SAML:2.0:nameid-format:entity">TotvsLabs</saml2:Issuer>
        <ds:Signature xmlns:ds="http://www.w3.org/2000/09/xmldsig#">
            <ds:SignedInfo>
                <ds:CanonicalizationMethod Algorithm="http://www.w3.org/2001/10/xml-exc-c14n#"/>
                <ds:SignatureMethod Algorithm="http://www.w3.org/2000/09/xmldsig#rsa-sha1"/>
                <ds:Reference URI="#_d6feb5f895b07cb84864045a6b714af0">
                    <ds:Transforms>
                        <ds:Transform Algorithm="http://www.w3.org/2000/09/xmldsig#enveloped-signature"/>
                        <ds:Transform Algorithm="http://www.w3.org/2001/10/xml-exc-c14n#">
                            <ec:InclusiveNamespaces PrefixList="xs" xmlns:ec="http://www.w3.org/2001/10/xml-exc-c14n#"/>
                        </ds:Transform>
                    </ds:Transforms>
                    <ds:DigestMethod Algorithm="http://www.w3.org/2000/09/xmldsig#sha1"/>
                    <ds:DigestValue>KVRcTCnmMPE0CZ5zJoIb2bn6CS4=</ds:DigestValue>
                </ds:Reference>
            </ds:SignedInfo>

#+END_EXAMPLE
** DONE strange chef update: chef-client is autostart, and machine reboot results in unexpect update
  CLOSED: [2015-03-05 Thu 16:59]
#+BEGIN_EXAMPLE
[3/5/15, 4:51:06 PM] Lucas Schiochet: Is also a important part of knowledge transfer
[3/5/15, 4:51:37 PM] Lucas Schiochet: The next ste is create a check list in things to verify to support team
[3/5/15, 4:51:59 PM] denny: Yes, it will definitely help.
[3/5/15, 4:56:25 PM] denny: Previously, we see two strange thing:
- The env is upgraded to master branch somehow
- couchbase configuration is changed to password in configuration file, which is incorrect.

All we know what happened is: customer rebooted the machine.
[3/5/15, 4:56:34 PM] denny: I think I know the root cause now.
[3/5/15, 4:57:35 PM] denny: The reason is:
- Resource env is a legacy system, which is deployed months ago before our chef is ready.
- chef-client service is configured as autostart (Try chkconfig —list | grep chef)
[3/5/15, 4:58:17 PM] denny: =============
So when the machine is restarted, chef-client command will run automatically without json file specified.

Thus it will lead the env upgraded to master branch with every parameter of default value.
[3/5/15, 4:58:28 PM] denny: So we see what we’re seeing.
#+END_EXAMPLE
** TODO [#A] chef request to sprepo.fluigidentity is extremely slow
#+BEGIN_EXAMPLE
0-05:00] INFO: file[/data/flagfile/enabled_services/hornetq] owner changed to 0
[2015-02-26T15:25:20-05:00] INFO: file[/data/flagfile/enabled_services/hornetq] group changed to 0
[2015-02-26T15:25:20-05:00] INFO: file[/data/flagfile/enabled_services/hornetq] mode changed to 755

    - change mode from '' to '0755'
    - change owner from '' to 'root'
    - change group from '' to 'root'
Recipe: fluig-couchbase::download_files
  * remote_file[Download couchbase package] action create_if_missing[2015-02-26T15:25:20-05:00] INFO: Processing remote_file[Download couchbase package] action create_if_missing (fluig-couchbase::download_files line 13)
#+END_EXAMPLE
** BYPASS CP-6539: Error 500 when try to sync Protheus App on qafluigidentity.com
  CLOSED: [2015-01-23 Fri 00:42]
https://totvslab.atlassian.net/browse/CLOUDPASS-6539
#+BEGIN_EXAMPLE
[1/20/15, 8:42:19 PM] Shivang: i assigned a bug to you .. 6539
[1/20/15, 8:42:29 PM] Shivang: it seems to be a deployment issue on qafluigidentity but I cannot pin point where
[1/20/15, 8:42:46 PM] Shivang: all i remember is we had this issue before and a fresh deployment fixed (without using jenkins)
[1/20/15, 8:42:59 PM] Shivang: I am gonna tell andre to test on other env .. but will you mind looking into this ?
[1/20/15, 8:44:09 PM] denny: hmm, I’ve read the ticket.

What I can do for that?
[1/20/15, 8:44:31 PM] Shivang: do a manual fresh install of everything
[1/20/15, 8:44:35 PM] Shivang: without using jenkins
[1/20/15, 8:44:46 PM] Shivang: a full clean install without automated process ..
[1/20/15, 8:44:53 PM] Shivang: that will give us a much better idea
[1/20/15, 8:45:05 PM] denny: That’s impossible, because we don’t have manual steps, Shivang
[1/20/15, 8:45:32 PM] Shivang: its not impossible .. it's definitely possible
[1/20/15, 8:45:37 PM] Shivang: i can build locally and copy over all the
[1/20/15, 8:45:41 PM] Shivang: jars files
[1/20/15, 8:45:55 PM] Shivang: i just thought you might have a machine locally to qafluigidentity network
[1/20/15, 8:46:00 PM] Shivang: so that copying can be easier
[1/20/15, 8:48:34 PM] denny: Nowhere to know how to change conf files, and too many steps involved.

I’m thinking whether we can have a better direction.

Say:
1. Understand what it means
2. perform a clean service restart for qafluigidentity
3. Deploy an all-in-one env and verify that.
[1/20/15, 8:48:55 PM] Shivang: I think we have this error before couple of months back
[1/20/15, 8:49:04 PM] Shivang: and I know for a fact that manual copying of jar files fixed it ..
[1/20/15, 8:49:12 PM] Shivang: BUT .. let me do my due deligence
[1/20/15, 8:49:19 PM] Shivang: and make sure I am right .. before we do the deployment
#+END_EXAMPLE
** CANCELED [#A] Restart adsync fail in prod env                  :IMPORTANT:
   CLOSED: [2015-01-20 Tue 14:11]
*** TODO [#A] restart app #2 doesn't work
#+BEGIN_EXAMPLE
ERROR [2014-12-17 13:44:46,875] com.sun.jersey.spi.container.ContainerResponse: Mapped exception to response: 500 (Internal Server Error)
! com.totvslabs.idm.rest.exception.FluigIdentityExceptionResponse: null
! at com.totvslabs.idm.rest.resources.scim.v2.UserEntitlementsResource.getUserEntitlements(UserEntitlementsResource.java:262) ~[rest.jar:na]
! at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.7.0_17]
! at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[na:1.7.0_17]
! at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_17]
! at java.lang.reflect.Method.invoke(Method.java:601) ~[na:1.7.0_17]
! at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$ResponseOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:205) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.codahale.metrics.jersey.InstrumentedResourceMethodDispatchProvider$TimedRequestDispatcher.dispatch(InstrumentedResourceMethodDispatchProvider.java:30) ~[metrics-jersey-3.0.1.jar:3.0.1]
! at io.dropwizard.jersey.caching.CacheControlledResourceMethodDispatchAdapter$CacheControlledRequestDispatcher.dispatch(CacheControlledResourceMethodDispatchAdapter.java:59) ~[dropwizard-jersey-0.7.0.jar:0.7.0]
! at io.dropwizard.jersey.guava.OptionalResourceMethodDispatchAdapter$OptionalRequestDispatcher.dispatch(OptionalResourceMethodDispatchAdapter.java:37) ~[dropwizard-jersey-0.7.0.jar:0.7.0]
! at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.ResourceObjectRule.accept(ResourceObjectRule.java:100) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409) [jersey-servlet-1.18.1.jar:1.18.1]
! at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:540) [jersey-servlet-1.18.1.jar:1.18.1]
! at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:715) [jersey-servlet-1.18.1.jar:1.18.1]
! at javax.servlet.http.HttpServlet.service(HttpServlet.java:848) [javax.servlet-3.0.0.v201112011016.jar:na]
! at io.dropwizard.jetty.NonblockingServletHolder.handle(NonblockingServletHolder.java:49) [dropwizard-jetty-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1515) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlets.UserAgentFilter.doFilter(UserAgentFilter.java:83) [jetty-servlets-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlets.GzipFilter.doFilter(GzipFilter.java:348) [jetty-servlets-9.0.7.v20131107.jar:9.0.7.v20131107]
! at io.dropwizard.jetty.BiDiGzipFilter.doFilter(BiDiGzipFilter.java:127) [dropwizard-jetty-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1486) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at io.dropwizard.servlets.ThreadNameFilter.doFilter(ThreadNameFilter.java:29) [dropwizard-servlets-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1486) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at com.totvslabs.idm.rest.security.filter.ScimCompanyIdVerificationFilter.doFilter(ScimCompanyIdVerificationFilter.java:155) [rest.jar:na]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1486) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:519) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1097) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:448) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1031) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:136) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:173) [metrics-jetty9-3.0.1.jar:3.0.1]
! at io.dropwizard.jetty.RoutingHandler.handle(RoutingHandler.java:51) [dropwizard-jetty-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:92) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:162) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.Server.handle(Server.java:446) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:271) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:246) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.io.AbstractConnection$ReadCallback.run(AbstractConnection.java:358) [jetty-io-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:601) [jetty-util-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:532) [jetty-util-9.0.7.v20131107.jar:9.0.7.v20131107]
! at java.lang.Thread.run(Thread.java:722) [na:1.7.0_17]
189.113.18.250 -  -  [17/Dec/2014:13:44:46 +0000] "GET /rest/v2/scim/v2/extensions/Entitlements/Companies/900eixqn28old0mq1406926758936/Users/t8cl455al09j8ayt1408114169125/old?startIndex=0&count=1&filter=&sortBy=&sortOrder=ASC&distinctBy=urn_scim_schemas_extension_2_0_Resource_id&resourceTypes=Company&restrictionIds= HTTP/1.1" 500 - "-" "Java/1.7.0_55" 65
201.48.226.194 -  -  [17/Dec/2014:13:45:05 +0000] "POST /rest/v2/companies/gupbtn1hkl4ezfx2/users/validate HTTP/1.1" 500 - "-" "Java/1.7.0_55" 469
root@app2:/data/fluigidentity-logs#
#+END_EXAMPLE
*** TODO [#A] restart app#1 doens't work
#+BEGIN_EXAMPLE
root@app1:/data/fluigidentity-logs# tail -n 500 ./rest.log
tail -n 500 ./rest.log
! at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:715) [jersey-servlet-1.18.1.jar:1.18.1]
! at javax.servlet.http.HttpServlet.service(HttpServlet.java:848) [javax.servlet-3.0.0.v201112011016.jar:na]
! at io.dropwizard.jetty.NonblockingServletHolder.handle(NonblockingServletHolder.java:49) [dropwizard-jetty-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1515) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlets.UserAgentFilter.doFilter(UserAgentFilter.java:83) [jetty-servlets-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlets.GzipFilter.doFilter(GzipFilter.java:348) [jetty-servlets-9.0.7.v20131107.jar:9.0.7.v20131107]
! at io.dropwizard.jetty.BiDiGzipFilter.doFilter(BiDiGzipFilter.java:127) [dropwizard-jetty-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1486) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at io.dropwizard.servlets.ThreadNameFilter.doFilter(ThreadNameFilter.java:29) [dropwizard-servlets-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1486) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at com.totvslabs.idm.rest.security.filter.ScimCompanyIdVerificationFilter.doFilter(ScimCompanyIdVerificationFilter.java:155) [rest.jar:na]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1486) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:519) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1097) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:448) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1031) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:136) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:173) [metrics-jetty9-3.0.1.jar:3.0.1]
! at io.dropwizard.jetty.RoutingHandler.handle(RoutingHandler.java:51) [dropwizard-jetty-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:92) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:162) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.Server.handle(Server.java:446) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:271) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:246) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.io.AbstractConnection$ReadCallback.run(AbstractConnection.java:358) [jetty-io-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:601) [jetty-util-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:532) [jetty-util-9.0.7.v20131107.jar:9.0.7.v20131107]
! at java.lang.Thread.run(Thread.java:722) [na:1.7.0_17]
WARN  [2014-12-17 13:45:31,429] com.totvslabs.idm.rest.bo.impl.NeoExtensionFluigUserBoImpl: getEntitlementsOfUser failed : thread: dw-32 - GET /rest/v2/scim/v2/extensions/Entitlements/Companies/gc78txf7mvv9bsoy/Users/9kjh2c7cbpbgpww41415275579639/old?startIndex=0&count=1&filter=&sortBy=&sortOrder=ASC&distinctBy=urn_scim_schemas_extension_2_0_Resource_id&resourceTypes=Company&restrictionIds=, {"errorCode":500,"errorMessage":"","possibleResponsibleField":""}
ERROR [2014-12-17 13:45:31,430] com.totvslabs.idm.rest.resources.scim.v2.UsersResource: getUserEntitlements : thread: dw-32 - GET /rest/v2/scim/v2/extensions/Entitlements/Companies/gc78txf7mvv9bsoy/Users/9kjh2c7cbpbgpww41415275579639/old?startIndex=0&count=1&filter=&sortBy=&sortOrder=ASC&distinctBy=urn_scim_schemas_extension_2_0_Resource_id&resourceTypes=Company&restrictionIds=, error: {"errorCode":500,"errorMessage":"","possibleResponsibleField":""}
ERROR [2014-12-17 13:45:31,432] com.sun.jersey.spi.container.ContainerResponse: Mapped exception to response: 500 (Internal Server Error)
! com.totvslabs.idm.rest.exception.FluigIdentityExceptionResponse: null
! at com.totvslabs.idm.rest.resources.scim.v2.UserEntitlementsResource.getUserEntitlements(UserEntitlementsResource.java:262) ~[rest.jar:na]
! at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.7.0_17]
! at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[na:1.7.0_17]
! at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_17]
! at java.lang.reflect.Method.invoke(Method.java:601) ~[na:1.7.0_17]
! at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$ResponseOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:205) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.codahale.metrics.jersey.InstrumentedResourceMethodDispatchProvider$TimedRequestDispatcher.dispatch(InstrumentedResourceMethodDispatchProvider.java:30) ~[metrics-jersey-3.0.1.jar:3.0.1]
! at io.dropwizard.jersey.caching.CacheControlledResourceMethodDispatchAdapter$CacheControlledRequestDispatcher.dispatch(CacheControlledResourceMethodDispatchAdapter.java:59) ~[dropwizard-jersey-0.7.0.jar:0.7.0]
! at io.dropwizard.jersey.guava.OptionalResourceMethodDispatchAdapter$OptionalRequestDispatcher.dispatch(OptionalResourceMethodDispatchAdapter.java:37) ~[dropwizard-jersey-0.7.0.jar:0.7.0]
! at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.ResourceObjectRule.accept(ResourceObjectRule.java:100) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409) [jersey-servlet-1.18.1.jar:1.18.1]
! at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:540) [jersey-servlet-1.18.1.jar:1.18.1]
! at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:715) [jersey-servlet-1.18.1.jar:1.18.1]
! at javax.servlet.http.HttpServlet.service(HttpServlet.java:848) [javax.servlet-3.0.0.v201112011016.jar:na]
! at io.dropwizard.jetty.NonblockingServletHolder.handle(NonblockingServletHolder.java:49) [dropwizard-jetty-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1515) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlets.UserAgentFilter.doFilter(UserAgentFilter.java:83) [jetty-servlets-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlets.GzipFilter.doFilter(GzipFilter.java:348) [jetty-servlets-9.0.7.v20131107.jar:9.0.7.v20131107]
! at io.dropwizard.jetty.BiDiGzipFilter.doFilter(BiDiGzipFilter.java:127) [dropwizard-jetty-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1486) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at io.dropwizard.servlets.ThreadNameFilter.doFilter(ThreadNameFilter.java:29) [dropwizard-servlets-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1486) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at com.totvslabs.idm.rest.security.filter.ScimCompanyIdVerificationFilter.doFilter(ScimCompanyIdVerificationFilter.java:155) [rest.jar:na]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1486) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:519) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1097) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:448) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1031) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:136) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:173) [metrics-jetty9-3.0.1.jar:3.0.1]
! at io.dropwizard.jetty.RoutingHandler.handle(RoutingHandler.java:51) [dropwizard-jetty-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:92) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:162) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.Server.handle(Server.java:446) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:271) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:246) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.io.AbstractConnection$ReadCallback.run(AbstractConnection.java:358) [jetty-io-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:601) [jetty-util-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:532) [jetty-util-9.0.7.v20131107.jar:9.0.7.v20131107]
! at java.lang.Thread.run(Thread.java:722) [na:1.7.0_17]
INFO  [2014-12-17 13:45:35,158] com.totvslabs.idm.rest.resources.scim.v2.UsersResource: getUserEntitlements : gc78txf7mvv9bsoy, null, 9kjh2c7cbpbgpww41415275579639, Company, 0, 1, , , ASC, urn_scim_schemas_extension_2_0_Resource_id,
INFO  [2014-12-17 13:45:35,158] com.totvslabs.idm.rest.resources.scim.v2.UsersResource: filter ==
WARN  [2014-12-17 13:45:35,182] com.totvslabs.idm.rest.bo.impl.NeoExtensionFluigUserBoImpl: getEntitlementsOfUser failed : thread: dw-28 - GET /rest/v2/scim/v2/extensions/Entitlements/Companies/gc78txf7mvv9bsoy/Users/9kjh2c7cbpbgpww41415275579639/old?startIndex=0&count=1&filter=&sortBy=&sortOrder=ASC&distinctBy=urn_scim_schemas_extension_2_0_Resource_id&resourceTypes=Company&restrictionIds=, {"errorCode":500,"errorMessage":"","possibleResponsibleField":""}
ERROR [2014-12-17 13:45:35,182] com.totvslabs.idm.rest.resources.scim.v2.UsersResource: getUserEntitlements : thread: dw-28 - GET /rest/v2/scim/v2/extensions/Entitlements/Companies/gc78txf7mvv9bsoy/Users/9kjh2c7cbpbgpww41415275579639/old?startIndex=0&count=1&filter=&sortBy=&sortOrder=ASC&distinctBy=urn_scim_schemas_extension_2_0_Resource_id&resourceTypes=Company&restrictionIds=, error: {"errorCode":500,"errorMessage":"","possibleResponsibleField":""}
INFO  [2014-12-17 13:45:35,158] com.totvslabs.idm.rest.resources.scim.v2.UsersResource: getUserEntitlements : gc78txf7mvv9bsoy, null, 9kjh2c7cbpbgpww41415275579639, Company, 0, 1, , , ASC, urn_scim_schemas_extension_2_0_Resource_id,
INFO  [2014-12-17 13:45:35,158] com.totvslabs.idm.rest.resources.scim.v2.UsersResource: filter ==
WARN  [2014-12-17 13:45:35,182] com.totvslabs.idm.rest.bo.impl.NeoExtensionFluigUserBoImpl: getEntitlementsOfUser failed : thread: dw-28 - GET /rest/v2/scim/v2/extensions/Entitlements/Companies/gc78txf7mvv9bsoy/Users/9kjh2c7cbpbgpww41415275579639/old?startIndex=0&count=1&filter=&sortBy=&sortOrder=ASC&distinctBy=urn_scim_schemas_extension_2_0_Resource_id&resourceTypes=Company&restrictionIds=, {"errorCode":500,"errorMessage":"","possibleResponsibleField":""}
ERROR [2014-12-17 13:45:35,182] com.totvslabs.idm.rest.resources.scim.v2.UsersResource: getUserEntitlements : thread: dw-28 - GET /rest/v2/scim/v2/extensions/Entitlements/Companies/gc78txf7mvv9bsoy/Users/9kjh2c7cbpbgpww41415275579639/old?startIndex=0&count=1&filter=&sortBy=&sortOrder=ASC&distinctBy=urn_scim_schemas_extension_2_0_Resource_id&resourceTypes=Company&restrictionIds=, error: {"errorCode":500,"errorMessage":"","possibleResponsibleField":""}
ERROR [2014-12-17 13:45:35,184] com.sun.jersey.spi.container.ContainerResponse: Mapped exception to response: 500 (Internal Server Error)
! com.totvslabs.idm.rest.exception.FluigIdentityExceptionResponse: null
! at com.totvslabs.idm.rest.resources.scim.v2.UserEntitlementsResource.getUserEntitlements(UserEntitlementsResource.java:262) ~[rest.jar:na]
! at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.7.0_17]
! at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[na:1.7.0_17]
! at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_17]
! at java.lang.reflect.Method.invoke(Method.java:601) ~[na:1.7.0_17]
! at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$ResponseOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:205) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.codahale.metrics.jersey.InstrumentedResourceMethodDispatchProvider$TimedRequestDispatcher.dispatch(InstrumentedResourceMethodDispatchProvider.java:30) ~[metrics-jersey-3.0.1.jar:3.0.1]
! at io.dropwizard.jersey.caching.CacheControlledResourceMethodDispatchAdapter$CacheControlledRequestDispatcher.dispatch(CacheControlledResourceMethodDispatchAdapter.java:59) ~[dropwizard-jersey-0.7.0.jar:0.7.0]
! at io.dropwizard.jersey.guava.OptionalResourceMethodDispatchAdapter$OptionalRequestDispatcher.dispatch(OptionalResourceMethodDispatchAdapter.java:37) ~[dropwizard-jersey-0.7.0.jar:0.7.0]
! at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.ResourceObjectRule.accept(ResourceObjectRule.java:100) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409) [jersey-servlet-1.18.1.jar:1.18.1]
! at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:540) [jersey-servlet-1.18.1.jar:1.18.1]
! at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:715) [jersey-servlet-1.18.1.jar:1.18.1]
! at javax.servlet.http.HttpServlet.service(HttpServlet.java:848) [javax.servlet-3.0.0.v201112011016.jar:na]
! at io.dropwizard.jetty.NonblockingServletHolder.handle(NonblockingServletHolder.java:49) [dropwizard-jetty-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1515) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlets.UserAgentFilter.doFilter(UserAgentFilter.java:83) [jetty-servlets-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlets.GzipFilter.doFilter(GzipFilter.java:348) [jetty-servlets-9.0.7.v20131107.jar:9.0.7.v20131107]
! at io.dropwizard.jetty.BiDiGzipFilter.doFilter(BiDiGzipFilter.java:127) [dropwizard-jetty-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1486) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at io.dropwizard.servlets.ThreadNameFilter.doFilter(ThreadNameFilter.java:29) [dropwizard-servlets-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1486) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at com.totvslabs.idm.rest.security.filter.ScimCompanyIdVerificationFilter.doFilter(ScimCompanyIdVerificationFilter.java:155) [rest.jar:na]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1486) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:519) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1097) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:448) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1031) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:136) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:173) [metrics-jetty9-3.0.1.jar:3.0.1]
! at io.dropwizard.jetty.RoutingHandler.handle(RoutingHandler.java:51) [dropwizard-jetty-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:92) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:162) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.Server.handle(Server.java:446) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:271) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:246) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.io.AbstractConnection$ReadCallback.run(AbstractConnection.java:358) [jetty-io-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:601) [jetty-util-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:532) [jetty-util-9.0.7.v20131107.jar:9.0.7.v20131107]
! at java.lang.Thread.run(Thread.java:722) [na:1.7.0_17]
ERROR [2014-12-17 13:45:35,184] com.sun.jersey.spi.container.ContainerResponse: Mapped exception to response: 500 (Internal Server Error)
! com.totvslabs.idm.rest.exception.FluigIdentityExceptionResponse: null
! at com.totvslabs.idm.rest.resources.scim.v2.UserEntitlementsResource.getUserEntitlements(UserEntitlementsResource.java:262) ~[rest.jar:na]
! at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.7.0_17]
! at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[na:1.7.0_17]
! at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_17]
! at java.lang.reflect.Method.invoke(Method.java:601) ~[na:1.7.0_17]
! at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$ResponseOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:205) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.codahale.metrics.jersey.InstrumentedResourceMethodDispatchProvider$TimedRequestDispatcher.dispatch(InstrumentedResourceMethodDispatchProvider.java:30) ~[metrics-jersey-3.0.1.jar:3.0.1]
! at io.dropwizard.jersey.caching.CacheControlledResourceMethodDispatchAdapter$CacheControlledRequestDispatcher.dispatch(CacheControlledResourceMethodDispatchAdapter.java:59) ~[dropwizard-jersey-0.7.0.jar:0.7.0]
! at io.dropwizard.jersey.guava.OptionalResourceMethodDispatchAdapter$OptionalRequestDispatcher.dispatch(OptionalResourceMethodDispatchAdapter.java:37) ~[dropwizard-jersey-0.7.0.jar:0.7.0]
! at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.ResourceObjectRule.accept(ResourceObjectRule.java:100) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409) [jersey-servlet-1.18.1.jar:1.18.1]
! at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:540) [jersey-servlet-1.18.1.jar:1.18.1]
! at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:715) [jersey-servlet-1.18.1.jar:1.18.1]
! at javax.servlet.http.HttpServlet.service(HttpServlet.java:848) [javax.servlet-3.0.0.v201112011016.jar:na]
! at io.dropwizard.jetty.NonblockingServletHolder.handle(NonblockingServletHolder.java:49) [dropwizard-jetty-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1515) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlets.UserAgentFilter.doFilter(UserAgentFilter.java:83) [jetty-servlets-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlets.GzipFilter.doFilter(GzipFilter.java:348) [jetty-servlets-9.0.7.v20131107.jar:9.0.7.v20131107]
! at io.dropwizard.jetty.BiDiGzipFilter.doFilter(BiDiGzipFilter.java:127) [dropwizard-jetty-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1486) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at io.dropwizard.servlets.ThreadNameFilter.doFilter(ThreadNameFilter.java:29) [dropwizard-servlets-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1486) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at com.totvslabs.idm.rest.security.filter.ScimCompanyIdVerificationFilter.doFilter(ScimCompanyIdVerificationFilter.java:155) [rest.jar:na]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1486) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:519) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1097) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:448) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1031) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:136) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:173) [metrics-jetty9-3.0.1.jar:3.0.1]
! at io.dropwizard.jetty.RoutingHandler.handle(RoutingHandler.java:51) [dropwizard-jetty-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:92) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:162) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.Server.handle(Server.java:446) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:271) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:246) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.io.AbstractConnection$ReadCallback.run(AbstractConnection.java:358) [jetty-io-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:601) [jetty-util-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:532) [jetty-util-9.0.7.v20131107.jar:9.0.7.v20131107]
! at java.lang.Thread.run(Thread.java:722) [na:1.7.0_17]
201.18.224.190 -  -  [17/Dec/2014:13:45:35 +0000] "GET /rest/v2/scim/v2/extensions/Entitlements/Companies/gc78txf7mvv9bsoy/Users/9kjh2c7cbpbgpww41415275579639/old?startIndex=0&count=1&filter=&sortBy=&sortOrder=ASC&distinctBy=urn_scim_schemas_extension_2_0_Resource_id&resourceTypes=Company&restrictionIds= HTTP/1.1" 500 - "-" "Java/1.7.0_55" 42
187.94.58.66 -  -  [17/Dec/2014:13:45:35 +0000] "GET /rest/v2/companies/zf0y84vo717g8hjx/users/email/wilson.silva@totvspartners.com.br HTTP/1.1" 200 - "-" "Java/1.6.0_11" 26
187.94.58.66 -  -  [17/Dec/2014:13:45:55 +0000] "GET /rest/v2/companies/zf0y84vo717g8hjx/users/email/fabiano.albuquerque@totvs.com.br HTTP/1.1" 200 - "-" "Java/1.6.0_11" 31
187.94.58.66 -  -  [17/Dec/2014:13:45:56 +0000] "GET /rest/v2/companies/zf0y84vo717g8hjx/users/email/daniel.barcelos@totvs.com.br HTTP/1.1" 200 - "-" "Java/1.6.0_11" 24
187.94.58.66 -  -  [17/Dec/2014:13:45:58 +0000] "GET /rest/v2/companies/zf0y84vo717g8hjx/users/email/edenira.hasse@totvs.com.br HTTP/1.1" 200 - "-" "Java/1.6.0_11" 34
INFO  [2014-12-17 13:46:04,058] com.totvslabs.idm.rest.resources.scim.v2.UsersResource: getUserEntitlements : 8pgyqh13v8povt2h1397759665424, null, hrid4xshhr7fy4ad1410975335874, Company, 0, 1, , , ASC, urn_scim_schemas_extension_2_0_Resource_externalId,
INFO  [2014-12-17 13:46:04,059] com.totvslabs.idm.rest.resources.scim.v2.UsersResource: filter ==
INFO  [2014-12-17 13:46:04,058] com.totvslabs.idm.rest.resources.scim.v2.UsersResource: getUserEntitlements : 8pgyqh13v8povt2h1397759665424, null, hrid4xshhr7fy4ad1410975335874, Company, 0, 1, , , ASC, urn_scim_schemas_extension_2_0_Resource_externalId,
INFO  [2014-12-17 13:46:04,059] com.totvslabs.idm.rest.resources.scim.v2.UsersResource: filter ==
WARN  [2014-12-17 13:46:04,086] com.totvslabs.idm.rest.bo.impl.NeoExtensionFluigUserBoImpl: getEntitlementsOfUser failed : thread: dw-70 - GET /rest/v2/scim/v2/extensions/Entitlements/Companies/8pgyqh13v8povt2h1397759665424/Users/hrid4xshhr7fy4ad1410975335874/old?startIndex=0&count=1&filter=&sortBy=&sortOrder=ASC&distinctBy=urn_scim_schemas_extension_2_0_Resource_externalId&resourceTypes=Company&restrictionIds=, {"errorCode":500,"errorMessage":"","possibleResponsibleField":""}
ERROR [2014-12-17 13:46:04,087] com.totvslabs.idm.rest.resources.scim.v2.UsersResource: getUserEntitlements : thread: dw-70 - GET /rest/v2/scim/v2/extensions/Entitlements/Companies/8pgyqh13v8povt2h1397759665424/Users/hrid4xshhr7fy4ad1410975335874/old?startIndex=0&count=1&filter=&sortBy=&sortOrder=ASC&distinctBy=urn_scim_schemas_extension_2_0_Resource_externalId&resourceTypes=Company&restrictionIds=, error: {"errorCode":500,"errorMessage":"","possibleResponsibleField":""}
ERROR [2014-12-17 13:46:04,117] com.sun.jersey.spi.container.ContainerResponse: Mapped exception to response: 500 (Internal Server Error)
! com.totvslabs.idm.rest.exception.FluigIdentityExceptionResponse: null
! at com.totvslabs.idm.rest.resources.scim.v2.UserEntitlementsResource.getUserEntitlements(UserEntitlementsResource.java:262) ~[rest.jar:na]
! at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.7.0_17]
! at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[na:1.7.0_17]
! at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_17]
! at java.lang.reflect.Method.invoke(Method.java:601) ~[na:1.7.0_17]
! at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$ResponseOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:205) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.codahale.metrics.jersey.InstrumentedResourceMethodDispatchProvider$TimedRequestDispatcher.dispatch(InstrumentedResourceMethodDispatchProvider.java:30) ~[metrics-jersey-3.0.1.jar:3.0.1]
! at io.dropwizard.jersey.caching.CacheControlledResourceMethodDispatchAdapter$CacheControlledRequestDispatcher.dispatch(CacheControlledResourceMethodDispatchAdapter.java:59) ~[dropwizard-jersey-0.7.0.jar:0.7.0]
! at io.dropwizard.jersey.guava.OptionalResourceMethodDispatchAdapter$OptionalRequestDispatcher.dispatch(OptionalResourceMethodDispatchAdapter.java:37) ~[dropwizard-jersey-0.7.0.jar:0.7.0]
! at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.ResourceObjectRule.accept(ResourceObjectRule.java:100) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409) [jersey-servlet-1.18.1.jar:1.18.1]
! at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:540) [jersey-servlet-1.18.1.jar:1.18.1]
! at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:715) [jersey-servlet-1.18.1.jar:1.18.1]
! at javax.servlet.http.HttpServlet.service(HttpServlet.java:848) [javax.servlet-3.0.0.v201112011016.jar:na]
! at io.dropwizard.jetty.NonblockingServletHolder.handle(NonblockingServletHolder.java:49) [dropwizard-jetty-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1515) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlets.UserAgentFilter.doFilter(UserAgentFilter.java:83) [jetty-servlets-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlets.GzipFilter.doFilter(GzipFilter.java:348) [jetty-servlets-9.0.7.v20131107.jar:9.0.7.v20131107]
! at io.dropwizard.jetty.BiDiGzipFilter.doFilter(BiDiGzipFilter.java:127) [dropwizard-jetty-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1486) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at io.dropwizard.servlets.ThreadNameFilter.doFilter(ThreadNameFilter.java:29) [dropwizard-servlets-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1486) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at com.totvslabs.idm.rest.security.filter.ScimCompanyIdVerificationFilter.doFilter(ScimCompanyIdVerificationFilter.java:155) [rest.jar:na]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1486) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:519) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1097) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:448) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1031) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:136) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:173) [metrics-jetty9-3.0.1.jar:3.0.1]
! at io.dropwizard.jetty.RoutingHandler.handle(RoutingHandler.java:51) [dropwizard-jetty-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:92) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:162) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.Server.handle(Server.java:446) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:271) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:246) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.io.AbstractConnection$ReadCallback.run(AbstractConnection.java:358) [jetty-io-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:601) [jetty-util-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:532) [jetty-util-9.0.7.v20131107.jar:9.0.7.v20131107]
! at java.lang.Thread.run(Thread.java:722) [na:1.7.0_17]
WARN  [2014-12-17 13:46:04,086] com.totvslabs.idm.rest.bo.impl.NeoExtensionFluigUserBoImpl: getEntitlementsOfUser failed : thread: dw-70 - GET /rest/v2/scim/v2/extensions/Entitlements/Companies/8pgyqh13v8povt2h1397759665424/Users/hrid4xshhr7fy4ad1410975335874/old?startIndex=0&count=1&filter=&sortBy=&sortOrder=ASC&distinctBy=urn_scim_schemas_extension_2_0_Resource_externalId&resourceTypes=Company&restrictionIds=, {"errorCode":500,"errorMessage":"","possibleResponsibleField":""}
ERROR [2014-12-17 13:46:04,087] com.totvslabs.idm.rest.resources.scim.v2.UsersResource: getUserEntitlements : thread: dw-70 - GET /rest/v2/scim/v2/extensions/Entitlements/Companies/8pgyqh13v8povt2h1397759665424/Users/hrid4xshhr7fy4ad1410975335874/old?startIndex=0&count=1&filter=&sortBy=&sortOrder=ASC&distinctBy=urn_scim_schemas_extension_2_0_Resource_externalId&resourceTypes=Company&restrictionIds=, error: {"errorCode":500,"errorMessage":"","possibleResponsibleField":""}
ERROR [2014-12-17 13:46:04,117] com.sun.jersey.spi.container.ContainerResponse: Mapped exception to response: 500 (Internal Server Error)
! com.totvslabs.idm.rest.exception.FluigIdentityExceptionResponse: null
! at com.totvslabs.idm.rest.resources.scim.v2.UserEntitlementsResource.getUserEntitlements(UserEntitlementsResource.java:262) ~[rest.jar:na]
! at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.7.0_17]
! at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[na:1.7.0_17]
! at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_17]
! at java.lang.reflect.Method.invoke(Method.java:601) ~[na:1.7.0_17]
! at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$ResponseOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:205) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.codahale.metrics.jersey.InstrumentedResourceMethodDispatchProvider$TimedRequestDispatcher.dispatch(InstrumentedResourceMethodDispatchProvider.java:30) ~[metrics-jersey-3.0.1.jar:3.0.1]
! at io.dropwizard.jersey.caching.CacheControlledResourceMethodDispatchAdapter$CacheControlledRequestDispatcher.dispatch(CacheControlledResourceMethodDispatchAdapter.java:59) ~[dropwizard-jersey-0.7.0.jar:0.7.0]
! at io.dropwizard.jersey.guava.OptionalResourceMethodDispatchAdapter$OptionalRequestDispatcher.dispatch(OptionalResourceMethodDispatchAdapter.java:37) ~[dropwizard-jersey-0.7.0.jar:0.7.0]
! at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.ResourceObjectRule.accept(ResourceObjectRule.java:100) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409) [jersey-servlet-1.18.1.jar:1.18.1]
! at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:540) [jersey-servlet-1.18.1.jar:1.18.1]
! at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:715) [jersey-servlet-1.18.1.jar:1.18.1]
! at javax.servlet.http.HttpServlet.service(HttpServlet.java:848) [javax.servlet-3.0.0.v201112011016.jar:na]
! at io.dropwizard.jetty.NonblockingServletHolder.handle(NonblockingServletHolder.java:49) [dropwizard-jetty-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1515) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlets.UserAgentFilter.doFilter(UserAgentFilter.java:83) [jetty-servlets-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlets.GzipFilter.doFilter(GzipFilter.java:348) [jetty-servlets-9.0.7.v20131107.jar:9.0.7.v20131107]
! at io.dropwizard.jetty.BiDiGzipFilter.doFilter(BiDiGzipFilter.java:127) [dropwizard-jetty-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1486) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at io.dropwizard.servlets.ThreadNameFilter.doFilter(ThreadNameFilter.java:29) [dropwizard-servlets-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1486) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at com.totvslabs.idm.rest.security.filter.ScimCompanyIdVerificationFilter.doFilter(ScimCompanyIdVerificationFilter.java:155) [rest.jar:na]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1486) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:519) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1097) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:448) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1031) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:136) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:173) [metrics-jetty9-3.0.1.jar:3.0.1]
! at io.dropwizard.jetty.RoutingHandler.handle(RoutingHandler.java:51) [dropwizard-jetty-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:92) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:162) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.Server.handle(Server.java:446) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:271) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:246) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.io.AbstractConnection$ReadCallback.run(AbstractConnection.java:358) [jetty-io-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:601) [jetty-util-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:532) [jetty-util-9.0.7.v20131107.jar:9.0.7.v20131107]
! at java.lang.Thread.run(Thread.java:722) [na:1.7.0_17]
187.94.60.3 -  -  [17/Dec/2014:13:46:04 +0000] "GET /rest/v2/scim/v2/extensions/Entitlements/Companies/8pgyqh13v8povt2h1397759665424/Users/hrid4xshhr7fy4ad1410975335874/old?startIndex=0&count=1&filter=&sortBy=&sortOrder=ASC&distinctBy=urn_scim_schemas_extension_2_0_Resource_externalId&resourceTypes=Company&restrictionIds= HTTP/1.1" 500 - "-" "Java/1.7.0_55" 75
INFO  [2014-12-17 13:46:08,496] com.totvslabs.idm.rest.resources.scim.v2.UsersResource: getUserEntitlements : 8pgyqh13v8povt2h1397759665424, null, hrid4xshhr7fy4ad1410975335874, Company, 0, 1, , , ASC, urn_scim_schemas_extension_2_0_Resource_externalId,
INFO  [2014-12-17 13:46:08,496] com.totvslabs.idm.rest.resources.scim.v2.UsersResource: filter ==
WARN  [2014-12-17 13:46:08,532] com.totvslabs.idm.rest.bo.impl.NeoExtensionFluigUserBoImpl: getEntitlementsOfUser failed : thread: dw-70 - GET /rest/v2/scim/v2/extensions/Entitlements/Companies/8pgyqh13v8povt2h1397759665424/Users/hrid4xshhr7fy4ad1410975335874/old?startIndex=0&count=1&filter=&sortBy=&sortOrder=ASC&distinctBy=urn_scim_schemas_extension_2_0_Resource_externalId&resourceTypes=Company&restrictionIds=, {"errorCode":500,"errorMessage":"","possibleResponsibleField":""}
ERROR [2014-12-17 13:46:08,533] com.totvslabs.idm.rest.resources.scim.v2.UsersResource: getUserEntitlements : thread: dw-70 - GET /rest/v2/scim/v2/extensions/Entitlements/Companies/8pgyqh13v8povt2h1397759665424/Users/hrid4xshhr7fy4ad1410975335874/old?startIndex=0&count=1&filter=&sortBy=&sortOrder=ASC&distinctBy=urn_scim_schemas_extension_2_0_Resource_externalId&resourceTypes=Company&restrictionIds=, error: {"errorCode":500,"errorMessage":"","possibleResponsibleField":""}
ERROR [2014-12-17 13:46:08,535] com.sun.jersey.spi.container.ContainerResponse: Mapped exception to response: 500 (Internal Server Error)
! com.totvslabs.idm.rest.exception.FluigIdentityExceptionResponse: null
! at com.totvslabs.idm.rest.resources.scim.v2.UserEntitlementsResource.getUserEntitlements(UserEntitlementsResource.java:262) ~[rest.jar:na]
! at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.7.0_17]
! at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[na:1.7.0_17]
! at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_17]
! at java.lang.reflect.Method.invoke(Method.java:601) ~[na:1.7.0_17]
! at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$ResponseOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:205) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.codahale.metrics.jersey.InstrumentedResourceMethodDispatchProvider$TimedRequestDispatcher.dispatch(InstrumentedResourceMethodDispatchProvider.java:30) ~[metrics-jersey-3.0.1.jar:3.0.1]
! at io.dropwizard.jersey.caching.CacheControlledResourceMethodDispatchAdapter$CacheControlledRequestDispatcher.dispatch(CacheControlledResourceMethodDispatchAdapter.java:59) ~[dropwizard-jersey-0.7.0.jar:0.7.0]
! at io.dropwizard.jersey.guava.OptionalResourceMethodDispatchAdapter$OptionalRequestDispatcher.dispatch(OptionalResourceMethodDispatchAdapter.java:37) ~[dropwizard-jersey-0.7.0.jar:0.7.0]
! at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.ResourceObjectRule.accept(ResourceObjectRule.java:100) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409) [jersey-servlet-1.18.1.jar:1.18.1]
! at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:540) [jersey-servlet-1.18.1.jar:1.18.1]
! at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:715) [jersey-servlet-1.18.1.jar:1.18.1]
! at javax.servlet.http.HttpServlet.service(HttpServlet.java:848) [javax.servlet-3.0.0.v201112011016.jar:na]
! at io.dropwizard.jetty.NonblockingServletHolder.handle(NonblockingServletHolder.java:49) [dropwizard-jetty-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1515) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlets.UserAgentFilter.doFilter(UserAgentFilter.java:83) [jetty-servlets-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlets.GzipFilter.doFilter(GzipFilter.java:348) [jetty-servlets-9.0.7.v20131107.jar:9.0.7.v20131107]
! at io.dropwizard.jetty.BiDiGzipFilter.doFilter(BiDiGzipFilter.java:127) [dropwizard-jetty-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1486) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at io.dropwizard.servlets.ThreadNameFilter.doFilter(ThreadNameFilter.java:29) [dropwizard-servlets-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1486) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at com.totvslabs.idm.rest.security.filter.ScimCompanyIdVerificationFilter.doFilter(ScimCompanyIdVerificationFilter.java:155) [rest.jar:na]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1486) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:519) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1097) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:448) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1031) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:136) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:173) [metrics-jetty9-3.0.1.jar:3.0.1]
! at io.dropwizard.jetty.RoutingHandler.handle(RoutingHandler.java:51) [dropwizard-jetty-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:92) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:162) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.Server.handle(Server.java:446) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:271) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:246) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.io.AbstractConnection$ReadCallback.run(AbstractConnection.java:358) [jetty-io-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:601) [jetty-util-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:532) [jetty-util-9.0.7.v20131107.jar:9.0.7.v20131107]
! at java.lang.Thread.run(Thread.java:722) [na:1.7.0_17]
INFO  [2014-12-17 13:46:08,496] com.totvslabs.idm.rest.resources.scim.v2.UsersResource: getUserEntitlements : 8pgyqh13v8povt2h1397759665424, null, hrid4xshhr7fy4ad1410975335874, Company, 0, 1, , , ASC, urn_scim_schemas_extension_2_0_Resource_externalId,
INFO  [2014-12-17 13:46:08,496] com.totvslabs.idm.rest.resources.scim.v2.UsersResource: filter ==
WARN  [2014-12-17 13:46:08,532] com.totvslabs.idm.rest.bo.impl.NeoExtensionFluigUserBoImpl: getEntitlementsOfUser failed : thread: dw-70 - GET /rest/v2/scim/v2/extensions/Entitlements/Companies/8pgyqh13v8povt2h1397759665424/Users/hrid4xshhr7fy4ad1410975335874/old?startIndex=0&count=1&filter=&sortBy=&sortOrder=ASC&distinctBy=urn_scim_schemas_extension_2_0_Resource_externalId&resourceTypes=Company&restrictionIds=, {"errorCode":500,"errorMessage":"","possibleResponsibleField":""}
ERROR [2014-12-17 13:46:08,533] com.totvslabs.idm.rest.resources.scim.v2.UsersResource: getUserEntitlements : thread: dw-70 - GET /rest/v2/scim/v2/extensions/Entitlements/Companies/8pgyqh13v8povt2h1397759665424/Users/hrid4xshhr7fy4ad1410975335874/old?startIndex=0&count=1&filter=&sortBy=&sortOrder=ASC&distinctBy=urn_scim_schemas_extension_2_0_Resource_externalId&resourceTypes=Company&restrictionIds=, error: {"errorCode":500,"errorMessage":"","possibleResponsibleField":""}
ERROR [2014-12-17 13:46:08,535] com.sun.jersey.spi.container.ContainerResponse: Mapped exception to response: 500 (Internal Server Error)
! com.totvslabs.idm.rest.exception.FluigIdentityExceptionResponse: null
! at com.totvslabs.idm.rest.resources.scim.v2.UserEntitlementsResource.getUserEntitlements(UserEntitlementsResource.java:262) ~[rest.jar:na]
! at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.7.0_17]
! at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[na:1.7.0_17]
! at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_17]
! at java.lang.reflect.Method.invoke(Method.java:601) ~[na:1.7.0_17]
! at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$ResponseOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:205) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.codahale.metrics.jersey.InstrumentedResourceMethodDispatchProvider$TimedRequestDispatcher.dispatch(InstrumentedResourceMethodDispatchProvider.java:30) ~[metrics-jersey-3.0.1.jar:3.0.1]
! at io.dropwizard.jersey.caching.CacheControlledResourceMethodDispatchAdapter$CacheControlledRequestDispatcher.dispatch(CacheControlledResourceMethodDispatchAdapter.java:59) ~[dropwizard-jersey-0.7.0.jar:0.7.0]
! at io.dropwizard.jersey.guava.OptionalResourceMethodDispatchAdapter$OptionalRequestDispatcher.dispatch(OptionalResourceMethodDispatchAdapter.java:37) ~[dropwizard-jersey-0.7.0.jar:0.7.0]
! at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.ResourceObjectRule.accept(ResourceObjectRule.java:100) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84) ~[jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409) [jersey-server-1.18.1.jar:1.18.1]
! at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409) [jersey-servlet-1.18.1.jar:1.18.1]
! at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:540) [jersey-servlet-1.18.1.jar:1.18.1]
! at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:715) [jersey-servlet-1.18.1.jar:1.18.1]
! at javax.servlet.http.HttpServlet.service(HttpServlet.java:848) [javax.servlet-3.0.0.v201112011016.jar:na]
! at io.dropwizard.jetty.NonblockingServletHolder.handle(NonblockingServletHolder.java:49) [dropwizard-jetty-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1515) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlets.UserAgentFilter.doFilter(UserAgentFilter.java:83) [jetty-servlets-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlets.GzipFilter.doFilter(GzipFilter.java:348) [jetty-servlets-9.0.7.v20131107.jar:9.0.7.v20131107]
! at io.dropwizard.jetty.BiDiGzipFilter.doFilter(BiDiGzipFilter.java:127) [dropwizard-jetty-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1486) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at io.dropwizard.servlets.ThreadNameFilter.doFilter(ThreadNameFilter.java:29) [dropwizard-servlets-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1486) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at com.totvslabs.idm.rest.security.filter.ScimCompanyIdVerificationFilter.doFilter(ScimCompanyIdVerificationFilter.java:155) [rest.jar:na]
! at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1486) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:519) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1097) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:448) [jetty-servlet-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1031) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:136) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:173) [metrics-jetty9-3.0.1.jar:3.0.1]
! at io.dropwizard.jetty.RoutingHandler.handle(RoutingHandler.java:51) [dropwizard-jetty-0.7.0.jar:0.7.0]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:92) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:162) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.Server.handle(Server.java:446) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:271) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:246) [jetty-server-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.io.AbstractConnection$ReadCallback.run(AbstractConnection.java:358) [jetty-io-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:601) [jetty-util-9.0.7.v20131107.jar:9.0.7.v20131107]
! at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:532) [jetty-util-9.0.7.v20131107.jar:9.0.7.v20131107]
! at java.lang.Thread.run(Thread.java:722) [na:1.7.0_17]
187.94.60.3 -  -  [17/Dec/2014:13:46:08 +0000] "GET /rest/v2/scim/v2/extensions/Entitlements/Companies/8pgyqh13v8povt2h1397759665424/Users/hrid4xshhr7fy4ad1410975335874/old?startIndex=0&count=1&filter=&sortBy=&sortOrder=ASC&distinctBy=urn_scim_schemas_extension_2_0_Resource_externalId&resourceTypes=Company&restrictionIds= HTTP/1.1" 500 - "-" "Java/1.7.0_55" 51
187.94.58.66 -  -  [17/Dec/2014:13:46:11 +0000] "GET /rest/v2/companies/zf0y84vo717g8hjx/users/email/ricardo@alvesbarreto.com.br HTTP/1.1" 200 - "-" "Java/1.6.0_11" 28
root@app1:/data/fluigidentity-logs#
#+END_EXAMPLE
** DELEGATE [#B] Debug rmi fd issue for app02
  CLOSED: [2015-01-20 Tue 14:07]
#+BEGIN_EXAMPLE
[1/7/15, 4:04:11 PM] Shivang: we just use
[1/7/15, 4:04:20 PM] Shivang: https://{companydomain}/cloudpass
[1/7/15, 4:04:31 PM] Shivang: and if there is any port (when testing locally) we use the prot as well
[1/7/15, 4:04:38 PM] Shivang: but other than that .. we don't use the full url
[1/7/15, 4:04:48 PM] Shivang: I am pushing this fix now ..
[1/7/15, 4:05:14 PM] denny: If one customer’s port is 123, another customer’s port is 124, we need some way to enable customer tell us. Right?
[1/7/15, 4:05:27 PM] Shivang: but we put apache in the front right?
[1/7/15, 4:05:32 PM] Shivang: and that will be taken care of by apache
[1/7/15, 4:05:41 PM] Shivang: normally even for onPremises we don't expect to see ports
[1/7/15, 4:05:43 PM] Shivang: for example
[1/7/15, 4:05:59 PM] Shivang: https://identity.brin3.com.br:8080/cloudpass
[1/7/15, 4:06:07 PM] Shivang: that won't happen (hopefully not)
[1/7/15, 4:06:36 PM] denny: To be simple, it’s hard code as 443 in most cases?
[1/7/15, 4:06:59 PM] Shivang: no .. for simplicity we always assume that
[1/7/15, 4:07:16 PM] Shivang: our product's apache configuration is solid and that we will always use https
[1/7/15, 4:07:24 PM] Shivang: if for some customers this is not the case, we can go in DB and change it
[1/7/15, 4:07:36 PM] denny: I see.
[1/7/15, 4:07:47 PM] denny: So can I safely ignore this in my side?
[1/7/15, 4:08:20 PM] Shivang: yes .. you can
[1/7/15, 4:08:23 PM] Shivang: i am about to push this to master
[1/7/15, 4:08:25 PM] Shivang: you can test it
[1/7/15, 4:08:56 PM] denny: How can I test that in detail?

And looks like it should go to QA effort.
[1/7/15, 4:09:50 PM] Shivang: yes .. i think they can test with 1.4.3 for an onpremises deployment (not sure how much qa tests in terms of onpremises though .. they are going to ask for an env to eb deployed as onpremises every release)
[1/7/15, 4:10:01 PM] Shivang: i fixed the bug in both 1.4.3 and master
[1/7/15, 4:11:45 PM] denny: How about this?

I still have the open issue of auto-assign for RAC agent, when I deploy on-premise master branch for that.

I ask you to verify this change of base url.
[1/7/15, 4:13:08 PM] Shivang: sorry back
[1/7/15, 4:13:13 PM] Shivang: yes .. sounds good
[1/7/15, 4:13:18 PM] Shivang: we test both of them together
[1/7/15, 4:14:01 PM] denny: Let me handle #1 first.

Looks like it blocks Vicente’s test for on-premise
[1/7/15, 4:14:40 PM] denny: Then I will go back to #2.

For now, my questions is the fd problem happens in app02, instead of machine of couch base.
[1/7/15, 4:15:12 PM] denny: Also the max open fd count of RMI service is 4096, from my check this morning
[1/7/15, 4:15:32 PM] Shivang: i looked on both prodapp1
[1/7/15, 4:15:32 PM] Shivang: and prodapp2
[1/7/15, 4:15:34 PM] Shivang: it was 1024
[1/7/15, 4:15:55 PM] Shivang: root@app1:~# ulimit -n
1024
root@app1:~#
[1/7/15, 4:16:01 PM] denny: Repost
[1/7/15, 10:50:54 AM] denny: And system’s ulimit is ulimited
[1/7/15, 10:51:16 AM] denny: root@app2:/proc/62253# ulimit
ulimit
unlimited
root@app2:/proc/62253# cat /proc/62253/limits | grep 'Max open files'
cat /proc/62253/limits | grep 'Max open files'
Max open files            4096                 4096                 files
[1/7/15, 4:16:31 PM] denny: Different process may have different ulimit, which may be different for system wise.

See something like /proc/$pid/limits
[1/7/15, 4:17:11 PM] Shivang: let me google a bit more on that
[1/7/15, 4:17:32 PM] Shivang: root@app2:~# ulimit -a
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 257217
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 257217
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
[1/7/15, 4:17:38 PM] Shivang: open files = 1024
[1/7/15, 4:18:41 PM] denny: I will work together with you on this, after finding out issue #1.
[1/7/15, 4:19:00 PM] denny: Different process’s open file count is different.
[1/7/15, 4:19:08 PM] Shivang: sure
[1/7/15, 4:19:09 PM] Shivang: that's fine
[1/7/15, 4:19:13 PM] Shivang: lets look at that later
[1/7/15, 4:20:44 PM] Shivang: just posting a link here for more reading ..
[1/7/15, 4:20:44 PM] Shivang: http://stackoverflow.com/questions/34588/how-do-i-change-the-number-of-open-files-limit-in-linux
[1/7/15, 4:20:59 PM] Shivang: this also talks about that apache issue we had couple of times in qa1b
[1/7/15, 4:21:05 PM] Shivang: [alert] (11)Resource temporarily unavailable: apr_thread_create: unable to create worker thread
[1/7/15, 4:23:15 PM] denny: That’s cool
[1/7/15, 6:38:37 PM] denny: Hi Shivang, do you have time for the fd issue?
[1/7/15, 6:38:51 PM] Shivang: defnitely
[1/7/15, 6:38:53 PM] Shivang: i sent out an email
[1/7/15, 6:38:58 PM] Shivang: from what I think is my analysis
[1/7/15, 6:39:13 PM] Shivang: and my strong recommendation for what I read in mongodb forum as well .
[1/7/15, 6:39:18 PM] denny: Yes, that’s an informative email.

Which machine’s ulimit you would suggest to change?
[1/7/15, 6:39:42 PM] Shivang: not couchbase ..
[1/7/15, 6:39:48 PM] Shivang: acutally it take it back
[1/7/15, 6:39:53 PM] Shivang: it should be ALL the machines
[1/7/15, 6:39:58 PM] Shivang: but we can start off with only
[1/7/15, 6:40:02 PM] Shivang: app servers and the rac server
[1/7/15, 6:40:15 PM] Shivang: you will need to restart the whole stack (or from what I read the whole machine)
[1/7/15, 6:40:19 PM] Shivang: espeically because these are
[1/7/15, 6:40:21 PM] denny: Hold on.
[1/7/15, 6:40:23 PM] Shivang: OS level changes
[1/7/15, 6:40:38 PM] denny: Does any part of identity has mongodb?
[1/7/15, 6:41:37 PM] Shivang: no
[1/7/15, 6:43:32 PM] denny: Let me read through your  email again carefully
[1/7/15, 6:44:07 PM] Shivang: ya no problem
[1/7/15, 6:44:48 PM] denny: First, I’m 100% sure, when the problem happen RMI fd limit in app02 is 4096.
[1/7/15, 6:45:01 PM] denny: root@app2:/proc/62253# cat /proc/62253/limits | grep 'Max open files'
cat /proc/62253/limits | grep 'Max open files'
Max open files            4096                 4096                 files
[1/7/15, 6:45:19 PM] denny: =============
I’m guessing, you’re saying 4096 is too small. Right?
[1/7/15, 6:47:53 PM] Shivang: i still don't quite agree that its 4096
[1/7/15, 6:48:00 PM] Shivang: if I follow the text book version of google
[1/7/15, 6:48:05 PM] Shivang: the command still tells me its 1024
[1/7/15, 6:48:15 PM] denny: Do you see the above command output?
[1/7/15, 6:48:25 PM] Shivang: ya .. did you set it specific for that process?
[1/7/15, 6:48:44 PM] denny: That was RMI of app02 this morning
[1/7/15, 6:48:51 PM] Shivang: ya but specific to that process?
[1/7/15, 6:48:54 PM] Shivang: 62253?
[1/7/15, 6:48:58 PM] denny: Yes
[1/7/15, 6:49:09 PM] Shivang: ok .. i don't know how FD works .. I will leave that part on you
[1/7/15, 6:49:11 PM] Shivang: from what I know .. when i do
[1/7/15, 6:49:13 PM] Shivang: ulimit -n
[1/7/15, 6:49:29 PM] Shivang: it shows 1024 .. which should be a much much bigger number (according to the forums i shared)
[1/7/15, 6:49:35 PM] Shivang: I will leave it to your best judgement on this one
[1/7/15, 6:51:08 PM] denny: Whatever 4096 or 1024, it’s not big enough.

That’s the point, right?
[1/7/15, 6:51:22 PM] Shivang: yes .. per the forums
[1/7/15, 6:52:06 PM] Shivang: http://support.couchbase.com/requests/7711
[1/7/15, 6:52:11 PM] Shivang: i created a
[1/7/15, 6:52:17 PM] Shivang: ticket for couchbase as well
[1/7/15, 6:52:18 PM] Shivang: to give us suggestions
[1/7/15, 6:52:53 PM] denny: Got it. Let me play with that later. Will reply the email tomorrow
[1/7/15, 6:53:04 PM] Shivang: no problem at all ..
[1/7/15, 6:54:14 PM] denny: If fd of Rmi keeps going up for a month, does that means something wrong?
[1/7/15, 6:54:32 PM] Shivang: yes .. if you look at the last part of the email
[1/7/15, 6:54:36 PM] Shivang: you will see what I am saying ..
[1/7/15, 6:54:54 PM] denny: Great
#+END_EXAMPLE
** TODO [#A] Service stop may hang: search/rest stuck in neo4j; neo4j run into recovery mode
* [#A] Cooperation with different teams
** Principle: Don't commit or reject immediately with your gut feeling hastily
- Whenever accept a request which takes over 30 min, remember to pause and think before answer
** Principle: when people from different team is helping you, don't reply with everything is done before fully test
*** TODO mail: RES: machine upgrades needed for our customers using user experience :noexport:
[[gnus:mail.misc#1D54E75757FC234EAD2AA394612CA17A3406F1DA@HYPERION.sp01.local][Email from Ovidio Borba, Jr. (Thu, 29 Jan 2015 13:02:42 -0600): RES: machine upgrades needed f]]
#+begin_example
From: Ovidio Borba Jr <ovidiojr@totvs.com.br>
Subject: RES: machine upgrades needed for our customers using user experience
To: Denny Zhang <denny.zhang@totvs.com>, Lucas Ciriaco dos Santos
        <lucas.ciriaco@totvs.com.br>, Eduardo Elias El Assais <eduardo@totvs.com.br>,
        Kung Wang <kung.wang@totvs.com>, Paulo Roberto Nobuo Maekawa
        <nobuo@totvs.com.br>
CC: Vinicius Mendes da Silva <vinicius@totvs.com.br>, Vicente Goetten
        <goetten@totvs.com>, sp.datacenter.gc <sp.datacenter.gc@totvs.com.br>
Date: Thu, 29 Jan 2015 13:02:42 -0600

Denny,

In order to mount an NFS share, you need to install a package name nfs-common (apt-get install
nfs-common).

I just installed it at 172.20.18.27 server and I was able to mount:

root@id-app:/sbin# ll /shared/

total 52

drwxrwx--x  6 root root 8192 Dec 17 16:19 ./

drwxr-xr-x 26 root root 4096 Jan 29 13:28 ../

-rw-r--r--  1 root root   67 Sep 19 04:05 NagiosCheck

drwxr-xr-x 12 root root 8192 Dec 16 15:19 backup/

drwx------  2 root root 8192 Aug 12 21:02 data/

drwxr-xr-x  2 root root 8192 Jan 28 18:17 to_be_deleted/

drwxr-xr-x 13 1100 1100 8192 Jul 22  2014 www/

If you have any doubt, feel free to contact me.

Regards,

cid:image001.png@01CF160E.33FDFBB0 Ovidio Borba Jr
                                   Datacenter TOTVS – Infraestrutura e
                                   Armazenamento

                                   ovidiojr@totvs.com.br

                                   Tel +55 11 2099 8199
                                   Cel +55 11 99148 6132

De: Denny Zhang
Enviada em: quinta-feira, 29 de janeiro de 2015 14:25
Para: Ovidio Borba Jr; Lucas Ciriaco dos Santos; Eduardo Elias El Assais; Kung Wang; Paulo Roberto
Nobuo Maekawa
Cc: Vinicius Mendes da Silva; Vicente Goetten; sp.datacenter.gc
Assunto: RE: machine upgrades needed for our customers using user experience

Great, Ovidio.

Looks like I can't mount from 172.20.18.27. Could you please help to check?

root@id-app:~# ifconfig | grep 'inet addr'

ifconfig | grep 'inet addr'

          inet addr:172.20.18.27  Bcast:172.20.18.128  Mask:255.255.255.128

          inet addr:127.0.0.1  Mask:255.0.0.0

root@id-app:~# mount -t nfs 172.20.16.27:/ibm/totvs01/fluig-id /shared

mount -t nfs 172.20.16.27:/ibm/totvs01/fluig-id /shared

mount: wrong fs type, bad option, bad superblock on 172.20.16.27:/ibm/totvs01/fluig-id,

       missing codepage or helper program, or other error

       (for several filesystems (e.g. nfs, cifs) you might

       need a /sbin/mount.<type> helper program)

       In some cases useful info is found in syslog - try

       dmesg | tail  or so

Regards,

Denny

---------------------------------------------------------------------------------------------------

From: Ovidio Borba Jr
Sent: Thursday, January 29, 2015 10:16 AM
To: Denny Zhang; Lucas Ciriaco dos Santos; Eduardo Elias El Assais; Kung Wang; Paulo Roberto Nobuo
Maekawa
Cc: Vinicius Mendes da Silva; Vicente Goetten; sp.datacenter.gc
Subject: RES: machine upgrades needed for our customers using user experience

Hi Denny, how are you?

I just added these IP´s to /ibm/totvs01/fluig-id mount point permissions.

If you have any problem with the NFS, please talk to me.

Regards,

cid:image001.png@01CF160E.33FDFBB0 Ovidio Borba Jr
                                   Datacenter TOTVS – Infraestrutura e
                                   Armazenamento

                                   ovidiojr@totvs.com.br

                                   Tel +55 11 2099 8199
                                   Cel +55 11 99148 6132

De: Denny Zhang
Enviada em: quinta-feira, 29 de janeiro de 2015 12:19
Para: Lucas Ciriaco dos Santos; Eduardo Elias El Assais; Kung Wang; Paulo Roberto Nobuo Maekawa
Cc: Vinicius Mendes da Silva; Vicente Goetten; sp.datacenter.gc
Assunto: RE: machine upgrades needed for our customers using user experience

Lucas, Thanks!

Reposted:

Looks like all VMs don't have access to internet, which blocks the deployment.

Who can help us to configure firewall for the 5 VMs:

- Allow all outgoing traffic

[Denny] Could you help us on this. I just tried, VM can't download files from several external
critical website

- Allow incoming traffic for port 443 and port 80

[Denny] It's done, verified

- Allow incoming ssh traffic for port 22, only if the IP is from VPN.

[Denny] It's done, verified

[Denny] Any one can help us to make sure the VM can mount NFS share directory.

Like: mount -t nfs 172.20.16.27:/ibm/totvs01/fluig-id /shared

Regards,

Denny

---------------------------------------------------------------------------------------------------

From: Lucas Ciriaco dos Santos
Sent: Thursday, January 29, 2015 7:25 AM
To: Eduardo Elias El Assais; Kung Wang; Paulo Roberto Nobuo Maekawa
Cc: Vinicius Mendes da Silva; Vicente Goetten; sp.datacenter.gc; Denny Zhang
Subject: RES: machine upgrades needed for our customers using user experience

Hi Denny!

Port 80 and 443 were created, follows:

                                  NAT IN

                 Name                   Private IP    Public IP     Port

                id-app                 172.20.18.27 187.94.63.141    80
                                                                    443

                id-msg                 172.20.18.28 187.94.63.142    80
                                                                    443

             id-racagent               172.20.18.29 187.94.63.143    80
                                                                    443

             id-keystore               172.20.18.30 187.94.63.144    80
                                                                    443

                id-cb                  172.20.18.31 187.94.63.145    80
                                                                    443

De: Eduardo Elias El Assais
Enviada em: quarta-feira, 28 de janeiro de 2015 17:10
Para: Kung Wang; Paulo Roberto Nobuo Maekawa
Cc: Vinicius Mendes da Silva; Vicente Goetten; sp.datacenter.gc; Denny Zhang; Lucas Ciriaco dos
Santos
Assunto: RES: machine upgrades needed for our customers using user experience

+Lucas Ciriaco to proceed with the rules.

De: Kung Wang
Enviada em: quarta-feira, 28 de janeiro de 2015 14:59
Para: Paulo Roberto Nobuo Maekawa
Cc: Eduardo Elias El Assais; Vinicius Mendes da Silva; Vicente Goetten; sp.datacenter.gc; Denny
Zhang
Assunto: Re: machine upgrades needed for our customers using user experience

Paulo,

Here are ports we like to open for each machine, please help us open these port to the right target
servers.

Thank you,

machine port              open targets

id-app                 80 public

    443 public

22

all internal IPs

                                                                                              11111

id-racagent

id-msg

                                                                                                 22

all internal IPs

                                                                                               2098

id-app, id-racagent

                                                                                               2099

id-app, id-racagent

                                                                                               5445

id-app, id-racagent

                                                                                               5455

id-app, id-racagent

                                                                                               7474

id-app, id-racagent

                                                                                              18084

id-app, id-racagent

id-racagent

                                                                                                 22

all internal IPs

id-keystore

                                                                                                 22

all internal IPs

                                                                                              11122

id-app, id-racagent

id-cb

                                                                                                 22

all internal IPs

                                                                                               8091

all internal IPs

                                                                                               8092

id-app, id-racagent

                                                                                              11207

id-app, id-racagent

                                                                                              11209

id-app, id-racagent

                                                                                              11210

id-app, id-racagent

                                                                                              11211

id-app, id-racagent

                                                                                              18091

all internal IPs

                                                                                              18092

id-app, id-racagent

    On Jan 28, 2015, at 8:19 AM, Denny Zhang <denny.zhang@totvs.com> wrote:

    Hi Paulo

    I'm deploying the identity on this cluster.

    Looks like all VMs don't have access to internet, which blocks the deployment.

    Who can help us to configure firewall for the 5 VMs:

    - Allow all outgoing traffic

    - Allow incoming traffic for port 443 and port 80

    - Allow incoming ssh traffic for port 22, only if the IP is from VPN.

    Regards,

    Denny

    -----------------------------------------------------------------------------------------------

    From: Paulo Roberto Nobuo Maekawa
    Sent: Wednesday, January 28, 2015 2:28 AM
    To: Denny Zhang; Eduardo Elias El Assais; Vinicius Mendes da Silva; Vicente Goetten; Kung Wang
    Cc: sp.datacenter.gc
    Subject: RES: machine upgrades needed for our customers using user experience

    Hi Denny

    The correct sheet is

        name          ip         mem       vcpu       hd          SO

       id-app    172.20.18.27     16         8        50        Ubuntu

       id-msg    172.20.18.28     16         8        300       Ubuntu

    id-racagent  172.20.18.29     16         8        50        Ubuntu

    id-keystore  172.20.18.30     4          2        50        Ubuntu

       id-cb     172.20.18.31     8          4        50        Ubuntu

    All VMs are assecible now

    We will allow the access to NFS server for these VMs

    <image001.png>     Paulo Roberto Nobuo Maekawa
                       IDSI – Infraestrutura, Datacenter e Segurança da
                       Informação

                       paulo.maekawa@totvs.com.br

                       Cel +55 11 99977 3614   /   +55 11 99197 9869

    De: Denny Zhang
    Enviada em: quarta-feira, 28 de janeiro de 2015 02:36
    Para: Paulo Roberto Nobuo Maekawa; Eduardo Elias El Assais; Vinicius Mendes da Silva; Vicente
    Goetten; Kung Wang
    Cc: sp.datacenter.gc
    Assunto: RE: machine upgrades needed for our customers using user experience

    Thanks, Paulo

    About monitoring, we will add related nagios checks in http://172.20.16.13/nagios3. That nagios
    sever monitors all critical envs.

    About backup, we will setup daily local backup, and copy the latest backup set to remote NFS
    server like prod env.

    Some issues shall need you help:

    1. IP of  id-racagent and id-msg are the same in the table.

    2. I can't ssh to 172.20.18.29/172.20.18.31

    3. Since we will copy backup set to remote NFS server, does these machine able to mount NFS
    server?

    Regards,

    Denny

    -----------------------------------------------------------------------------------------------

    From: Paulo Roberto Nobuo Maekawa
    Sent: Tuesday, January 27, 2015 9:44 PM
    To: Denny Zhang; Eduardo Elias El Assais; Vinicius Mendes da Silva; Vicente Goetten; Kung Wang
    Cc: sp.datacenter.gc
    Subject: RES: machine upgrades needed for our customers using user experience

    Hi Denny

    The VMs are available

        name          ip         mem       vcpu       hd          SO

       id-app    172.20.18.27     16         8        50        Ubuntu

       id-msg    172.20.18.28     16         8        300       Ubuntu

    id-racagent  172.20.18.28     16         8        50        Ubuntu

    id-keystore  172.20.18.30     4          2        50        Ubuntu

       id-cb     172.20.18.31     8          4        50        Ubuntu

    User – root

    Password – totvs@123

    Are necessary backup and monitoring?

    <image001.png>     Paulo Roberto Nobuo Maekawa
                       IDSI – Infraestrutura, Datacenter e Segurança da
                       Informação

                       paulo.maekawa@totvs.com.br

                       Cel +55 11 99977 3614   /   +55 11 99197 9869

    De: Denny Zhang
    Enviada em: terça-feira, 27 de janeiro de 2015 23:00
    Para: Paulo Roberto Nobuo Maekawa; Eduardo Elias El Assais; Vinicius Mendes da Silva; Vicente
    Goetten; Kung Wang
    Assunto: RE: machine upgrades needed for our customers using user experience

    Hi Paulo

    Yes, 5 new VMs in 172.20.18.0 network works.

    No special requirement for the names.

    Either "node1, node2, node3, node4 and node5" or "id-app, id-msg, id-racagent, id-keystore,
    id-cb".

    Regards,

    Denny

    -----------------------------------------------------------------------------------------------

    From: Paulo Roberto Nobuo Maekawa
    Sent: Tuesday, January 27, 2015 6:26 PM
    To: Eduardo Elias El Assais; Vinicius Mendes da Silva; Vicente Goetten; Kung Wang; Denny Zhang
    Subject: RES: machine upgrades needed for our customers using user experience

    Hi Kung

    Just to confirm. Your request is to provide you these 5 new VMs in the network 172.20.18.0?

    That’s it

    Which name for each VM do you want?

    <image001.png>     Paulo Roberto Nobuo Maekawa
                       IDSI – Infraestrutura, Datacenter e Segurança da
                       Informação

                       paulo.maekawa@totvs.com.br

                       Cel +55 11 99977 3614   /   +55 11 99197 9869

    De: Eduardo Elias El Assais
    Enviada em: terça-feira, 27 de janeiro de 2015 20:51
    Para: Paulo Roberto Nobuo Maekawa
    Assunto: ENC: machine upgrades needed for our customers using user experience

    Nobuo,

    Consegue viabilizar isso?

    Abs,

    E Assais

    De: Vinicius Mendes da Silva
    Enviada em: terça-feira, 27 de janeiro de 2015 20:41
    Para: Vicente Goetten; Kung Wang; Alexandre Picagli Gallo Lavrador; Eduardo Elias El Assais
    Cc: Denny Zhang
    Assunto: RES: machine upgrades needed for our customers using user experience

    Edu,

                    Please check and return to Vicente.

                    Obrigado.

    Att.

    Vinicius

    De: Vicente Goetten
    Enviada em: terça-feira, 27 de janeiro de 2015 17:41
    Para: Kung Wang; Alexandre Picagli Gallo Lavrador; Vinicius Mendes da Silva
    Cc: Denny Zhang
    Assunto: Re: machine upgrades needed for our customers using user experience
    Prioridade: Alta

    Alexandre and Vinicius,

    We need this upgrade ASAP since it is going to be used for a huge conference where several
    demos will be done. Please let us know the estimation to complete the upgrade.

    Thanks

    Vicente Goetten

    +1 650 933-4902   -   goetten@totvs.com

    From: Kung Wang <kung.wang@totvs.com>
    Date: Monday, January 26, 2015 at 11:56 AM
    To: Alexandre Picagli Gallo Lavrador <alexandre.lavrador@totvs.com.br>
    Cc: Vinicius Mendes da Silva <vinicius@totvs.com.br>, Denny Zhang <denny.zhang@totvs.com>,
    Vicente Goetten <goetten@totvs.com>
    Subject: machine upgrades needed for our customers using user experience

    Alex,

    Currently we have a all-in-one machine to support all our customer’s testing on user experience
    project. Recently, we found this machine now is under power to support all our customers.

    Here we propose upgrade this machine to multi-machine layout, similar to production, to support
    more customers we will be having.

    | Name  | Role                              | Spec                            |

    |-------+-----------------------------------+---------------------------------|

    | node1 | apache, tomcat, rmi, adsync, rest | 16G mem; 8 CPU cores; 50G disk  |

    | node2 | search, hornetq, neo4j            | 16G mem; 8 CPU cores; 300G disk |

    | node3 | 2 rac agents                      | 16G mem; 8 CPU cores; 50G disk  |

    | node4 | keystore                          | 4G mem; 2 CPU cores; 50G disk   |

    | node5 | couchbase                         | 8G mem; 4 CPU cores; 50G disk   |

    Please help us provision these machines, for IT expenses and cost calculation, please ping
    Vicente for details.

    —Kung

#+end_example
** Principle: When coordinate with others, don't expect others to be the same requirement for everything
** [#A] Principle: avoid people's wrong image for my role
#+BEGIN_EXAMPLE
[1/19/15, 11:13:12 AM] Lucas Schiochet: Tks :D
[1/19/15, 11:29:38 AM] Lucas Schiochet: Denny
[1/19/15, 11:29:50 AM] Lucas Schiochet: Can you create a company called adtsys in production ?
[1/19/15, 11:30:30 AM] denny: Lucas, I only operate system at infra level, instead of feature level.

You need to contact with John for this.
[1/19/15, 11:30:39 AM] Lucas Schiochet: Ah, ok
[1/19/15, 11:30:42 AM] Lucas Schiochet: No problem
#+END_EXAMPLE
** [#A] Principle: DevOps don't own issues, but provide tools     :IMPORTANT:
http://www.quora.com/Can-DevOps-get-in-the-way-of-innovation
** [Pricinple] If people have one way out without you, keep rejecting them make things worse
** #  --8<-------------------------- separator ------------------------>8--
** Argument: Don't operate QA Test/On-premise env, but only provide documentation
/Users/mac/Dropbox/private_data/project/devops/Fluig Env List - TechOps - Confluence.pdf

- QA env is supposed to always have issues. It's time consuming and meaningless for us to be dragged into less communication
- Lead us to improve with feasible documentation
#+BEGIN_EXAMPLE
[1/26/15, 10:05:15 AM] Andre Uhlrich: good morning Denny
[1/26/15, 10:05:39 AM] denny: Morning, Andre
[1/26/15, 10:06:14 AM] Andre Uhlrich: I found an error on qafluigidentity john RAC agent. it seems to be stoped since jan24
[1/26/15, 10:06:17 AM] Andre Uhlrich: [24 Jan 2015;19:57:14.281] - [INFO ] [UserServicesThread:138] - Starting to make external calls for user with id: xvi7ys5sd4lqcb731416929670487 and application: etw9wddflxkzur591416576775681 for action: DEPROVISIONING
/cloudpass/backend/build/bin/racagent_start.sh: line 11:  6967 Aborted                 (core dumped) java $JAVA_OPTS -jar -Xms1024m -Xmx2048m $jarfile $1
[1/26/15, 10:11:12 AM] Andre Uhlrich: can you try to restart it?
[1/26/15, 10:12:50 AM] denny: I've notice the similar issue before. Would u please report it to shivang?
[1/26/15, 10:13:06 AM] Andre Uhlrich: yes, I can
[1/26/15, 10:13:21 AM] Andre Uhlrich: can you take a look into production, to see if they are ok?
[1/26/15, 10:14:05 AM] denny: Sure. Let me check
[1/26/15, 10:28:22 AM] denny: Andre, in prod env, we don’t have this issue.
[1/26/15, 10:28:42 AM] Andre Uhlrich: great
[1/26/15, 10:29:07 AM] denny: Maybe I could add a nagios check of prod env to racagent log, in order to monitor this “core dump”
[1/26/15, 10:29:11 AM] denny: Thanks for that, Andre.
[1/26/15, 10:32:55 AM] denny: BTW, if we need to restart services, here is the procedure.
https://totvslab.atlassian.net/wiki/display/TECH/Fluig+Env+List

I only directly operate prod env; For other envs like QA or dev envs, we operate according to doc.
[1/26/15, 10:33:43 AM] denny: =======================
Below info is quite sensitive.
root password of QA env: Totvs123abc

It applies to qafluigidentity/customerfi/psfliugidentity
#+END_EXAMPLE
** Propose in-house training for common questions
- win-win: Answer people for common questions, and ask them to maintain the knowledgebase
** When cooperation, declare requirements clearly
*** mail: Need help about some VMs' Network issue                  :noexport:
[[gnus:mail.misc#EF9859611DA81140B2B29B02EC8AD6EAF95932@helios.mex01.local][Email from Denny Zhang (Mon, 2 Feb 2015 12:48:57 -0600): Need help about some VMs' Netw]]
#+begin_example
From: Denny Zhang <denny.zhang@totvs.com>
Subject: Need help about some VMs' Network issue
To: sp.datacenter.redes <sp.datacenter.redes@totvs.com.br>
CC: Willian Antonio Guedes dos Santos <willian@totvs.com.br>, Kung Wang
        <kung.wang@totvs.com>, Lucas Vinicius Schiochet <lucas.schiochet@fluig.com>,
        Vicente Goetten <goetten@totvs.com>, Denny Zhang <denny.zhang@totvs.com>
Date: Mon, 02 Feb 2015 12:48:57 -0600

Hi there

Could you please help us with below network issues?

- Below VMs can't access internet.
  172.20.18.27: ping www.google.com fail
  172.20.18.28: ping www.google.com fail
  172.20.18.29: ping www.google.com fail
  172.20.18.30: ping www.google.com fail
  172.20.18.31: ping www.google.com fail

   I'm trying to deploy a new cluster env of customerfi on above VMs. Then found this issue.

- 172.20.16.13: telnet totvslabs.psfluigidentity.com 443 fail
- 172.20.16.13: telnet totvslabs.customerfi.com 443 fail

Regards,
Denny

#+end_example
** DONE [#B] Treat different people by their personality
   CLOSED: [2015-02-02 Mon 20:42]
** [#A] 态度要好: 做了一百件好事，但发一次脾气，给人的image会很不好 :IMPORTANT:
* [#A] [Risk Mgmt] Forsee potential issues and do the audit       :IMPORTANT:
** Release uncertified release to customerfi/psfliugidentiy: lots of app sync problem
** TODO [#A] Refine the process of Maintaining prod env           :IMPORTANT:
*** TODO Rollback system identity-1.3.5
scp -r /var/www/fluig_share/identity-1.3.5/ root@172.20.16.13:/home/denny/
run_command_in_all_nodes.sh "scp -r /home/denny/identity-1.3.5/ root@HOSTIP:/home/denny/" "172.21.16.11 172.21.16.12 172.20.16.14 172.20.16.20 172.20.16.16 172.20.16.11 172.20.16.12 172.20.16.26"

# replace packages and library
run_command_in_all_nodes.sh "ssh root@HOSTIP cp /home/denny/identity-1.3.5/fluig_packages/* /cloudpass/backend/build/dist/" "172.21.16.11 172.21.16.12 172.20.16.14 172.20.16.20 172.20.16.16 172.20.16.11 172.20.16.12 172.20.16.26"
run_command_in_all_nodes.sh "ssh root@HOSTIP cp /home/denny/identity-1.3.5/fluig_java_lib/* /cloudpass/backend/build/lib/" "172.21.16.11 172.21.16.12 172.20.16.14 172.20.16.20 172.20.16.16 172.20.16.11 172.20.16.12 172.20.16.26"

logback.xml <-- fine
server.propoerties <-- fine

adsync.xml <-- Need manual intervine

# In app01 and app02
/home/denny/adsync.yml

stop-all
*** DONE Maintain prod env: for intenert speed, do the internal copy: use squid
    CLOSED: [2014-11-25 Tue 17:45]
*** HALF [#A] Need to do backup for data, configuration, and packages for rollback and double check
run_command_in_all_nodes.sh "ssh root@HOSTIP mkdir -p /home/denny/backup_20141031/" "172.21.16.11 172.21.16.12 172.20.16.14 172.20.16.20 172.20.16.16 172.20.16.11 172.20.16.12 172.20.16.26"
run_command_in_all_nodes.sh "ssh root@HOSTIP cp -r /cloudpass/backend/build/config /home/denny/backup_20141031/" "172.21.16.11 172.21.16.12 172.20.16.14 172.20.16.20 172.20.16.16 172.20.16.11 172.20.16.12 172.20.16.26"
run_command_in_all_nodes.sh "ssh root@HOSTIP cp -r /cloudpass/backend/build/dist /home/denny/backup_20141031/" "172.21.16.11 172.21.16.12 172.20.16.14 172.20.16.20 172.20.16.16 172.20.16.11 172.20.16.12 172.20.16.26"
run_command_in_all_nodes.sh "ssh root@HOSTIP cp -r /cloudpass/backend/build/lib /home/denny/backup_20141031/" "172.21.16.11 172.21.16.12 172.20.16.14 172.20.16.20 172.20.16.16 172.20.16.11 172.20.16.12 172.20.16.26"
run_command_in_all_nodes.sh "ssh root@HOSTIP ls -lth /home/denny/backup_20141031/" "172.21.16.11 172.21.16.12 172.20.16.14 172.20.16.20 172.20.16.16 172.20.16.11 172.20.16.12 172.20.16.26"
*** HALF roll-back adsync.yml in app01 and app02
vim /home/denny/adsync.yml
#+begin_example
root@fluig-id-chef:/home/denny/15_simulate_11# diff -r 15 11
diff -r 15/config/adsync.yml 11/config/adsync.yml
42a43,274
> #
> hornetQClientConfiguration:
>     enabled: true
>     contextFactory: "org.jnp.interfaces.NamingContextFactory"
>     factoryPackage: "org.jboss.naming:org.jnp.interfaces"
>     providerUrl: jnp://172.20.16.16:2099
>     connectionFactory: "/ConnectionFactory"
> #    username: "adSyncServer"
> #    password: "529b9cbefa343b41727046ca06655a1e"
>
>
> loginRequestConsumerConfiguration:
>     messageTopic: "/topic/AD/LoginRequestTopic"
>     username: "adSyncServer"
>     password: "529b9cbefa343b41727046ca06655a1e"
>     messageQueueSize: 10
>     numberOfConsumers: 1
>     timerTaskInterval: 50
>
>
> importUserConsumerConfiguration:
>     messageTopic: "/topic/AD/ImportUserTopic"
>     username: "adSyncServer"
>     password: "529b9cbefa343b41727046ca06655a1e"
>     messageQueueSize: 10
>     numberOfConsumers: 1
>     # import user command will be added immediately or checked every 10 seconds if needs to be added
>     timerTaskInterval: 10000
>
>
> adVerificationResultProducerConfiguration:
>     messageTopic: "/topic/AD/VerifiedTopic"
>     username: "adSyncServer"
>     password: "529b9cbefa343b41727046ca06655a1e"
>     messageQueueSize: 100
>     numberOfProducers: 10
>     producerQueueSize: 10
>
> adSyncResultTimerConfiguration:
>     timerTaskInterval: 50
>
> changePasswordResultProducerConfiguration:
>     messageTopic: "/topic/AD/ChangePasswordResultTopic"
>     username: "adSyncServer"
>     password: "529b9cbefa343b41727046ca06655a1e"
>     messageQueueSize: 100
>     numberOfProducers: 10
>     producerQueueSize: 10
>     timerTaskInterval: 500
>
>
> changePasswordConsumerConfiguration:
>     messageTopic: "/topic/AD/ChangePasswordTopic"
>     username: "adSyncServer"
>     password: "529b9cbefa343b41727046ca06655a1e"
>     messageQueueSize: 10
>     numberOfConsumers: 1
>
>
> changePasswordResultTimerConfiguration:
>     timerTaskInterval: 500
>
>
> createUserResultProducerConfiguration:
>     messageTopic: "/topic/AD/CreateUserResultTopic"
>     username: "adSyncServer"
>     password: "529b9cbefa343b41727046ca06655a1e"
>     messageQueueSize: 100
>     numberOfProducers: 10
>     producerQueueSize: 10
>     timerTaskInterval: 500
>
>
> createUserConsumerConfiguration:
>     messageTopic: "/topic/AD/CreateUserTopic"
>     username: "adSyncServer"
>     password: "529b9cbefa343b41727046ca06655a1e"
>     messageQueueSize: 10
>     numberOfConsumers: 1
>
>
> createUserResultTimerConfiguration:
>     timerTaskInterval: 500
>
> queryADGroupsProducerConfiguration:
>     messageTopic: "/topic/AD/GetGroupsResultTopic"
>     username: "adSyncServer"
>     password: "529b9cbefa343b41727046ca06655a1e"
>     messageQueueSize: 100
>     numberOfProducers: 10
>     producerQueueSize: 10
>     timerTaskInterval: 500
>
>
> queryADGroupsConsumerConfiguration:
>     messageTopic: "/topic/AD/GetGroupsTopic"
>     username: "adSyncServer"
>     password: "529b9cbefa343b41727046ca06655a1e"
>     messageQueueSize: 10
>     numberOfConsumers: 1
>
> addADUserToGroupResultProducerConfiguration:
>     messageTopic: "/topic/AD/AddUserToGroupResultTopic"
>     username: "adSyncServer"
>     password: "529b9cbefa343b41727046ca06655a1e"
>     messageQueueSize: 100
>     numberOfProducers: 10
>     producerQueueSize: 10
>     timerTaskInterval: 500
>
>
> addADUserToGroupConsumerConfiguration:
>     messageTopic: "/topic/AD/AddUserToGroupTopic"
>     username: "adSyncServer"
>     password: "529b9cbefa343b41727046ca06655a1e"
>     messageQueueSize: 10
>     numberOfConsumers: 1
>
>
> addADUserToGroupResultTimerConfiguration:
>     timerTaskInterval: 500
>
> removeADUserFromGroupResultProducerConfiguration:
>     messageTopic: "/topic/AD/RemoveUserFromGroupResultTopic"
>     username: "adSyncServer"
>     password: "529b9cbefa343b41727046ca06655a1e"
>     messageQueueSize: 100
>     numberOfProducers: 10
>     producerQueueSize: 10
>     timerTaskInterval: 500
>
>
> removeADUserFromGroupConsumerConfiguration:
>     messageTopic: "/topic/AD/RemoveUserFromGroupTopic"
>     username: "adSyncServer"
>     password: "529b9cbefa343b41727046ca06655a1e"
>     messageQueueSize: 10
>     numberOfConsumers: 1
>
>
> removeADUserFromGroupResultTimerConfiguration:
>     timerTaskInterval: 500
>
>
> deleteADUserResultProducerConfiguration:
>     messageTopic: "/topic/AD/DeleteUserResultTopic"
>     username: "adSyncServer"
>     password: "529b9cbefa343b41727046ca06655a1e"
>     messageQueueSize: 100
>     numberOfProducers: 10
>     producerQueueSize: 10
>     timerTaskInterval: 500
>
>
> deleteADUserConsumerConfiguration:
>     messageTopic: "/topic/AD/DeleteUserTopic"
>     username: "adSyncServer"
>     password: "529b9cbefa343b41727046ca06655a1e"
>     messageQueueSize: 10
>     numberOfConsumers: 1
>
>
> deleteADUserResultTimerConfiguration:
>     timerTaskInterval: 500
>
> getADOrganizationalUnitsResultProducerConfiguration:
>     messageTopic: "/topic/AD/GetOrganizationalUnitsResultTopic"
>     username: "adSyncServer"
>     password: "529b9cbefa343b41727046ca06655a1e"
>     messageQueueSize: 100
>     numberOfProducers: 10
>     producerQueueSize: 10
>     timerTaskInterval: 500
>
>
> getADOrganizationalUnitsConsumerConfiguration:
>     messageTopic: "/topic/AD/GetOrganizationalUnitsTopic"
>     username: "adSyncServer"
>     password: "529b9cbefa343b41727046ca06655a1e"
>     messageQueueSize: 10
>     numberOfConsumers: 1
>
>
> getADOrganizationalUnitsResultTimerConfiguration:
>     timerTaskInterval: 500
>
> addADUserToOrganizationalUnitResultProducerConfiguration:
>     messageTopic: "/topic/AD/AddUserToOrganizationalUnitResultTopic"
>     username: "adSyncServer"
>     password: "529b9cbefa343b41727046ca06655a1e"
>     messageQueueSize: 100
>     numberOfProducers: 10
>     producerQueueSize: 10
>     timerTaskInterval: 500
>
>
> addADUserToOrganizationalUnitConsumerConfiguration:
>     messageTopic: "/topic/AD/AddUserToOrganizationalUnitTopic"
>     username: "adSyncServer"
>     password: "529b9cbefa343b41727046ca06655a1e"
>     messageQueueSize: 10
>     numberOfConsumers: 1
>
>
> addADUserToOrganizationalUnitResultTimerConfiguration:
>     timerTaskInterval: 500
>
> removeADUserFromOrganizationalUnitResultProducerConfiguration:
>     messageTopic: "/topic/AD/RemoveUserFromOrganizationalUnitResultTopic"
>     username: "adSyncServer"
>     password: "529b9cbefa343b41727046ca06655a1e"
>     messageQueueSize: 100
>     numberOfProducers: 10
>     producerQueueSize: 10
>     timerTaskInterval: 500
>
>
> removeADUserFromOrganizationalUnitConsumerConfiguration:
>     messageTopic: "/topic/AD/RemoveUserFromOrganizationalUnitTopic"
>     username: "adSyncServer"
>     password: "529b9cbefa343b41727046ca06655a1e"
>     messageQueueSize: 10
>     numberOfConsumers: 1
>
>
> removeADUserFromOrganizationalUnitResultTimerConfiguration:
>     timerTaskInterval: 500
>
> oAuthConfiguration:
>     userIdUrl: http://localhost:8080/cloudpass/login/currentUser
>
>
68c300
<     archivedLogFilenamePattern: /data/fluigidentity-logs/adsync/adsync-%d.log.gz
---
>     archivedLogFilenamePattern: /data/fluigidentity-logs/adsync-%d.log.gz
diff -r 15/config/com/totvslabs/idm/rmi/client/scim/scim.rmi.server.properties 11/config/com/totvslabs/idm/rmi/client/scim/scim.rmi.server.properties
1d0
< # rest server
Only in 15/config: create-database.txt
Only in 15/config: fluig.png
Only in 15/config: jdbc.properties
diff -r 15/config/keystore.server.properties 11/config/keystore.server.properties
5,7c5,7
< keyStoreAlias==totvslabs
< keyStorePassword=totvslabs
< alreadyLoaded=yes
\ No newline at end of file
---
> keyStoreAlias=totvslabs
> keyStorePassword=M@5}i%><!28&3)v
> alreadyLoaded=yes
diff -r 15/config/keystore.yml 11/config/keystore.yml
51c51
<     keyStorePassword: "totvslabs"
---
>     keyStorePassword: "M@5}i%><!28&3)v"
58c58
<     listenAddress: "172.20.18.15"
---
>     listenAddress: "172.20.16.14"
68c68
< # TODO: specifiy address and remote options correctly
---
>
70c70
<     address: "localhost"
---
>     address: "172.20.16.14"
72c72
<     remote: "localhost"
---
>     remote: "172.20.16.20"
98c98
<           archivedLogFilenamePattern: /data/fluigidentity-logs/keystore/keystore-%d.log.gz
---
>           archivedLogFilenamePattern: /data/fluigidentity-logs/keystore-%d.log.gz
Only in 11/config/META-INF/services: io.dropwizard.logging.AppenderFactory
Only in 11/config: rest.yml
Only in 11/config: search.yml
diff -r 15/config/server.properties 11/config/server.properties
5d4
< # TODO couchbaseServerUrls support multiple servers
24,25c23,24
< #email_admin_name=kungwang
< #email_admin_password=u5378Ey25eU153h
---
> #email_admin_name=support@fluigidentity.com
> #email_admin_password=s[78Q4-52331FE)
root@fluig-id-chef:/home/denny/15_simulate_11# exit
#+end_example
** Principle: always add audit logs, in the common procedure
** TODO Track what commands has been executed ever, for both manually or tools :IMPORTANT:
* [#A] [Push] Push change to prod env
** Principle: After release, whenever we have a new fix, verify in staging server first
http://www.slideshare.net/chipadeedoodah/infrastructure-modeling-with-chef
P7
#+BEGIN_EXAMPLE
[2/5/15, 12:02:27 PM] denny: Just checked psfluigidentity, which is upgraded by chef last night.
[2/5/15, 12:02:32 PM] denny: It’s done indeed.

root@fluig-id-dev-03:/opt/neo4j-server/conf# grep -C 3 'cache_type=none' /opt/neo4j-server/conf -r
<eo4j-server/conf# grep -C 3 'cache_type=none' /opt/neo4j-server/conf -r
/opt/neo4j-server/conf/neo4j.properties-remote_shell_port=1337
/opt/neo4j-server/conf/neo4j.properties-
/opt/neo4j-server/conf/neo4j.properties-# change internal cache type
/opt/neo4j-server/conf/neo4j.properties:#cache_type=none
[2/5/15, 12:02:43 PM] denny: Let’s double confirm in qafluigidentity, after the push
[2/5/15, 12:02:54 PM] denny: I mean Suresh’s upgrade
[2/5/15, 12:52:54 PM] denny: ========================
qafluigidentity looks good, after push.
ssh root@104.131.134.190 grep -C 3 'cache_type=none' /opt/neo4j-server/conf -r

Maybe we should add a section in the common procedure:
- After release, whenever we have a new fix which needs to push in prod env, always verify first in QA staging env.
#+END_EXAMPLE
** Principle: Don't push change to end of month, because business activity
** TODO [#A] How to track change for differnent release
** TODO detect whether conf template is changed
http://www.infoq.com/cn/articles/wide-range-devops
第一步是用标准的开源模式进行变更：Pull请求和代码复审。当开发人员希望加入一些新东西时，他（或她）可以直接进行变更并发布一个Pull请求。开发人员可以使用提前在Vagrant中配置好的虚拟机测试这些变更。 Pull请求为运维团队提供了一个对这些变更进行审查和完备性测试的机会。如果有问题，反馈至开发人员，这样就可以避免问题重复出现。最后，Pull请求被合并，这时，开发人员可以为实施一个变更而感到自信和骄傲，而运维人员也会放心，因为变更的审查是由运维负责的。
** TODO [#A] Lesson: Don't release without issue resolved for identity-1.4.1 :IMPORTANT:
Some packages not updated, which result in neo4j update not changed
** #  --8<-------------------------- separator ------------------------>8--
** [#A] wrong package was updated in the production node.           :Problem:
** Store critical version info: when code is built; when it's updated
** TODO chef bug: neo4j libraries may not be updated to right version
** TODO How to track the change of different upgrade path for different envs
** TODO When to restart service: especial during upgrade
** rest service takes a long time to die, due to neo4j
** search service use too much cpu, due to neo4j
** TODO automate how to initial data for AD
* [#A] [Consultant] Principle to get better DevOps consultant
http://www.rightbrainnetworks.com/#the-founder
** Communication: See what part we can charge to customers as consultant in a reasonable way
** TODO Communication: What kind of scenario I shall say no?
* [#A] Public Cloud: DigitalOcean & AWS & self-owned data center
** Use AMI image to speed up the deployment process and lower the network traffic
** Don't keep VM long run, if it really have to
* TODO [#A] Process: How to support DevOps for a new project
- Automate Code build
- Automate Deployment
  Sandbox for a clean test
- Automate monitoring
- Update documents for Developers

* #  --8<-------------------------- separator ------------------------>8--
* [#A] [Monitoring] auto detection and quickly check system's healthy
| Name             | Summary                                      |
|------------------+----------------------------------------------|
| nagios exchanges | http://exchange.nagios.org                   |
| nagios plugins   | https://github.com/Inuits/monitoring-plugins |
** DONE [#A] Monitor log files for critical/errors/exceptions     :IMPORTANT:
   CLOSED: [2015-03-06 Fri 10:25]
*** nagios check_logfiles setting example
#+BEGIN_EXAMPLE
# Configuration file for check_logfiles command
#

# where the state information will be saved.
$seekfilesdir = '/var/tmp';

# where protocols with found patterns will be stored.
$protocolsdir = '/var/tmp';

# where scripts will be searched for.
#$scriptpath = '/data/fluigidentity-logs';

@searches = (
  {
    logfile => '/data/fluigidentity-logs/rest.log',

    criticalpatterns => [
	'Timeout waiting for value',
        'Exception',
        'core dumped',
	],

    warningpatterns => [
	'WARN',
	'error',
        'Error',
        'ERROR',
	],

     okpatterns => [
        '^\[[^\[]*\[WARN',
        '^WARN  ',
        ],

     options => 'noprotocol,count,nologfilenocry',
  },
);
#+END_EXAMPLE
** DONE nagios monitor cpu/memory/fd at process level
   CLOSED: [2015-03-06 Fri 10:19]
** DONE selnium GUI mockup test, like login test
   CLOSED: [2015-03-06 Fri 10:20]
** DONE monitor 3rd party provider: not so well-known, but your system use it
   CLOSED: [2015-03-06 Fri 10:18]
- mail server
  CP-6945: [Service Provider] Can't open TOTVS email
** DONE application layer service health_check
   CLOSED: [2015-03-06 Fri 10:28]
** DONE VM Network connectivity: ssh, email server
   CLOSED: [2015-03-06 Fri 14:08]
** #  --8<-------------------------- separator ------------------------>8--
** [#A] Capacity planning: Collect datat from monitoring and advise for upgrade or reclaim hardware :IMPORTANT:
** [#B] Predict the future of a given metric
- predict
- 周环比
- ranking
** [#A] disk usage by huge garbage data
*** Huge core dumps filling up a partition.                         :Problem:
*** A temporary folder filling up with hundreds of thousands of zero byte files. :Problem:
*** A folder containing debug information filling up with over 32,000 folders containing debug information. :Problem:
** [#A] Generate weekly report from history, from business perspective
** [#A] Use elasticsearch to analysis log                    :IMPORTANT:
** #  --8<-------------------------- separator ------------------------>8--
** Problem: Too many logfile warnings, since false negative pattern not recognized
** Problem: GUI login is flipping
*** DELEGATE Filed CP-6922: nagios check flipping: selenium login of prod env
  CLOSED: [2015-02-11 Wed 08:43]
[09 Feb 2015;18:54:55.806] - [INFO ] [APIExecutor:123] - POST https://suporte.totvs.com/rest/auth returned a response status of 401 Unauthorized
[09 Feb 2015;18:54:55.806] - [WARN ] [APIExecutor:149] - Error occured while trying to convert the response to FluigIdentityException. The response string was: {"errorCode" : 401, User not Authenticated.", "possibleResponsibleField" : "email or password authentication" }
[09 Feb 2015;18:54:55.811] - [INFO ] [CompanyServiceInterfaceImpl:634] - GET COMPLETE APPLICATION FOR COMPANY - companyId: zf0y84vo717g8hjx | appId: y6k661wf5a5vh9u11405012401405
[09 Feb 2015;18:54:56.321] - [INFO ] [CompanyServiceInterfaceImpl:634] - GET COMPLETE APPLICATION FOR COMPANY - companyId: zf0y84vo717g8hjx | appId: y6k661wf5a5vh9u11405012401405
[09 Feb 2015;18:54:58.349] - [INFO ] [UserServiceInterfaceImpl:1470] - VALIDATE USER (MULTI-CONTEXT-PERSONAL)- emailAddress: fluigid.rjo@totvs.com.br | domain: totvs.fluigidentity.com
[09 Feb 2015;18:54:58.354] - [INFO ] [UserServiceInterfaceImpl:1484] - Cannot validate user with personal credentials .. Checking to see if user has AD account with one of the contexts ..
[09 Feb 2015;18:54:58.354] - [INFO ] [UserServiceInterfaceImpl:1105] - GET USER BY EMAIL ADDRESS (MULTI-CONTEXT-PERSONAL) - emailAddress: fluigid.rjo@totvs.com.br
** Problem: Tomcat/neo4j/rmi/search use too much CPU
** Problem: Tomcat/neo4j/rmi/search use too much memory
** Problem: nightly backup will copy and zip data of 20 GB, which result in alert of low disk
*** mail: FW: ** PROBLEM Service Alert: app.customerfi.com/check_disk_rootfs is WARNING ** :noexport:
[[gnus:mail.misc#EF9859611DA81140B2B29B02EC8AD6EAFAFC22@helios.mex01.local][Email from Denny Zhang (Thu, 12 Feb 2015 03:47:00 +0000): FW: ** PROBLEM Service Alert: ]]
#+begin_example
From: Denny Zhang <denny.zhang@totvs.com>
Subject: FW: ** PROBLEM Service Alert: app.customerfi.com/check_disk_rootfs is WARNING **
To: "filebat.mark@gmail.com" <filebat.mark@gmail.com>
Date: Wed, 11 Feb 2015 21:47:00 -0600

________________________________________
From: nagios@fluig-id-cdn-01.fluigidentity.com [nagios@fluig-id-cdn-01.fluigidentity.com]
Sent: Wednesday, February 11, 2015 8:10 PM
To: Denny Zhang
Subject: ** PROBLEM Service Alert: app.customerfi.com/check_disk_rootfs is WARNING **

 ***** Nagios *****

Notification Type: PROBLEM

Service: check_disk_rootfs
Host: app.customerfi.com
Address: 172.20.18.23
State: WARNING

Date/Time: Thu Feb 12 02:10:04 GMT 2015

Additional Info:

DISK WARNING - free space: / 13569 MB (15% inode=97%):

#+end_example

backup process will copy and tar huge files

https://totvslab.atlassian.net/browse/CLOUDPASS-5662
#+begin_example
[7/11/14, 13:14:58] Shivang: what is that VM?
[7/11/14, 13:15:12] Shivang: is that a chef server or something ?
[7/11/14, 13:15:33] denny: Quoted from email:

Vicente

It's one vm of PROD cluster, which runs cdn02, nfs-server, ubuntu repo (see from the wiki)

You can search 172.20.16.18 in below wiki:
https://totvslab.atlassian.net/wiki/display/TECH/BR-FI-SERVERS-01

Regards,
Denny
[7/11/14, 13:15:37] Shivang: VABuildScript basically builds some files specific to Virtual Appliance
[7/11/14, 13:15:54] Shivang: now i don't know why SO MANY of them were running
[7/11/14, 13:16:19] denny: Then I see. It should be invoked by jenkins.

If some jenkins jobs hang, it may result in a orphan process.
[7/11/14, 13:16:39] Shivang: I am not sure about that part .. the question is
[7/11/14, 13:16:44] Shivang: why is it running int he first place
[7/11/14, 13:16:51] Shivang: the VABuildScript should only run when we actually
[7/11/14, 13:16:58] Shivang: have some customers wanting to DOWNLOAD
[7/11/14, 13:17:01] Shivang: a virtual appliance
[7/11/14, 13:17:09] Shivang: and from what I know, I don't think we have any
[7/11/14, 13:18:59] Shivang: ..
[7/11/14, 13:19:01] Shivang: I am going to start driving here so i can be at work by 11 ..
[7/11/14, 13:19:07] denny: I see. I should have got enough info to trouble cause this problem now.

I will keep you updated, if I have find something.
[7/11/14, 13:19:38] denny: It should be not a big issue. Drive safe, Shivang.
[7/11/14, 13:19:43] Shivang: sounds good ..
[7/11/14, 13:19:46] Shivang: no problem.
#+end_example
** #  --8<-------------------------- separator ------------------------>8--
** Define priority for the failure of different checks
- Too many alerts, it's meaningless
- Report low disk issue to developers of application layer doesn't make sense
- Some failure of log file check doesn't necessarily means a critical problem
** A RAID drive that failed, but not found or alerted               :Problem:
Only discovered after the mirrored drive also failed.
** TODO Able to zoom in and zoom out for the failure history of the whole system
** TODO Common check for common service: RMDB, NOSQL DB, Queue, etc
http://www.infoq.com/cn/articles/mongodb-deployment-monitoring
** TODO Allow users to subscripe for the failure of interested metrics
** #  --8<-------------------------- separator ------------------------>8--
** Detect what metric are getting abnormally problemetic
** How to present the monitoring system to dummies or boss?
** Monitor dashbarod, should be able go to mobile
** rest.log is generating too fast, in the mid night VM run out of disk
** TODO Nagios monitor racagent
https://totvslab.atlassian.net/wiki/display/TECH/fluigidentity+-+RAC+agents
#+begin_example
[10/16/14, 11:38:40] denny: denny added kungchaowang, Shivang to this conversation
[10/16/14, 11:38:47] denny: denny set topic to “Monitor racagent”
[10/16/14, 11:39:26] denny: Hi Shivang

I'm thinking enable monitoring for racagent instances.

Do you have any suggestions for what checks we can perform, to ensure its sanity
[10/16/14, 11:58:37] Shivang: hey denny
[10/16/14, 11:58:38] Shivang: sorry about that
[10/16/14, 11:58:43] Shivang:  was getting ready to leave for work
[10/16/14, 11:59:08] Shivang: yes .. what kind of monitoring are you going to add? because we already have a monitoring for all rac agents  (although our UI doesn't show it just yet)
[10/16/14, 11:59:12] denny: It's not urgent. That's fine. Just chimp that in mind.
[10/16/14, 11:59:49] Shivang: right now each agent pings couchbase with it's name and updates
[10/16/14, 11:59:59] Shivang: the last ping (along with the ip of the box it's setup on)
[10/16/14, 12:00:08] Shivang: our UI doesn't show it just yet ..
[10/16/14, 12:00:19] Shivang: but they plan to add it some time soon ..
[10/16/14, 12:00:21] denny: My motivation is do the monitoring and alerting automatically for RAC agent problems.
[10/16/14, 12:00:31] Shivang: definitely so tell me .. you gonna use nagios?
[10/16/14, 12:00:41] Shivang: because if you give me a rest endpoint to ping
[10/16/14, 12:00:44] Shivang: i can add that to it's ping
[10/16/14, 12:01:01] Shivang: or you monitor it like you monitor other services, your choice
[10/16/14, 12:01:26] denny: Would you please show me detail about current status?
[10/16/14, 12:01:45] Shivang: yes .. if you have an env where the agents are running
[10/16/14, 12:01:51] Shivang: go to couchbase and just search a document with
[10/16/14, 12:01:58] Shivang: the key: "agents"
[10/16/14, 12:02:05] Shivang: you will see the details there
[10/16/14, 12:02:56] denny: Let me see that, and get back to you later. Thanks, Shivang.
[10/16/14, 12:03:04] Shivang: let me get uyou a sample
[10/16/14, 12:03:05] Shivang: juyst a min
[10/16/14, 12:03:31] Shivang: {
  "invincible": {
    "name": "invincible",
    "companyIds": [
      "hfrmwc4bf7s2shdm1410413382917",
      "a5bkb6byb8l2zbg41410979967031",
      "00ogp3uofsjlwhc11410389672381",
      "o72fn2yffdvng1ka1410389399191",
      "43esylwopdanonh11410389584069",
      "1u15qvmsarh7by9j1410397781962",
      "uu8582olf7nt548h1411131956366",
      "mv2pz549rffv4keo1410399256562",
      "foq54sc8mox2pb3s1410389954738",
      "q77l41u5khzsuhn81410389667214",
      "059r55qdp4xzo20w1410456619982",
      "t6g88rk9rea5s8851410389870784",
      "8g7m8u5sivmph48h1410438115876",
      "76d01odo5x6rv55a1410453201820",
      "h2t3b7w99rq4iswl1410544002358",
      "6rpc3yqja85fg7zq1410396442738",
      "l2t5od7vlqtcxuc71410462055220",
      "m1nuxtwngx45f4t61410389811781",
      "lteodrn5ckp9kl181410443016241",
      "3r27yjkv0be707d81410446296046",
      "6eus4qe777pf7scm1410390003614",
      "esvr7w9bukc7bxmt1410468579054",
      "munyhzn5eyr4tyfz1410420901780",
      "0pe3m9p6bfa5fvna1410389839675",
      "6stj5k3qv5nsqfsz1410474979613",
      "oaq3ssk03fl6sxvi1410390042739",
      "l2ez7ij4ak7sofl11410389640595",
      "drm7bn0hip71z3wi1411241439022"
    ],
    "status": "AVAILABLE",
    "lastPing": 1413478996430,
    "ip": "127.0.0.1",
    "available": true,
    "companyId": ""
  }
}
[10/16/14, 12:03:36] Shivang: http://qa1b:8091/index.html#sec=documents&bucketName=cloudpass&documentsPageNumber=0&docId=agents
[10/16/14, 12:03:57] denny: Yes?
[10/16/14, 12:04:15] denny: You mean check the field of "status" for "AVAILABLE"?
[10/16/14, 12:04:19] Shivang: that's how the agents ping couchbase
[10/16/14, 12:04:25] Shivang: and updage the ping time, status
[10/16/14, 12:04:26] Shivang: etc etc
[10/16/14, 12:04:51] Shivang: anyways .. let me know when you dive into it
[10/16/14, 12:04:55] Shivang: we can talk more than
[10/16/14, 12:07:07] denny: First we need to figure out potential problems of RAC agent we have encounter.

I noticed two in below. What else you would advise, Shivang?
1. rac agent instance is down
2. query couchbase, and the field of "status"is not "AVAILBLE"
[10/16/14, 12:07:52] Shivang: I think that's pretty much all ..
[10/16/14, 12:07:58] denny: Do we need to check "lastPing" filed?
[10/16/14, 12:08:00] Shivang: the other stuff is going to be handled by the application itself
[10/16/14, 12:08:07] Shivang: it'd be good if you don't want to rely on
[10/16/14, 12:08:08] Shivang: AVAILABLE
[10/16/14, 12:08:17] Shivang: the ping happens every 30 seconds
[10/16/14, 12:09:05] denny: We have two fields in below, what does that mean?
"status": "AVAILABLE",
"available": true,
[10/16/14, 12:09:38] Shivang: actually one is just a boolean true or false
[10/16/14, 12:09:42] Shivang: the status could be more eventually
[10/16/14, 12:09:52] Shivang: for example: SYNCING ..
[10/16/14, 12:10:26] denny: I see. So if we need to query couchbase to identity agents problem, what exactly we should do?
[10/16/14, 12:10:54] Shivang: you will need to make use of couchbase rest apis
[10/16/14, 12:10:56] Shivang: and use curl to get this data
[10/16/14, 12:11:07] Shivang: and if you do find an issue
[10/16/14, 12:11:10] Shivang: we should know right away
[10/16/14, 12:11:19] Shivang: if it's down it's donw .. you can't really do much
[10/16/14, 12:11:30] Shivang: unless, you want to start another agent automatically with the same name
[10/16/14, 12:11:34] denny: Yes, I can handle that.

My question is, which one I should do in below
[10/16/14, 12:11:44] denny: 1. Make sure "available" is true
[10/16/14, 12:11:57] denny: 2. Make sure "status" is "AVAILABLE" or "SYNCING"
[10/16/14, 12:12:08] Shivang: actually I will take that back .. I think you should concentrate on the last ping
[10/16/14, 12:12:25] Shivang: because the status and the flag won't turn to false till the time agent isn't pingign
[10/16/14, 12:12:34] Shivang: these statuses are going to be handled at application level
[10/16/14, 12:13:23] Shivang: so my recommendation
[10/16/14, 12:13:29] Shivang: 1) check lastPing
[10/16/14, 12:13:51] Shivang: if currentSystemMillis - lastPing > 60000 (60 seconds)
[10/16/14, 12:13:55] Shivang: we have a problem
[10/16/14, 12:14:13] denny: nice. And else?
[10/16/14, 12:15:29] Shivang: if that condition is true (meaning it's not pinging), I recommend we do:
1) check at process level if that agent with that name is running or not. If it is, kill it
2) restart the agent with the same name
[10/16/14, 12:15:45] Shivang: 3) check the ping again for health
[10/16/14, 12:17:04] denny: So you mean if  currentSystemMillis - lastPing < 60000, we will the arc agent?
[10/16/14, 12:24:14] Shivang: not sure I understand your question
[10/16/14, 12:24:17] Shivang: what I basically mean is
[10/16/14, 12:24:26] Shivang: if the agent hasn't pinged in last 1 minute, we have a problem
[10/16/14, 12:24:34] Shivang: because it is supposed to ping every 30 seconds technically
[10/16/14, 12:25:19] denny: So the only check is make sure agent has pined within last 1 min.

No other check in couchbase for this? Right?
[10/16/14, 12:25:32] Shivang: no i think that should me more than enough
[10/16/14, 12:25:45] Shivang: and if it hasn't pinged in the last 1 minute:
[10/16/14, 12:25:56] Shivang: we do the above 3 steps automatically if need be
[10/16/14, 12:26:10] Shivang: gonna leave for work now .. let me kping you once I get there
[10/16/14, 12:26:43] denny: monitoring system should not change system's status.

Thus we won't do service restart in that phase.
[10/16/14, 12:26:56] Shivang: no porblem
[10/16/14, 12:26:59] Shivang: alert would be gpod
[10/16/14, 12:27:04] Shivang: see you in a while
[10/16/14, 12:27:10] denny: Yes, see you later.
[10/16/14, 12:32:18] denny: Shivang, I have updated related wiki for "Monitor RAC Agent for problems" https://totvslab.atlassian.net/wiki/display/TECH/fluigidentity+-+RAC+agents

Please advise, if you have any more thoughts or suggestions.
#+end_example
** [Monitoring] Monitor java programs
*** TODO Check java GC
http://www.cubrid.org/blog/dev-platform/how-to-monitor-java-garbage-collection/
*** TODO Java thread: BLOCKED thread without “waiting to lock …”
http://stackoverflow.com/questions/7067058/java-thread-dump-blocked-thread-without-waiting-to-lock
*** TODO java gc log
http://stackoverflow.com/questions/13311416/what-do-real-user-and-sys-mean-in-the-java-cms-gc-log
*** TODO GC
jstat -gc 23165 1000

tail -f /data/fluigidentity-logs/rest_gc.log
*** TODO java heap memory
** TODO [#A] Run nagios check active as a command line
- fluig_status_all.sh: trigger nagios test
** TODO nagios plugin: check_proc_age.sh
http://exchange.nagios.org/directory/Plugins/Operating-Systems/Linux/check_proc_age-2Esh/details
** DONE mctop monitor network traffic of memcache
   CLOSED: [2015-03-30 Mon 10:42]
mctop是开源的一个检测工具，依靠ruby的pcap进行抓包分析

一眼就看到了，是esf-wordfilter__all的值过大占了4m/s的带宽，通知业务部门优化之~
https://github.com/etsy/mctop
http://www.itsprite.com/mctop-installationmemcached-monitoring-tool/
http://zhangbo.blog.51cto.com/350645/1600512
* [#A] [Backup] clean backup and recovery
** For critical VM of EC2/digital ocean, take snapshot every month
** DONE [#A] RTO and RPO DR Design                                :IMPORTANT:
  CLOSED: [2015-04-15 Wed 14:13]
Recovery time objective (RTO) 
— The time it takes after a disruption to restore a business process
to its service level, as defined by the operational level agreement
(OLA). For example, if a disaster occurs at 12:00 PM (noon) and the
RTO is eight hours, the DR process should restore the business process
to the acceptable service level by 8:00 PM.

Recovery point objective (RPO)
— The acceptable amount of data loss measured in time. For example, if
a disaster occurs at 12:00 PM (noon) and the RPO is one hour, the
system should recover all data that was in the system before 11:00
AM. Data loss will span only one hour, between 11:00 AM and 12:00 PM
(noon).

A company typically decides on an acceptable RTO and RPO based on the
financial impact to the business when systems are unavailable. The
company determines financial impact by considering many factors, such
as the loss of business and damage to its reputation due to downtime
and the lack of systems availability.
** #  --8<-------------------------- separator ------------------------>8--
** TODO Why neo4j recovery take 8 hours for ~10 GB data?
** DONE Testing the restore process: test for customerfi          :IMPORTANT:
   CLOSED: [2015-03-18 Wed 18:57]
https://totvslab.atlassian.net/browse/TECH-63
https://totvslab.atlassian.net/wiki/display/TECH/Backup+-+Operations

http://198.199.105.82
https://app.customerfi.com

mkdir -p /home/denny/restore

/home/denny/restore
*** [Verify restore]: Company count: Menu --> Company
*** [Verify restore]: Application count: Menu --> Application
*** [Verify restore]: Users counts for one company: Choose one company, then swtich to users
*** [Verify restore] perform login for special user
*** #  --8<-------------------------- separator ------------------------>8--
*** Problem: After restore, Users count of group number is different
Is it changed after my backup?
*** #  --8<-------------------------- separator ------------------------>8--
*** copy backup set
In customerfi(172.20.18.23)

scp /data/backup/log/2014-12-03-163458_log.tar.gz root@198.199.105.82:/home/denny/restore/
scp /data/backup/nagios_rrd/2014-12-03-163458_nagios_rrd.tar.gz root@198.199.105.82:/home/denny/restore/
scp /data/backup/keystore/2014-12-03-163458_keystore.tar.gz root@198.199.105.82:/home/denny/restore/
scp /data/backup/totvslabs/2014-12-03-163458_totvslabs.tar.gz root@198.199.105.82:/home/denny/restore/
scp /data/backup/couchbase/2014-12-03-163458_couchbase.tar.gz root@198.199.105.82:/home/denny/restore/
scp /data/backup/config/2014-12-03-163458_config.tar.gz root@198.199.105.82:/home/denny/restore/

cd /home/denny/restore
tar -xf 2014-12-03-163458_config.tar.gz
tar -xf 2014-12-03-163458_couchbase.tar.gz
tar -xf 2014-12-03-163458_totvslabs.tar.gz
tar -xf 2014-12-03-163458_keystore.tar.gz
tar -xf 2014-12-03-163458_nagios_rrd.tar.gz
tar -xf 2014-12-03-163458_log.tar.gz

ls -lth /home/denny/restore/2014-12-03-163458_log
*** stop all services
fluig_stop_all.sh
service neo4j stop
*** backup before restore
#+BEGIN_EXAMPLE
root@InternalJenkins:~# ls -lth /data/backup/*
ls -lth /data/backup/*
/data/backup/log:
total 476K
-rw-r--r-- 1 root root 474K Dec  4 10:59 2014-12-04-105926_log.tar.gz

/data/backup/nagios_rrd:
total 28K
-rw-r--r-- 1 root root 25K Dec  4 10:59 2014-12-04-105926_nagios_rrd.tar.gz

/data/backup/keystore:
total 4.0K
-rw-r--r-- 1 root root 2.8K Dec  4 10:59 2014-12-04-105926_keystore.tar.gz

/data/backup/totvslabs:
total 128K
-rw-r--r-- 1 root root 125K Dec  4 10:59 2014-12-04-105926_totvslabs.tar.gz

/data/backup/couchbase:
total 104K
-rw-r--r-- 1 root root  99K Dec  4 10:59 2014-12-04-105926_couchbase.tar.gz
-rw-r--r-- 1 root root 1.5K Dec  4 09:49 2014-12-04-094947_couchbase.tar.gz

/data/backup/config:
total 860K
-rw-r--r-- 1 root root 858K Dec  4 10:59 2014-12-04-105926_config.tar.gz

/data/backup/CloudpassKeystore:
total 12K
-rw-r--r-- 1 root root 2.8K Dec  4 09:55 CloudpassKeystore-2014-12-04-095501.tar.gz
-rw-r--r-- 1 root root 3.0K Dec  4 09:55 CloudpassKeystore
-rw-r--r-- 1 root root   11 Dec  4 09:55 cksum.txt
root@InternalJenkins:~#
#+END_EXAMPLE
*** #  --8<-------------------------- separator ------------------------>8--
*** restore keystore
cp /home/denny/restore/2014-12-03-163458/CloudpassKeystore  /cloudpass/backend/build/bin/CloudpassKeystore
*** restore neo4j
mv /data/totvslabs/* /tmp/
cp -rf /home/denny/restore/2014-12-03-163458/suggestions /data/totvslabs/
ls /data//totvslabs
cp -rf /home/denny/restore/2014-12-03-163458/timeline /data/totvslabs/
ls /data//totvslabs
cp -rf /home/denny/restore/2014-12-03-163458/globalsearch /data/totvslabs/
ls /data//totvslabs
cp -rf /home/denny/restore/2014-12-03-163458/neo4j /data/totvslabs/
ls /data//totvslabs

cp -rf /home/denny/restore/2014-12-03-163458/scim /data/totvslabs/
ls -lth /data/totvslabs

service neo4j start
tail -f /opt/neo4j-server/data/log/console.log
tail -f /data/totvslabs/scim/neo4j/embedded/messages.log
*** restore couchbase
https://totvslab.atlassian.net/wiki/display/TECH/Backup+-+Operations

source /etc/profile
/opt/couchbase/bin

cbbackup -b cloudpass http://localhost:8091 /tmp/couchbase -u Administrator -p password1234

cd /tmp/couchbase
cbrestore . -u Administrator -p password1234 -x rehash=1 couchbase://localhost:8091 -b cloudpass -B cloudpass

cbrestore /home/denny/restore/2014-12-03-163458/ -u Administrator -p password1234 -x rehash=1 couchbase://localhost:8091  -b cloudpass -B cloudpass
*** neo4j recovery
#+BEGIN_EXAMPLE
2014-12-03 01:45:48.420+0000 INFO  [o.n.k.i.t.TxManager]: TM opening log: /data/totvslabs/scim/neo4j/embedded/tm_tx_log.1
2014-12-03 01:45:48.470+0000 INFO  [o.n.k.i.t.x.XaLogicalLog]: Non clean shutdown detected on log [/data/totvslabs/scim/neo4j/embedded/index/lucene.log.2]. Recovery started ...
2014-12-03 01:45:48.472+0000 INFO  [o.n.k.i.t.x.XaLogicalLog]: [/data/totvslabs/scim/neo4j/embedded/index/lucene.log.2] logVersion=298 with committed tx=507183
#+END_EXAMPLE
** TODO How to backup hornetq
https://access.redhat.com/documentation/en-US/JBoss_Enterprise_Application_Platform/5/html/HornetQ_User_Guide/ch38s02.html
** TODO Provide a restore procedure for system upgrade
** TODO Backup: rest service may not shutdown gracefully
** TODO Backup: work with the cluster deployment; test restore for cluster deployment
** TODO [#B] Backup: verify backup set, by checking and restore
** TODO [#A] JIRA: neo4j full backup: need stop for clean backup; recovery mode take several hours :IMPORTANT:
root@fluig-id-messaging-01:/data/backup/totvslabs# bash -e /usr/local/bin/fluig_backup.sh all
</data/backup/totvslabs# bash -e /usr/local/bin/fluig_backup.sh all
[2014-12-13 00:19:06] Clean up old backup
[2014-12-13 00:19:06] ############### Begin Backup ####################################
[2014-12-13 00:19:06] Backup all
[2014-12-13 00:19:06] Backup config to /data/backup/config/2014-12-13-001906.tar.gz
[2014-12-13 00:19:06] Backup /data/totvslabs/ to /data/backup/totvslabs/2014-12-13-001906
[2014-12-13 00:19:06] /bin/cp -r /data/totvslabs/globalsearch /data/backup/totvslabs/2014-12-13-001906/
[2014-12-13 00:19:07] /bin/cp -r /data/totvslabs/neo4j /data/backup/totvslabs/2014-12-13-001906/
  C-c C-c^C[2014-12-13 00:19:08] Backup operation fail
[2014-12-13 00:19:08] Backup operation fail
root@fluig-id-messaging-01:/data/backup/totvslabs# rm -rf /data/backup/totvslabs/2014-12-13-001906/
</data/backup/totvslabs# rm -rf /data/backup/totvslabs/2014-12-13-001906/
root@fluig-id-messaging-01:/data/backup/totvslabs# rm -rf  /data/backup/config/2014-12-13-001906.tar.gz
</data/backup/totvslabs# rm -rf  /data/backup/config/2014-12-13-001906.tar.gz
root@fluig-id-messaging-01:/data/backup/totvslabs# fluig_stop_all.sh all
fluig_stop_all.sh all
[2014-12-13 00:19:31] ========= Stop down the whole service stack. It shall take 1~2 min ============
[2014-12-13 00:19:31] stop search
root@fluig-id-messaging-01:/data/backup/totvslabs# service neo4j stop
service neo4j stop
Stopping Neo4j Server [54314]........ done
root@fluig-id-messaging-01:/data/backup/totvslabs# fluig_backup.sh all
fluig_backup.sh all
[2014-12-13 00:19:52] Clean up old backup
[2014-12-13 00:19:52] ############### Begin Backup ####################################
[2014-12-13 00:19:52] Backup all
[2014-12-13 00:19:52] Backup config to /data/backup/config/2014-12-13-001952.tar.gz
[2014-12-13 00:19:52] Backup /data/totvslabs/ to /data/backup/totvslabs/2014-12-13-001952
[2014-12-13 00:19:52] /bin/cp -r /data/totvslabs/globalsearch /data/backup/totvslabs/2014-12-13-001952/
[2014-12-13 00:19:52] /bin/cp -r /data/totvslabs/neo4j /data/backup/totvslabs/2014-12-13-001952/
[2014-12-13 00:20:49] /bin/cp -r /data/totvslabs/scim /data/backup/totvslabs/2014-12-13-001952/
[2014-12-13 00:22:52] /bin/cp -r /data/totvslabs/suggestions /data/backup/totvslabs/2014-12-13-001952/
[2014-12-13 00:22:52] /bin/cp -r /data/totvslabs/timeline /data/backup/totvslabs/2014-12-13-001952/
[2014-12-13 00:32:34] Collect critical log files to /data/backup/log/2014-12-13-001952
[2014-12-13 00:32:34] Collect log succeed
[2014-12-13 00:32:34] Backup operation is done
[12/12/14, 5:51:37 PM] kungchaowang: yes, please stop it, as it’s a transactional database
[12/12/14, 5:51:44 PM] kungchaowang: you always want to clean shutdown the database
[12/12/14, 5:52:58 PM] denny: Yes, I see.

Need more consideration about this later.

The neo4j backup takes ~20 min. If we have to shutdown, then daily backup will introduce 20 min downtime. And it may bring in some other potential issues.
** TODO old backup is not good enough
*** backup Nov 8th by Denny
root@fluig-id-messaging-01:/shared/to_to_deleted/totvslabs/scim# du -h -d 1
du -h -d 1
46M	./lucene
4.2G	./neo4j
336K	./userexp
4.2G	.
*** backup totvslabs.20141201.tar.gz by Kung
root@fluig-id-messaging-01:/home/denny/data# du -h -d 1 totvslabs/scim
du -h -d 1 totvslabs/scim
31M	totvslabs/scim/lucene
2.3G	totvslabs/scim/neo4j
168K	totvslabs/scim/userexp
2.3G	totvslabs/scim
*** current size by 2014-12-03
root@fluig-id-messaging-01:/data/totvslabs/scim# du -h -d 1
du -h -d 1
31M	./lucene
18G	./neo4j
168K	./userexp
18G	.
*** #  --8<-------------------------- separator ------------------------>8--
*** kung's backup
*** current size
** TODO [#A] Need people to check the real status: scim is not backup :IMPORTANT:
** TODO [#A] Crontab: Backup mulitple couchbase instance in different time :IMPORTANT:
** TODO Verify the backup set, to make sure restore works
** TODO [#B] setup daily bakcup and remote bakcup for QA1B
#+BEGIN_EXAMPLE
Last login: Mon Nov 17 16:07:00 2014 from 10.165.0.30
qa1b:~# date; cp -r /data/totvslabs/scim/neo4j/embedded /home/denny/; date
Mon Nov 17 16:08:29 GMT 2014
Mon Nov 17 16:27:42 GMT 2014
qa1b:~# cd /home/denny/
qa1b:/home/denny# df -h
Filesystem      Size  Used Avail Use% Mounted on
/dev/sda1       238G  172G   55G  76% /
udev             32G   12K   32G   1% /dev
tmpfs           6.3G  280K  6.3G   1% /run
none            5.0M     0  5.0M   0% /run/lock
none             32G     0   32G   0% /run/shm
qa1b:/home/denny# tar -zcf test.tar.gz ./embedded/
^C
qa1b:/home/denny# date; tar -zcf test.tar.gz ./embedded/; date
Mon Nov 17 16:32:21 GMT 2014


Mon Nov 17 17:12:53 GMT 2014
#+END_EXAMPLE
** TODO [#A] Prod env: Why backup is not the exact same time??
** TODO [#B] How to restore couchbase cluster with multiple nodes
** TODO [#A] data backup logic: introduce system down for clean backup; take too much time due to data volume
https://totvslab.atlassian.net/browse/TECH-67
#+BEGIN_EXAMPLE
Current backup logic is not good enough:
- We're copying neo4j directory while services are running. This may result in data inconsistency
- Backup couch base takes ~5 min, neo4j takes ~20 min.
So we're not backup services at the same time, since backup one service itself may take time.
- Need to setup remote copy mechanism
- Data cleanup, since we don't have enough disk for huge history data
- Send out emails, if backup fails or something strange with the backup set.
#+END_EXAMPLE
** Need data backup and recovery to simulate prod env: setup as staging server quickly
#+BEGIN_EXAMPLE
[2/18/15, 12:36:24 PM] kungchaowang: can we qa on qafluigidentity.com after Reinaldo tested locally?
[2/18/15, 12:37:01 PM] kungchaowang: my suggestion is, at least QA has a hand on it before landed on production
[2/18/15, 12:37:46 PM] denny: That’s definitely a good idea.

@Suresh, what do you think?
[2/18/15, 12:51:08 PM] kungchaowang: I believe we do have production like envioronment for qafluigidenitty.com, so there should be no setup time and will give us good idea for any issues that may raise on multi-servers
#+END_EXAMPLE
** DONE setup a crontab to remove old backup set
  CLOSED: [2015-01-25 Sun 21:18]
find /shared/backup -name "*.gz" -mtime +30 -and -not -type d -delete

Need to log this critical action
#+BEGIN_EXAMPLE
root@app1:~# crontab -l
# m h  dom mon dow   command
*/5 * * * * /home/denny/server-check/fluig-server-check.sh 2>&1 >> /var/log/fluig-server-check.log

# Remove old backup in NFS server
0 3 1 * * find /shared/backup -name "*.gz" -mtime +30 -and -not -type d -delete

# Chef Name: cron_backup_fluig
0 2 * * * bash -e /usr/local/bin/fluig_backup.sh all >> /var/log/backup.log 2>&1

# Chef Name: cron_clean_cached_memory
0 4 * * * /usr/local/bin/clean_cached_memory.sh
# Chef Name: cron_backup_cloudpasskeystore
*/5 * * * * bash -e /usr/local/bin/fluig_backup_file.sh /cloudpass/backend/build/bin/CloudpassKeystore >> /var/log/backup_cloudpasskeystore.log 2>&1

# Chef Name: remote_copy_backupset
20 3 * * * bash -e /usr/local/bin/remote_copy_backupset.sh >> /var/log/remote_copy_backupset.log 2>&1

# Chef Name: cron_daily_clean
0 4 * * * bash -e /usr/local/bin/fluig_daily_clean.sh
root@app1:~# find /shared/backup -name "*.gz" -mtime +30 -and -not -type d -delete
root@app1:~# df -h
Filesystem                          Size  Used Avail Use% Mounted on
/dev/sda2                           198G   96G   93G  51% /
udev                                 17G   12K   17G   1% /dev
tmpfs                               3.3G  264K  3.3G   1% /run
none                                5.0M     0  5.0M   0% /run/lock
none                                 17G     0   17G   0% /run/shm
172.20.16.27:/ibm/totvs01/fluig-id 1000G  536G  465G  54% /shared
#+END_EXAMPLE
** DONE [#B] Warm Standby Solution: a scaled-down version of a fully functional environment
   CLOSED: [2015-04-15 Wed 14:15]
The term warm standby is used to describe a DR scenario in which a
scaled-down version of a fully functional environment is always
running in the cloud. A warm standby solution extends the pilot light
elements and preparation.It further decreases the recovery time
because some services are always running. By identifying your
business-critical systems, you can fully duplicate these systems on
AWS and have them always on.

These servers can be running on a minimum-sized fleet of Amazon EC2
instances on the smallest sizes possible. This
solutionisnotscaledtotake
afull-productionload,butitisfullyfunctional.Itcanbe
usedfornon-productionwork, such as testing, quality assurance, and
internal use.
* [#A] [Testing] Cooperate with QA effort
** [#A] Principle: Do local test first, when debug something
** [#A] Principle: Always be able to build from nothing except the code
** [#A] Principle: Always be able to test everything locally and as fast as possible
** Principle: always remember to check and verify, if you perform something change or chef check-in
** TODO [#A] Principle: [sandbox test]: won't touch any prod services: jenkins/repo/chef, etc
#+BEGIN_EXAMPLE
[2/24/15, 1:34:47 PM] kungchaowang: because we can not allow everyone to test on digital ocean, it costs more and also need control. but if we can somehow, help them to do a sandbox testing and not change any setting/installation of their local machine, that will be ideal.
[2/24/15, 1:36:06 PM] denny: So we assume almost everyone’s machine is powerful enough to do that. Right?
[2/24/15, 1:36:56 PM] kungchaowang: so, my plan is, on their local machine, I will start two instance for them, one instance is chef server, the other is AIO. after chef server starts, cookbook uploaded, we start another AIO in VM, and this AIO will use this chef server for recipe installation, after installation is done, they are free to test AIO.
[2/24/15, 1:37:28 PM] kungchaowang: I am not sure, but I think everyone’s machine should be powerful enough to start at least one VM with 4G
[2/24/15, 1:38:41 PM] kungchaowang: so, another thing I am thinking is that everyone can start their VM, but using one of in-house Chef server for installation
[2/24/15, 1:39:05 PM] kungchaowang: so, we provide in house chef and jenkins, and they provide VM on their own machine
[2/24/15, 1:39:22 PM] kungchaowang: but, if we do that, they will have trouble if they are not in office.
[2/24/15, 1:39:30 PM] denny: What’s the hosting OS? All OSX?
[2/24/15, 1:39:51 PM] kungchaowang: it does not matter, but that OS needs to run virtualbox
[2/24/15, 1:40:23 PM] denny: I guess your are using knife, test kitchen, etc.

We will need setup those in the hosting OS.
[2/24/15, 1:40:44 PM] kungchaowang: i am currently not using test kitchen
[2/24/15, 1:41:22 PM] kungchaowang: but I will take a look at chef solo
[2/24/15, 1:41:34 PM] kungchaowang: see if we can reduce memory footprint
[2/24/15, 1:41:53 PM] kungchaowang: probably you will use test-kitchen more
[2/24/15, 1:42:19 PM] denny: Yes, one VM would be better, thus we need less resource( especially memory)
[2/24/15, 1:42:45 PM] kungchaowang: for developers, their needs is to quickly start the application for demo, testing, so now they are asking you to create one for them or asking us to prepare that in their local machine, those tasks should be eliminated from your job
[2/24/15, 1:43:02 PM] denny: How about this:
- boot one VM for AIO
- In AIO, we setup docker which have: chef server, jenkins server
[2/24/15, 1:43:49 PM] denny: Thus different services are isolated and use only one VM.
[2/24/15, 1:44:01 PM] kungchaowang: that also a great idea
[2/24/15, 1:45:12 PM] denny: Maybe it can evolve into a very typical and common way for different projects.
#+END_EXAMPLE
** [#A] Principle: Whenever do some change, must perform verfication and validation in staging server and prod server
** #  --8<-------------------------- separator ------------------------>8--
** TODO [#A] How we can differentiate Deploy issue and Code issue :IMPORTANT:
#+BEGIN_EXAMPLE
[3/3/15, 1:13:54 PM] denny: denny added Andre Uhlrich, John Kaplan to this conversation
[3/3/15, 1:36:49 PM] Andre Uhlrich: Hi Denny. Any idea about the jenkins problem??
[3/3/15, 1:43:57 PM] denny: Hi Andre, I’m helping on another issue of identity.

Would you please confirm whether tomcat is restarted, after you updated the env?
[3/3/15, 1:46:18 PM] Andre Uhlrich: ==========
[2015-03-03 13:15:24] ========= Stop down the whole service stack. It shall take 1~2 min ============
[2015-03-03 13:15:24] stop apache2
 * Stopping web server apache2
 ... waiting apache2: Could not reliably determine the server's fully qualified domain name, using 107.170.231.91 for ServerName
.   ...done.
[2015-03-03 13:15:26] stop tomcat7
 * Stopping Tomcat servlet engine tomcat7
[2015-03-03 13:15:31] stop rest
[2015-03-03 13:15:36] stop adsync
[2015-03-03 13:15:41] stop rmi

========== On 107.170.242.31 Run: ssh -i /var/lib/jenkins/.ssh/id_rsa -o StrictHostKeyChecking=no root@107.170.242.31 fluig_stop_all.sh all ==========
[2015-03-03 13:15:47] ========= Stop down the whole service stack. It shall take 1~2 min ============
[2015-03-03 13:15:47] stop apache2
 * Stopping web server apache2
 ... waiting apache2: Could not reliably determine the server's fully qualified domain name, using 107.170.242.31 for ServerName
.   ...done.
[2015-03-03 13:15:49] stop tomcat7
 * Stopping Tomcat servlet engine tomcat7
[2015-03-03 13:15:54] stop rest
[2015-03-03 13:15:59] stop adsync
[2015-03-03 13:16:04] stop rmi
==========
[2015-03-03 13:16:46] ========= Start the whole service stack. It shall take 1~2 min ============
[2015-03-03 13:16:46] start rest
[2015-03-03 13:16:52] start rmi
[2015-03-03 13:16:56] start adsync
[2015-03-03 13:17:01] start tomcat7
 * Starting Tomcat servlet engine tomcat7
   ...done.
[2015-03-03 13:17:06] start apache2
 * Starting web server apache2
apache2: Could not reliably determine the server's fully qualified domain name, using 107.170.231.91 for ServerName
   ...done.

========== On 107.170.242.31 Run: ssh -i /var/lib/jenkins/.ssh/id_rsa -o StrictHostKeyChecking=no root@107.170.242.31 fluig_start_all.sh all ==========
[2015-03-03 13:17:08] ========= Start the whole service stack. It shall take 1~2 min ============
[2015-03-03 13:17:08] start rest
[2015-03-03 13:17:14] start rmi
[2015-03-03 13:17:17] start adsync
[2015-03-03 13:17:21] start tomcat7
 * Starting Tomcat servlet engine tomcat7
   ...done.
[2015-03-03 13:17:26] start apache2
 * Starting web server apache2
apache2: Could not reliably determine the server's fully qualified domain name, using 107.170.242.31 for ServerName
   ...done.
[3/3/15, 1:50:18 PM] denny: So it’s restarted correctly.

qafluigidentity is a cluster env. When you say your local build works, is that the same env like qafluigidentity?
[3/3/15, 1:50:49 PM] Andre Uhlrich: no, its my machine
[3/3/15, 1:51:06 PM] denny: I assume that’s all-in-one
[3/3/15, 1:51:13 PM] Andre Uhlrich: yes
[3/3/15, 1:51:33 PM] denny: We didn’t change chef about deployment and update for weeks.
[3/3/15, 1:51:44 PM] Andre Uhlrich: it could be some git issue?
[3/3/15, 1:52:19 PM] denny: No, it won’t for sure.
[3/3/15, 1:52:51 PM] denny: The frontend code control whether it will show up that UI component.

It may read some stuff or do some logic to decide.
[3/3/15, 1:53:36 PM] denny: So would it help to ask frontend developer to do some trouble shooting?

If upgrade job run correctly in the Jenkins UI, the update succeed.
[3/3/15, 1:54:50 PM] denny: When I’m released, I will check that in detail.
Just let you know we don’t see any issue about that jenkins task for the last 3 months.
[3/3/15, 1:55:10 PM] denny: So it’s better to fetch frontend developer/knowledge to do more trouble shooting
[3/3/15, 1:56:13 PM] Andre Uhlrich: but the logic is simple: if you click on Thick App, that field is diplauyed
[3/3/15, 1:58:05 PM] denny: Not really that simple. If you can check more with frontend developer
[3/3/15, 1:58:18 PM] Andre Uhlrich: ok
[3/3/15, 1:59:11 PM] denny: I will check that as well in 1 hour later.
#+END_EXAMPLE
** Need to automate all-in-one deployment in digtial ocean
*** CANCELED All in one deployment for search fail to start
  CLOSED: [2015-01-26 Mon 18:10]
#+BEGIN_EXAMPLE
[26 Jan 2015;23:30:37.432] - [INFO ] [ContextHandler:?] - Started i.d.j.MutableServletContextHandler@7a803ee7{/search,null,AVAILABLE}
[26 Jan 2015;23:30:37.434] - [INFO ] [AdminEnvironment:?] - tasks =

    POST    /tasks/gc (io.dropwizard.servlets.tasks.GarbageCollectionTask)

[26 Jan 2015;23:30:37.442] - [INFO ] [ContextHandler:?] - Started i.d.j.MutableServletContextHandler@139cf776{/admin,null,AVAILABLE}
[26 Jan 2015;23:30:37.452] - [INFO ] [ServerConnector:?] - Started application@45cc9007{HTTP/1.1}{0.0.0.0:18084}
[26 Jan 2015;23:30:37.456] - [INFO ] [ServerConnector:?] - Started admin@7903df5d{HTTP/1.1}{0.0.0.0:18085}
[26 Jan 2015;23:30:51.185] - [INFO ] [GlobalSearchCore:?] - hits = 0
[26 Jan 2015;23:30:51.185] - [INFO ] [GlobalSearchCore:?] - hits = 0
[26 Jan 2015;23:30:51.186] - [INFO ] [GlobalSearchCore:?] - hits = 0
[26 Jan 2015;23:30:51.186] - [INFO ] [GlobalSearchCore:?] - hits = 0
[26 Jan 2015;23:30:51.186] - [INFO ] [GlobalSearchCore:?] - hits = 0
[26 Jan 2015;23:30:51.186] - [INFO ] [GlobalSearchCore:?] - hits = 0
[26 Jan 2015;23:30:51.187] - [INFO ] [GlobalSearchCore:?] - hits = 0
[26 Jan 2015;23:30:51.190] - [INFO ] [GlobalSearchCore:?] - hits = 0
[26 Jan 2015;23:30:51.190] - [INFO ] [GlobalSearchCore:?] - hits = 0
[26 Jan 2015;23:30:51.192] - [INFO ] [GlobalSearchCore:?] - hits = 0
[26 Jan 2015;23:32:13.957] - [WARN ] [RemotingConnectionImpl:?] - Connection failure has been detected: The connection was disconnected because of server shutdown [code=4]
[26 Jan 2015;23:32:13.958] - [WARN ] [RemotingConnectionImpl:?] - Connection failure has been detected: The connection was disconnected because of server shutdown [code=4]
[26 Jan 2015;23:32:14.887] - [INFO ] [ServerConnector:?] - Stopped application@45cc9007{HTTP/1.1}{0.0.0.0:18084}
[26 Jan 2015;23:32:14.891] - [INFO ] [ServerConnector:?] - Stopped admin@7903df5d{HTTP/1.1}{0.0.0.0:18085}
[26 Jan 2015;23:32:14.893] - [INFO ] [ContextHandler:?] - Stopped i.d.j.MutableServletContextHandler@139cf776{/admin,null,UNAVAILABLE}
[26 Jan 2015;23:32:14.894] - [INFO ] [ContextHandler:?] - Stopped i.d.j.MutableServletContextHandler@7a803ee7{/search,null,UNAVAILABLE}
#+END_EXAMPLE
** TODO Need QA to test all-in-one deployment
** TODO Need QA to test onpremise enterprise deployment
** TODO How to handle questions of linux basic
#+BEGIN_EXAMPLE
[3/3/15, 9:22:48 AM] Gustavo Henrique Pereira: Denny
[3/3/15, 9:22:59 AM] Gustavo Henrique Pereira: how can i restart all the server in a on-premisse env:?
[3/3/15, 9:23:11 AM] denny: https://totvslab.atlassian.net/wiki/display/TECH/Fluig+Env+List
[3/3/15, 9:23:30 AM] denny: Gustavo, Check above link. Like search by “restart"
[3/3/15, 9:25:09 AM] Gustavo Henrique Pereira: i see
and about the sh fluig_stop_all what is the directory;/
[3/3/15, 9:25:10 AM] Gustavo Henrique Pereira: ?
[3/3/15, 9:25:46 AM] denny: 1. Use which command to locate binary in linux
[3/3/15, 9:26:26 AM] denny: 2. Just run fluig_stop_all.sh, instead of “sh fliug_stop_all.sh”, because we don’t know whether sh point to bash, zsh, ksh.
[3/3/15, 9:26:52 AM] denny: If you do want to specify the sh interpreter, try “bash fluig_stop_all.sh”
#+END_EXAMPLE
** TODO [#A] machine will run out of disk eventually
#+BEGIN_EXAMPLE
[2/25/15, 2:37:38 PM] denny: Hi Suresh
[2/25/15, 2:37:47 PM] Suresh Sathyanarayan: I am getting “No space left on device” on the Jenkins machine.
[2/25/15, 2:38:01 PM] denny: The John’s Jenkins?
[2/25/15, 2:38:20 PM] Suresh Sathyanarayan: 104.131.146.94
[2/25/15, 2:38:28 PM] denny: Yes, no disk now.
[2/25/15, 2:38:31 PM] denny: Let me check about that
[2/25/15, 2:38:35 PM] Suresh Sathyanarayan: Ok thanks
[2/25/15, 2:45:54 PM] denny: We’re fine now.
[2/25/15, 2:46:02 PM] denny: We shall not see this problem happen again.
[2/25/15, 2:47:02 PM] denny: This server also serves as backup storage for qaflugidentity

Since everyday it will receive ~1G backupset, it keeps grow, thus it run out of disk finally.
[2/25/15, 2:47:32 PM] denny: I’ve setup a crontab, which will delete old backupset for qafluigidentity, which is 15 days ago.
#+END_EXAMPLE
** DONE Server Spec - Testing if servers are built and have the necessary tools installed to meet your expectations
   CLOSED: [2015-03-19 Thu 10:23]
** [#B] Perform fire drills: switch the DNS to simulated envs and perform the test
http://www.agilesysadmin.net/ec2-outage-lessons

pick a day, and run through the process of bringing up the DR systems, and recovering from backup. Follow the process - and improve it if you can.

Your backups mean nothing if you haven't verified you can restore them.

- Know how long it takes to restore your systems.
** TODO Ask QA to provide functional test scripts
#+BEGIN_EXAMPLE
[2/5/15, 9:50:14 AM] kungchaowang: also Denny, for edge case, we should have schedule Jenkins jobs to run and check, don’t use nagios.
[2/5/15, 9:50:52 AM] denny: Sure, it’s only a bash script.

People can easily integrate it in Jenkins
[2/5/15, 9:51:51 AM] kungchaowang: for those cases, and how to check, let’s ask Suresh to provide the selenium script.
[2/5/15, 9:52:04 AM] denny: agree
#+END_EXAMPLE
** Verify deployment by server reboot
** #  --8<-------------------------- separator ------------------------>8--
** TODO Build code but do keep latest release, without overwriting
** TODO Try maven build as a helloworld
** web page: 跟Monty Taylor和Jim Blair聊OpenStack的持续集成与自动化测试
http://www.infoq.com/cn/articles/interview-openstack-ci-test-automation
*** webcontent                                                     :noexport:
#+begin_example
Location: http://www.infoq.com/cn/articles/interview-openstack-ci-test-automation
BT

  * 投稿
  * 关于我们
  * 合作伙伴

  * 欢迎关注我们的：
  * [weibo_16x1]
  * [weixin_16_]
  * [rss]

InfoQ - 促进软件开发领域知识与创新的传播
[搜索关键词          ]  submit
登录
[logo_bigge]

  * En |
  * 中文 |
  * 日本 |
  * Fr |
  * Br

482,381 十二月独立访问用户

  * 语言 & 开发
      + Java
      + .Net
      + 云计算
      + 移动
      + HTML 5
      + JavaScript
      + Ruby
      + DSLs
      + Python
      + PHP
      + PaaS

    特别专题

    []

    浏览所有语言 & 开发
  * 架构 & 设计
      + 建模
      + 性能和可伸缩性
      + 领域驱动设计
      + AOP
      + 设计模式
      + 安全
      + 云计算
      + SOA

    特别专题

    []

    浏览所有架构 & 设计
  * 过程 & 实践
      + Agile
      + 领导能力
      + 团队协作
      + 敏捷技术
      + 方法论
      + 持续集成
      + 精益
      + 客户及需求

    特别专题

    []

    浏览所有过程 & 实践
  * 运维 & 基础架构
      + 性能和可伸缩性
      + 大数据
      + DevOps
      + 云计算
      + 虚拟化
      + NoSQL
      + 应用服务器
      + 运维

    特别专题

    []

    浏览所有运维 & 基础架构
  * 企业架构
      + 企业架构
      + 业务流程建模
      + 业务/IT整合
      + Integration (EAI)
      + 治理
      + Web 2.0
      + SOA

    特别专题

    []

    浏览所有企业架构

[20150104_b]

  * 移动
  * Docker
  * Node.js
  * 云计算
  * 大数据
  * 架构师
  * QCon
  * ArchSummit
  * AWS
  * Azure
  * Helion

全部话题
您目前处于： InfoQ首页文章跟Monty Taylor和Jim Blair聊OpenStack的持续集成与自动化测试

跟Monty Taylor和Jim Blair聊OpenStack的持续集成与自动化测试 [logo]

作者 Sai Yang ，译者杨赛发布于 2014年8月5日 |

  * 分享到：微博微信 Facebook Twitter 有道云笔记邮件分享
  * `稍后阅读'
  * `我的阅读清单'

OpenStack社区有一个CI和自动化测试小组，该小组为OpenStack社区的开发者们提供服务，而该服务所用的工具
正是他们自己维护的一个OpenStack云环境。

对于这样一个囊括了十数个子项目，每月有300多位开发者提交代码的复杂项目，普通的CI系统是难以处理的。

我们跟该小组的负责人Monty Taylor和James Blair沟通，了解他们在构建和测试过程中所面临的挑战，以及他们
是如何解决这些挑战的。

相关厂商内容

前JavaEye网站创始人范凯：一个程序员的创业寻梦坎坷之路

DevOps的概念与实践，InfoQ迷你书

QCon北京2015增至18个专题，八折报名中。

QCon北京2015 PHP开发组核心成员惠新宸

QCon北京2015讲师 Spark SQL开发者连城

相关赞助商

[QCon]

全球软件开发大会，4月23-25日，北京，敬请期待！

InfoQ：你们的CI系统每天处理多少次提交？你预计到Icehouse版本发布时会有多少？（注：本采访完成于2013年
11月，当时距离Icehouse发布还有半年）

    Monty：印象中，我们的系统最高处理过每日400次提交。这些仅仅是通过测试的部分，实际上我们的测试量
    要大于这个数字，因为只有通过测试的代码才会进入CI。

    Jim：每次提交被审查之后，我们在实施合并之前会再做一轮测试。

    Monty：对于每个被合并的提交，我们都会对其做8-10个不同的测试任务。因为测试会在上传的时候和合并之
    前各做一次，相当于每次变更我们都会跑将近20个测试任务。有一段时间我们的系统一天就跑了10000个任务
    。

    从Grizzly到Havana，我们的集成、测试量基本上增加了一倍。基本上每个新版本我们都会增加一倍的量，到
    Icehouse应该也是如此。

InfoQ：你们都跑哪些测试任务？

    Jim：首先是代码风格检测。因为我们的协作开发者人数众多，因此代码风格统一是非常重要的，我们需要确
    保大家都使用同样的编码方式。这是个很简单的任务，但很重要。

    然后是单元测试，仅仅测试被变更的子项目，不考虑跟其他子模块之间有网络交互的情况。我们针对几个不
    同的平台做测试，包括2.6、2.7和3.3，基本上我们在CentOS上跑2.6，在Ubuntu上跑2.7。

    然后是集成测试。我们用DevStack将所有的组件安装起来，然后在安装起来的这个单节点云实例上跑不同的
    模板。不同的模板对不同的模块进行不同的设置，比如使用不同的数据库、不同的消息队列。可以选择的种
    类很多，不过基本上我们只测试那些常用的，比如MySQL、PostgreSQL、RabbitMQ这些。

    Monty：我们最近也在考虑引入ZeroMQ的测试。

    Jim：如果社区里认为某个子模块比较重要，使用的人也越来越多，也有更多的人愿意参与到debug工作当中
    ，那我们也会将这个模块加入。

InfoQ：测试任务是由谁来写的？

    Monty：开发者自己写。我们的QA团队很小，基本上只关注测试系统本身的工作，不会有太多精力去关注测试
    任务本身。所以我们要求开发者自己提供单元测试和集成测试。

    Jim：我们最近在讨论的一个话题就是在这方面做更严格的限制，即只有写好了集成测试的变更提交才能够被
    接受。

    Monty：我们总觉得未经测试的变更就是有问题的。一般来说的确是这样。

    Jim：现在项目发展的这么快，有这么多组件，这里或那里的一个小错误可能就把整个系统搞死。

InfoQ：性能测试有在做吗？

    Jim：还没有，不过我觉得可能差不多可以启动了。我听说Boris Pavlovic正在做一个叫做Rally的测试系统
    ，Joe Gordon则在进行一些可扩展性测试的工作——跟性能测试不太一样，不过关联比较大。这都是我们希望
    做的事情。

    我们的测试显然没有覆盖所有的方面，不过我们最终希望测试所有的东西，当然这需要时间。

    在本次发布周期内，我们关注于升级测试。现在我们已经在做一些，不过做的还不够，需要做更多。

InfoQ：在一个实例上运行一个测试任务大概需要多久？

    Monty：一般在20-40分钟，具体时间长短跟实例的配置有关。

    Jim：我们花了很多精力让测试变得并行化。我们构建了一个叫做Test Repository的框架，大多数单元测试
    在这个框架中已经可以并行处理，测试结果出的很快。

    Monty：还有Jim写的Zuul，这个工具可以一方面并行的测试成套的变更，同时又保持他们的测试顺序不变。

InfoQ：运行测试用到了多少机器？用于运行测试用例的实例配置是怎样的？

    Monty：我们自己是没有机器的。所有的测试都跑在公有云上，有些来自Rackspace，有些来自HP，都是赞助
    的。他们没找我们要钱，而我们需要多少就可以用多少。

    Jim：上一个版本周期内，最高的时候我们并行跑了340个实例，一个实例就是一个VM。集成测试一般使用很
    基础的VM——8GB内存，系统是Ubuntu Precise。我们把这个节点搞起来，然后让DevStack在这个VM上安装
    OpenStack。

    Monty：实际情况要比这个复杂，不过大概意思就是这样。我们有一个nodepool用来管理这些VM，通过缓存来
    预备这些机器。我们需要将DevStack需要的依赖等东西都预先下载到本地，这样测试本身就可以离线运转。

    Jim：测试跑完之后，我们再销毁这些VM。实际创建的VM数量要比跑成功的测试数量多，因为Zuul的随机机制
    ，有些时候它的测试跑到一半的时候才发现还需要一些其他东西，于是测试跑不下去了，我们会干掉这个VM
    ，起一个新的。一个大致的比例是，如果一天跑10000个任务，那么启动的VM数量差不多在100000的量级。

InfoQ：可以认为用于OpenStack的Zuul模式是nvie git分支模式的一个改进吗？感觉Zuul似乎不适合分支过多的
情况。

    Monty：实际上我们是不采用nvie git分支模式的，因为我们用了Gerrit，所以我们的代码提交模式跟Linux
    内核的模式更像：人们在邮件里交换补丁。我们的做法不是建立很多的分支然后做合并，而是让每一个变更
    形成一个虚拟的私有分支。相对于将每一次变更生成一个新的commit并增添至分支的顶端的做法，我们的做
    法是：在之前的一次修改之上再进行修改。我们的测试针对每一个独立的commit，而不是针对一个分支。

    每一个开发者可以建立本地的分支，这些分支是私有的，没有什么发布机制。我并不知道Jim的笔记本上的分
    支是什么样的。我自己用git的方式比较奇葩，我不用分支，而是每次在我的master上重置ref——这是个非主
    流的用法，git新手最好还是不要这么尝试。

    所以，OpenStack的git补丁流程其实是基于Gerrit的。

    Jim：另外，我们需要确保审查人员审查的对象是每一个commit（而不是分支）。理想状态下，每一个进入项
    目的commit都被人仔细的检查过。分支的话就会比较混乱。把每一个commit把关好，把好的commit合并，是
    比较精细的做法。

InfoQ：除了Zuul之外，你还提到了在Jenkins上使用Gearman来提高可扩展性，使用Logstash做debug，还有你上
面提到的Test Repository将测试输出自动发给committer。目前的反馈机制是如何运转的？理想的情况是怎样的
？

    Monty：反馈机制整体来说是越来越好的。你的问题涉及到几个方面。有关用Gearman来提高Jenkins的可扩展
    性这一点，首先Jenkins本身的设计是针对一个master的情况，让它支持多个节点是通过hack的方式来完成的
    。我们一开始的用法是跑一个Jenkins master和若干个slave，并行跑的测试任务数量要比正常的Jenkins用
    法要多很多。Jenkins在设计当中涉及到很多全局锁，所以要像我们这样用起来，会遇到很多可扩展性的问题
    。

    Jim：因为Jenkins在设计的时候根本没考虑过我们这样的用法。

    Monty：所以我们就写了Gearman插件，这个插件的作用是让Jenkins将所有任务注册为潜在的Gearman任务，
    标记在Gearman服务器上。这样一来我们就可以针对一组测试任务建立多个Jenkins master，让Gearman来做
    任务分发，如果一个Jenkins master开始遇到瓶颈，我们就让Gearman把任务分发到下一个Jenkins master上
    。

    Jim：一般来说，一个Jenkins master带100个slave之后就会遇到问题。我们要同时跑340个任务，那就需要
    3.4个Jenkins master来处理。

    Monty：Logstash集群是个很有意思的东西。每一次DevStack安装的是整个的云环境，然后针对这个小环境跑
    测试。仅仅是安装的过程就会制造很多日志，包括Nova、Glance等等。如果遇到问题，开发者根本无从下手
    去debug，能够依赖的只有日志。所以，我们把所有的日志丢到一个很大的Logstash集群当中，这个集群通过
    elastic search的方式给所有的log建索引。这样，开发者就可以进去查看日志，了解到底发生了什么问题。
    这里面的Elastic Recheck是Joe Gordon、Sean Dague和Clark Boylan写的。

    Joe：那个图表功能是我写的。

    Monty：比如我们发现有一个任务导致测试跑失败了，我们会在LogStash上运行脚本，来检测这是否是我们之
    前见到过的错误类型。如果有匹配，我们会在邮件通知里将之前的bug报告附上，这样会帮助开发者更快的定
    位问题。

    Jim：这其实是很酷，也很独特的。世界上像这种规模的项目是很少的，这种规模的测试、这种规模的日志，
    开发者很少能够在其他项目获取到。云平台这样的项目，开发者在自己的机器上是很难去发现代码可能会引
    起的问题的，因为很多问题都是要跑很多次不同的测试才能抓到——而我们的测试平台可以做到这一点！下一
    个发布周期内，我们会尝试让问题识别变得更加自动化，将变更和行为的特征更多的抽取出来，帮助开发者
    更快的定位问题。

InfoQ：你们做的这一大堆自动化测试的工作，感觉最难的地方是在哪里？

    Monty：开发者很多，代码很多，测试需求量每6个月都会增长一倍。面对commit数量如此众多、快速增长的
    情况，我们需要提前预见到可能发生的问题，做好准备——因为如果真的遇到了问题，那么那个时候再去开发
    系统来解决问题就来不及了。自动化解决的问题不是今天的问题，而是三个月之后的问题。

    正因为所有的测试都在我们这里，我们就必须确保这个系统一直能够正常运转。你的测试一天跑10000次，万
    一系统出了问题，给开发者发邮件说你的代码有错（而实际上根本不是他们代码出了错，是系统本身出了错
    ），那就会很糟糕。误报比不报更糟糕，所以自动化必须做的非常靠谱。

    还有就是，我们总是会遇到网络中断的问题——基本上我们有一半的时间都用来处理这个问题。所有的网站都
    会连不上：平时你自己去刷网页是感觉不到的，但如果你一天跑10000次自动化测试呢？如果Github平均有1%
    的时间是不可用的，你作为用户去刷页面没打开，重试一次就好；而我的测试系统每天从Github做10000次抓
    取，1%的不可用就相当于100次失败。

    由于我们在跑的这个系统，我们也成了RackSpace和HP云的性能监控器。很多时候我们发现有一个问题，就去
    问他们的运维：“你们这个数据中心是不是网络出问题了？”然后他们会说：“对啊！我们也刚刚发现！”

    Jim：Rackspace和HP云都是基于OpenStack的系统，所以我们的测试系统是在OpenStack上运行、为OpenStack
    做测试。用自己测试自己的代码，同时又测试自己的运行状态，这是个很酷的事情。

受访者简介

[0731020]Monty Taylor是HP杰出工程师，OpenStack技术委员会成员、OpenStack基金会个人董事。他带领
OpenStack基础架构项目、Ironic项目和TrippleO项目。

Jim Blair现在是OpenStack基础软件组的核心开发者，也是OpenStack CI项目的核心开发者。他也是OpenStack技
术委员会成员，OpenStack基础架构项目的技术领导者。他目前任职于OpenStack基金会。

查看英文原文：Monty Taylor and Jim Blair on CI and Test Automation at OpenStack

  * 领域
  * 运维 & 基础架构
  * 架构 & 设计
  * 语言 & 开发
  * 专栏
  * 测试
  * 私有云
  * DevOps
  * 部署
  * 虚拟化
  * OpenStack
  * 持续集成
  * 代码复查
  * 敏捷
  * 自动化操作
  * 云计算
  * 敏捷技术
  * IaaS
  * 自动化测试

相关内容

您好，朋友！

您需要注册一个InfoQ账号或者登录才能进行评论。在您完成注册后还需要进行一些设置。

获得来自InfoQ的更多体验。

告诉我们您的想法

[                    ] [                    ]

允许的HTML标签: a,b,br,blockquote,i,li,pre,u,ul,p

[ ] 当有人回复此评论时请E-mail通知我
发送信息
社区评论
关闭

by

发布于

  * 查看
  * 回复
  * 回到顶部

关闭
主题 [                    ] 您的回复引用原消息 [                    ]

允许的HTML标签: a,b,br,blockquote,i,li,pre,u,ul,p

[ ] 当有人回复此评论时请E-mail通知我
发送信息    取消
关闭
主题 [                    ] 您的回复 [                    ]

允许的HTML标签: a,b,br,blockquote,i,li,pre,u,ul,p

[ ] 当有人回复此评论时请E-mail通知我

    取消
关闭

 OK
讨论

  * 热点内容
  * 10天
  * 40天
  * 近6个月

深度内容

  * 全部
  * 文章
  * 演讲
  * 访谈
  * 迷你书

互联网金融系统中的资金正确性保障

陆怡 1月28日

[luyi_100]

BaaS服务的定义、发展以及未来

郭蕾 1月28日

[cloud2]

从计划到进化

任鑫 1月28日

[renxin_100]

解读2014之安全篇：史诗级漏洞频发

黄丹 1月27日

[road]

Tower团队24个月的远程协作实践

沈学良 1月27日

[shenxuelia]

从360手机卫士的开发历程看如何实施大型移动应用开发

姚彤 1月27日

[yaotong_10]

  * 更早的 >

赞助商链接

InfoQ每周精要

通过个性化定制的新闻邮件、RSS Feeds和InfoQ业界邮件通知，保持您对感兴趣的社区内容的时刻关注。

[click2view]
[您的邮箱            ]  订阅
  * 首页
  * 全部话题
  * QCon全球软件开发大会
  * 关于我们
  * 投稿
  * 创建账号
  * 登录

  * 全球QCon
  * 伦敦 2015年3月2-6日
  * 圣保罗 2015年3月23-27日
  * 北京 2015年4月23-25日
  * 东京 2015年4月 21
  * 纽约 2015年6月8-12日
  * 里约 2015年8月24-28日
  * 上海 2015年10月15-17日
  * 旧金山 2015年11月16-20日

InfoQ每周精要

通过个性化定制的新闻邮件、RSS Feeds和InfoQ业界邮件通知，保持您对感兴趣的社区内容的时刻关注。

[click2view]
[您的邮箱            ]  订阅
  * 属于您的个性化RSS
  * InfoQ官方微博
  * InfoQ官方微信
  * 社区新闻和热点

特别专题

  * IBM
  * 技术社区活动日历
  * 百度技术沙龙
  * 月刊：《架构师》
  * 线下活动：QClub
  * AWS专区
  * 物联网大会

定制您感兴趣的技术领域

    [*] 语言 & 开发
    [*] 架构 & 设计
    [*] 过程 & 实践
    [*] 运维 & 基础架构
    [*] 企业架构

这会影响您在主页和RSS订阅中看到的内容。点击“偏好设置”可选择更多精彩定制内容。

                                                                                InfoQ.com及所有内容
                                                                                ，版权所有 ©
                                                                                2006-2015 C4Media
                                                                                Inc. InfoQ.com 服务
提供反馈              错误报告          商务合作           内容合作             器由 Contegix提供,
feedback@cn.infoq.com bugs@cn.infoq.com sales@cn.infoq.com editors@cn.infoq.com 我们最信赖的ISP伙伴
                                                                                。
                                                                                北京创新网媒广告有
                                                                                限公司京ICP备
                                                                                09022563号-7 隐私政
                                                                                策
BT
Close
E-mail [                    ] 密码 [                    ]  submit
使用Google账号登录
使用Microsoft账号登录

忘记密码？

InfoQ账号使用的E-mail [                    ] 发送邮件

重新登录

重新发送激活信息 [                    ] 重新发送

重新登录

没有用户名？

点击注册

#+end_example
** [#A] Setup local squid in mac and make sure kitchen test use it :IMPORTANT:
** TODO DevOps: simulate system reboot scenario
** DONE [#A] Figure out file change list for different relese:  git diff --name-only identity-1.4.4 master | grep ml
  CLOSED: [2015-03-04 Wed 11:50]
#+BEGIN_EXAMPLE
macs-MacBook-Air:backend mac$ git diff --name-only identity-1.4.4 master | grep ml
core/pom.xml
core/src/main/resources/logback.xml
scripts/pom.xml
scripts/scripts-ad/assembly.xml
scripts/scripts-ad/pom.xml
service/keystore/pom.xml
service/neoext/pom.xml
service/rest/pom.xml
service/rest/rest.yml
service/search/pom.xml
service/search/search.yml
#+END_EXAMPLE
** #  --8<-------------------------- separator ------------------------>8--
* Jenkins: Code Build
** Track version in Jenkins, so that people can understand what the commit diff is.
http://java.dzone.com/articles/whats-version-my-deployed?mz=38541-devops
- When the code is built
- Which build server/ip built the code
- Branch name
- What's the git commit version for each component
*** Jenkins build Hadoop sample
#+BEGIN_EXAMPLE
hduser@denny-chef-ubuntu-10:~$ hadoop version
Hadoop 2.6.0
Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1
Compiled by jenkins on 2014-11-13T21:10Z
Compiled with protoc 2.5.0
From source with checksum 18e43357c8f927c0695f1e9522859d6a
This command was run using /usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar
#+END_EXAMPLE
** Jenkins send email for different stage
http://192.241.219.217:8180/job/BuildRedhatLiveCD/2/console
http://stackoverflow.com/questions/11628065/error-when-sending-email-with-jenkins
#+begin_example
ERROR: Could not connect to SMTP host: localhost, port: 25
javax.mail.MessagingException: Could not connect to SMTP host: localhost, port: 25;
  nested exception is:
	java.net.ConnectException: Connection refused
	at com.sun.mail.smtp.SMTPTransport.openServer(SMTPTransport.java:1391)
	at com.sun.mail.smtp.SMTPTransport.protocolConnect(SMTPTransport.java:412)
	at javax.mail.Service.connect(Service.java:288)
	at javax.mail.Service.connect(Service.java:169)
	at javax.mail.Service.connect(Service.java:118)
	at javax.mail.Transport.send0(Transport.java:188)
	at javax.mail.Transport.send(Transport.java:118)
	at hudson.tasks.MailSender.execute(MailSender.java:111)
	at hudson.tasks.Mailer.perform(Mailer.java:101)
	at hudson.tasks.BuildStepMonitor$1.perform(BuildStepMonitor.java:19)
	at hudson.model.AbstractBuild$AbstractRunner.perform(AbstractBuild.java:692)
	at hudson.model.AbstractBuild$AbstractRunner.performAllBuildSteps(AbstractBuild.java:667)
	at hudson.model.AbstractBuild$AbstractRunner.performAllBuildSteps(AbstractBuild.java:645)
	at hudson.model.Build$RunnerImpl.post2(Build.java:161)
	at hudson.model.AbstractBuild$AbstractRunner.post(AbstractBuild.java:614)
	at hudson.model.Run.run(Run.java:1400)
	at hudson.model.FreeStyleBuild.run(FreeStyleBuild.java:46)
	at hudson.model.ResourceController.execute(ResourceController.java:88)
	at hudson.model.Executor.run(Executor.java:175)
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:327)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:193)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:180)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:385)
	at java.net.Socket.connect(Socket.java:546)
	at com.sun.mail.util.SocketFetcher.createSocket(SocketFetcher.java:231)
	at com.sun.mail.util.SocketFetcher.getSocket(SocketFetcher.java:189)
	at com.sun.mail.smtp.SMTPTransport.openServer(SMTPTransport.java:1359)
	... 18 more
Finished: FAILURE
#+end_example
** Configure scheduled Jenkins build
** [#A] Jenkins build: skip component build, if no update for code
** TODO setup JIRA Monitor jenkins chef-in
[11/24/14, 7:54:12 PM] kungchaowang: then I don’t know why it’s not there
[11/24/14, 7:54:58 PM] kungchaowang: anyway, please run this cookbook again, and see if that file will be copied, it should
[11/24/14, 7:56:03 PM] denny: Yes, it’s on the way.

Need find some time to setup a jenkins script or git hook:
If files like neo4j_server_start.sh or config files updated, send out alerting email.
*** neo4j_server_start.sh
#+BEGIN_EXAMPLE
[11/24/14, 7:51:04 PM] kungchaowang: I have a script in the /cloudpass/backend/build/bin/neo4j_server_start.sh that will tell you what files are needed and where they should be copied into
[11/24/14, 7:52:03 PM] kungchaowang: Kung-at-Totvslabs:backend kungwang$ cd build/bin/
Kung-at-Totvslabs:bin kungwang$ more neo4j_server_start.sh
#!/bin/bash
export NEO4J_HOME=${NEO4J_HOME:-/opt/neo4j-server}
export BACKEND_HOME=${BACKEND_HOME:-~/cloudpass/backend}
echo "use NEO4J_HOME $NEO4J_HOME"
echo "use BACKEND_HOME $BACKEND_HOME"

cp ${BACKEND_HOME}/build/lib/boon-0.29.jar ${NEO4J_HOME}/lib/
cp ${BACKEND_HOME}/build/lib/spring-context-3.1.2.RELEASE.jar ${NEO4J_HOME}/lib/
cp ${BACKEND_HOME}/build/lib/gson-2.2.2.jar ${NEO4J_HOME}/lib/
cp ${BACKEND_HOME}/build/lib/lucene3x-1.0.jar ${NEO4J_HOME}/lib/
cp ${BACKEND_HOME}/build/lib/antlr4-runtime-4.0.jar ${NEO4J_HOME}/lib/
cp ${BACKEND_HOME}/build/lib/neo4j2x-1.0.jar ${NEO4J_HOME}/lib/
cp ${BACKEND_HOME}/build/lib/idm-common-model-1.0.jar ${NEO4J_HOME}/lib/
cp ${BACKEND_HOME}/build/dist/rest.jar ${NEO4J_HOME}/lib/
cp ${BACKEND_HOME}/build/dist/neoext.jar ${NEO4J_HOME}/plugins/

${NEO4J_HOME}/bin/neo4j start
[11/24/14, 7:52:15 PM] denny: cp ${BACKEND_HOME}/build/dist/rest.jar ${NEO4J_HOME}/lib/
cp ${BACKEND_HOME}/build/dist/neoext.jar ${NEO4J_HOME}/plugins/
[11/24/14, 7:52:48 PM] denny: I see, right now, chef is correct for this.

But this way, it’s so easily out-of sync
[11/24/14, 7:53:04 PM] kungchaowang: yes, I know, so, please check your neo4j chef cookbook
[11/24/14, 7:53:13 PM] denny: https://github.com/TOTVS/chef/commit/9ae1062c16d23769214ea789e4f18fe0d0dff616
[11/24/14, 7:53:16 PM] kungchaowang: I remember you move these copy files out of default recipies
[11/24/14, 7:53:24 PM] kungchaowang: and as another recipies now
#+END_EXAMPLE
** #  --8<-------------------------- separator ------------------------>8--
** TODO Chef Jenkins: address not configured yet <nobody@nowhere>
** TODO Chef jenkins sending out mail: wrong mail password
ssh root@198.199.105.82
http://198.199.105.82:8180

cat jenkins/hudson.tasks.Mailer.xml
cat jenkins/jenkins.model.JenkinsLocationConfiguration.xml
*** /sshx:root@198.199.105.82:/var/lib/jenkins/jenkins.model.JenkinsLocationConfiguration.xml
#+BEGIN_EXAMPLE
cat > /var/lib/jenkins/jenkins.model.JenkinsLocationConfiguration.xml <<EOF
<?xml version='1.0' encoding='UTF-8'?>
<jenkins.model.JenkinsLocationConfiguration>
  <adminAddress>jenkins@fluigidentity.com</adminAddress>
  <jenkinsUrl>http://198.199.105.82:8180/</jenkinsUrl>
</jenkins.model.JenkinsLocationConfiguration>
EOF
#+END_EXAMPLE
*** /sshx:root@198.199.105.82:/var/lib/jenkins/hudson.tasks.Mailer.xml
#+BEGIN_EXAMPLE
cat > /var/lib/jenkins/hudson.tasks.Mailer.xml <<EOF
<?xml version='1.0' encoding='UTF-8'?>
<hudson.tasks.Mailer_-DescriptorImpl plugin="mailer@1.8">
  <defaultSuffix>@fluigidentity.com</defaultSuffix>
  <hudsonUrl>http://198.199.105.82:8180/</hudsonUrl>
  <smtpAuthUsername>jenkins@fluigidentity.com</smtpAuthUsername>
  <smtpAuthPassword>i4xfK7bN0m5FaM1vZsrkjvHPh9pY/w62qMjsbUGATXM=</smtpAuthPassword>
  <replyToAddress>jenkins@fluigidentity.com</replyToAddress>
  <smtpHost>mail.fluigidentity.com</smtpHost>
  <useSsl>false</useSsl>
  <smtpPort>mail.fluigidentity.com</smtpPort>
  <charset>UTF-8</charset>
</hudson.tasks.Mailer_-DescriptorImpl>
EOF
#+END_EXAMPLE
** TODO [#A] developer's laptop is not powerful enough to run the test: DataXu
** TODO [#B] Jenkins: Build version without overwriting previous version
** TODO jenkins build: need tag previous build, just in case the latest build block
** TODO Jenkins: get last build message and cksum: /data/fluig_state/version
/sshx:fluig@10.165.4.198:/home/denny/chef/cookbooks/fluig-core/recipes/default.rb
cat /data/fluig_state/version

Version: master
Timestamp for build: XX
Build from Jenkins: IP #Task #Num
Update from Repo server: XX

==================== CKSUM =========================
2492923418 19285 dist/PendingAgent.jar
1868125385 619261 dist/ServerStop.jar
516106831 619262 dist/ServerStart.jar
3829369003 248448 dist/KeystoreServerStart.jar
950546843 257070 dist/ADSync.jar
3732650686 671253 dist/Search.jar
4278575176 108482 dist/rest-client-1.0.jar
3041998407 861004 dist/rest.jar
2669608122 5717 dist/scim-client-1.0.jar
1765783565 19299 dist/UpgradeScript.jar
1233734323 8601 dist/DownloadGlobalApps.jar
1598208495 8497 dist/SyncGlobalApps.jar
4154491705 11419 dist/RandomScripts.jar
1936753493 11842 dist/VAPopulateScript.jar
2336663991 11840 dist/VABuildScript.jar
394884652 77298184 dist/VMManager.jar


================ Backend Repo: Git Log -n 2 ==============
testenv:/home/denny/chef# git log -n 2
commit dbae338bee902c6a803316b2cbcde2a2dbd8683c
Author: filebat.mark@gmail.com <filebat.mark@gmail.com>
Date:   Thu Oct 23 21:32:41 2014 +0000

    improve chef_deploy.sh

commit 0528f3d59c50ea5b5d4955bdf348f199a09642d7
Author: filebat.mark@gmail.com <filebat.mark@gmail.com>
Date:   Thu Oct 23 20:27:15 2014 +0000

    update package
==================== Git Log -n 3 =========================

================ Frontend Repo: Git Log -n 2 ==============
testenv:/home/denny/chef# git log -n 2
commit bc9a71f90b9e02b3ea64243ce618b880db90c86f
Author: filebat.mark@gmail.com <filebat.mark@gmail.com>
Date:   Thu Oct 23 21:52:47 2014 +0000

    jenkins job

commit dbae338bee902c6a803316b2cbcde2a2dbd8683c
Author: filebat.mark@gmail.com <filebat.mark@gmail.com>
Date:   Thu Oct 23 21:32:41 2014 +0000

    improve chef_deploy.sh
==================== Git Log -n 3 =========================
** Regression issue of Jenkins: Apache server stopped; config template is changed
#+BEGIN_EXAMPLE
[3/3/15, 1:13:54 PM] denny: denny added Andre Uhlrich, John Kaplan to this conversation
[3/3/15, 1:36:49 PM] Andre Uhlrich: Hi Denny. Any idea about the jenkins problem??
[3/3/15, 1:43:57 PM] denny: Hi Andre, I’m helping on another issue of identity.

Would you please confirm whether tomcat is restarted, after you updated the env?
[3/3/15, 1:46:18 PM] Andre Uhlrich: ==========
[2015-03-03 13:15:24] ========= Stop down the whole service stack. It shall take 1~2 min ============
[2015-03-03 13:15:24] stop apache2
 * Stopping web server apache2
 ... waiting apache2: Could not reliably determine the server's fully qualified domain name, using 107.170.231.91 for ServerName
.   ...done.
[2015-03-03 13:15:26] stop tomcat7
 * Stopping Tomcat servlet engine tomcat7
[2015-03-03 13:15:31] stop rest
[2015-03-03 13:15:36] stop adsync
[2015-03-03 13:15:41] stop rmi

========== On 107.170.242.31 Run: ssh -i /var/lib/jenkins/.ssh/id_rsa -o StrictHostKeyChecking=no root@107.170.242.31 fluig_stop_all.sh all ==========
[2015-03-03 13:15:47] ========= Stop down the whole service stack. It shall take 1~2 min ============
[2015-03-03 13:15:47] stop apache2
 * Stopping web server apache2
 ... waiting apache2: Could not reliably determine the server's fully qualified domain name, using 107.170.242.31 for ServerName
.   ...done.
[2015-03-03 13:15:49] stop tomcat7
 * Stopping Tomcat servlet engine tomcat7
[2015-03-03 13:15:54] stop rest
[2015-03-03 13:15:59] stop adsync
[2015-03-03 13:16:04] stop rmi
==========
[2015-03-03 13:16:46] ========= Start the whole service stack. It shall take 1~2 min ============
[2015-03-03 13:16:46] start rest
[2015-03-03 13:16:52] start rmi
[2015-03-03 13:16:56] start adsync
[2015-03-03 13:17:01] start tomcat7
 * Starting Tomcat servlet engine tomcat7
   ...done.
[2015-03-03 13:17:06] start apache2
 * Starting web server apache2
apache2: Could not reliably determine the server's fully qualified domain name, using 107.170.231.91 for ServerName
   ...done.

========== On 107.170.242.31 Run: ssh -i /var/lib/jenkins/.ssh/id_rsa -o StrictHostKeyChecking=no root@107.170.242.31 fluig_start_all.sh all ==========
[2015-03-03 13:17:08] ========= Start the whole service stack. It shall take 1~2 min ============
[2015-03-03 13:17:08] start rest
[2015-03-03 13:17:14] start rmi
[2015-03-03 13:17:17] start adsync
[2015-03-03 13:17:21] start tomcat7
 * Starting Tomcat servlet engine tomcat7
   ...done.
[2015-03-03 13:17:26] start apache2
 * Starting web server apache2
apache2: Could not reliably determine the server's fully qualified domain name, using 107.170.242.31 for ServerName
   ...done.
[3/3/15, 1:50:18 PM] denny: So it’s restarted correctly.

qafluigidentity is a cluster env. When you say your local build works, is that the same env like qafluigidentity?
[3/3/15, 1:50:49 PM] Andre Uhlrich: no, its my machine
[3/3/15, 1:51:06 PM] denny: I assume that’s all-in-one
[3/3/15, 1:51:13 PM] Andre Uhlrich: yes
[3/3/15, 1:51:33 PM] denny: We didn’t change chef about deployment and update for weeks.
[3/3/15, 1:51:44 PM] Andre Uhlrich: it could be some git issue?
[3/3/15, 1:52:19 PM] denny: No, it won’t for sure.
[3/3/15, 1:52:51 PM] denny: The frontend code control whether it will show up that UI component.

It may read some stuff or do some logic to decide.
[3/3/15, 1:53:36 PM] denny: So would it help to ask frontend developer to do some trouble shooting?

If upgrade job run correctly in the Jenkins UI, the update succeed.
[3/3/15, 1:54:50 PM] denny: When I’m released, I will check that in detail.
Just let you know we don’t see any issue about that jenkins task for the last 3 months.
[3/3/15, 1:55:10 PM] denny: So it’s better to fetch frontend developer/knowledge to do more trouble shooting
[3/3/15, 1:56:13 PM] Andre Uhlrich: but the logic is simple: if you click on Thick App, that field is diplauyed
[3/3/15, 1:58:05 PM] denny: Not really that simple. If you can check more with frontend developer
[3/3/15, 1:58:18 PM] Andre Uhlrich: ok
[3/3/15, 1:59:11 PM] denny: I will check that as well in 1 hour later.
[3/3/15, 3:02:48 PM] denny: Andre, I just checked the env.

I don’t see anything suspicious with deployment.
[3/3/15, 3:03:12 PM] denny: I will try to perform a fresh all-in-one deployment, to see whether it reproduce.
[3/3/15, 3:05:55 PM] denny: Oh, I found something
[3/3/15, 3:07:30 PM] denny: The upgrade failed
[3/3/15, 3:10:51 PM] denny: =========================
The reason why it fail: we have setup an apache service, which is necessary for this upgrade task.
[3/3/15, 3:11:39 PM] denny: The apache is not running. So the upgrade fail.
[3/3/15, 3:13:06 PM] denny:
You mean think: Why jenkins job show it succeed, while it actually failed?
It’s somewhat a regression issue of chef code.

I’ve changed one location of the log file, thus I need to update the jenkins job.
[3/3/15, 3:15:35 PM] denny: =================
To be short,

1. You can retry that task from Jenkins, for the problem you’re seeing.
2. The regression issue of Jenkins job is resolved.

When jenkins job report succeed, it mean upgrade is done.

Sorry about the regression issue, Andre
#+END_EXAMPLE
* [#A] Better communication with developer lead
** [#B] Set up monthly 1-1 feedback with Boss
** [#B] DevOps: Need to have regular meeting to sync up with developers/team lead for general problems and priority
** TODO [#A] Staging server, as simulation of prod env, and ask Dev lead/QA lead to maintain
- fade away for this as DevOps
** TODO Around the OPS tickets, hold a share session with dev lead, or even QA lead
* #  --8<-------------------------- separator ------------------------>8--
* [Upgrade] Smoothly upgrade
** TODO When to restart service of neo4j?? Always to restart
* [Verify] Auto Acceptance test: Check system's healthy
** TODO QA: what does full regression test do? And functional test?
** TODO Suresh: smoke test fail in digital ocean: show me how to do things manually
http://10.165.4.198:8180/job/DeployFluigSystem/95/console
#+begin_example
[2014-11-08 17:25:27] working_dir: /var/lib/jenkins/smoke_test/code
[2014-11-08 17:25:27] Prepare for test
[2014-11-08 17:25:27] Perform test case of CreateCompanyAndCompleteRegistrationByHtml on https://104.236.184.27/cloudpass
The company registration URL I got is: https://104.236.184.27/cloudpass/?resetId=7d503441-fcbf-42c6-b2c8-9592a5835ccf&ucaLoginId=3l02b4bvrai1tyjz1415467631247&companyId=cj8zanrxeocuijzm1415467621185 <tr align="center" valign="center"> <td width="33.3%" height="50" align="center"><b>CREATE COMPANY AND COMPLETE REGISTRATION</b> <td width="33.3%" height="50" align="center"><b>PASSED</b> </tr>
[2014-11-08 17:28:04] Function test of CreateCompanyAndCompleteRegistrationByHtml succeed
[2014-11-08 17:28:04] Perform test case of CreateUsersInCompany on https://104.236.184.27/cloudpass
[2014-11-08 17:29:57] Test failed
[2014-11-08 17:29:57] tail -n 20 CreateUsersInCompany.log
Successfully found a.cp-h-admin
Successfully went to the Dashboard of the newly created company admin
Successfully found Users
Successfully went to the Manage Users page
Failed to find Add New UserFailed to find firstNameFailed to find lastNameFailed to find emailAddressFailed to find button.btn.btn-successSuccessfully found seleniumTestId ....The complete basic user registration URL
Successfully found the user search field and specified the user email
Successfully clicked on the basic user
Successfully found Assign
Successfully clicked on Assign Applications
Failed to find button.btn.btn-success
Failed to find button.btn.btn-success
Failed to find button.btn.btn-success
Failed to find button.btn.btn-success
Failed to find button.btn.btn-success
Failed to find button.btn.btn-success
Failed to find button.btn.btn-success
Failed to find button.btn.btn-success
Failed to find button.btn.btn-success
Failed to find button.btn.btn-success
Failed to specify the basic user registration URLFailed to find Sign UpFailed to find passwordFailed to find confirmPasswordFailed to find //input[@type='checkbox']Failed to find //button[@type='submit']Build step 'Execute shell' marked build as failure
Finished: FAILURE
#+end_example
** TODO [#A] SmokeTest doesn't work for cluster deployment: http://10.165.4.198:8180/job/SmokeTestAIOEnv/148/console
** TODO smoke test of customerfi fail
#+BEGIN_EXAMPLE
[11/26/14, 12:27:04 AM] denny: As a parallel task, I’ve upgrade customerfi to latest identity-1.4.1.

Manually login it succeed. But run smoke test, it fails.

http://10.165.4.198:8180/job/PerformSmokeTest/214/console

Would you please manually reproduce the selenium test?
[11/26/14, 12:29:03 AM] Suresh Sathyanarayan: ok i can check
[11/26/14, 12:30:57 AM] denny: Thanks
[11/26/14, 12:34:01 AM] Suresh Sathyanarayan: Things are fine on customerfi. I just checked manually. Maybe some timing issue, and that’s why second smoke test failed.
[11/26/14, 12:34:28 AM] denny: OK, thanks, Suresh. Let’s get back to this later.
#+END_EXAMPLE
** TODO What url I can try to check more about adsync
* [Backbone] Service initscript
https://github.com/elasticsearch/cookbook-elasticsearch/blob/master/templates/default/elasticsearch.init.erb
** program ulimit
** [#A] Make sure: all projects and services we're doing can be restarted immediately
** Notify the whole system to pause for different components
** #  --8<-------------------------- separator ------------------------>8--
** TODO Figure out java XMX
http://stackoverflow.com/questions/15282178/java-using-up-far-more-memory-than-allocated-with-xmx
** HALF CentOS after reboot: racagent is not autostart
#+BEGIN_EXAMPLE
root@denny-chef-centos-12:~# fluig_status_all.sh
fluig_status_all.sh
[2014-11-19 19:57:46] =========== Fluig version: identity-1.4.1 =====================
couchbase-server is running
 * Neo4j Server is running at pid 1360
 * hornetq is running (pid 1152).
 * httpd (pid  1833) is running...
 * tomcat7 is running (pid 1886).
 * keystore is running (pid 1189).
 * search is running (pid 1677).
 * rest is running (pid 1589).
 * rmi is running (pid 1626).
 * adsync is running (pid 1048).
 * racagent_racagent01 process is not running
[2014-11-19 19:57:47] ERROR: some errors are found in current machine of fluig system
Error to run /usr/local/bin/fluig_status_all.sh
root@denny-chef-centos-12:~# service racagent
service racagent
Usage: /etc/init.d/racagent {start|stop|status} racagent
root@denny-chef-centos-12:~# service racagent start
service racagent start
start racagent_racagent01
root@denny-chef-centos-12:~# chkconfig --list racagent
chkconfig --list racagent
service racagent supports chkconfig, but is not referenced in any runlevel (run 'chkconfig --add racagent')
root@denny-chef-centos-12:~# chkconfig --list racagent
chkconfig --list racagent
service racagent supports chkconfig, but is not referenced in any runlevel (run 'chkconfig --add racagent')
root@denny-chef-centos-12:~#
#+END_EXAMPLE
** TODO mockup server fail to update tomcat
#+BEGIN_EXAMPLE
++ echo '[2014-12-13T00:21:10+00:00] ERROR: Running exception handlers
[2014-12-13T00:21:10+00:00] ERROR: Exception handlers complete
[2014-12-13T00:21:10+00:00] FATAL: Stacktrace dumped to /var/chef/cache/chef-stacktrace.out
[2014-12-13T00:21:10+00:00] ERROR: service[tomcat7] (fluig-tomcat::default line 132) had an error: Mixlib::ShellOut::ShellCommandFailed: Expected process to exit with [0], but received '\''1'\''
---- Begin output of /etc/init.d/tomcat7 start ----
STDOUT: * invalid CATALINA_BASE: /var/lib/tomcat7
STDERR:
---- End output of /etc/init.d/tomcat7 start ----
Ran /etc/init.d/tomcat7 start returned 1
[2014-12-13T00:21:11+00:00] FATAL: Chef::Exceptions::ChildConvergeError: Chef run process exited unsuccessfully (exit code 1)'
++ grep 'Chef Run complete in'
++ echo '[2014-12-13T00:21:10+00:00] ERROR: Running exception handlers
[2014-12-13T00:21:10+00:00] ERROR: Exception handlers complete
[2014-12-13T00:21:10+00:00] FATAL: Stacktrace dumped to /var/chef/cache/chef-stacktrace.out
[2014-12-13T00:21:10+00:00] ERROR: service[tomcat7] (fluig-tomcat::default line 132) had an error: Mixlib::ShellOut::ShellCommandFailed: Expected process to exit with [0], but received '\''1'\''
---- Begin output of /etc/init.d/tomcat7 start ----
STDOUT: * invalid CATALINA_BASE: /var/lib/tomcat7
STDERR:
---- End output of /etc/init.d/tomcat7 start ----
Ran /etc/init.d/tomcat7 start returned 1
[2014-12-13T00:21:11+00:00] FATAL: Chef::Exceptions::ChildConvergeError: Chef run process exited unsuccessfully (exit code 1)'
++ grep -v 'Error connecting to.*, retry '
++ grep ' ERROR: '
++ finish_ok=false
++ break
++ echo false
+ '[' false = true ']'
+ log 'Error to run chef update. Please check log for detail.'
+ local 'msg=Error to run chef update. Please check log for detail.'
++ date '+[%Y-%m-%d %H:%M:%S]'
+ echo -ne '[2014-12-13' '00:21:11] Error to run chef update. Please check log for detail.\n'
[2014-12-13 00:21:11] Error to run chef update. Please check log for detail.
+ exit 1
(none):~#
(none):~#
#+END_EXAMPLE
** TODO [#A] Fail to start hornetq                                :IMPORTANT:
#+begin_example
[2014-09-24T13:40:33-04:00] ERROR: Running exception handlers
[2014-09-24T13:40:33-04:00] ERROR: Exception handlers complete
[2014-09-24T13:40:33-04:00] FATAL: Stacktrace dumped to /var/chef/cache/chef-stacktrace.out
[2014-09-24T13:40:33-04:00] ERROR: service[hornetq] (fluig-messaging::default line 40) had an error: Mixlib::ShellOut::ShellCommandFailed: Expected process to exit with [0], but received '1'
---- Begin output of /etc/init.d/hornetq start ----
STDOUT: Fail to start hornetq. Please stop it first
STDERR:
---- End output of /etc/init.d/hornetq start ----
Ran /etc/init.d/hornetq start returned 1
[2014-09-24T13:40:33-04:00] FATAL: Chef::Exceptions::ChildConvergeError: Chef run process exited unsuccessfully (exit code 1)
#+end_example
** TODO Chef: Fail to stop hornetq
#+begin_example
testenv:~# /etc/init.d/hornetq status
 * hornetq is running (pid 29322).
testenv:~# /etc/init.d/hornetq stop
testenv:~# /etc/init.d/hornetq status
 * hornetq is running (pid 29322).
testenv:~# /etc/init.d/hornetq status
 * hornetq is running (pid 29322).
testenv:~# ps -ef | grep hornetq
root       449 32752  0 13:52 pts/2    00:00:00 grep --color=auto hornetq
root      2308  2305  0 Oct19 ?        00:01:22 java -Djnp.port=2099 -Djnp.rmiPort=2098 -Djnp.host=104.131.147.51 -Dhornetq.remoting.netty.host=104.131.147.51 -Dhornetq.remoting.netty.port=5445 -XX:+UseParallelGC -XX:+AggressiveOpts -XX:+UseFastAccessorMethods -Xms512M -Xmx1024M -Dhornetq.config.dir=../config/stand-alone/non-clustered -Djava.util.logging.config.file=../config/stand-alone/non-clustered/logging.properties -Djava.library.path=. -classpath ../lib/twitter4j-core.jar:../lib/netty.jar:../lib/jnpserver.jar:../lib/jnp-client.jar:../lib/jboss-mc.jar:../lib/jboss-jms-api.jar:../lib/hornetq-twitter-integration.jar:../lib/hornetq-spring-integration.jar:../lib/hornetq-logging.jar:../lib/hornetq-jms.jar:../lib/hornetq-jms-client.jar:../lib/hornetq-jms-client-java5.jar:../lib/hornetq-jboss-as-integration.jar:../lib/hornetq-core.jar:../lib/hornetq-core-client.jar:../lib/hornetq-core-client-java5.jar:../lib/hornetq-bootstrap.jar:../config/stand-alone/non-clustered:../schemas/ -Dcom.sun.management.jmxremote org.hornetq.integration.bootstrap.HornetQBootstrapServer hornetq-beans.xml
root     29322 29319  0 Oct18 ?        00:07:49 java -Djnp.port=2099 -Djnp.rmiPort=2098 -Djnp.host=localhost -Dhornetq.remoting.netty.host=localhost -Dhornetq.remoting.netty.port=5445 -XX:+UseParallelGC -XX:+AggressiveOpts -XX:+UseFastAccessorMethods -Xms512M -Xmx1024M -Dhornetq.config.dir=../config/stand-alone/non-clustered -Djava.util.logging.config.file=../config/stand-alone/non-clustered/logging.properties -Djava.library.path=. -classpath ../lib/twitter4j-core.jar:../lib/netty.jar:../lib/jnpserver.jar:../lib/jnp-client.jar:../lib/jboss-mc.jar:../lib/jboss-jms-api.jar:../lib/hornetq-twitter-integration.jar:../lib/hornetq-spring-integration.jar:../lib/hornetq-logging.jar:../lib/hornetq-jms.jar:../lib/hornetq-jms-client.jar:../lib/hornetq-jms-client-java5.jar:../lib/hornetq-jboss-as-integration.jar:../lib/hornetq-core.jar:../lib/hornetq-core-client.jar:../lib/hornetq-core-client-java5.jar:../lib/hornetq-bootstrap.jar:../config/stand-alone/non-clustered:../schemas/ -Dcom.sun.management.jmxremote org.hornetq.integration.bootstrap.HornetQBootstrapServer hornetq-beans.xml
#+end_example
** TODO Bug: multiple start of hornetq
** TODO [#A] fluig_stop_all.sh fail to stop fluig services
#+begin_example
root@denny-chef-Ubuntu-09:/data/fluigidentity-logs# ps -ef | grep java
ps -ef | grep java
root      5440  3658  0 20:29 pts/1    00:00:00 grep --color=auto java
root     18682     1  3 20:12 ?        00:00:32 java -Xms2048M -Xmx6144M -jar ../dist/rest.jar server ../config/rest.yml
root     19012     1  1 20:13 ?        00:00:16 java -Xms1024M -Xmx2048M -jar ../dist/ADSync.jar server ../config/adsync.yml
root     30874 30870  1 20:14 ?        00:00:13 java -Xms1024M -Xmx2048M -jar ../dist/Search.jar server ../config/search.yml
You have new mail in /var/mail/root
root@denny-chef-Ubuntu-09:/data/fluigidentity-logs#
#+end_example
** TODO Fail to stop service /etc/init.d/search adsync
** TODO Service restart isn't what we suppose
#+BEGIN_EXAMPLE
Q: Why starting rmi takes quite a lot of time?
A: Log tells inside info, but still not enough detail: tail -f /data/fluigidentity-logs/rmi.log
#+END_EXAMPLE
** [#A] Why neo4j stop will result in 8 hours' recovery??
** TODO neo4j grace shutdown
#+BEGIN_EXAMPLE
[12/2/14, 6:47:01 PM] kungchaowang: 2014-12-03 00:43:08.467+0000 INFO  [o.n.k.i.t.TxManager]: TM opening log: /data/totvslabs/scim/neo4j/embedded/tm_tx_log.2
2014-12-03 00:43:08.735+0000 INFO  [o.n.k.i.t.x.XaLogicalLog]: Non clean shutdown detected on log [/data/totvslabs/scim/neo4j/embedded/index/lucene.log.1]. Recovery started ...
2014-12-03 00:43:08.736+0000 INFO  [o.n.k.i.t.x.XaLogicalLog]: [/data/totvslabs/scim/neo4j/embedded/index/lucene.log.1] logVersion=97 with committed tx=671594
[12/2/14, 6:47:26 PM] kungchaowang: yes, if you are running that, it should graceful shutdown. I don’t know why it was not.
#+END_EXAMPLE
** TODO [#B] when stop rest, first stop racagent
#+BEGIN_EXAMPLE
[11/25/14, 10:58:18 PM] denny: Hi Guys, any problems we’re trying to resolve right now?
[11/25/14, 10:58:29 PM] Shivang: the racagent4 hangs
[11/25/14, 10:58:35 PM] Shivang: because it was trying to connect to rest server
[11/25/14, 10:58:38 PM] Shivang: and it failed
[11/25/14, 10:58:44 PM] Shivang: and it was trying to do a lot of
[11/25/14, 10:58:50 PM] Shivang: project related stuff
[11/25/14, 10:58:58 PM] Shivang: (or something like that .. not sure what)
[11/25/14, 10:59:11 PM] denny: So if rest is started, we’re fine with racagent. Right?
[11/25/14, 10:59:13 PM] Shivang: so we got to be careful .. if we stop rest .. we should stop everything else
[11/25/14, 10:59:18 PM] Shivang: right not that is a single point of failure
[11/25/14, 10:59:36 PM] denny: got it.
#+END_EXAMPLE
** TODO [#A] Bug: tomcat problem in CentOS: result in mulitple instance :IMPORTANT:
#+BEGIN_EXAMPLE
[11/19/14, 6:23:58 PM] John Kaplan: Hi Denny. Looks like the last deploy to cluster_5 failed.
[11/19/14, 6:36:48 PM] denny: let me see.
[11/19/14, 6:38:01 PM] John Kaplan: Thanks
[11/19/14, 6:38:17 PM] denny: Thanks for the patient
[11/19/14, 6:38:53 PM] John Kaplan: No problem. You have allot going on. I am glad you have some time to attend to these issues>
[11/19/14, 6:40:08 PM] denny: Yes, a lot of things to do. Glad situation is getting better and better.

Chef may fail, since I’m check-in various improvement for the chef repo.

It should not be a big problem.
[11/19/14, 6:41:00 PM] John Kaplan: yes it will take some time to get everything in plave
[11/19/14, 6:41:01 PM] John Kaplan: place
[11/19/14, 6:41:26 PM] John Kaplan: Just let me know when I can deploy again
[11/19/14, 6:41:44 PM] denny: I see the problem.
[11/19/14, 6:42:42 PM] denny: The env I gave you is CentOS.

There should be some bug in the initscript of tomcat for CentOS version.
It may happen from time to time.

I’m performing some workaround. And come back to the issue later next week.
[11/19/14, 6:43:06 PM] denny: To be short: there’re multiple instances of tomcat are running.
[11/19/14, 6:43:26 PM] John Kaplan: I see
#+END_EXAMPLE

#+BEGIN_EXAMPLE
root@denny-chef-centos-12:/# ps -ef | grep tomcat
root       517     1  4 19:09 ?        00:01:30 /opt/jdk/bin/java -Djava.util.logging.config.file=/var/lib/tomcat7/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -server -Xms1024m -Xmx4096m -XX:MaxPermSize=1024m -XX:PermSize=512m -XX:+UseConcMarkSweepGC -XX:+CMSClassUnloadingEnabled -XX:+CMSPermGenSweepingEnabled -Djava.endorsed.dirs=/var/lib/tomcat7/endorsed -classpath /var/lib/tomcat7/bin/bootstrap.jar:/var/lib/tomcat7/bin/tomcat-juli.jar -Dcatalina.base=/var/lib/tomcat7 -Dcatalina.home=/var/lib/tomcat7 -Djava.io.tmpdir=/var/lib/tomcat7/temp org.apache.catalina.startup.Bootstrap start
root      7696  7137  0 19:40 pts/2    00:00:00 grep --color=auto tomcat
root      9085     1  1 17:09 ?        00:01:38 /opt/jdk/bin/java -Djava.util.logging.config.file=/var/lib/tomcat7/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -server -Xms1024m -Xmx4096m -XX:MaxPermSize=1024m -XX:PermSize=512m -XX:+UseConcMarkSweepGC -XX:+CMSClassUnloadingEnabled -XX:+CMSPermGenSweepingEnabled -Djava.endorsed.dirs=/var/lib/tomcat7/endorsed -classpath /var/lib/tomcat7/bin/bootstrap.jar:/var/lib/tomcat7/bin/tomcat-juli.jar -Dcatalina.base=/var/lib/tomcat7 -Dcatalina.home=/var/lib/tomcat7 -Djava.io.tmpdir=/var/lib/tomcat7/temp org.apache.catalina.startup.Bootstrap start
root     15613     1  1 17:56 ?        00:01:23 /opt/jdk/bin/java -Djava.util.logging.config.file=/var/lib/tomcat7/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -server -Xms1024m -Xmx4096m -XX:MaxPermSize=1024m -XX:PermSize=512m -XX:+UseConcMarkSweepGC -XX:+CMSClassUnloadingEnabled -XX:+CMSPermGenSweepingEnabled -Djava.endorsed.dirs=/var/lib/tomcat7/endorsed -classpath /var/lib/tomcat7/bin/bootstrap.jar:/var/lib/tomcat7/bin/tomcat-juli.jar -Dcatalina.base=/var/lib/tomcat7 -Dcatalina.home=/var/lib/tomcat7 -Djava.io.tmpdir=/var/lib/tomcat7/temp org.apache.catalina.startup.Bootstrap start
root     21110     1  1 18:00 ?        00:01:44 /opt/jdk/bin/java -Djava.util.logging.config.file=/var/lib/tomcat7/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -server -Xms1024m -Xmx4096m -XX:MaxPermSize=1024m -XX:PermSize=512m -XX:+UseConcMarkSweepGC -XX:+CMSClassUnloadingEnabled -XX:+CMSPermGenSweepingEnabled -Djava.endorsed.dirs=/var/lib/tomcat7/endorsed -classpath /var/lib/tomcat7/bin/bootstrap.jar:/var/lib/tomcat7/bin/tomcat-juli.jar -Dcatalina.base=/var/lib/tomcat7 -Dcatalina.home=/var/lib/tomcat7 -Djava.io.tmpdir=/var/lib/tomcat7/temp org.apache.catalina.startup.Bootstrap start
#+END_EXAMPLE
** TODO [#A] initscript write pid file: will binary remove pid file, when exit :IMPORTANT:
** TODO Bug: init script of neo4j looks too length
cat /opt/neo*/bin/neo4j

# add any plugin jars in nested folders
  for jar in "$NEO4J_HOME"/plugins/**/*.jar ; do
    if [ -e "$jar" ] ; then
      ALL_JARS="$ALL_JARS":"$jar"
    fi
  done

#+BEGIN_EXAMPLE
root@denny-chef-centos-12:~# ps -ef | grep rest
ps -ef | grep rest
root     27371     1 18 23:30 pts/0    00:00:09 /usr/bin/java -cp /opt/neo4j-server/lib/antlr4-runtime-4.0.jar:/opt/neo4j-server/lib/concurrentlinkedhashmap-lru-1.3.1.jar:/opt/neo4j-server/lib/geronimo-jta_1.1_spec-1.1.1.jar:/opt/neo4j-server/lib/gson-2.2.2.jar:/opt/neo4j-server/lib/idm-common-model-1.0.jar:/opt/neo4j-server/lib/lucene-core-3.6.2.jar:/opt/neo4j-server/lib/lucene3x-1.0.jar:/opt/neo4j-server/lib/neo4j-cypher-2.1.5.jar:/opt/neo4j-server/lib/neo4j-cypher-commons-2.1.5.jar:/opt/neo4j-server/lib/neo4j-cypher-compiler-1.9-2.0.3.jar:/opt/neo4j-server/lib/neo4j-cypher-compiler-2.0-2.0.3.jar:/opt/neo4j-server/lib/neo4j-cypher-compiler-2.1-2.1.5.jar:/opt/neo4j-server/lib/neo4j-graph-algo-2.1.5.jar:/opt/neo4j-server/lib/neo4j-graph-matching-2.1.5.jar:/opt/neo4j-server/lib/neo4j-jmx-2.1.5.jar:/opt/neo4j-server/lib/neo4j-kernel-2.1.5.jar:/opt/neo4j-server/lib/neo4j-lucene-index-2.1.5.jar:/opt/neo4j-server/lib/neo4j-primitive-collections-2.1.5.jar:/opt/neo4j-server/lib/neo4j-shell-2.1.5.jar:/opt/neo4j-server/lib/neo4j-udc-2.1.5.jar:/opt/neo4j-server/lib/neo4j2x-1.0.jar:/opt/neo4j-server/lib/opencsv-2.0.jar:/opt/neo4j-server/lib/org.apache.servicemix.bundles.jline-0.9.94_1.jar:/opt/neo4j-server/lib/parboiled-core-1.1.6.jar:/opt/neo4j-server/lib/parboiled-scala_2.10-1.1.6.jar:/opt/neo4j-server/lib/rest.jar:/opt/neo4j-server/lib/scala-library-2.10.4.jar:/opt/neo4j-server/lib/server-api-2.1.5.jar:/opt/neo4j-server/lib/spring-context-3.1.2.RELEASE.jar:/opt/neo4j-server/system/lib/asm-3.1.jar:/opt/neo4j-server/system/lib/bcprov-jdk16-140.jar:/opt/neo4j-server/system/lib/commons-beanutils-1.8.0.jar:/opt/neo4j-server/system/lib/commons-beanutils-core-1.8.0.jar:/opt/neo4j-server/system/lib/commons-collections-3.2.1.jar:/opt/neo4j-server/system/lib/commons-compiler-2.6.1.jar:/opt/neo4j-server/system/lib/commons-configuration-1.6.jar:/opt/neo4j-server/system/lib/commons-digester-1.8.1.jar:/opt/neo4j-server/system/lib/commons-io-1.4.jar:/opt/neo4j-server/system/lib/commons-lang-2.4.jar:/opt/neo4j-server/system/lib/commons-logging-1.1.1.jar:/opt/neo4j-server/system/lib/jackson-core-asl-1.9.7.jar:/opt/neo4j-server/system/lib/jackson-jaxrs-1.9.7.jar:/opt/neo4j-server/system/lib/jackson-mapper-asl-1.9.7.jar:/opt/neo4j-server/system/lib/janino-2.6.1.jar:/opt/neo4j-server/system/lib/javax.servlet-3.0.0.v201112011016.jar:/opt/neo4j-server/system/lib/jcl-over-slf4j-1.6.1.jar:/opt/neo4j-server/system/lib/jersey-core-1.9.jar:/opt/neo4j-server/system/lib/jersey-multipart-1.9.jar:/opt/neo4j-server/system/lib/jersey-server-1.9.jar:/opt/neo4j-server/system/lib/jetty-http-9.0.5.v20130815.jar:/opt/neo4j-server/system/lib/jetty-io-9.0.5.v20130815.jar:/opt/neo4j-server/system/lib/jetty-security-9.0.5.v20130815.jar:/opt/neo4j-server/system/lib/jetty-server-9.0.5.v20130815.jar:/opt/neo4j-server/system/lib/jetty-servlet-9.0.5.v20130815.jar:/opt/neo4j-server/system/lib/jetty-util-9.0.5.v20130815.jar:/opt/neo4j-server/system/lib/jetty-webapp-9.0.5.v20130815.jar:/opt/neo4j-server/system/lib/jetty-xml-9.0.5.v20130815.jar:/opt/neo4j-server/system/lib/jsr311-api-1.1.2.r612.jar:/opt/neo4j-server/system/lib/logback-access-1.1.2.jar:/opt/neo4j-server/system/lib/logback-classic-1.1.2.jar:/opt/neo4j-server/system/lib/logback-core-1.1.2.jar:/opt/neo4j-server/system/lib/mimepull-1.6.jar:/opt/neo4j-server/system/lib/neo4j-browser-2.1.5.jar:/opt/neo4j-server/system/lib/neo4j-server-2.1.5-static-web.jar:/opt/neo4j-server/system/lib/neo4j-server-2.1.5.jar:/opt/neo4j-server/system/lib/opencsv-2.0.jar:/opt/neo4j-server/system/lib/rhino-1.7R4.jar:/opt/neo4j-server/system/lib/rrd4j-2.0.7.jar:/opt/neo4j-server/system/lib/slf4j-api-1.6.2.jar:/opt/neo4j-server/plugins/commons-pool-1.5.4.jar:/opt/neo4j-server/plugins/gt-api-9.2.jar:/opt/neo4j-server/plugins/gt-coverage-9.2.jar:/opt/neo4j-server/plugins/gt-cql-9.2.jar:/opt/neo4j-server/plugins/gt-data-9.2.jar:/opt/neo4j-server/plugins/gt-main-9.2.jar:/opt/neo4j-server/plugins/gt-metadata-9.2.jar:/opt/neo4j-server/plugins/gt-opengis-9.2.jar:/opt/neo4j-server/plugins/gt-process-9.2.jar:/opt/neo4j-server/plugins/gt-referencing-9.2.jar:/opt/neo4j-server/plugins/gt-render-9.2.ja
#+END_EXAMPLE
** TODO tomcat initscript doesn't set $? correctly
#+begin_example
========== On 107.170.212.114 Run: ssh -i /var/lib/jenkins/.ssh/fake_id_rsa -o StrictHostKeyChecking=no root@107.170.212.114 fluig_start_all.sh ==========
[2014-11-08 12:54:11] ========= Start the whole service stack. It shall take 1~2 min ============
[2014-11-08 12:54:11] start rmi
[2014-11-08 12:54:13] start adsync
[2014-11-08 12:54:19] start tomcat7
Starting Tomcat: /var/lib/tomcat7/bin/setenv.sh: line 2: unexpected EOF while looking for matching `"'
/var/lib/tomcat7/bin/setenv.sh: line 3: syntax error: unexpected end of file
Tomcat started.
[2014-11-08 12:54:29] start httpd
Starting httpd: httpd: Could not reliably determine the server's fully qualified domain name, using 107.170.212.114 for ServerName
[  OK  ]
[2014-11-08 12:54:29] start racagent
start racagent_racagent03
#+end_example
** TODO Shivang: when restart rmi, should we restart racagent
** DONE [#A] Service take a long time to start: selenium in linux takes over 1 min to start :IMPORTANT:
  CLOSED: [2015-01-25 Sun 09:25]
09:23:02.597 INFO - Started HttpContext[/,/]
09:24:22.503 INFO - Started org.openqa.jetty.jetty.servlet.ServletHandler@5b7da0d1
09:24:22.504 INFO - Started HttpContext[/wd,/wd]

#+BEGIN_EXAMPLE
root@denny-chef-ubuntu-9:/#  java -jar /usr/local/selenium/server/selenium-server-standalone-2.44.0.jar
09:23:02.342 INFO - Launching a standalone server
09:23:02.392 INFO - Java: Oracle Corporation 24.65-b04
09:23:02.392 INFO - OS: Linux 3.13.0-32-generic amd64
09:23:02.412 INFO - v2.44.0, with Core v2.44.0. Built from revision 76d78cf
09:23:02.502 INFO - Default driver org.openqa.selenium.ie.InternetExplorerDriver registration is skipped: registration capabilities Capabilities [{platform=WINDOWS, ensureCleanSession=true, browserName=internet explorer, version=}] does not match with current platform: LINUX
09:23:02.593 INFO - RemoteWebDriver instances should connect to: http://127.0.0.1:4444/wd/hub
09:23:02.594 INFO - Version Jetty/5.1.x
09:23:02.595 INFO - Started HttpContext[/selenium-server/driver,/selenium-server/driver]
09:23:02.596 INFO - Started HttpContext[/selenium-server,/selenium-server]
09:23:02.597 INFO - Started HttpContext[/,/]
09:24:22.503 INFO - Started org.openqa.jetty.jetty.servlet.ServletHandler@5b7da0d1
09:24:22.504 INFO - Started HttpContext[/wd,/wd]
09:24:22.511 INFO - Started SocketListener on 0.0.0.0:4444
09:24:22.511 INFO - Started org.openqa.jetty.jetty.Server@5aedacd2

#+END_EXAMPLE
* [Operate] Forsee risks, when operating prod env
** Don't mount nfs, only for remote copy of backup set
Once NFS server is slow or unreachable, the CPU would be extremely high
** [Monitor] logfiles for errors and exceptions
** TODO Fail to stop search service
#+BEGIN_EXAMPLE
root@fluig-id-messaging-01:/data/fluigidentity-logs# tail -n 1000 ./search.log | grep -v GlobalSearchCore | tail -n 20
<tail -n 1000 ./search.log | grep -v GlobalSearchCore | tail -n 20
out: SocialECMHealthCheck: check
[14 Jan 2015;15:25:10.447] - [INFO ] [SearchHealthCheck:?] - logger: SocialECMHealthCheck: check
127.0.0.1 -  -  [14/Jan/2015:15:25:10 +0000] "GET http://localhost/admin/healthcheck HTTP/1.1" 200 - "-" "check_http/v1.4.15 (nagios-plugins 1.4.15)" 8
[14 Jan 2015;15:25:20.650] - [INFO ] [ServerConnector:?] - Stopped application@39611358{HTTP/1.1}{0.0.0.0:18084}
[14 Jan 2015;15:25:20.651] - [INFO ] [ServerConnector:?] - Stopped admin@143d13d6{HTTP/1.1}{0.0.0.0:18085}
[14 Jan 2015;15:25:20.653] - [INFO ] [ContextHandler:?] - Stopped i.d.j.MutableServletContextHandler@32436c84{/admin,null,UNAVAILABLE}
[14 Jan 2015;15:25:20.653] - [INFO ] [ContextHandler:?] - Stopped i.d.j.MutableServletContextHandler@61bfa744{/search,null,UNAVAILABLE}
Exception in thread "Timer-1" java.lang.NullPointerException
	at com.totvslabs.idm.service.search.core.TimeLineCore.queryPartitionIndexUsingQuery(TimeLineCore.java:1387)
	at com.totvslabs.idm.service.search.core.TimeLineCore.queryIndexUsingQuery(TimeLineCore.java:1415)
	at com.totvslabs.idm.service.search.core.TimeLineCore.getEvent(TimeLineCore.java:1619)
	at com.totvslabs.idm.service.search.core.TimeLineCore.doesEventExist(TimeLineCore.java:1441)
	at com.totvslabs.idm.service.search.core.TimeLineCore.doesEventExist(TimeLineCore.java:1454)
	at com.totvslabs.idm.service.search.core.TimeLineCore$NewEventLogLoadingTimerTask.run(TimeLineCore.java:240)
	at java.util.TimerThread.mainLoop(Timer.java:555)
	at java.util.TimerThread.run(Timer.java:505)
#+END_EXAMPLE
** TODO Prod env Fail to stop search
#+BEGIN_EXAMPLE
root@fluig-id-messaging-01:/data/fluigidentity-logs# service search stop
service search stop
root@fluig-id-messaging-01:/data/fluigidentity-logs# ps -ef | grep -i search
ps -ef | grep -i search
root      2954     1  0 Jan08 ?        00:00:00 /bin/bash /cloudpass/backend/build/bin/search_service_start.sh
root      2987  2954 99 Jan08 ?        9-03:21:21 java -Xms1024M -Xmx2048M -jar ../dist/Search.jar server ../config/search.yml
root     27409 21142  0 03:40 pts/2    00:00:00 grep --color=auto -i search
root@fluig-id-messaging-01:/data/fluigidentity-logs# service search stop
service search stop
root@fluig-id-messaging-01:/data/fluigidentity-logs# service search status
service search status
 * search is running with problem (pid 2987)
#+END_EXAMPLE
* [Logging] handle with log
** Pricinple One of the most common is a unmonitored partition filling up with unrotated log files. :Problem:
** A log monitor sending huge amounts of log data over the network to a log server. :Problem:
** #  --8<-------------------------- separator ------------------------>8--
** Wrong log rotate mechanism leads to missing critical old logfiles
#+BEGIN_EXAMPLE
[2/9/15, 10:03:10 AM] denny: denny added kungchaowang, Shivang to this conversation
[2/9/15, 10:04:30 AM] denny: Hi Shivang

I checked psfluigidentity for racagent log.

It’s nice that it have log rotate mechanism.

I’ve checked the archived log: /data/fluigidentity-logs/cloudpass_logs/shivang_logs_archieve
[2/9/15, 10:05:36 AM] denny: Looks like the latest log is Feb 9th.

This means we can’t find any older log than today about racagent.

Should this be a problem?
[2/9/15, 10:06:38 AM] Shivang: possibly because its too much logging
[2/9/15, 10:06:44 AM] Shivang: because its timer based ..
[2/9/15, 10:06:50 AM] Shivang: so i think it should be fine for now ..
[2/9/15, 10:07:37 AM] denny: Do we need yesterday’s log for trouble shooting racagent problem in some scenario?
[2/9/15, 10:08:46 AM] denny: root@fluig-id-dev-03:/etc/nagios/nrpe.d# ls -lth /data/flui*logs/cloudpass_logs/shivang_logs_archieve
<agios/nrpe.d# ls -lth /data/flui*logs/cloudpass_logs/shivang_logs_archieve
total 46M
-rw-r--r-- 1 root root 3.5M Feb  9 15:47 shivang.1.log.zip
-rw-r--r-- 1 root root 3.5M Feb  9 15:26 shivang.2.log.zip
-rw-r--r-- 1 root root 3.5M Feb  9 15:07 shivang.3.log.zip
-rw-r--r-- 1 root root 3.5M Feb  9 14:47 shivang.4.log.zip
-rw-r--r-- 1 root root 3.5M Feb  9 14:28 shivang.5.log.zip
-rw-r--r-- 1 root root 3.5M Feb  9 14:09 shivang.6.log.zip
-rw-r--r-- 1 root root 3.5M Feb  9 13:47 shivang.7.log.zip
-rw-r--r-- 1 root root 3.5M Feb  9 13:24 shivang.8.log.zip
-rw-r--r-- 1 root root 3.5M Feb  9 13:02 shivang.9.log.zip
-rw-r--r-- 1 root root 3.5M Feb  9 12:39 shivang.10.log.zip
-rw-r--r-- 1 root root 3.5M Feb  9 12:16 shivang.11.log.zip
-rw-r--r-- 1 root root 3.5M Feb  9 11:55 shivang.12.log.zip
-rw-r--r-- 1 root root 3.5M Feb  9 11:33 shivang.13.log.zip
[2/9/15, 10:09:05 AM] denny: Each file is ~3.5 MB. Should we configure it to be a little larger, say 35MB?
[2/9/15, 10:13:06 AM] denny: Filed CP-6902: [OPS] racagent archived log in psfluigidentity doesn't have older log than yesterday
[2/9/15, 10:13:11 AM] denny: https://totvslab.atlassian.net/browse/CLOUDPASS-6902
[2/9/15, 10:13:54 AM] Shivang: the file size is already 500MB limit
[2/9/15, 10:14:01 AM] Shivang: the zip file probably is 3.5
[2/9/15, 10:14:34 AM] Shivang: you can look at the logback for this setting .. but 500mB is already big enough
[2/9/15, 10:15:01 AM] Shivang: the reason it only shows feb 9th is because we have too many logs every second
[2/9/15, 10:15:09 AM] Shivang: and thats why 500MB fills up really fast
[2/9/15, 10:15:17 AM] Shivang: cant do much about that
[2/9/15, 10:15:34 AM] Shivang: we can increase the number of archieve zips
[2/9/15, 10:15:38 AM] Shivang: meaning instead of 14
[2/9/15, 10:15:42 AM] Shivang: we can have like 100 or something
[2/9/15, 10:15:45 AM] denny: If I unzip shivang.1.log.zip, do you mean I may get a log file about 500 MB?
[2/9/15, 10:15:54 AM] Shivang: let me check the setting
[2/9/15, 10:16:25 AM] Shivang: oh shit
[2/9/15, 10:16:27 AM] Shivang: my bad
[2/9/15, 10:16:30 AM] denny: :)
[2/9/15, 10:16:33 AM] Shivang: i checked in iwth 1MB
[2/9/15, 10:16:34 AM] Shivang: size
[2/9/15, 10:16:38 AM] Shivang: i changed it for testing
[2/9/15, 10:16:42 AM] Shivang: and never changed it back
[2/9/15, 10:18:03 AM] denny: That’s fine. Let’s confirmed and verify what we can do to make up.

Then plan to patch the system, because next scheduled upgrade would be 3 weeks later.
[2/9/15, 10:18:30 AM] Shivang: 1MB will be nothing .. if something goes wrong there is no way w ewill be able to see
[2/9/15, 10:18:33 AM] Shivang: whats going on .. even on production
[2/9/15, 10:18:42 AM] Shivang: so I suggest we change just the logback.xml
[2/9/15, 10:18:49 AM] denny: Yes, that’s my concern as well.
[2/9/15, 10:18:49 AM] Shivang: on all the servers and restart stack
[2/9/15, 10:18:58 AM] Shivang: not right now .. maybe sometime in the evening
[2/9/15, 10:19:06 AM] Shivang: i will fix this in master
[2/9/15, 10:19:33 AM] denny: Would you please comment the ticket with detail procedure?
[2/9/15, 10:19:43 AM] Shivang: yes .. will do ..
[2/9/15, 10:19:46 AM] Shivang: give me 10 minutes
[2/9/15, 10:19:48 AM] denny: I can install a cluster env, and let’s verify the fix as staging server.
[2/9/15, 10:20:28 AM] Shivang: i wil l check in to 1.4.4 as well
[2/9/15, 10:20:30 AM] denny: If we can use qafluigidentity as staging server, that would be even better.
[2/9/15, 10:20:37 AM] denny: Thanks, Shivang
[2/9/15, 10:21:21 AM] Shivang: cool
#+END_EXAMPLE
** [#A] nagios log check timeout, due to the log file is so huge (>50G)
*** mail: CP-6792: neo4j-server log file of console.log is way too big. :noexport:
[[gnus:mail.misc#EF9859611DA81140B2B29B02EC8AD6EAF9756D@helios.mex01.local][Email from Denny Zhang (Wed, 4 Feb 2015 09:51:02 -0600): CP-6792: neo4j-server log file]]
#+begin_example
From: Denny Zhang <denny.zhang@totvs.com>
Subject: CP-6792: neo4j-server log file of console.log is way too big.
To: Kung Wang <kung.wang@totvs.com>
CC: Denny Zhang <denny.zhang@totvs.com>
Date: Wed, 04 Feb 2015 09:51:02 -0600

Hi Kung

Below check in QA1B timeout.

I found out CP-6792 reproduced in QA1B. This issue is first found in customerfi.

Anyone can help me resolve this issue?

[cid]

Regards,

Denny

#+end_example
** Watch out that developers may dumping message to logfile in a very fast speed
- Disk capacity is all token by rest.log and neo4j console.log
** Watch out that developers may create very large log file
- nagios won't be fast enough to monitor logfiles
** #  --8<-------------------------- separator ------------------------>8--
** quickly backup logfile, so that developers can easily look into there
** Make sure no huge log messages are generated
** Make sure big log files are rotated, instead of taking too much disk capacity
** Provide readonly OS user for people to check logfiles
** TODO [#B] Provide webGUI for people to read log or check system status
https://totvslab.atlassian.net/browse/TECH-49
#+begin_example
[10/17/14, 13:40:29] John Kaplan: Hi Denny, I know you are rally busy now, so Fellipe had a quick idea about giving read only logs access to Fluid (Brazil) support
[10/17/14, 13:40:59] denny: Yes, I'd glad to hear that.
[10/17/14, 13:41:09] Fellipe Augusto da Silva: Hi Denny
[10/17/14, 13:41:14] denny: Hi Fellipe
[10/17/14, 13:41:37] Fellipe Augusto da Silva: yeah, they asked if we can't use a logging system to display the logs on the web, since it would be easier for the support team to check in one place instead of SSH in the machine
[10/17/14, 13:41:53] Fellipe Augusto da Silva: they suggested splunk or graylog2, did you heard of this two guys before?
[10/17/14, 13:42:02] denny: Yes, that would be a good idea.
[10/17/14, 13:42:30] denny: I used splunk before.

Let me grab you a link
[10/17/14, 13:43:30] Fellipe Augusto da Silva: ok thanks! Do you think this is possible to do with the production logs?
[10/17/14, 13:43:33] denny: https://10.165.4.198/nagios/fluig_operate.php
[10/17/14, 13:44:00] denny: We can add another button called: view log
[10/17/14, 13:44:08] Fellipe Augusto da Silva: I see
[10/17/14, 13:44:13] Fellipe Augusto da Silva: (it request login and password for that link)
[10/17/14, 13:44:18] denny: That link is a POC.

What do you think?
[10/17/14, 13:44:37] denny: Yes, we will ask users to login first.
[10/17/14, 13:44:44] Fellipe Augusto da Silva: oh I see
[10/17/14, 13:44:47] Fellipe Augusto da Silva: yeah, that should be enough
[10/17/14, 13:45:00] Fellipe Augusto da Silva: just let me check if people inside TOTVS can reach that link
#+end_example
** DONE Provide QA and dev with OS readonly user to check logfiles
  CLOSED: [2015-01-21 Wed 13:23]
#+BEGIN_EXAMPLE
[1/21/15, 12:48:26 PM] denny: Hi Guys

I’m getting you a list of all readonly user for all QA env.
Andre & John, Would you please track the info somewhere and share with related colleagues?

| Env             | Summary     | OS user                               |
|-----------------+-------------+---------------------------------------|
| qa1b            | all-in-one  | ssh readonly@172.20.18.13  TestFluig3 |
| customerfi      | all-in-one  | ssh readonly@172.20.18.23  fluigAbc1  |
| psfluigidentity | all-in-one  | ssh readonly@172.20.18.17  TestFluig3 |
| qafluigidentity | cluster env | ssh readonly@$server_ip  fluigTest6   |
[1/21/15, 12:50:44 PM] Andre Uhlrich: Thank you
#+END_EXAMPLE
** DONE centrialized location for logfiles: Chef add symbol link for various logfile
  CLOSED: [2015-01-21 Wed 23:58]
#+BEGIN_EXAMPLE
@All:  To simplify the question where is the log for any service.

Chef will make sure all log files are placed in /data/fluigidentity-logs directory.
If it’s not, it will have a symbol link point to there.
#+END_EXAMPLE
** web page: On the Importance of Logs — AWS Startup Collection — Medium
https://medium.com/aws-activate-startup-blog/on-the-importance-of-logs-72afccab49d7
*** webcontent                                                     :noexport:
#+begin_example
Location: https://medium.com/aws-activate-startup-blog/on-the-importance-of-logs-72afccab49d7
Ready to publish?
Change the story’s title, subtitle, and visibility as needed
AWS Activate
5 min read
Close
VisibilityFeaturedPublish changes
 AWS Startup Collection

Published inAWS Startup Collection

 Sign in / Sign up
AWS Startup Collection[0]AWS Activate
on May 14, 20145 min
Read next
The author chose to make this story unlisted, which means only people with a link can see it. Are
you sure you want to share it?Yes, show me sharing options

On the Importance of Logs

  * Share on Twitter
  * Share on Facebook
  * Share by email

---------------------------------------------------------------------------------------------------

On the Importance of Logs

301 level guidance from an AWS Solutions Architect

Introduction

As a Solutions Architect at Amazon Web Services, I work with a lot startups, helping them to build,
deploy, manage, and grow their infrastructures on the AWS platform. When I meet with a new company,
one of the first questions I ask is “What are you doing with your logs?” More often than not, the
answer is little to nothing. Most folks just make sure logs aren’t filling up their disk space.
Some people are aggregating them but don’t monitor or track them. Most aren’t keeping their log
data for more than a handful of days at best.

Some of these companies however, are doing the right thing, and recognize the value in properly
aggregating, analyzing, and storing this extremely important operational data.

So what are you doing with your logs?

The Importance of Logs

Log data contains some of the most valuable raw information you can gather and analyze about your
infrastructure and applications. Your operating systems generate them, as well as your web servers,
your applications, your databases, etc.

Amid the mess of confusing lines of seemingly random text can be hints about performance, security,
bugs in code, access patterns, and other operational data. But AWS customers use log data for many
nonoperational reasons as well, including generating product recommendations, performing A/B tests
on site design, tracking user interactions, and delivering targeted ads to end users.

Without the proper tools, finding these insights can be like searching for a needle in a haystack.
But with the right practices in place, your logs can become the number one source of both
operational and business information. Holding onto and making log information available to others
inside your organization can be incredibly valuable. To paraphrase heavily, “there’s gold in them
thar hills” (of logs)!

Types of Logs

Throughout your infrastructure are many different sources of logs:

Operating system logs: Some of the most basic information is about what the operating system is
doing. Are processes dying? Are they being started? Is something causing host resource starvation?
Is someone attempting to log into your hosts via SSH repeatedly? Are hardware components failing?
Depending on your OS, your operating system logs can offer a wealth of information.

Web Server logs: Apache, Nginx, IIS, and others all provide a ton of logging information about
requests and how the server itself is performing. Are there errors in your code that the language
handler can’t handle? Is someone looking at your web server for data that isn’t there, or that
shouldn’t be there? Is someone actively trying to scan your web server for vulnerabilities? How is
your page performing? Lots of basic and not so basic information can be found in your web server
logs, making them some of the most important.

Application logs: Application logging is a feature that you might have written into your own
applications or is already written into an application you are using. Is your application having
trouble connecting to your database? How quickly is it addressing requests? Why did your
application crash? What caused users to see that error page? Often application logs can be the
first place to go for troubleshooting issues that customers might be experiencing, making them an
incredibly valuable resource to keep around.

Database logs: Slow queries? Stability issues? Corruption? All queries? Database logs potentially
provide access to all of this information.

CDN logs: Most CDNs provide logs very similar to those your web server would give you. This can be
very valuable in analyzing site usage and generating recommendations and more.

Amazon Web Service Logs

A number of different Amazon Web Services generate and provide logs. Often these logs are stored as
files in an Amazon S3 bucket of your choosing, or made available via the service’s API or web
console. Here are the AWS services that today provide access to logs:

Amazon S3 Access logs
Amazon CloudFront Access logs
Elastic Load Balancer (ELB) logs
Amazon Relational Database Service (RDS) logs
Amazon Elastic MapReduce (EMR) logs
Amazon Redshift logs
AWS Elastic Beanstalk logs
AWS OpsWorks logs (or this link)
AWS Import/Export logs
AWS Data Pipeline logs
AWS CloudTrail logs

The last one above, CloudTrail, records API calls for your account and delivers log files to you.
You will definitely want to enable CloudTrail on your accounts.

You’ll want to make sure that you keep an eye on the log data you are saving, either regularly
purging it or rotating it to Amazon Glacier for even longer term storage depending on your
business’s data archival policies. Use S3’s object lifecycle management to define this.

Tools for Log Analysis

Once you have all of your logs centralized and in a single place, what next? Having all this data
and no way to analyze it doesn’t help increase operational understanding or intelligence. You need
a tool that can help you with this mountain of information. Sometimes this is a tool purposefully
built for log analysis, or it could be a something as simple as a data warehouse workflow using
services like Amazon Redshift or Elastic MapReduce (EMR) and Data Pipeline to provide nightly log
analysis reports. Many companies use a combination of these services over time as they find more
and more uses cases for log information.

Whatever the use, find a tool that offers you the flexibility, right cost, and scalability that
your business needs and dive on in. Here are just a handful broken down by SaaS solutions, open
source, and enterprise:

SaaS Solutions
- Boundary
- Cloudlytics
- Loggly
- Papertrail
- Splunk Storm
- SumoLogic

Open Source Solutions
- Graylog2
- LogStash + Kibana + ElasticSearch
- Log.io

Enterprise Solutions
- Logscape
- Splunk
- Tibco LogLogic

For an example of how to do some log analysis in AWS using EMR, check out these two great tutorials
of ours:
-Analyze Log Data with Apache Hive, Windows PowerShell, and Amazon EMR
- Analyze Elastic Load Balancing Log Data

Getting Going

Logs and log analysis can be a big topic. Hopefully you’ve gotten the idea that if you aren’t
keeping and tracking your logs today, you are missing out and should take the time and opportunity
to start handling this super important and valuable data better! As you’ve read here, there are
many different sources and origins for log information, and a huge number of tools you can use to
analyze that data. Putting the data and tools together in a meaningful way can pay off well in both
gained operational intelligence and potentially even a business opportunity.

I hope you’ve enjoyed this post and continue to come back to keep on top of the guidance and advice
we will be offering up here in the near future. As always, feel free to ping us at AWS for more
information, help, or advice this and other topics. Happy hacking!

Chris Munns
AWS Solutions Architect

RecommendRecommended
BookmarkBookmarkedShareMore
Go to AWS Startup Collection
Published in
AWS Startup Collection
For startups building on AWS.
Follow by email
Email me when there are new stories in the publication
Follow
---------------------------------------------------------------------------------------------------
[0]
Written on May 14, 2014 by
AWS Activate
Amazon Web Services Startup Program. Follow @AWSstartups. 
Follow by email
Email me when the author publishes or recommends
Follow
Thanks to Donn Morrill.

#+end_example
** DONE [#A] get detail output for update_docker.sh
  CLOSED: [2015-03-20 Fri 10:28]

# Run chef update inside docker
execute "Update docker by chef, check /var/log/chef/update_docker.log for detail" do
  command "ssh mdmdocker.totvs.com /root/mdmdevops/misc/update_docker.sh"
  timeout 3600 # timeout for 60 min
  action :run
end

#+BEGIN_EXAMPLE
#!/bin/bash -e
##-------------------------------------------------------------------
## File : update_docker.sh
## Author : Denny <denny.zhang001@gmail.com>
## Description :
## --
## Created : <2015-03-10>
## Updated: Time-stamp: <2015-03-20 10:25:45>
##-------------------------------------------------------------------
. /etc/profile
force_update=${1:-"no"}
chef_recipe=${2:-"jenkins-mdm"}

function log() {
    local msg=${1?}
    echo -ne `date +['%Y-%m-%d %H:%M:%S']`" $msg\n"
    
    if [ -n "$LOG_FILE" ]; then
        echo -ne `date +['%Y-%m-%d %H:%M:%S']`" $msg\n" >> $LOG_FILE
    fi
}

LOG_FILE="/var/log/chef/update_docker.log"
[ -d /var/log/chef ] || mkdir -p /var/log/chef

log "Run update_docker.sh, check $LOG_FILE for detail"
# Checkout code to run chef update
cd /root/mdmdevops/cookbooks/jenkins-mdm

output=$(git pull)
if echo $output | grep 'Already up-to-date.'; then
    if [ "$force_update" = "no" ]; then
        log "no code change, skip update"
        exit 0
    fi
fi

log "Run berks install, retry multiple times"
berks install || berks install || berks install

log "copy cookbooks by tripping version number"
for f in `ls -1 /root/.berkshelf/cookbooks`;do
 mkdir -p /root/mdmdevops/cookbooks/${f%-*}/;
 cp -r /root/.berkshelf/cookbooks/$f/* /root/mdmdevops/cookbooks/${f%-*}/;
done

# Perform chef update
echo "cookbook_path '/root/mdmdevops/cookbooks'" > /root/docker.rb
echo "{\"run_list\": [\"recipe[$chef_recipe]\"]}" > /root/docker.json
chef-solo --config /root/docker.rb -j /root/docker.json -L $LOG_FILE
################################################################################
## File : update_docker.sh ends
#+END_EXAMPLE
* [Rollback] Last resort of prod env push
** TODO Handle database inconsistencies with the roll backed code
** TODO Try rollbackup feature
#+BEGIN_EXAMPLE
[2/4/15, 12:31:05 PM] kungchaowang: Denny, is it easy to rollback to previous version on customerfi?
[2/4/15, 12:31:39 PM] denny: We haven’t tried that.

How about overwrite the neo4j data with old backup?
[2/4/15, 12:32:07 PM] kungchaowang: we can try that too, but we don’t have much time, need to decide which way is best for us
[2/4/15, 12:32:17 PM] kungchaowang: if we can fix it in place, of course it’s better
[2/4/15, 12:32:29 PM] denny: Did you find the data in old backup?
[2/4/15, 12:32:36 PM] kungchaowang: the data should be ok
[2/4/15, 12:32:42 PM] kungchaowang: but since they reloaded it
[2/4/15, 12:32:50 PM] kungchaowang: I am not sure if the current data is still good
[2/4/15, 12:33:42 PM] kungchaowang: so, you investigate if it’s possible to rollback, on my side, I will investigate the data a little more
[2/4/15, 12:35:25 PM] denny: We can do a quick test by this:
[2/4/15, 12:35:51 PM] denny: Use chef to deploy 1.4.3 for customerfi, without changing any data.

And verify that.
#+END_EXAMPLE
* [Reporting] Email problems
** when chef-update fail, send out email
** When bacukp fail, send out emails
** Ask nagios to monitor log files
** Send out email alerts, if problems happens
** TODO [#A] linux send out email by postfix                      :IMPORTANT:
ssh root@198.199.105.82

root@InternalJenkins:/etc/chef# cat >/etc/postfix/sasl_passwd <<EOF

sudo service postfix restart
*** install and configure postfix
sudo apt-get install libsasl2-modules
sudo apt-get install postfix

# mail passwd
cat > /etc/postfix/sasl_passwd <<EOF
mail.fluigidentity.com:433 jenkins@fluigidentity:Totvs@123
EOF

sudo postmap /etc/postfix/sasl_passwd

sudo chown root:root /etc/postfix/sasl_passwd /etc/postfix/sasl_passwd.db
sudo chmod 0600 /etc/postfix/sasl_passwd /etc/postfix/sasl_passwd.db

# change main.cf
sed -i 's/^#myorigin =/myorigin =/g' /etc/postfix/main.cf
sed -i 's/^relayhost = .*/relayhost = /g' /etc/postfix/main.cf
sed -i 's/^myhostname =.*/myhostname = fluigidentity.com/g' /etc/postfix/main.cf
sed -i 's/^mydestination =.*/mydestination = fluigidentity.com, localhost.fluigidentity.com, , localhost/g' /etc/postfix/main.cf

# /etc/mailname
echo "fluigidentity.com" > /etc/mailname
# aliases
echo "root: jenkins" >> /etc/aliases
cat /etc/aliases

# Restart postfix
/etc/init.d/postfix restart

# Test by sending out email
echo "body of your email" | mail -s "This is a Subject" -a "From: jenkins@fluigidentity.com" 249950670@qq.com

echo "body of your email" | mail -s "This is a Subject" -a "From: jenkins@fluigidentity.com" denny.zhang@totvs.com
*** DONE postfix configuration: /etc/postfix/main.cf
  CLOSED: [2014-12-14 Sun 20:00]
root@InternalJenkins:~# postconf -n
alias_database = hash:/etc/aliases
alias_maps = hash:/etc/aliases
append_dot_mydomain = no
biff = no
config_directory = /etc/postfix
inet_interfaces = all
mailbox_size_limit = 0
mydestination = InternalJenkins, localhost.localdomain, , localhost
myhostname = InternalJenkins
mynetworks = 127.0.0.0/8 [::ffff:127.0.0.0]/104 [::1]/128
readme_directory = no
recipient_delimiter = +
relayhost = [mail.fluigidentity.com]:587
smtp_tls_session_cache_database = btree:${data_directory}/smtp_scache
smtpd_banner = $myhostname ESMTP $mail_name (Ubuntu)
smtpd_tls_cert_file = /etc/ssl/certs/ssl-cert-snakeoil.pem
smtpd_tls_key_file = /etc/ssl/private/ssl-cert-snakeoil.key
smtpd_tls_session_cache_database = btree:${data_directory}/smtpd_scache
smtpd_use_tls = yes
*** TODO fail to send out email: Relay access denied: Error no valid recipients
20:04:12.452589 IP (tos 0x8, ttl 42, id 3232, offset 0, flags [DF], proto TCP (6), length 161)
    174.129.225.122.587 > 198.199.105.82.35947: Flags [P.], cksum 0x79fd (correct), seq 213:322, ack 166, win 486, options [nop,nop,TS val 2080641502 ecr 21814109], length 109
	0x0000:  0000 0001 0006 3c8a b00d 3ff0 0000 0800  ......<...?.....
	0x0010:  4508 00a1 0ca0 4000 2a06 8399 ae81 e17a  E.....@.*......z
	0x0020:  c6c7 6952 024b 8c6b 0ef4 0c09 dcd3 eee9  ..iR.K.k........
	0x0030:  8018 01e6 79fd 0000 0101 080a 7c04 11de  ....y.......|...
	0x0040:  014c db5d 3235 3020 322e 312e 3020 4f6b  .L.]250.2.1.0.Ok
	0x0050:  0d0a 3535 3420 352e 372e 3120 3c66 696c  ..554.5.7.1.<fil
	0x0060:  6562 6174 2e6d 6172 6b40 676d 6169 6c2e  ebat.mark@gmail.
	0x0070:  636f 6d3e 3a20 5265 6c61 7920 6163 6365  com>:.Relay.acce
	0x0080:  7373 2064 656e 6965 640d 0a35 3534 2035  ss.denied..554.5
	0x0090:  2e35 2e31 2045 7272 6f72 3a20 6e6f 2076  .5.1.Error:.no.v
	0x00a0:  616c 6964 2072 6563 6970 6965 6e74 730d  alid.recipients.
	0x00b0:  0a                                       .
*** #  --8<-------------------------- separator ------------------------>8--
*** TODO fail to send out email
	0x0040:  000e 9f8d 3235 3020 322e 312e 3020 4f6b  ....250.2.1.0.Ok
	0x0050:  0d0a 3435 3020 342e 312e 3820 3c72 6f6f  ..450.4.1.8.<roo
	0x0060:  7440 496e 7465 726e 616c 4a65 6e6b 696e  t@InternalJenkin
	0x0070:  733e 3a20 5365 6e64 6572 2061 6464 7265  s>:.Sender.addre
	0x0080:  7373 2072 656a 6563 7465 643a 2044 6f6d  ss.rejected:.Dom
	0x0090:  6169 6e20 6e6f 7420 666f 756e 640d 0a35  ain.not.found..5
	0x00a0:  3534 2035 2e35 2e31 2045 7272 6f72 3a20  54.5.5.1.Error:.
	0x00b0:  6e6f 2076 616c 6964 2072 6563 6970 6965  no.valid.recipie
	0x00c0:  6e74 730d 0a                             nts..

#+BEGIN_EXAMPLE
root@InternalJenkins:~# sudo tcpdump  -vvv -XX -s 0 -f -c 1000 -nn -i any 'port  587 '
<o tcpdump  -vvv -XX -s 0 -f -c 1000 -nn -i any 'port  587 '
tcpdump: listening on any, link-type LINUX_SLL (Linux cooked), capture size 65535 bytes
20:53:38.877691 IP (tos 0x0, ttl 64, id 47520, offset 0, flags [DF], proto TCP (6), length 60)
    198.199.105.82.47084 > 174.129.225.122.587: Flags [S], cksum 0xc044 (incorrect -> 0x65e7), seq 795682543, win 29200, options [mss 1460,sackOK,TS val 958287 ecr 0,nop,wscale 8], length 0
	0x0000:  0004 0001 0006 0401 338d 0901 0000 0800  ........3.......
	0x0010:  4500 003c b9a0 4000 4006 c105 c6c7 6952  E..<..@.@.....iR
	0x0020:  ae81 e17a b7ec 024b 2f6d 26ef 0000 0000  ...z...K/m&.....
	0x0030:  a002 7210 c044 0000 0204 05b4 0402 080a  ..r..D..........
	0x0040:  000e 9f4f 0000 0000 0103 0308            ...O........
20:53:38.960012 IP (tos 0x8, ttl 42, id 0, offset 0, flags [DF], proto TCP (6), length 60)
    174.129.225.122.587 > 198.199.105.82.47084: Flags [S.], cksum 0x0971 (correct), seq 3868420277, ack 795682544, win 14480, options [mss 1460,sackOK,TS val 2059783129 ecr 958287,nop,wscale 5], length 0
	0x0000:  0000 0001 0006 3c8a b00d 6ff0 0000 0800  ......<...o.....
	0x0010:  4508 003c 0000 4000 2a06 909e ae81 e17a  E..<..@.*......z
	0x0020:  c6c7 6952 024b b7ec e693 68b5 2f6d 26f0  ..iR.K....h./m&.
	0x0030:  a012 3890 0971 0000 0204 05b4 0402 080a  ..8..q..........
	0x0040:  7ac5 cbd9 000e 9f4f 0103 0305            z......O....
20:53:38.960099 IP (tos 0x0, ttl 64, id 47521, offset 0, flags [DF], proto TCP (6), length 52)
    198.199.105.82.47084 > 174.129.225.122.587: Flags [.], cksum 0xc03c (incorrect -> 0x7043), seq 1, ack 1, win 115, options [nop,nop,TS val 958308 ecr 2059783129], length 0
	0x0000:  0004 0001 0006 0401 338d 0901 0000 0800  ........3.......
	0x0010:  4500 0034 b9a1 4000 4006 c10c c6c7 6952  E..4..@.@.....iR
	0x0020:  ae81 e17a b7ec 024b 2f6d 26f0 e693 68b6  ...z...K/m&...h.
	0x0030:  8010 0073 c03c 0000 0101 080a 000e 9f64  ...s.<.........d
	0x0040:  7ac5 cbd9                                z...
20:53:39.043186 IP (tos 0x8, ttl 42, id 41819, offset 0, flags [DF], proto TCP (6), length 94)
    174.129.225.122.587 > 198.199.105.82.47084: Flags [P.], cksum 0x9931 (correct), seq 1:43, ack 1, win 453, options [nop,nop,TS val 2059783150 ecr 958308], length 42
	0x0000:  0000 0001 0006 3c8a b00d 6ff0 0000 0800  ......<...o.....
	0x0010:  4508 005e a35b 4000 2a06 ed20 ae81 e17a  E..^.[@.*......z
	0x0020:  c6c7 6952 024b b7ec e693 68b6 2f6d 26f0  ..iR.K....h./m&.
	0x0030:  8018 01c5 9931 0000 0101 080a 7ac5 cbee  .....1......z...
	0x0040:  000e 9f64 3232 3020 6d61 696c 2e66 6c75  ...d220.mail.flu
	0x0050:  6967 6964 656e 7469 7479 2e63 6f6d 2045  igidentity.com.E
	0x0060:  534d 5450 2050 6f73 7466 6978 0d0a       SMTP.Postfix..
20:53:39.043261 IP (tos 0x0, ttl 64, id 47522, offset 0, flags [DF], proto TCP (6), length 52)
    198.199.105.82.47084 > 174.129.225.122.587: Flags [.], cksum 0xc03c (incorrect -> 0x6ff0), seq 1, ack 43, win 115, options [nop,nop,TS val 958328 ecr 2059783150], length 0
	0x0000:  0004 0001 0006 0401 338d 0901 0000 0800  ........3.......
	0x0010:  4500 0034 b9a2 4000 4006 c10b c6c7 6952  E..4..@.@.....iR
	0x0020:  ae81 e17a b7ec 024b 2f6d 26f0 e693 68e0  ...z...K/m&...h.
	0x0030:  8010 0073 c03c 0000 0101 080a 000e 9f78  ...s.<.........x
	0x0040:  7ac5 cbee                                z...
20:53:39.043694 IP (tos 0x0, ttl 64, id 47523, offset 0, flags [DF], proto TCP (6), length 74)
    198.199.105.82.47084 > 174.129.225.122.587: Flags [P.], cksum 0xc052 (incorrect -> 0xc309), seq 1:23, ack 43, win 115, options [nop,nop,TS val 958328 ecr 2059783150], length 22
	0x0000:  0004 0001 0006 0401 338d 0901 0000 0800  ........3.......
	0x0010:  4500 004a b9a3 4000 4006 c0f4 c6c7 6952  E..J..@.@.....iR
	0x0020:  ae81 e17a b7ec 024b 2f6d 26f0 e693 68e0  ...z...K/m&...h.
	0x0030:  8018 0073 c052 0000 0101 080a 000e 9f78  ...s.R.........x
	0x0040:  7ac5 cbee 4548 4c4f 2049 6e74 6572 6e61  z...EHLO.Interna
	0x0050:  6c4a 656e 6b69 6e73 0d0a                 lJenkins..
20:53:39.125410 IP (tos 0x8, ttl 42, id 41820, offset 0, flags [DF], proto TCP (6), length 52)
    174.129.225.122.587 > 198.199.105.82.47084: Flags [.], cksum 0x6e74 (correct), seq 43, ack 23, win 453, options [nop,nop,TS val 2059783170 ecr 958328], length 0
	0x0000:  0000 0001 0006 3c8a b00d 6ff0 0000 0800  ......<...o.....
	0x0010:  4508 0034 a35c 4000 2a06 ed49 ae81 e17a  E..4.\@.*..I...z
	0x0020:  c6c7 6952 024b b7ec e693 68e0 2f6d 2706  ..iR.K....h./m'.
	0x0030:  8010 01c5 6e74 0000 0101 080a 7ac5 cc02  ....nt......z...
	0x0040:  000e 9f78                                ...x
20:53:39.125463 IP (tos 0x8, ttl 42, id 41821, offset 0, flags [DF], proto TCP (6), length 222)
    174.129.225.122.587 > 198.199.105.82.47084: Flags [P.], cksum 0x6dec (correct), seq 43:213, ack 23, win 453, options [nop,nop,TS val 2059783170 ecr 958328], length 170
	0x0000:  0000 0001 0006 3c8a b00d 6ff0 0000 0800  ......<...o.....
	0x0010:  4508 00de a35d 4000 2a06 ec9e ae81 e17a  E....]@.*......z
	0x0020:  c6c7 6952 024b b7ec e693 68e0 2f6d 2706  ..iR.K....h./m'.
	0x0030:  8018 01c5 6dec 0000 0101 080a 7ac5 cc02  ....m.......z...
	0x0040:  000e 9f78 3235 302d 6d61 696c 2e66 6c75  ...x250-mail.flu
	0x0050:  6967 6964 656e 7469 7479 2e63 6f6d 0d0a  igidentity.com..
	0x0060:  3235 302d 5049 5045 4c49 4e49 4e47 0d0a  250-PIPELINING..
	0x0070:  3235 302d 5349 5a45 0d0a 3235 302d 4554  250-SIZE..250-ET
	0x0080:  524e 0d0a 3235 302d 5354 4152 5454 4c53  RN..250-STARTTLS
	0x0090:  0d0a 3235 302d 4155 5448 2050 4c41 494e  ..250-AUTH.PLAIN
	0x00a0:  204c 4f47 494e 0d0a 3235 302d 4155 5448  .LOGIN..250-AUTH
	0x00b0:  3d50 4c41 494e 204c 4f47 494e 0d0a 3235  =PLAIN.LOGIN..25
	0x00c0:  302d 454e 4841 4e43 4544 5354 4154 5553  0-ENHANCEDSTATUS
	0x00d0:  434f 4445 530d 0a32 3530 2d38 4249 544d  CODES..250-8BITM
	0x00e0:  494d 450d 0a32 3530 2044 534e 0d0a       IME..250.DSN..
20:53:39.125607 IP (tos 0x0, ttl 64, id 47524, offset 0, flags [DF], proto TCP (6), length 171)
    198.199.105.82.47084 > 174.129.225.122.587: Flags [P.], cksum 0xc0b3 (incorrect -> 0x1b6d), seq 23:142, ack 213, win 119, options [nop,nop,TS val 958349 ecr 2059783170], length 119
	0x0000:  0004 0001 0006 0401 338d 0901 0000 0800  ........3.......
	0x0010:  4500 00ab b9a4 4000 4006 c092 c6c7 6952  E.....@.@.....iR
	0x0020:  ae81 e17a b7ec 024b 2f6d 2706 e693 698a  ...z...K/m'...i.
	0x0030:  8018 0077 c0b3 0000 0101 080a 000e 9f8d  ...w............
	0x0040:  7ac5 cc02 4d41 494c 2046 524f 4d3a 3c72  z...MAIL.FROM:<r
	0x0050:  6f6f 7440 496e 7465 726e 616c 4a65 6e6b  oot@InternalJenk
	0x0060:  696e 733e 2053 495a 453d 3332 350d 0a52  ins>.SIZE=325..R
	0x0070:  4350 5420 544f 3a3c 6669 6c65 6261 742e  CPT.TO:<filebat.
	0x0080:  6d61 726b 4067 6d61 696c 2e63 6f6d 3e20  mark@gmail.com>.
	0x0090:  4f52 4350 543d 7266 6338 3232 3b66 696c  ORCPT=rfc822;fil
	0x00a0:  6562 6174 2e6d 6172 6b40 676d 6169 6c2e  ebat.mark@gmail.
	0x00b0:  636f 6d0d 0a44 4154 410d 0a              com..DATA..
20:53:39.208901 IP (tos 0x8, ttl 42, id 41822, offset 0, flags [DF], proto TCP (6), length 181)
    174.129.225.122.587 > 198.199.105.82.47084: Flags [P.], cksum 0x2975 (correct), seq 213:342, ack 142, win 453, options [nop,nop,TS val 2059783191 ecr 958349], length 129
	0x0000:  0000 0001 0006 3c8a b00d 6ff0 0000 0800  ......<...o.....
	0x0010:  4508 00b5 a35e 4000 2a06 ecc6 ae81 e17a  E....^@.*......z
	0x0020:  c6c7 6952 024b b7ec e693 698a 2f6d 277d  ..iR.K....i./m'}
	0x0030:  8018 01c5 2975 0000 0101 080a 7ac5 cc17  ....)u......z...
	0x0040:  000e 9f8d 3235 3020 322e 312e 3020 4f6b  ....250.2.1.0.Ok
	0x0050:  0d0a 3435 3020 342e 312e 3820 3c72 6f6f  ..450.4.1.8.<roo
	0x0060:  7440 496e 7465 726e 616c 4a65 6e6b 696e  t@InternalJenkin
	0x0070:  733e 3a20 5365 6e64 6572 2061 6464 7265  s>:.Sender.addre
	0x0080:  7373 2072 656a 6563 7465 643a 2044 6f6d  ss.rejected:.Dom
	0x0090:  6169 6e20 6e6f 7420 666f 756e 640d 0a35  ain.not.found..5
	0x00a0:  3534 2035 2e35 2e31 2045 7272 6f72 3a20  54.5.5.1.Error:.
	0x00b0:  6e6f 2076 616c 6964 2072 6563 6970 6965  no.valid.recipie
	0x00c0:  6e74 730d 0a                             nts..
20:53:39.213567 IP (tos 0x0, ttl 64, id 47525, offset 0, flags [DF], proto TCP (6), length 64)
    198.199.105.82.47084 > 174.129.225.122.587: Flags [P.], cksum 0xc048 (incorrect -> 0x2163), seq 142:154, ack 342, win 123, options [nop,nop,TS val 958371 ecr 2059783191], length 12
	0x0000:  0004 0001 0006 0401 338d 0901 0000 0800  ........3.......
	0x0010:  4500 0040 b9a5 4000 4006 c0fc c6c7 6952  E..@..@.@.....iR
	0x0020:  ae81 e17a b7ec 024b 2f6d 277d e693 6a0b  ...z...K/m'}..j.
	0x0030:  8018 007b c048 0000 0101 080a 000e 9fa3  ...{.H..........
	0x0040:  7ac5 cc17 5253 4554 0d0a 5155 4954 0d0a  z...RSET..QUIT..
20:53:39.295468 IP (tos 0x8, ttl 42, id 41823, offset 0, flags [DF], proto TCP (6), length 81)
    174.129.225.122.587 > 198.199.105.82.47084: Flags [P.], cksum 0x73ae (correct), seq 342:371, ack 154, win 453, options [nop,nop,TS val 2059783213 ecr 958371], length 29
	0x0000:  0000 0001 0006 3c8a b00d 6ff0 0000 0800  ......<...o.....
	0x0010:  4508 0051 a35f 4000 2a06 ed29 ae81 e17a  E..Q._@.*..)...z
	0x0020:  c6c7 6952 024b b7ec e693 6a0b 2f6d 2789  ..iR.K....j./m'.
	0x0030:  8018 01c5 73ae 0000 0101 080a 7ac5 cc2d  ....s.......z..-
	0x0040:  000e 9fa3 3235 3020 322e 302e 3020 4f6b  ....250.2.0.0.Ok
	0x0050:  0d0a 3232 3120 322e 302e 3020 4279 650d  ..221.2.0.0.Bye.
	0x0060:  0a                                       .
20:53:39.295567 IP (tos 0x8, ttl 42, id 41824, offset 0, flags [DF], proto TCP (6), length 52)
    174.129.225.122.587 > 198.199.105.82.47084: Flags [F.], cksum 0x6c52 (correct), seq 371, ack 154, win 453, options [nop,nop,TS val 2059783213 ecr 958371], length 0
	0x0000:  0000 0001 0006 3c8a b00d 6ff0 0000 0800  ......<...o.....
	0x0010:  4508 0034 a360 4000 2a06 ed45 ae81 e17a  E..4.`@.*..E...z
	0x0020:  c6c7 6952 024b b7ec e693 6a28 2f6d 2789  ..iR.K....j(/m'.
	0x0030:  8011 01c5 6c52 0000 0101 080a 7ac5 cc2d  ....lR......z..-
	0x0040:  000e 9fa3                                ....
20:53:39.295633 IP (tos 0x0, ttl 64, id 47526, offset 0, flags [DF], proto TCP (6), length 52)
    198.199.105.82.47084 > 174.129.225.122.587: Flags [F.], cksum 0xc03c (incorrect -> 0x6d87), seq 154, ack 372, win 123, options [nop,nop,TS val 958391 ecr 2059783213], length 0
	0x0000:  0004 0001 0006 0401 338d 0901 0000 0800  ........3.......
	0x0010:  4500 0034 b9a6 4000 4006 c107 c6c7 6952  E..4..@.@.....iR
	0x0020:  ae81 e17a b7ec 024b 2f6d 2789 e693 6a29  ...z...K/m'...j)
	0x0030:  8011 007b c03c 0000 0101 080a 000e 9fb7  ...{.<..........
	0x0040:  7ac5 cc2d                                z..-
20:53:39.377122 IP (tos 0x8, ttl 42, id 41825, offset 0, flags [DF], proto TCP (6), length 52)
    174.129.225.122.587 > 198.199.105.82.47084: Flags [.], cksum 0x6c29 (correct), seq 372, ack 155, win 453, options [nop,nop,TS val 2059783233 ecr 958391], length 0
	0x0000:  0000 0001 0006 3c8a b00d 6ff0 0000 0800  ......<...o.....
	0x0010:  4508 0034 a361 4000 2a06 ed44 ae81 e17a  E..4.a@.*..D...z
	0x0020:  c6c7 6952 024b b7ec e693 6a29 2f6d 278a  ..iR.K....j)/m'.
	0x0030:  8010 01c5 6c29 0000 0101 080a 7ac5 cc41  ....l)......z..A
	0x0040:  000e 9fb7                                ....
#+END_EXAMPLE
*** useful link
https://www.linode.com/docs/email/postfix/postfix-smtp-debian7
* [Network] Network & Firewall
** http proxy
*** TODO Bug: Change VMManger to add http proxy, it the variables are given
It will be given by java program
** network connectivity issue
#+BEGIN_EXAMPLE
[2/4/15, 1:29:05 PM] denny: Hi Lucas

Thanks for the quick response.
[2/4/15, 1:29:56 PM] Lucas Ciriaco: Below VMs can't access internet.
  172.20.18.27: ping www.google.com fail
  172.20.18.28: ping www.google.com fail
  172.20.18.29: ping www.google.com fail
  172.20.18.30: ping www.google.com fail
  172.20.18.31: ping www.google.com fail
[2/4/15, 1:30:15 PM] Lucas Ciriaco: Is not released icmp
[2/4/15, 1:30:50 PM] Lucas Ciriaco: for this reason has failed
[2/4/15, 1:30:58 PM] Lucas Ciriaco: 172.20.16.13: telnet totvslabs.psfluigidentity.com 443 fail
- 172.20.16.13: telnet totvslabs.customerfi.com 443 fail
[2/4/15, 1:31:08 PM] Lucas Ciriaco: try again
[2/4/15, 1:31:17 PM] denny: np for the ping failure.
[2/4/15, 1:32:06 PM] denny: About telnet failure, it works now.
[2/4/15, 1:32:59 PM] Lucas Ciriaco: telnet worked?
[2/4/15, 1:33:05 PM] denny: It works now.
[2/4/15, 1:33:12 PM] denny: Previously it worked
[2/4/15, 1:33:49 PM] denny: Like one or two weeks ago.

There was some network maintaince. After that, it failed to work
#+END_EXAMPLE
** TODO Figure out network traffic list
#+BEGIN_EXAMPLE
[1/27/15, 4:10:28 PM] kungchaowang: sure
[1/27/15, 10:58:34 PM] kungchaowang: Besides those 2 IPs are not accessible, any ports between these servers that we need to open to each other?

For now I see these ports should be open for these machines:

id-app: 22, 80, 443, 18080, 11111, 11133
id-msg: 22, 2098, 2099, 18084, 5455, 5445
id-racagent: 22
id-keystore: 22, 11122, 1305
id-cb: 22, 80, 443, 8091
[1/27/15, 10:58:57 PM] kungchaowang: am i right on this? do you have list of ports that need to be open for each server?
[1/27/15, 11:15:33 PM] denny: Hi Kung

I don’t have a list of ports.

I would suggest:
- Allow all traffic among those machines
- For incoming traffic from internet, open port 80 and 443
- For incoming ssh login, open port 22 to ip of VPN.

I agree even more restricted network than above would be safer. I’m not sure whether it’s a good timing to enforce this.

Probably it may bring us more trouble than the benefits.
[1/27/15, 11:16:41 PM] denny: =========================
In MDM project, we can enable iptables for this by chef.

Thus we can easily get what we need for firewall configuration
#+END_EXAMPLE
** TODO How to detect network is becoming slow?
** service bind ip address of a certain network nic            :Problem:
#+BEGIN_EXAMPLE
[2/3/15, 6:00:57 PM] kungchaowang: from the log I see it stuck on connecting to messaging server
[2/3/15, 6:01:12 PM] kungchaowang: and why messaging server hang, so far I don’t know yet.
[2/3/15, 6:01:37 PM] kungchaowang: but i do see one figuration error in this file:
[2/3/15, 6:01:46 PM] denny: What’s that?
[2/3/15, 6:02:02 PM] kungchaowang: /opt/hornetq/config/stand-alone/non-clustered/hornetq-beans.xml
[2/3/15, 6:02:33 PM] kungchaowang: now is:

      <property name="port">${jnp.port:2099}</property>
      <property name="bindAddress">${jnp.host:172.20.16.16}</property>
      <property name="rmiPort">${jnp.rmiPort:2098}</property>
      <property name="rmiBindAddress">${jnp.host:172.20.16.16}</property>

it was originally:

      <property name="port">${jnp.port:2099}</property>
      <property name="bindAddress">${jnp.host:0.0.0.0}</property>
      <property name="rmiPort">${jnp.rmiPort:2098}</property>
      <property name="rmiBindAddress">${jnp.host:0.0.0.0}</property>
[2/3/15, 6:02:57 PM] kungchaowang: it won’t work as JNDI is not able to connect to 0.0.0.0 itself
[2/3/15, 6:03:13 PM] kungchaowang: so it has to be it’s external IP, which is 172.20.16.16
[2/3/15, 6:03:41 PM] kungchaowang: to match what we have here in this file: /opt/hornetq/bin/run.sh

export CLUSTER_PROPS="-Djnp.port=2099 -Djnp.rmiPort=2098 -Djnp.host=172.20.16.16 -Dhornetq.remoting.netty.host=172.20.16.16 -Dhornetq.remoting.ne
tty.port=5445"
[2/3/15, 6:03:43 PM] denny: Let me see.

No change about this for 1.4.4 release
[2/3/15, 6:04:17 PM] kungchaowang: no, it is just what I found, it’s not your fault
[2/3/15, 6:04:27 PM] denny: Chef doesn’t handle this file
[2/3/15, 6:04:46 PM] denny: Just confirmed.

Should I automate this to chef?
[2/3/15, 6:05:56 PM] denny: Same problem happen in customerfi and psfluigidentity.
[2/3/15, 6:07:08 PM] denny: And doesn’t see any complain about customerfi and psfluigidentity, from Suresh’s test.
[2/3/15, 6:12:49 PM] denny: Note: these two are all-in-one
[2/3/15, 6:15:54 PM] kungchaowang: yes, because they are AIO, if it’s the same box, you will be able to loop back using 0.0.0.0
[2/3/15, 6:16:08 PM] kungchaowang: but since it’s multi node, you should use external ip
[2/3/15, 6:17:28 PM] denny: OK, I will change chef to manage hornetq-beans.xml
[2/3/15, 6:24:19 PM] denny: Just checked qafluigidentity.

It’s also 0.0.0.0

What problem would end user feel this conf error?
[2/3/15, 6:24:45 PM] denny: From Suresh’s recent daily update, we don’t need concern from QA test.
#+END_EXAMPLE
* #  --8<-------------------------- separator ------------------------>8--
* [User] OS user management
** A vendor setting up a service account with their own name and password. :Problem:
 Once the vendor left and their account was deleted from LDAP/AD the Production batch stopped when it tried to authenticate with the web service.
** A user hosted the web contents folder in their home directory.   :Problem:
It was deleted when their account was de-provisioned.
* [Repo] Maintain repo server
** Don't avoid chef code to download files from external links
- external links may be changed or out of service
- company firewall may disable this
** Chef code recognize cache behavior
* [Security] Linux and website security
  http://java.dzone.com/articles/why-security-devops?mz=38541-devops
  Why Security is DevOps | Javalobby
** Detect Heartbleed test
https://filippo.io/Heartbleed/#app.customerfi.com
** Drawback of giving off readonly OS user
** Limit sshd configure: only IP from VPN can access
** Web Application Security Test
https://www.owasp.org/index.php/Web_Application_Security_Testing_Cheat_Sheet
** web page: Web Application Security Testing Cheat Sheet - OWASP
https://www.owasp.org/index.php/Web_Application_Security_Testing_Cheat_Sheet
*** webcontent                                                     :noexport:
#+begin_example
Location: https://www.owasp.org/index.php/Web_Application_Security_Testing_Cheat_Sheet
Web Application Security Testing Cheat Sheet

From OWASP
Jump to: navigation, search

  * 1 DRAFT CHEAT SHEET - WORK IN PROGRESS
  * 2 Introduction
  * 3 Purpose
  * 4 The Checklist
      + 4.1 Information Gathering
      + 4.2 Configuration Management
      + 4.3 Secure Transmission
      + 4.4 Authentication
      + 4.5 Session Management
      + 4.6 Authorization
      + 4.7 Data Validation
      + 4.8 Denial of Service
      + 4.9 Business Logic
      + 4.10 Cryptography
      + 4.11 Risky Functionality - File Uploads
      + 4.12 Risky Functionality - Card Payment
      + 4.13 HTML 5
      + 4.14 Error Handling
  * 5 Other Formats
  * 6 Authors and primary contributors
  * 7 Other Contributors
  * 8 Related articles

DRAFT CHEAT SHEET - WORK IN PROGRESS

Introduction

This cheat sheet provides a checklist of tasks to be performed when performing a blackbox security
test of a web application.

Purpose

This checklist is intended to be used as an aide memoire for experienced pentesters and should be
used in conjunction with the OWASP Testing Guide. It will be updated as the Testing Guide v4 is
progressed.

The intention is that this guide will be available as an XML document, with scripts that convert it
into formats such as pdf, Media Wiki markup, HTML etc.

This will allow it to be consumed within security tools as well as being available in a format
suitable for printing.

All feedback or offers of help will be appreciated - and if you have specific chances you think
should be made, just get stuck in.

The Checklist

Information Gathering

  * Manually explore the site
  * Spider/crawl for missed or hidden content
  * Check the Webserver Metafiles for information leakage files that expose content, such as
    robots.txt, sitemap.xml, .DS_Store
  * Check the caches of major search engines for publicly accessible sites
  * Check for differences in content based on User Agent (eg, Mobile sites, access as a Search
    engine Crawler)
  * Check The Webpage Comments and Metadata for Information Leakage
  * Check The Web Application Framework
  * Perform Web Application Fingerprinting
  * Identify technologies used
  * Identify user roles
  * Identify application entry points
  * Identify client-side code
  * Identify multiple versions/channels (e.g. web, mobile web, mobile app, web services)
  * Identify co-hosted and related applications
  * Identify all hostnames and ports
  * Identify third-party hosted content

Configuration Management

  * Check for commonly used application and administrative URLs
  * Check for old, backup and unreferenced files
  * Check HTTP methods supported and Cross Site Tracing (XST)
  * Test file extensions handling
  * Test RIA cross domain policy
  * Test for security HTTP headers (e.g. CSP, X-Frame-Options, HSTS)
  * Test for policies (e.g. Flash, Silverlight, robots)
  * Test for non-production data in live environment, and vice-versa
  * Check for sensitive data in client-side code (e.g. API keys, credentials)

Secure Transmission

  * Check SSL Version, Algorithms, Key length
  * Check for Digital Certificate Validity (Duration, Signature and CN)
  * Check credentials only delivered over HTTPS
  * Check that the login form is delivered over HTTPS
  * Check session tokens only delivered over HTTPS
  * Check if HTTP Strict Transport Security (HSTS) in use

Authentication

  * Test for user enumeration
  * Test for authentication bypass
  * Test for brute force protection
  * Test for Credentials Transported over an Encrypted Channel
  * Test password quality rules
  * Test remember me functionality
  * Test for autocomplete on password forms/input
  * Test password reset and/or recovery
  * Test password change process
  * Test CAPTCHA
  * Test multi factor authentication
  * Test for logout functionality presence
  * Test for cache management on HTTP (eg Pragma, Expires, Max-age)
  * Test for default logins
  * Test for user-accessible authentication history
  * Test for out-of channel notification of account lockouts and successful password changes
  * Test for consistent authentication across applications with shared authentication schema / SSO
    and alternative channels
  * Test for Weak security question/answer

Session Management

  * Establish how session management is handled in the application (eg, tokens in cookies, token in
    URL)
  * Check session tokens for cookie flags (httpOnly and secure)
  * Check session cookie scope (path and domain)
  * Check session cookie duration (expires and max-age)
  * Check session termination after a maximum lifetime
  * Check session termination after relative timeout
  * Check session termination after logout
  * Test to see if users can have multiple simultaneous sessions
  * Test session cookies for randomness
  * Confirm that new session tokens are issued on login, role change and logout
  * Test for consistent session management across applications with shared session management
  * Test for session puzzling
  * Test for CSRF and clickjacking

Authorization

  * Test for path traversal
  * Test for vertical Access control problems (a.k.a. Privilege Escalation)
  * Test for horizontal Access control problems (between two users at the same privilege level)
  * Test for missing authorisation
  * Test for Insecure Direct Object References

Data Validation

  * Test for Reflected Cross Site Scripting
  * Test for Stored Cross Site Scripting
  * Test for DOM based Cross Site Scripting
  * Test for Cross Site Flashing
  * Test for HTML Injection
  * Test for SQL Injection
  * Test for LDAP Injection
  * Test for ORM Injection
  * Test for XML Injection
  * Test for XXE Injection
  * Test for SSI Injection
  * Test for XPath Injection
  * Test for XQuery Injection
  * Test for IMAP/SMTP Injection
  * Test for Code Injection
  * Test for Expression Language Injection
  * Test for Command Injection
  * Test for Overflow (Stack, Heap and Integer)
  * Test for Format String
  * Test for incubated vulnerabilities
  * Test for HTTP Splitting/Smuggling
  * Test for HTTP Verb Tampering
  * Test for Open Redirection
  * Test for Local File Inclusion
  * Test for Remote File Inclusion
  * Compare client-side and server-side validation rules
  * Test for NoSQL injection
  * Test for HTTP parameter pollution
  * Test for auto-binding
  * Test for Mass Assignment
  * Test for NULL/Invalid Session Cookie

Denial of Service

  * Test for anti-automation
  * Test for account lockout
  * Test for HTTP protocol DoS
  * Test for SQL wildcard DoS

Business Logic

  * Test for feature misuse
  * Test for lack of non-repudiation
  * Test for trust relationships
  * Test for integrity of data
  * Test segregation of duties
  * Test for Process Timing
  * Test Number of Times a Function Can be Used Limits
  * Test for the Circumvention of Work Flows
  * Test Defenses Against Application Mis-use
  * Test Upload of Unexpected File Types

Cryptography

  * Check if data which should be encrypted is not
  * Check for wrong algorithms usage depending on context
  * Check for weak algorithms usage
  * Check for proper use of salting
  * Check for randomness functions

Risky Functionality - File Uploads

  * Test that acceptable file types are whitelisted
  * Test that file size limits, upload frequency and total file counts are defined and are enforced
  * Test that file contents match the defined file type
  * Test that all file uploads have Anti-Virus scanning in-place.
  * Test that unsafe filenames are sanitised
  * Test that uploaded files are not directly accessible within the web root
  * Test that uploaded files are not served on the same hostname/port
  * Test that files and other media are integrated with the authentication and authorisation
    schemas

Risky Functionality - Card Payment

  * Test for known vulnerabilities and configuration issues on Web Server and Web Application
  * Test for default or guessable password
  * Test for non-production data in live environment, and vice-versa
  * Test for Injection vulnerabilities
  * Test for Buffer Overflows
  * Test for Insecure Cryptographic Storage
  * Test for Insufficient Transport Layer Protection
  * Test for Improper Error Handling
  * Test for all vulnerabilities with a CVSS v2 score > 4.0
  * Test for Authentication and Authorization issues
  * Test for CSRF

HTML 5

  * Test Web Messaging
  * Test for Web Storage SQL injection
  * Check CORS implementation
  * Check Offline Web Application

Error Handling

  * Check for Error Codes
  * Check for Stack Traces

Other Formats

  * DradisPro template format on github
  * Asana template on Templana (thanks to Bastien Siebman)

Authors and primary contributors

Simon Bennetts
Rory McCune
Colin Watson
Simone Onofri
Amro AlOlaqi

All the authors of the Testing Guide v3

Other Contributors

Ryan Dewhurst

Related articles

OWASP Testing Guide

Mozilla Web Security Verification

OWASP Cheat Sheets Project Homepage

  * OWASP Cheat Sheet Series

Developer Cheat Sheets (Builder)

  * Authentication Cheat Sheet
  * Choosing and Using Security Questions Cheat Sheet
  * Clickjacking Defense Cheat Sheet
  * C-Based Toolchain Hardening Cheat Sheet
  * Cross-Site Request Forgery (CSRF) Prevention Cheat Sheet
  * Cryptographic Storage Cheat Sheet
  * DOM based XSS Prevention Cheat Sheet
  * Forgot Password Cheat Sheet
  * HTML5 Security Cheat Sheet
  * Input Validation Cheat Sheet
  * JAAS Cheat Sheet
  * Logging Cheat Sheet
  * .NET Security Cheat Sheet
  * Password Storage Cheat Sheet
  * Pinning Cheat Sheet
  * Query Parameterization Cheat Sheet
  * Ruby on Rails Cheatsheet
  * REST Security Cheat Sheet
  * Session Management Cheat Sheet
  * SQL Injection Prevention Cheat Sheet
  * Transport Layer Protection Cheat Sheet
  * Unvalidated Redirects and Forwards Cheat Sheet
  * User Privacy Protection Cheat Sheet
  * Web Service Security Cheat Sheet
  * XSS (Cross Site Scripting) Prevention Cheat Sheet

Assessment Cheat Sheets (Breaker)

  * Attack Surface Analysis Cheat Sheet
  * XSS Filter Evasion Cheat Sheet
  * REST Assessment Cheat Sheet

Mobile Cheat Sheets

  * IOS Developer Cheat Sheet
  * Mobile Jailbreaking Cheat Sheet

OpSec Cheat Sheets (Defender)

  * Virtual Patching Cheat Sheet

Draft Cheat Sheets

  * OWASP Top Ten Cheat Sheet
  * Access Control Cheat Sheet
  * Application Security Architecture Cheat Sheet
  * Business Logic Security Cheat Sheet
  * PHP Security Cheat Sheet
  * Secure Coding Cheat Sheet
  * Secure SDLC Cheat Sheet
  * Threat Modeling Cheat Sheet
  * Web Application Security Testing Cheat Sheet
  * Grails Secure Code Review Cheat Sheet
  * IOS Application Security Testing Cheat Sheet
  * Key Management Cheat Sheet
  * Insecure Direct Object Reference Prevention Cheat Sheet
  * Content Security Policy Cheat Sheet

Retrieved from "
https://www.owasp.org/index.php?title=Web_Application_Security_Testing_Cheat_Sheet&oldid=178473"
Categories:

  * Cheatsheets
  * OWASP Breakers

Navigation menu

Personal tools

  * Log in
  * Request account

Namespaces

  * Page
  * Discussion

Variants

Views

  * Read
  * View source
  * View history

Actions

Search

 Search  Go

Navigation

  * Home
  * About OWASP
  * Acknowledgements
  * Advertising
  * AppSec Events
  * Books
  * Brand Resources
  * Chapters
  * Donate to OWASP
  * Downloads
  * Funding
  * Governance
  * Initiatives
  * Mailing Lists
  * Membership
  * Merchandise
  * News
  * Community portal
  * Presentations
  * Press
  * Projects
  * Video
  * Volunteer

Reference

  * Activities
  * Attacks
  * Code Snippets
  * Controls
  * Glossary
  * How To...
  * Java Project
  * .NET Project
  * Principles
  * Technologies
  * Threat Agents
  * Vulnerabilities

Language

  * English
  * español

Tools

  * What links here
  * Related changes
  * Special pages
  * Printable version
  * Permanent link
  * Page information

  * This page was last modified on 9 July 2014, at 21:56.
  * This page has been accessed 146,325 times.
  * Content is available under a Creative Commons 3.0 License unless otherwise noted.

  * Privacy policy
  * About OWASP
  * Disclaimers

  * a Creative Commons 3.0 License
  * Powered by MediaWiki Powered by Rackspace Managed Cloud

#+end_example
** Tool to check website SSL
https://www.ssllabs.com/ssltest/analyze.html?d=app.fluigidentity.com&latest
http://www.networking4all.com/en/support/tools/site+check/report/?fqdn=app.customerfi.com&protocol=https
https://snitch.io
** linux OS security patches
https://access.redhat.com/security/updates/active/

https://www.debian.org/security/
* [Public Cloud] Experience to Operate VMs in digitalocean/AWS
** After spin an VM, pay attention to this:
- configure sshd to disallow username/password login
- configure iptables to avoid malicious access
- keep consistent for the naming of VM
** DDoS attack
* [Metric] Collect what info to provide feedback for developers
** DELEGATE JIRA 6676: RMI service of app02 is opening many strange file handler
  CLOSED: [2015-01-22 Thu 00:47]
https://totvslab.atlassian.net/browse/CLOUDPASS-6676
* [Go green] Capacity measurement and planning
** Capacity planning: Fluig OpenStack Cluster
#+BEGIN_EXAMPLE
Skip to content
Skip to breadcrumbs
Skip to header menu
Skip to action menu
Skip to quick search
Linked Applications
Confluence
Spaces
People
 Create
Quick Search
0


TechOps
Configure
 Edit  Watch  Share
Pages  TechOps Home  Misc DevOps Projects
Skip to end of banner
Go to start of banner
Fluig OpenStack Cluster
Skip to end of metadata
Created by Denny Zhang, last modified on Jul 16, 2014 Go to start of metadata
We leverage OpenStack to:
In-house simulated env for product env
Perform various tests for QA and staging cycle
OpenStack Resource Caculation:
Ideally we need enough resource to replicate 1.5 scale of the production env.
1. Deploy an env looks almost the same as production env.
2. Rest of the resource can be used to create on-demand testbeds flexibly.
Detail info about our production env can be found here: Prod Envs and Critical Envs of Identity
To sum up, it's about 14 VMs, 93 cores, 188G memory, 2610G disk.
      So the totally resource we need is to:
 Support launching 21 vms,  139 cores, 282G memory, 3915G disk
OpenStack itself need some hardware resource.
Draft estimation for this: consider each hardware server runs as an openstack computing node.
Each server shall reserve: 4 cores, 4G memory, 50G disk.
Hence for 3 hardware servers, we need reserve below resource just for openstack itself, not counting resource for VMs:
  12 cores, 12G memory, 150G disks.

    As a conclusion, we shall need to support:
        21 VMs, 151 cores(VM cores, not hardware cores), 294G memory, 4065G disk.
        Note: VM cores are different from hardware cpu cores. Say we have a hardware with 4 cores, which may run 8 VM each have 2 cores.

Questions:
Do we need to support taking snapshot for VMs?
LikeBe the first to like this
No labels Edit Labels
3 Comments
 User icon: Denny
Denny Zhang
Here is one live OpenStack Clusters:
       We can use this information as a reference, when we are doing hardware resource planning for our Openstack.
       There're 2 hardware servers(Dell T620). Each has 24 cores, 48G memory, 2T disk.
      Currently it runs 10 VMs, 24 cores, 40G memory, 300G disk.
ReplyEditDeleteLikeJul 16, 2014
 User icon: john.kaplan
John Kaplan
Do we own this hardware now, or is this just the spec?
ReplyDeleteLikeJul 24, 2014
 User icon: Denny
Denny Zhang
not yet.
ReplyEditDeleteLikeJul 24, 2014
User icon: Denny
Write a comment…
Powered by Atlassian | Terms of Use | Answers | Maintenance Schedule
#+END_EXAMPLE
** TODO [#B] Lack of capacity planning and capacity monitoring.
* HA -- Single Point Of failure
** Upload image from webserver: need shared storage
NFS server may work, but:
1. once nfs server is slow of unreachable, CPU load would be extremely high
2. Still single point of failure in NFS server
** TODO [#A] a dedicate server for standup: for quickly replacement of an existing machine
** TODO [#A] setup up apache load balancer module                 :IMPORTANT:
configure apache load balancer to distribute /adsync load into two servers running inside the machine with different ports
#+begin_example
[7/23/14, 14:25:21] kungchaowang: Bill, can you help verify if our Brazil IT team can do any of these two things?
(1) see if there is a setting to expire user's session to server table in load balancer in like 30 minutes.
(2) see if we can have path matching while doing load balancing, so we can have them not sticky session /adsync for load balancing.
[7/23/14, 14:25:28] kungchaowang: Shivang, I see what you say
[7/23/14, 14:25:45] kungchaowang: but that means we again have a single point of failure if that server does not work
[7/23/14, 14:25:46] Shivang: but it will only work perfectly AFTER we are done with all commands refractoring
[7/23/14, 14:25:52] Shivang: no .. not true
[7/23/14, 14:25:56] Shivang: we can have multiple servers
[7/23/14, 14:26:41] kungchaowang: yes, I mean the one that handle the distribution, which is apache server
[7/23/14, 14:26:52] Shivang: but we can have multiples of that too
[7/23/14, 14:26:58] Shivang: basically we have 2 app servers
[7/23/14, 14:27:03] Shivang: and on both app servers we have
[7/23/14, 14:27:07] Shivang: 2 adsync servers each
[7/23/14, 14:27:09] Shivang: that's 4 of thedm
[7/23/14, 14:27:10] Shivang: them(
[7/23/14, 14:27:12] Shivang: them*
[7/23/14, 14:28:22] kungchaowang: we can give it a try and see if that would work.

Bill and Denny, do you have any experience on setting up apache load balancer module?
[7/23/14, 14:29:28] Shivang: we want round robin on those .. which basically means ..
[7/23/14, 14:29:38] Shivang: on app01.1 at t=0
[7/23/14, 14:29:43] Shivang: and app01.2 at t=1
[7/23/14, 14:29:45] Bill Nguyen: i don't, i am thinking about other balancers without using sticky session
[7/23/14, 14:29:56] Shivang: remember .. we do need sticky session
[7/23/14, 14:29:58] Shivang: for our users
[7/23/14, 14:30:00] Shivang: no matter what
[7/23/14, 14:30:13] Bill Nguyen: not for adsync right?
[7/23/14, 14:30:21] Shivang: specific to adsync .. no
[7/23/14, 14:30:42] Bill Nguyen: we can route any traffic any way you want?
[7/23/14, 14:30:42] Shivang: if we can turn off for adsync only .. that's even better
[7/23/14, 14:30:55] Bill Nguyen: yes
[7/23/14, 14:30:56] Shivang: can we? i thought load balancer is not allowing you to
[7/23/14, 14:31:05] Bill Nguyen: that is what I am thinking
[7/23/14, 14:31:09] Shivang: have balancing with and without sticky session together
[7/23/14, 14:31:25] Shivang: oh .. ok .. i thought our LB doesn't allow that feature
[7/23/14, 14:31:45] Bill Nguyen: that is what i am checking with the network team right now
#+end_example
* [VM] Private Cloud: Virtualbox & Docker & OpenStack nova
** TODO virtualbox: VM specify the ip address
http://serverfault.com/questions/161642/how-to-set-a-fixed-ip-address-for-a-virtualbox-machine-using-nat-interface
** DONE [#A] Use virtualbox for VM test automation: test kitchen  :IMPORTANT:
   CLOSED: [2015-03-18 Wed 18:59]
#+begin_example
Another JIRA ticket: automate the different tests of chef cookbook.

Currently, we have tens of cookbooks with different deployment version.
Right now, I'm doing the test of cookbooks combination manually.

It's better be automated.
#+end_example
* #  --8<-------------------------- separator ------------------------>8--
* [#A] Find new opportunites of DevOps
Caicty
tomcast
steligent
** [#A] Technical Recruiter
| Name                                 | Summary            | Link                                                                                                                                                                                                                                                                            |
|--------------------------------------+--------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Heinz Bartesch <heinz@pcninc.com>    | Canifornia         |                                                                                                                                                                                                                                                                                 |
| Jagruti Chopra <jchopra@incxo.com>   | DataXu             |                                                                                                                                                                                                                                                                                 |
| Anne Haley <anne@hubrecruiting.com>  | DataXu             |                                                                                                                                                                                                                                                                                 |
|--------------------------------------+--------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Caity Burton                         |                    | https://www.linkedin.com/profile/view?id=143423421&trk=send_invitation_success_message_name&goback=%2Emid_I5971450195026673666*4500_*1_*1_*1%2Enpv_143423421_*1_*1_name_E1dW_*1_*1_*1_*2_*1_*1_*1_*1_*1_*1_*1_*1_*1_*1_*1_*1_*1_*1_*1_*1_*1_*1_*1_*1_*1_*1_*1_*1_*1_*1_*1_*1_*1 |
| Mark <mark.colp@curatepartners.com>  | Curate Partners    |                                                                                                                                                                                                                                                                                 |
|--------------------------------------+--------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| David Callahan <david@colaberry.com> | colaberry          | Opportunity at Silverail, 617-710-0115                                                                                                                                                                                                                                                      |
| James Lewis                          | colaberry, Founder | +1-617-955-0805                                                                                                                                                                                                                                                                 |
** message template
Hi Remy

I came across the opportunity you posted in linkedin.
https://www.linkedin.com/jobs2/view/14975160?trk=vsrp_jobs_res_name&trkInfo=VSRPsearchId%3A820397671423701371115%2CVSRPtargetId%3A14975160%2CVSRPcmpt%3Aprimary

It looks very nice to me. Is it a position of DevOps + Remote + Contract/Consultant?

#  --8<-------------------------- separator ------------------------>8--
Since I'd like stay close with my family, it would be nice to be: DevOps + Remote + Contract/Consultant.

If this one doesn't fit, please let me know if you have suitable ones
now or later.

My latest CV can be found in below
https://github.com/DennyZhang/Denny_CV/blob/master/denny_devops.pdf
** applied
   https://www.linkedin.com/jobs2/view/33929519?trk=ss_email&midToken=AQEPtUUJ_I5d_Q
   DevOps Engineer&#47;Developer &#40;remote position&#41; at Digium in CAN WORK REMOTELY - Job | LinkedIn

https://www.linkedin.com/jobs2/view/32024483?trk=vsrp_jobs_res_name&trkInfo=VSRPsearchId%3A820397671425012015595%2CVSRPtargetId%3A32024483%2CVSRPcmpt%3Aprimary
REMOTE DevOps Engineer
AccruePartners - USA

https://www.linkedin.com/jobs2/view/32008418?trk=vsrp_jobs_res_name&trkInfo=VSRPsearchId%3A820397671425012286804%2CVSRPtargetId%3A32008418%2CVSRPcmpt%3Aprimary
Senior Devops Automation Engineer - WORK REMOTE!
CyberCoders - Reston, VA
*** TODO mail: Message replied: RE: Hello!                         :noexport:
[[gnus:SNS#1915381872.7498996.1425665643577.JavaMail.app@lva1-app8913.prod][Email from Jagruthi Chopra (Fri, 6 Mar 2015 18:14:03 +0000 (UTC)): Message replied: RE: Hello!]]
#+begin_example
From: Jagruthi Chopra <hit-reply@linkedin.com>
Subject: Message replied: RE: Hello!
To: Denny Zhang <denny.zhang001@gmail.com>
Date: Fri, 06 Mar 2015 12:14:03 -0600
Reply-To: Jagruthi Chopra <787fa95f-093e-4188-b8fa-ec4845d92488@reply.linkedin.com>

               LinkedIn                                                                            

                  InMail: You have a new message                                                   

                  Date: 3/06/2015                                                                  
                  Subject: RE: Hello!                                                              
                                                                                                   
                  Hello Denny,                                                                     
                                                                                                   
                  This is not a remote opportunity though. It's a very cool                        
                  company to work at. The contract duration would be about 6                       
                  months and you can always work from Boston on your remote                        
                  jobs. Please let me know if that is feasible.                                    
                                                                                                   
                  Jagruthi                                                                         
                                                                                                   
                  >On Mar 06/2015 1:00PM, Denny Zhang wrote:                                       
                  >Hi Jagruthi                                                                     
                  >                                                                                
                  > That's nice. I'm quite interested.                                             
                  > You can contact me by email (denny.zhang001@gmail.com) or                      
                  by phone(+1-832-312-4346).                                                       
                  >                                                                                
                  > Regards,                                                                       
                  > Denny                                                                          
                  >                                                                                
                  > On 3/6/15 5:54 PM, Jagruthi Chopra wrote:                                      
                  > --------------------                                                           
                  > Hello Denny,                                                                   
                  >                                                                                
                  > Impressive background! Wanted to touch base and find out if                    
                  you'd be interested in exploring new opportunities at this                       
                  point. I have an opening for the position of a Senior Systems                    
                  Engineer - DevOps (contract) with one of our leading clients,                    
                  a cool Ad/tech company in the Boston Area for which your                         
                  background looks a perfect it. Please let me know your                           
                  thoughts about it, would love to talk with you!                                  
                  >                                                                                
                  > My Best,                                                                       
                  >                                                                                
                  > Jagruti                                                                        
                                                                                                   
                    View Message                                                                   

               You are receiving InMail/Open Profile notifications emails.                         
               Unsubscribe                                                                         
               This email was intended for Denny Zhang (DevOps Consultant at TOTVS                 
               Labs, Mountain View, CA). Learn why we included this.                               
               If you need assistance or have questions, please contact LinkedIn                   
               Customer Service.                                                                   
                                                                                                   
               © 2015, LinkedIn Corporation. 2029 Stierlin Ct. Mountain View, CA                 
               94043, USA                                                                          
                                                                                                   
[1cueaf-i6x]

#+end_example
**** #  --8<-------------------------- separator ------------------------>8--
** failed
https://www.linkedin.com/jobs2/view/44447573?trk=vsrp_jobs_res_name&trkInfo=VSRPsearchId%3A820397671423701371115%2CVSRPtargetId%3A44447573%2CVSRPcmpt%3Aprimary
[Honquest Fine Furnishings] Public Cloud Consultant
Request Technology-Robyn Honquest - Houston, TX, US

https://www.linkedin.com/jobs2/view/14975160?trk=vsrp_jobs_res_name&trkInfo=VSRPsearchId%3A820397671423701371115%2CVSRPtargetId%3A14975160%2CVSRPcmpt%3Aprimary
[] DevOps Engineer - AWS, Chef/Puppet - San Francisco, CA
CyberCoders - San Francisco, CA

https://www.linkedin.com/jobs2/view/28634567?trk=vsrp_jobs_res_name&trkInfo=VSRPsearchId%3A820397671423701994856%2CVSRPtargetId%3A28634567%2CVSRPcmpt%3Aprimary
[FILD] Senior DevOps Engineer – AWS – Voted one of the Fastest Growing Companies
FILD - Austin, TX

https://www.linkedin.com/jobs2/view/29973760?trk=vsrp_jobs_res_name&trkInfo=VSRPsearchId%3A820397671423701994856%2CVSRPtargetId%3A29973760%2CVSRPcmpt%3Aprimary
[TrueTandem] Sr. Systems Engineer- DevOps
TrueTandem - Washington D.C. Metro Area

https://www.linkedin.com/jobs2/view/29955154?trk=vsrp_jobs_res_name&trkInfo=VSRPsearchId%3A820397671423701994856%2CVSRPtargetId%3A29955154%2CVSRPcmpt%3Aprimary
[Technical Connections Inc] Senior DevOps Engineer
Technical Connections Inc. - West LA

https://www.linkedin.com/jobs2/view/29980305?trk=vsrp_jobs_res_name&trkInfo=VSRPsearchId%3A820397671423701994856%2CVSRPtargetId%3A29980305%2CVSRPcmpt%3Aprimary
[] DevOps Engineer (Downtown Boston)
Jobspring Partners - Boston MA

https://www.linkedin.com/jobs2/view/13703398?trk=vsrp_jobs_res_name&trkInfo=VSRPsearchId%3A820397671423701994856%2CVSRPtargetId%3A13703398%2CVSRPcmpt%3Aprimary
[Peak Hosting] DevOps Software Engineer
Peak Hosting - Tualatin, OR

https://www.linkedin.com/jobs2/view/29480156?trk=vsrp_jobs_res_name&trkInfo=VSRPsearchId%3A820397671423701371115%2CVSRPtargetId%3A29480156%2CVSRPcmpt%3Aprimary
DevOps Engineer - Linux, Puppet, Chef - Manhattan!
CyberCoders - New York City, NY

https://www.linkedin.com/jobs2/view/27469536?trk=vsrp_jobs_res_name&trkInfo=VSRPsearchId%3A820397671423701371115%2CVSRPtargetId%3A27469536%2CVSRPcmpt%3Aprimary
[]Senior DevOps Engineer - Chef, Puppet, Docker
CyberCoders - San Francisco, CA

https://www.ziprecruiter.com/jobs/confidential-26714f3a/devops-automation-engineer-100-remote-work-great-pay-b8d7f662?source=email-candidate-job-alert&_zat=VOCsF38AAAEAAGSgfcsAAAAB
DevOps Automation Engineer - 100% Remote Work - Great Pay
 Confidential  San Francisco, CA
** TODO mail: RE: Boston DevOps Contract opportunity               :noexport:
[[gnus:mail.misc#42e901c8a9f3df2e26ce053027080782@mail.gmail.com][Email from Jagruti Chopra (Fri, 6 Mar 2015 14:35:25 -0500): RE: Boston DevOps Contract opp]]
#+begin_example
From: Jagruti Chopra <jchopra@hubrecruiting.com>
Subject: RE: Boston DevOps Contract opportunity
To: Denny Zhang <filebat.mark@gmail.com>
Date: Fri, 06 Mar 2015 13:35:25 -0600
X-Mailer: Microsoft Outlook 14.0

Sure, That works!

Can I get a copy of your resume sent to this email in a word format if
possible.

-----Original Message-----
From: Denny Zhang [mailto:filebat.mark@gmail.com]
Sent: Friday, March 6, 2015 2:33 PM
To: Jagruti Chopra
Subject: Re: Boston DevOps Contract opportunity

Hi Jagruti

How about tomorrow morning?

Let's keep it simply as normal on-site contract. No need to mention about
the remote wish to the account manager.

Do they accept corp-to-corp contract?

--
Denny Zhang(张巍)

The questions you ask determine the quality of your life.

  /\ /\
   ( )
 .( o ).

Fri, 6 Mar 2015 14:27:03 -0500 Jagruti Chopra <jchopra@hubrecruiting.com>
writes:

> Sure, will let Anne know about it. I suggest we submit your resume
> after Anne talks with you and then after 2 months or so once you warm
> up to the company and share that rapport you could propose that, if
> you want us to mention this before the interview then we can do that as
> well.
>
> Also this is a very urgent requirement and we hope to close it soon.
> Please let me know if we can schedule the call sooner. Tonight or
> tomorrow morning sometime?
>
> Best,
>
> Jagruthi
> -----Original Message-----
> From: Denny Zhang [mailto:filebat.mark@gmail.com]
> Sent: Friday, March 6, 2015 2:22 PM
> To: Jagruti Chopra
> Subject: Boston DevOps Contract opportunity
>
> Hi Jagruti
>
> Would you please help to schedule the call at mornings next week?
>
> As you said, it's a 6 months contract of DevOps in Boston with onsite
> required.
>
> To your knowledge, would it be possible that I stay onsite for the
> first one or two months, while working remotely from time to time?
>
> I understand the inconvenience, which I will surely make up with my
> expertise.
>
> --
> Denny Zhang(张巍)
>
> Most of what we learn, we learn indirectly
>
>  ~\(≧▽≦)/~
>
> Fri, 6 Mar 2015 13:39:01 -0500 Jagruti Chopra
> <jchopra@hubrecruiting.com>
> writes:
>
>> Hello Denny,
>>
>> I was a little confused with the location, Are you in Hoston, Texas
>> or Boston?
>>
>> I’d like to schedule a phone call between my account manager Anne
>> Haley and you if you are available for that. Please let me know.
>>
>> Thanks,
>>
>>
>>
>> Jagruthi Chopra
>>
>> Talent Acquisition Specialist
>> Hub Recruiting
>>
>> 18 Main Street
>>
>> Concord, MA 01742
>>
>> 978-394-7873 (cell)
>>
>> jchopra@hubrecruiting.com
>>
>> www.hubrecruiting.com
>>
>>

#+end_example
** MIT DevOps
*** mail: Re: Hello from Denny, DevOps Consultant             :noexport:
[[gnus:nnfolder%2Barchive:mail.sent.mail#m2bni42wic.fsf@gmail.com][Email from Denny Zhang (Fri, 01 May 2015 09:38:35 -0500): Re: Hello from Denny, DevOps C]]
#+begin_example
From: Denny Zhang <filebat.mark@gmail.com>
Subject: Re: Hello from Denny, DevOps Consultant
To: Mark Colp <mark.colp@curatepartners.com>
Date: Fri, 01 May 2015 09:38:35 -0500
User-Agent: Gnus/5.13 (Gnus v5.13) Emacs/24.4 (darwin)

Mark

The MIT DevOps positions look nice to me.

If I have to say, maybe we can start from:
- DevOps Engineer (Cloud Platforms IaaS) ­ 1 open role
- DevOps Engineer (Cloud Platforms - Automation)

-- 
Denny Zhang(张巍)

Enjoy learning for nothing.

(⊙_⊙)

Fri, 1 May 2015 14:26:33 +0000 Mark Colp <mark.colp@curatepartners.com>
writes:

> Hi Denny,
>
> Great speaking to you as well!  Please see the descriptions below for the
> MIT jobs we spoke of‹if these don¹t necessarily peak your interest, we can
> look into some other things as we have a bit of time given your travel
> arrangements.
>
> Let me know what you think next week.
>
>
> Openings:
> DevOps Engineer (Cloud Platforms)
> DevOps Engineer (Cloud Platforms IaaS)
> DevOps Engineer (Cloud Platforms ­ Automation)
> DevOps Engineer (Cloud Platforms ­StaaS)
> DevOps Engineer (Business Systems)
> DevOps Engineer (Integration ­ Emerging)
> (2) DevOps Engineer (Integration ­ Enabling)
> (2) DevOps Engineer (Operations)
>
>
> Full descriptions below:
>
> DevOps Engineer (Cloud Platforms) ­ 1 open role
> DevOps Engineers work closely with clients and IT Team members to
> understand the departmental stakeholder requirements that drive the
> analysis and design of quality technical solutions. They are responsible
> for the design and implementation of applications¹ build, release,
> deployment, and configuration activities. Other responsibilities include,
> but are not limited to, working with internal business partners to gather
> requirements, prototyping, architecting, implementing/updating solution,
> build and executing test plans, performing quality reviews, managing
> operations, and triaging ad fixing operational issues.
> DevOps Engineers require the ability to interact, develop, engineer, and
> communicate collaboratively at the highest technical levels with clients,
> vendors, partners, and all levels of MIT staff.
> Essential Functions:
>
> * Create and distribute development estimates and operational requirements
> to enable accurate planning with realistic timelines.
> * Assess client needs utilizing a structured requirements process
> (gathering, analyzing, documenting, and managing changes).
> * Write and communicate business requirements and functional
> specifications for the implementation of client solutions.
> * Analyze client operations to uncover opportunities for improvements.
> * Work closely with architects to assure all systems are in line with
> IS&T¹s long-term strategy.
> * Translate business and technical requirements into test cases, test
> scenarios, and scripts.
> * Develop and/or implement reusable components.
> * Code and document custom test automation frameworks.
> * Maintain new and existing object reference files.
> * Build automated deployments using configuration management technology.
> * Work with Release Management to ensure modules are production-ready.
> * Assist in establishing requirements, methods, and procedures for routine
> maintenance.
> * Evaluate existing applications and platforms and provide recommendations
> for improving performance by conducting gap analysis, identifying feasible
> alternative solutions, and assisting in the scope of modifications.
> * Participation in an on-call rotation.
>
> Qualifications & Technical Skills:
>
> * Bachelor¹s or Master¹s Degree in Programming/Systems or Computer Science
> or other related field or equivalent work experience.
> * Typically requires three to five years of scripting experience.
> * Experience working in applications, systems, or IT operations.
> * Knowledge of an agile team environment and process.
> * Excellent troubleshooting and problem solving skills.
> * Requires working knowledge of two or more programming languages; Python,
> Perl, or Ruby preferred.
> * Comfort with frequent, incremental code, testing, and deployment.
> * Experience developing in a modern web framework (e.g., Django) a plus.
>
> Location: Cambridge, MA
>  **********************************************************************
> DevOps Engineer (Cloud Platforms IaaS) ­ 1 open role
> DevOps Engineers work closely with clients and IT Team members to
> understand the departmental stakeholder requirements that drive the
> analysis and design of quality technical solutions. They are responsible
> for the design and implementation of applications¹ build, release,
> deployment, and configuration activities. Other responsibilities include,
> but are not limited to, working with internal business partners to gather
> requirements, prototyping, architecting, implementing/updating solution,
> build and executing test plans, performing quality reviews, managing
> operations, and triaging ad fixing operational issues.
> DevOps Engineers require the ability to interact, develop, engineer, and
> communicate collaboratively at the highest technical levels with clients,
> vendors, partners, and all levels of MIT staff.
> Essential Functions:
>
> * Collaborate with project managers to prioritize development of
> capabilities.
> * Contribute to strategic planning meetings and provides guidance and
> expertise on system options, risk, cost vs. benefits, and impacts on
> departmental processes and goals.
> * Coordinate communication and activities between technical teams.
> * Assess client needs utilizing a structured requirements process
> (gathering, analyzing, documenting, and managing changes).
> * Lead development and communicate business requirements and functional
> specifications for the design and implementation of client solutions.
> * Analyze client operations to uncover opportunities for improvements.
> * Work closely with architects to assure all systems are in line with
> IS&T¹s long-term strategy.
> * Review and advise on technical design specifications developed by junior
> DevOps Engineers.
> * Develop custom integration solutions including major enhancements,
> interfaces, functions, and features.
> * Develop and/or implement reusable components.
> * Setup and maintain the test environments for both manual and automated
> testing.
> * Assist in defining DevOps and quality guidelines and standards.
> * Build automated deployments using configuration management technology.
> * Work with Release Management to ensure modules are production-ready.
> * Assist in establishing requirements, methods, and procedures for routine
> maintenance.
> * Evaluate existing applications and platforms and provide recommendations
> for improving performance by conducting gap analysis, identifying feasible
> alternative solutions, and assisting in the scope of modifications.
> * Participation in an on-call rotation.
>
> Qualifications & Technical Skills:
>
> * Bachelor¹s  or Master¹s Degree, preferably in Computer Science
> * Typically requires seven or more years of analysis and scripting
> experience.
> * Experience working in applications, systems, or IT operations.
> * In-depth knowledge of a broad range of hardware and software products.
> * Experience leading an agile team environment.
> * Ability to analyze and interpret complex problems or processes, identify
> and understand requirements and develop alternate solutions.
> * Experience designing, developing, testing, and deploying applications/
> systems using proven or emerging technologies, in a variety of
> technologies and environments.
> * Strong grasp of automation (e.g., API.)
> * Strong expertise in Infrastructure as a Service (e.g., AWS, OpenStack,
> vCA, vCD, vCAC, CloudForms.)
> * Strong troubleshooting and problem solving skills.
> * Requires working knowledge of two or more programming languages; Python,
> Perl, or Ruby preferred.
> * Knowledge of private cloud platforms (e.g., vSphere) a plus.
> * Experience developing in modern web frameworks (e.g., Django) a plus.
>
> Location: Cambridge, MA
>  ***********************************************************************
> DevOps Engineer (Cloud Platforms - Automation)
> DevOps Engineers work closely with clients and IT Team members to
> understand the departmental stakeholder requirements that drive the
> analysis and design of quality technical solutions. They are responsible
> for the design and implementation of applications¹ build, release,
> deployment, and configuration activities. Other responsibilities include,
> but are not limited to, working with internal business partners to gather
> requirements, prototyping, architecting, implementing/updating solution,
> build and executing test plans, performing quality reviews, managing
> operations, and triaging ad fixing operational issues.
> DevOps Engineers require the ability to interact, develop, engineer, and
> communicate collaboratively at the highest technical levels with clients,
> vendors, partners, and all levels of MIT staff.
> Essential Functions:
>
> * Collaborate with project managers to prioritize development of
> capabilities.
> * Contribute to strategic planning meetings and provides guidance and
> expertise on system options, risk, cost vs. benefits, and impacts on
> departmental processes and goals.
> * Coordinate communication and activities between technical teams.
> * Assess client needs utilizing a structured requirements process
> (gathering, analyzing, documenting, and managing changes).
> * Lead development and communicate business requirements and functional
> specifications for the design and implementation of client solutions.
> * Analyze client operations to uncover opportunities for improvements.
> * Work closely with architects to assure all systems are in line with
> IS&T¹s long-term strategy.
> * Review and advise on technical design specifications developed by junior
> DevOps Engineers.
> * Develop custom integration solutions including major enhancements,
> interfaces, functions, and features.
> * Develop and/or implement reusable components.
> * Setup and maintain the test environments for both manual and automated
> testing.
> * Assist in defining DevOps and quality guidelines and standards.
> * Build automated deployments using configuration management technology.
> * Work with Release Management to ensure modules are production-ready.
> * Assist in establishing requirements, methods, and procedures for routine
> maintenance.
> * Evaluate existing applications and platforms and provide recommendations
> for improving performance by conducting gap analysis, identifying feasible
> alternative solutions, and assisting in the scope of modifications.
> * Participate in an on-call rotation
>
>  Qualifications & Technical Skills:
>
> * Bachelor¹s  or Master¹s Degree, preferably in Computer Science
> * Typically requires seven or more years of analysis and scripting
> experience.
> * Experience working in applications, systems, or IT operations.
> * In-depth knowledge of a broad range of hardware and software products.
> * Experience leading an agile team environment
> * Ability to analyze and interpret complex problems or processes, identify
> and understand requirements and develop alternate solutions.
> * Experience designing, developing, testing, and deploying applications/
> systems using proven or emerging technologies, in a variety of
> technologies and environments.
> * Strong grasp of automation tools.
> * Strong troubleshooting and problem solving skills.
> * Requires working knowledge of two or more programming languages; Python,
> Perl, or Ruby preferred.
> * Strong grasp of Linux (e.g., optimizing, securing, and troubleshooting);
> Redhat Enterprise preferred.
> * Knowledge of OpenStack a plus.
> * Knowledge of private cloud platforms (e.g., vSphere) a plus.
> * Experience developing in web frameworks (e,g., Django) a plus.
>
> Location: Cambridge, MA
>  **********************************************************************
> DevOps Engineer (Cloud Platforms - StaaS) ­ 1 open role
> DevOps Engineers work closely with clients and IT Team members to
> understand the departmental stakeholder requirements that drive the
> analysis and design of quality technical solutions. They are responsible
> for the design and implementation of applications¹ build, release,
> deployment, and configuration activities. Other responsibilities include,
> but are not limited to, working with internal business partners to gather
> requirements, prototyping, architecting, implementing/updating solution,
> build and executing test plans, performing quality reviews, managing
> operations, and triaging ad fixing operational issues.
> DevOps Engineers require the ability to interact, develop, engineer, and
> communicate collaboratively at the highest technical levels with clients,
> vendors, partners, and all levels of MIT staff.
> Essential Functions:
>
> * Collaborate with project managers to prioritize development of
> capabilities.
> * Contribute to strategic planning meetings and provides guidance and
> expertise on system options, risk, cost vs. benefits, and impacts on
> departmental processes and goals.
> * Coordinate communication and activities between technical teams.
> * Assess client needs utilizing a structured requirements process
> (gathering, analyzing, documenting, and managing changes).
> * Lead development and communicate business requirements and functional
> specifications for the design and implementation of client solutions.
> * Analyze client operations to uncover opportunities for improvements.
> * Work closely with architects to assure all systems are in line with
> IS&T¹s long-term strategy.
> * Review and advise on technical design specifications developed by junior
> DevOps Engineers.
> * Develop custom integration solutions including major enhancements,
> interfaces, functions, and features.
> * Develop and/or implement reusable components.
> * Setup and maintain the test environments for both manual and automated
> testing.
> * Assist in defining DevOps and quality guidelines and standards.
> * Build automated deployments using configuration management technology.
> * Work with Release Management to ensure modules are production-ready.
> * Assist in establishing requirements, methods, and procedures for routine
> maintenance.
> * Evaluate existing applications and platforms and provide recommendations
> for improving performance by conducting gap analysis, identifying feasible
> alternative solutions, and assisting in the scope of modifications.
> * Participate in an on-call rotation.
>
> Qualifications & Technical Skills:
>
> * Bachelor¹s  or Master¹s Degree, preferably in Computer Science
> * Typically requires seven or more years of analysis and scripting
> experience.
> * Experience working in applications, systems, or IT operations.
> * In-depth knowledge of a broad range of hardware and software products.
> * Experience leading an agile team environment
> * Ability to analyze and interpret complex problems or processes, identify
> and understand requirements and develop alternate solutions.
> * Experience designing, developing, testing, and deploying applications/
> systems using proven or emerging technologies, in a variety of
> technologies and environments.
> * Knowledge of Software Defined Storage platforms (e.g., Swift, VSAN,
> Ceph.)
> * Experience working with EMC¹s product suite (e.g., Data Domain, Isilon,
> VMAX, VPLEX, VNX, XtremeIO.)
> * Strong grasp of automation tools.
> * Strong troubleshooting and problem solving skills.
> * Requires working knowledge of two or more programming languages; Python,
> Perl, or Ruby preferred.
> * Knowledge of modern configuration management software (e.g., Puppet) a
> plus.
> * Knowledge of OpenStack a plus.
>
> Location: Cambridge, MA
>  
> **********************************************************************
> DevOps Engineer (Business Systems) ­ 1 open role
>
> DevOps Engineers work closely with clients and IT team members to
> understand the departmental stakeholder requirements that drive the
> analysis and design of quality technical solutions.  They are responsible
> for the design and implementation of applications¹ build, release,
> deployment, and configuration activities.  Other responsibilities include,
> but are not limited to, working with internal business partners to gather
> requirements, prototyping, architecting, implementing/updating solution,
> build and executing test plans, performing quality reviews, managing
> operations, and triaging ad fixing operational issues.
>
> DevOps Engineers require the ability to interact, develop, engineer and
> communicate collaboratively at the highest technical levels with clients,
> vendors, partners, and all levels of MIT staff.
>
> Essential Functions:
> ·        Develop custom integration solutions including major
> enhancements, interfaces, functions, and features.
> ·        Build automated deployments using configuration management
> technology.
> ·        Work with Release Management to ensure modules are
> production-ready.
> ·        Collaborate with project managers to prioritize development of
> capabilities.
> ·        Contribute to strategic planning meetings and provides guidance
> and expertise on system options, risk, cost vs benefits, and impacts on
> departmental processes and goals
> ·        Lead development and communicate business requirements and
> functional specifications for the design and implementation of client
> solutions.
> ·        Work closely with architects to assure all systems are in line
> with IS&T¹s long-term strategy.
> ·        Develop and/or implement reusable components.
> ·        Assist in defining DevOps and quality guidelines and standards.
> ·        Evaluate existing applications and platforms and provide
> recommendations for improving performance by conducting gap analysis,
> identifying feasible  alternative solutions, and assisting   in the scope
> of modifications.
>
> Qualifications & Technical Skills:
>  
> ·        Typically requires 7 or more years of analysis and programming
> experience
> ·        Experience working in applications, systems or IT operations.
> ·        In-depth knowledge of a broad range of hardware and software
> products.
> ·        Experience leading an agile team environment.
> ·        Ability to analyze and interpret complex problems or processes,
> identify  and understand requirements and develop alternate solutions.
> ·        Experience designing, developing, testing and deploying
> applications/systems using proven or emerging
> ·        Experience with development in two or more of C/C++, Java,
> Python, PHP or Ruby.
> ·        Experience with front-end web development using HTML, CSS and
> JavaScript
> ·        Experience designing, developing and supporting RESTful web API¹s.
> ·        Experience supporting and making use of SOAP based API¹s.
> ·        Working understanding of HTTP, HTTPS and SSL protocols.
> ·        Experience with distributed version control and social coding
> platforms, i.e. GitHub.
> ·        Experience supporting an SAP ERP environment including custom
> ABAP development and third-party and custom integrations with SAP
> solutions.
> ·        Experience developing systems using Oracle, Microsoft SQL Server,
> or MySQL relation database backends, including use of stored procedures;
> exposure to development making use of NoSQL database backends a plus.
> ·        Experience integrating both on-premises and software-as-a-service
> (SaaS) commercial solutions with enterprise identity and directory
> services, i.e. Active Directory, SAML.
> ·        Strong troubleshooting and problem solving skills as well as
> communication skills.
>
>
> Location: Cambridge, MA
>
>
> ************************************************************************
>  
> DevOps Engineer (Integration-Emerging) ­ 1 open role
>  
>
> The Integration team is concerned with:
>  
> ·        Data Integration between software systems.
> ·        Providing a web API platform and related tools for the MIT
> community.
>  
> The team belongs to a larger Emerging Solutions group which is focused on
> innovation.  Multiple technologies are in play, but particularly useful is
> experience with Java, Spring and MuleSofts Anypoint and Cloudhub platforms.
>
> DevOps Engineers work closely with clients and IT team members to
> understand the departmental stakeholder requirements that drive the
> analysis and design of quality technical solutions for system integrations
> and web API¹s.  They are responsible  for the design and implementation of
> applications¹ build, release, deployment, and configuration activities.
> Other responsibilities include, but are not limited to, working with
> internal business partners to gather requirements, prototyping,
> architecting, implementing/updating solution, build and executing test
> plans, performing quality reviews, managing operations, and triaging ad
> fixing operational issues.
>
> DevOps Engineers require the ability to interact, develop, engineer, and
> communicate collaboratively at the highest technical levels with clients,
> vendors, partners and all levels of MIT staff.
>  
> Essential Functions:
> ·        Create and distribute development estimates and operational
> requirements to enable accurate planning with realistic timelines.
> ·        Assess client needs utilizing an Agile requirements process
> (gathering, analyzing, documenting and managing changes).
> ·        Write and communicate business requirements and functional
> specifications for the implementation of client solutions.
> ·        Analyze client operations to uncover opportunities for
> improvements.
> ·        Work closely with architects to assure all systems are in line
> with IS&T¹s long-term strategy.
> ·        Translate business and technical requirements into test cases,
> test scenarios and scripts.
> ·        Build automated deployments using configuration management
> technology.
> ·        Work with release management to ensure modules are
> production-ready.
> ·        Evaluate existing applications and platforms and provide
> recommendations for improving performance by conducting gap analysis,
> identifying feasible  alternative solutions, and assisting in the scope of
> modifications.
>  
> Qualifications & Technical Skills:
> ·        Typically requires 3-5 years of programming experience
> ·        Experience working in applications, systems or IT operations.
> ·        Experience with Java, Spring and MuleSofts Anypoint and
> Cloudplatforms.
> ·        Knowledge of an agile team environment and process
> ·        Excellent troubleshooting and problem solving skills.
> ·        Requires working knowledge of two or more programming languages.
> ·        Comfort with frequent, incremental code, testing and deployment.
>
>
> Location: Cambridge, MA
> **********************************************************************
> DevOps Engineer (Integration-Enabling) ­ 2 open roles
>  
> DevOps Engineers work closely with clients and IT Team members to
> understand the departmental stakeholder requirements that drive the
> analysis and design of quality technical solutions. They are responsible
> for the design and implementation of applications¹ build, release,
> deployment, and configuration activities. Other responsibilities include,
> but are not limited to, working with internal business partners to gather
> requirements, prototyping, architecting, implementing/updating solution,
> build and executing test plans, performing quality reviews, managing
> operations, and triaging ad fixing operational issues.
>  
> DevOps Engineers require the ability to interact, develop, engineer, and
> communicate collaboratively at the highest technical levels with clients,
> vendors, partners, and all levels of MIT staff.
> Essential Functions:
>
> * Develop custom integration solutions including major enhancements,
> interfaces, functions, and features.
> * Build automated deployments using configuration management technology.
> * Work with Release Management to ensure modules are production-ready.
> * Collaborate with project managers to prioritize development of
> capabilities.
> * Contribute to strategic planning meetings and provides guidance and
> expertise on system options, risk, cost vs. benefits, and impacts on
> departmental processes and goals.
> * Coordinate communication and activities between technical teams.
> * Assess client needs utilizing a structured requirements process
> (gathering, analyzing, documenting, and managing changes).
> * Lead development and communicate business requirements and functional
> specifications for the design and implementation of client solutions.
> * Analyze client operations to uncover opportunities for improvements.
> * Work closely with architects to assure all systems are in line with
> IS&T¹s long-term strategy.
> * Review and advise on technical design specifications developed by junior
> DevOps Engineers.
> * Develop and/or implement reusable components.
> * Setup and maintain the test environments for both manual and automated
> testing.
> * Assist in defining DevOps and quality guidelines and standards.
> * Assist in establishing requirements, methods, and procedures for routine
> maintenance.
> * Evaluate existing applications and platforms and provide recommendations
> for improving performance by conducting gap analysis, identifying feasible
> alternative solutions, and assisting in the scope of modifications.
>
> Qualifications & Technical Skills:
>
> * Bachelor¹s or Master¹s Degree in Programming/Systems or Computer Science
> or other related field or equivalent work experience.
> * Typically requires 7 or more years of analysis and programming
> experience.
> * Experience working in applications, systems, or IT operations.
> * In-depth knowledge of a broad range of hardware and software products.
> * Experience leading an agile team environment.
> * Ability to analyze and interpret complex problems or processes, identify
> and understand requirements and develop alternate solutions.
> * Experience in web development (e.g., API development, Application
> Maintenance)
> * Experience developing in a Linux environment.
> * Experience designing, developing, testing, and deploying
> applications/systems using proven or emerging technologies, in a variety
> of technologies and environments.
> * Experience with development in two or more of Python, Java, PHP, Ruby,
> or C/C++.
> * Experience with front-end web development using HTML, CSS, and
> Javascript.
> * Experience designing, developing, and supporting RESTful web APIs.
> * Experience supporting and making use of SOAP-based APIs.
> * Experience integrating with SAML and OAuth2 authentication protocols.
> * Working understanding of HTTP, HTTPS, and SSL protocols.
> * Experience with one or more web application frameworks, i.e., Spring,
> Django, Apache Struts.
> * Experience with one or more web content management systems, i.e.,
> Drupal, WordPress, Joomla.
> * Experience automating deployment of applications using Puppet or a
> similar configuration management tool.
> * Experience with one or more relational database management systems
> (RDBMS), i.e., MySQL, Oracle.
> * Experience with distributed version control and social coding platforms,
> i.e. GitHub.
> * Strong grasp of automation tools.
> * Strong troubleshooting and problem solving skills.
> * Requires working knowledge of two or more programming languages.
>
> Location: Cambridge, MA
>  
> ************************************************************************
>  
> DevOps Engineer (Operations) ­ 2 open roles
> DevOps Engineers work closely with clients and IT Team members to
> understand the departmental stakeholder requirements that drive the
> analysis and design of quality technical solutions. They are responsible
> for the design and implementation of applications¹ build, release,
> deployment, and configuration activities. Other responsibilities include,
> but are not limited to, working with internal business partners to gather
> requirements, prototyping, architecting, implementing/updating solution,
> build and executing test plans, performing quality reviews, managing
> operations, and triaging ad fixing operational issues.
> DevOps Engineers require the ability to interact, develop, engineer, and
> communicate collaboratively at the highest technical levels with clients,
> vendors, partners, and all levels of MIT staff.
> Essential Functions:
>
> * Develop custom integration solutions including major enhancements,
> interfaces, functions, and features.
> * Build automated deployments using configuration management technology.
> * Work with Release Management to ensure modules are production-ready.
> * Collaborate with project managers to prioritize development of
> capabilities.
> * Contribute to strategic planning meetings and provides guidance and
> expertise on system options, risk, cost vs. benefits, and impacts on
> departmental processes and goals.
> * Coordinate communication and activities between technical teams.
> * Assess client needs utilizing a structured requirements process
> (gathering, analyzing, documenting, and managing changes).
> * Lead development and communicate business requirements and functional
> specifications for the design and implementation of client solutions.
> * Analyze client operations to uncover opportunities for improvements.
> * Work closely with architects to assure all systems are in line with
> IS&T¹s long-term strategy.
> * Review and advise on technical design specifications developed by junior
> DevOps Engineers.
> * Develop and/or implement reusable components.
> * Setup and maintain the test environments for both manual and automated
> testing.
> * Assist in defining DevOps and quality guidelines and standards.
> * Assist in establishing requirements, methods, and procedures for routine
> maintenance.
> * Evaluate existing applications and platforms and provide recommendations
> for improving performance by conducting gap analysis, identifying feasible
> alternative solutions, and assisting in the scope of modifications.
>
> Qualifications & Technical Skills:
>
> * Typically requires 7 or more years of analysis and programming
> experience.
> * Experience working in applications, systems, or IT operations.
> * In-depth knowledge of a broad range of hardware and software products.
> * Experience leading an agile team environment
> * Ability to analyze and interpret complex problems or processes, identify
> and understand requirements and develop alternate solutions.
> * Experience designing, developing, testing, and deploying applications/
> systems using proven or emerging technologies, in a variety of
> technologies and environments.
> * Experience with development in two or more of C/C++, Java, Python, PHP,
> or Ruby.
> * Experience with front-end web development using HTML, CSS, and
> Javascript.
> * Experience designing, developing, and supporting RESTful web APIs.
> * Experience supporting and making use of SOAP-based APIs.
> * Experience integrating with SAML and OAuth2 authentication protocols.
> * Working understanding of HTTP, HTTPS, and SSL protocols.
> * Experience automating deployment of applications using Puppet or a
> similar configuration management tool.
> * Experience with distributed version control and social coding platforms,
> i.e. GitHub.
> * Experience developing systems using Oracle, Microsoft SQL Server, or
> MySQL relation database backends, including use of stored procedures;
> exposure to development making use of NoSQL database backends a plus.
> * Experience integrating both on-premises and software-as-a-service (SaaS)
> commercial solutions with enterprise identity and directory services, i.e.
> Active Directory, SAML.
> * Experience supporting an SAP ERP environment including custom ABAP
> development and third-party and custom integrations with SAP solutions.
> * For the Operations / Application Delivery DevOps engineer, please make
> these additions to the qualifications / technical skills section:
> * Experience with development in two or more of C/C++, Java, Python, PHP,
> or Ruby.
> * Experience integrating with SAML, OAuth2, and Kerberos authentication
> protocols.
> * Working understanding of HTTP, HTTPS, and SSL protocols.
> * Experience automating deployment of applications using Puppet or a
> similar configuration management tool.
> * Experience with distributed version control and social coding platforms,
> i.e. GitHub.
> * Experience developing and deploying applications in public cloud
> platforms, both infrastructure as a service (Amazon AWS) and platform as a
> service, i.e. Heroku.
> * Experience developing, deploying, and supporting applications in a
> VMware vSphere private cloud environment.
> * Experience integrating both on-premises and software-as-a-service (SaaS)
> commercial solutions with enterprise identity and directory services, i.e.
> Active Directory, SAML.
> * Experience provisioning and supporting applications in both Linux
> (Redhat Enterprise and Ubuntu) and Windows Server environments.
> * Experience configuring, deploying, and supporting applications making
> use of Oracle, MySQL, and Microsoft SQL Server relational database
> platforms.
> * Strong troubleshooting and problem solving skills.
>
> Location: Cambridge, MA
>
>
>
>
> Mark Colp
> http://www.curatepartners.com <http://www.curatepartners.com/>
> O:617-600-4907
> C: 508-317-3654
>
> https://www.linkedin.com/in/mcolp
>
>
>
>
> On 5/1/15, 10:22 AM, "Denny Zhang" <filebat.mark@gmail.com> wrote:
>
>>Hi Mark
>>
>>It's nice talking to you this morning.
>>
>>Enclosed is my latest CV. Keep in touch.

#+end_example
* Issue list of identity prod env
** Issue: problem happen when people visit from VPN
#+BEGIN_EXAMPLE
Skip to content
Skip to breadcrumbs
Skip to header menu
Skip to action menu
Skip to quick search
Linked Applications
Confluence
Spaces
People
 Create
Quick Search
0


TechOps
Configure
 Edit  Watch  Share
Pages  TechOps Home  Issues List For Service Maintainnce
Skip to end of banner
Go to start of banner
Issue: 2014/07/11 Fluig system is not reachable, when visitors are connected to our VPN
Skip to end of metadata
Created by Denny Zhang, last modified on Jul 31, 2014 Go to start of metadata
See the list of all issues here: https://totvslab.atlassian.net/wiki/display/TECH/Issues+List+For+Service+maintainnce
Issue Summary:
The issue happened in 2014/07/11. Vicente Goetten, Fellipe Augusto da Silva, Denny Zhang, Kung Wang , Shivang Shah and some other colleagues are involved.
When visitors are connected to our vpn, fluig system is not reachable; When they are not connected to our VPN, they can visit our fluig system with no problem.
Improvement points:
Details:
[7/11/14, 14:13:33] Vicente Goetten: ok, so the problem is happening sometimes for external
[7/11/14, 14:13:36] Vicente Goetten: some times for internal users
[7/11/14, 14:13:41] Vicente Goetten: they are getting bad gateway
[7/11/14, 14:14:14] Fellipe Augusto da Silva: yeah, for me if I'm not connected to the VPN it's working fine
[7/11/14, 14:14:20] Fellipe Augusto da Silva: but if I connect I cannot access anymore

LikeBe the first to like this
No labels Edit Labels
User icon: Denny
Write a comment…
Powered by Atlassian | Terms of Use | Answers | Maintenance Schedule

#+END_EXAMPLE
** DONE Issue: NFS server issue
  CLOSED: [2015-03-06 Fri 13:25]
#+BEGIN_EXAMPLE
Skip to content
Skip to breadcrumbs
Skip to header menu
Skip to action menu
Skip to quick search
Linked Applications
Confluence
Spaces
People
 Create
Quick Search
0


TechOps
Configure
 Edit  Watch  Share
Pages  TechOps Home  Issues List For Service Maintainnce
Skip to end of banner
Go to start of banner
Issue: 2014/07/11 NFS fail to mount
Skip to end of metadata
Created by Denny Zhang, last modified on Jul 31, 2014 Go to start of metadata
See the list of all issues here: https://totvslab.atlassian.net/wiki/display/TECH/Issues+List+For+Service+maintainnce
Issue Summary:
The issue happened in 2014/07/11. Shivang Shah, Kung Wang , Vicente Goetten, Denny Zhang and some other colleagues are involved.

The main reason should be one server run out of memory.
This morning, we are already warned by an alerting email, sent from our monitoring system.
As Shivang mentioned, we have failed to pay enough attention to that.
In this case, we may also suffer some network issues. But we're not 100% sure about that.
Improvement points:
After reboot node18, its hostname is (none), which means hostname missing. It's quite strange. We may need dig more for this problem.
Fail to open https://www.fluigidentity.com. And previously if we visit  https://www.fluigidentity.com, it will redirect to https://www.fluigidentity.com/#/home . Then Kung helped to restart apache, everything works fine. But we may need watch this issue closely.

Details:
[7/11/14, 16:26:59] denny: Hi guys, I may know the problem
[7/11/14, 16:27:46] denny: Remember my first email this morning about: 172.20.16.18 run into slow memory, this morning?
It's exactly the same node for nfs server.
[7/11/14, 16:37:41] denny: ===========================================
172.20.16.18 run into out of memory, which is confirmed by /var/log/kern.log
,-----------
| Jul 11 20:09:53 fluig-id-cdn-02 kernel: [22844928.350384] [34948] 101 34948 62378 160 24 0 0 rsyslogd                                     |
| Jul 11 20:09:53 fluig-id-cdn-02 kernel: [22844928.350388] [34949] 108 34949 5387 117 16 0 0 rpc.statd                                     |
| Jul 11 20:09:53 fluig-id-cdn-02 kernel: [22844928.350391] Out of memory: Kill process 34948 (rsyslogd) score 0 or sacrifice child         |
| Jul 11 20:09:53 fluig-id-cdn-02 kernel: [22844928.351277] Killed process 34948 (rsyslogd) total-vm:249512kB, anon-rss:640kB, file-rss:0kB |
| Jul 11 20:11:55 fluig-id-cdn-02 kernel: Kernel logging (proc) stopped.                                                                    |
| Jul 11 20:14:08 (none) kernel: imklog 5.8.6, log source = /proc/kmsg started.                                                             |
`-----------
[7/11/14, 16:39:40] denny: ==============================================
More info about OOM issue in 172.20.16.18
,-----------
| root@(none):/var/log# grep -i 'out of memory' /var/log/kern.log
| grep -i 'out of memory' /var/log/kern.log
| Jul 11 18:15:25 fluig-id-cdn-02 kernel: [22838079.394271] Out of memory: Kill process 58383 (java) score 41 or sacrifice child
| Jul 11 18:16:44 fluig-id-cdn-02 kernel: [22838158.398417] Out of memory: Kill process 29305 (java) score 45 or sacrifice child
| Jul 11 18:17:51 fluig-id-cdn-02 kernel: [22838225.064817] Out of memory: Kill process 29379 (java) score 43 or sacrifice child
| Jul 11 18:33:51 fluig-id-cdn-02 kernel: [22839183.102701] Out of memory: Kill process 25599 (java) score 40 or sacrifice child
| ...
| ...
| ...
| Jul 11 19:55:32 fluig-id-cdn-02 kernel: [22844070.698439] Out of memory: Kill process 11889 (java) score 0 or sacrifice child
| Jul 11 19:56:25 fluig-id-cdn-02 kernel: [22844123.769331] Out of memory: Kill process 33975 (rsyslogd) score 0 or sacrifice child
| Jul 11 20:09:05 fluig-id-cdn-02 kernel: [22844883.103653] Out of memory: Kill process 34009 (rsyslogd) score 0 or sacrifice child
| Jul 11 20:09:15 fluig-id-cdn-02 kernel: [22844893.895508] Out of memory: Kill process 33973 (rpc.statd) score 0 or sacrifice child
| Jul 11 20:09:15 fluig-id-cdn-02 kernel: [22844893.941378] Out of memory: Kill process 34934 (rsyslogd) score 0 or sacrifice child
| Jul 11 20:09:53 fluig-id-cdn-02 kernel: [22844928.350391] Out of memory: Kill process 34948 (rsyslogd) score 0 or sacrifice child
`-----------
[7/11/14, 16:40:27] Shivang: so basically .18 went out of memroy?
[7/11/14, 16:40:35] kungchaowang: do you think we should upgrade that server?
[7/11/14, 16:41:09] kungchaowang: denny?
[7/11/14, 16:41:12] kungchaowang: what do you think?
[7/11/14, 16:42:00] denny: Frankly speaking
[7/11/14, 16:42:49] kungchaowang: yes, frankly speaking please
[7/11/14, 16:43:52] denny: The hardware resource should be enough, though upgrade it would be better.
The problem shall lie in jenkins stuff, at my first glance. 27 processes of VABuildScript.jar, should be invoked by jenkins somehow.
[7/11/14, 16:44:28] kungchaowang: where, which machine you see VABuildScript.jar running?
[7/11/14, 16:44:55] denny: 18
https://totvslab.atlassian.net/wiki/pages/viewpage.action?pageId=36667740
[7/11/14, 16:46:39] kungchaowang: good observation Denny.
[7/11/14, 16:46:52] kungchaowang: how can we stop this from happening? do you have any insight?
[7/11/14, 16:47:52] denny: I need to check about our jenkins in detail.
It shall take some time.
If we can quickly upgrade the memory of VM, it should be fine. But technically speaking, it's not a must.
[7/11/14, 16:48:18] kungchaowang: let's work on fixing it
[7/11/14, 16:48:30] kungchaowang: first, we stop this script from running
[7/11/14, 16:48:38] kungchaowang: then we fix the script before we run it again
[7/11/14, 16:48:56] denny: Yes, sir.
[7/11/14, 16:49:29] kungchaowang: does that sound like a good start? if you guys also think yes, then let's do it
[7/11/14, 16:49:50] Shivang: lets just debug .. very quick .. to see why it was being called
[7/11/14, 16:49:53] Shivang: and just STOP it for now
[7/11/14, 16:50:00] Shivang: no one is really using VApp at this momemnt anyways
[7/11/14, 16:50:28] kungchaowang: ok, seems all of us agree to just stop it first, then let's stop it, and have Denny to look into how it run and fix it
Summary Email from Vicente:
Vicente Goetten
To:  Marcelo Eduardo Sant'Anna Cosentino‎; Marilia Rocca‎; Fernando Faustino
Cc:  Kung Wang‎; Shivang Shah‎; Denny Zhang‎; Bill Nguyen
Friday, July 11, 2014 5:08 PM

Flag for follow up. Start by Friday, July 11, 2014. Due by Friday, July 11, 2014.

This message was sent with High importance.

You forwarded this message on 7/11/2014 5:19 PM.
All,

As you know this morning we had a service interruption for Fluig Identity caused by our infra-structure. Please find bellow what we could find by looking to our logs:

1) The first error we noticed was that some users were able to access the services and some users weren’t. The error happened about 11am PDT (3pm BRT).
502 Error Error – Bad Gateway

2) To avoid even more downtime we restarted the App Servers (both of them)

3) At 12:45pm PDT (4:45 pm BRT) we noticed this issue again. Then our team started to dig into the logs and found out that the one of the servers could not communicate with the CDN server (CDN server is responsible a centralized storage for all the images and logs). Just after that we determined that the CDN server has crashed and for a few minutes none of us could login to the server to restart it. The server was completely hosed (no one could communicate to the server).

4) At this time we also noticed that the internal App Servers (NONE OF THEM) could NOT connect to the messaging server
Caused by: javax.naming.CommunicationException: Could not obtain connection to any of these urls: 172.20.16.16:2099 and discovery failed with error: javax.naming.CommunicationException: Receive timed out [Root exception is java.net.SocketTimeoutException: Receive timed out]

5) Eventually we were able to login to the CDN server and we immediately restarted it. After this restart the CDN server issue was fixed and memory usage brought to normal.

6) Just after this we tried to mount the CDN server but it would take a VERY LONG time, almost minute, clearly a network latency. Due to this issue we had to restart ALL the servers, APP Servers, Messaging Servers, ADSync Servers, etc.

Conversation between Alexandre Lavrador and Kung Wang
[7/11/14, 1:31:42 PM] kungchaowang: root@app2:~# mount /www let me do tcp dump
[7/11/14, 1:31:56 PM] kungchaowang: oh, it comes back, after like 40 seconds
[7/11/14, 1:32:03 PM] kungchaowang: and now disk is mounted
[7/11/14, 1:32:18 PM] kungchaowang: it usually won't take that long to mount
[7/11/14, 1:32:29 PM] kungchaowang: 172.20.16.18:/export/www  197G   49G  139G  27% /www

7) After restarting all the servers the service is back to normal
8) We also notice that there is a huge latency to just read logs files on production. Between writing the file and reading the file it just toke 15 SECONDS! But in general it takes between 2-5 seconds. That’s too much.
9) We also have an automation test that keeps login to our product all the time. The average time it takes to login is less than a second. But this morning it was taking 10 seconds.
10) we will be adding the script described on #9 in our monitoring tool.
This is what we need from our Cloud/IT team (please let me know when we can get them in place):
Monitor ALL the servers/services. Including network, memory, etc
Alert our DevOps team right away if something goes wrong (Bill and Denny cc’d here)
Hotline contact phone #. Someone we can contact 24/7. For example, today we could not even connect to some servers to restart them
This is what we are doing from our side:
Removing some services that were using CDN server to decrease the memory usage
Adding monitoring to our (TOTVS Labs) Nagios
The bottom line is, this is a SaaS application that CAN NOT go down. Service MUST be live 24/7.

Regards

Vicente Goetten
+1 650 933-4902   -   goetten@totvs.com
LikeBe the first to like this
No labels Edit Labels
User icon: Denny
Write a comment…
Powered by Atlassian | Terms of Use | Answers | Maintenance Schedule

#+END_EXAMPLE
** DONE Issue: QA1B run out of disk
  CLOSED: [2015-03-06 Fri 13:25]
#+BEGIN_EXAMPLE
Skip to content
Skip to breadcrumbs
Skip to header menu
Skip to action menu
Skip to quick search
Linked Applications
Confluence
Spaces
People
 Create
Quick Search
0


TechOps
Configure
 Edit  Watch  Share
Pages  TechOps Home  Issues List For Service Maintainnce
Skip to end of banner
Go to start of banner
Issue: 2014/09/10 QA1B run out of disk
Skip to end of metadata
Created by Denny Zhang on Sep 17, 2014 Go to start of metadata
See the list of all issues here: https://totvslab.atlassian.net/wiki/display/TECH/Issues+List+For+Service+maintainnce

Issue Summary:
The issue happened in 2014/09/10.  Vicente Goetten Kung Wang  Denny Zhang and some other colleagues are involved.
QA1B run out of disk in a sudden. Previously we have nagios alerts, complaining free disk is below 15%

Improvement points:
Detail:
[9/10/14, 16:22:01] denny: Guys,
[9/10/14, 16:22:08] denny: QA1B have no free disk now
[9/10/14, 16:22:21] denny: @Kung, please do some data clean in /data/
qa1b:~# df -h
Filesystem Size Used Avail Use% Mounted on
/dev/sda1 238G 235G 0 100% /
udev 32G 4.0K 32G 1% /dev
tmpfs 6.3G 276K 6.3G 1% /run
none 5.0M 0 5.0M 0% /run/lock
none 32G 0 32G 0% /run/shm
[9/10/14, 16:22:36] Vicente Goetten: can we increase the space there?
[9/10/14, 16:23:20] denny: Yes, it takes time. Send request to BR, and reboot VM
[9/10/14, 16:23:53] Bill Nguyen: go to /daa/log
[9/10/14, 16:24:03] Bill Nguyen: and clean up old logs
[9/10/14, 16:24:08] Bill Nguyen: kung is coming
[9/10/14, 16:24:20] Shivang: dont just celan up the logs
[9/10/14, 16:24:22] Shivang: back them up somewhere
[9/10/14, 16:24:27] Shivang: especially like the GC logs and stuff
[9/10/14, 16:24:29] Shivang: we might need it
[9/10/14, 16:25:15] denny: Note: Without free disk, applications will have wired behavior.
[9/10/14, 16:25:26] Shivang: agreed
[9/10/14, 16:25:59] Shivang: do we have a local storage somewhere
[9/10/14, 16:26:06] Shivang: where we can copy all these stuff?
[9/10/14, 16:26:09] Shivang: Bill ? Denny ?
[9/10/14, 16:27:48] denny: Yes. Bill, where is our backup server? Let's do a quick scp right now.
[9/10/14, 16:29:05] denny: QA1B is almost not responding.
I will delete some none critical files, before Kung online
[9/10/14, 16:29:12] denny: Otherwise, the server would crash soon.
[9/10/14, 16:32:09] Vicente Goetten: UI is not responding anyomre
[9/10/14, 16:32:11] Vicente Goetten: actually
[9/10/14, 16:32:13] Vicente Goetten: is very slow
[9/10/14, 16:32:26] Vicente Goetten: Sorry, we could not process your request. Please contact your system administrator for assistance
[9/10/14, 16:32:45] denny: We need to remove some data, before do anything, say scp
[9/10/14, 16:32:52] Shivang: yes .. remove all the llog.gz
[9/10/14, 16:32:59] Shivang: only keep the .bak ones
[9/10/14, 16:33:01] Shivang: if thats the case
[9/10/14, 16:33:11] denny: ok
[9/10/14, 16:36:42] denny: /data/fluigidentity-logs/rest.log is 68G, /data/logs/rest.log is 43G.
[9/10/14, 16:37:10] Bill Nguyen: kung will stop and rotate the logs
[9/10/14, 16:37:30] Bill Nguyen: this will be a real issues the server will crash?
[9/10/14, 16:37:36] Shivang: no
[9/10/14, 16:37:43] Shivang: whats the size of the hDD?
[9/10/14, 16:37:52] Bill Nguyen: 250 GB
[9/10/14, 16:38:04] Shivang: oh ..
[9/10/14, 16:42:11] Vicente Goetten: who is fixing this guys?
[9/10/14, 16:42:34] denny: I'm doing that
[9/10/14, 16:43:00] denny: Will send an email to BR to enlarge the disk, or add a new disk. OK?
But we need a server reboot
[9/10/14, 16:43:05] kungchaowang: Denny, can I stop server now?
[9/10/14, 16:43:22] denny: Actually, I'm just doing the scp.
[9/10/14, 16:43:26] denny: Nothing else.
[9/10/14, 16:43:50] kungchaowang: ok, let me shutdown now
[9/10/14, 16:43:57] kungchaowang: and I see you have new script to stop and start the logs
[9/10/14, 16:44:00] Vicente Goetten: Denny, can you please reply to Luiz email?
[9/10/14, 16:45:44] Vicente Goetten: ok we need to restore asap
[9/10/14, 16:47:49] denny: Just noticed the free disk is 71G now. Looks like Kung has done some clean up
[9/10/14, 16:48:33] denny: @Kung, should we demand BR team to enlarge the disk or add a new disk?
[9/10/14, 16:59:55] kungchaowang: yes, we should make request to resize the disk to bigger size
[9/10/14, 17:00:09] kungchaowang: but we can only do it in the after hours
[9/10/14, 17:01:02] kungchaowang: for now, the disk has enough reserve, and I also turn off the rest.log in the init script, as it’s redundant to /data/logs/rest.log
[9/10/14, 17:01:46] denny: Agree.
[9/10/14, 17:01:58] Vicente Goetten: but we can already schedule with the DC team
[9/10/14, 17:02:05] kungchaowang: i will also do database backup now
[9/10/14, 17:45:29] denny: Happy birthday, Kung
[9/10/14, 18:32:41] Vicente Goetten: Geny and Bill
[9/10/14, 18:32:50] Vicente Goetten: this disc issue has caused a database corruption
[9/10/14, 18:33:00] Vicente Goetten: right now we are having to purge the data and start it all over on QA1B
[9/10/14, 18:34:12] Bill Nguyen: That is what I was concerned earlier
[9/10/14, 18:34:30] Vicente Goetten: why we didn't take action guys?
[9/10/14, 18:34:32] Vicente Goetten: honestly
[9/10/14, 18:34:41] Bill Nguyen: we did what we could
[9/10/14, 18:34:50] Vicente Goetten: what did we do?
[9/10/14, 18:35:12] denny: We sent alerts yesterday and this morning
[9/10/14, 18:35:40] Vicente Goetten: and again
[9/10/14, 18:35:42] Vicente Goetten: nothing was done
[9/10/14, 18:35:49] Vicente Goetten: it's not only about sending alerts
[9/10/14, 18:35:52] Vicente Goetten: it's about taking action
[9/10/14, 18:35:53] Vicente Goetten: ok?
[9/10/14, 18:36:09] denny: Vicente
[9/10/14, 18:36:50] Vicente Goetten: Denny, we can find any excuse now
[9/10/14, 18:36:56] Vicente Goetten: what I am saying is
[9/10/14, 18:36:59] Vicente Goetten: we need to take ACTION
[9/10/14, 18:37:00] Vicente Goetten: FAST
[9/10/14, 18:37:22] Vicente Goetten: increase the disk space, restart the server
[9/10/14, 18:37:24] Vicente Goetten: whatever
[9/10/14, 18:37:33] denny: This morning, the free disk is 20G.
LikeBe the first to like this
No labels Edit Labels
User icon: Denny
Write a comment…
Powered by Atlassian | Terms of Use | Answers | Maintenance Schedule

#+END_EXAMPLE
** DONE Issue: VM run into low memory
  CLOSED: [2015-03-06 Fri 13:25]
#+BEGIN_EXAMPLE
Skip to content
Skip to breadcrumbs
Skip to header menu
Skip to action menu
Skip to quick search
Linked Applications
Confluence
Spaces
People
 Create
Quick Search
0


TechOps
Configure
 Edit  Watch  Share
Pages  TechOps Home  Issues List For Service Maintainnce
Skip to end of banner
Go to start of banner
Issue: 2014/07/11 One VM(172.20.16.18) run to low memory
Skip to end of metadata
Created by Denny Zhang, last modified on Jul 31, 2014 Go to start of metadata
See the list of all issues here: https://totvslab.atlassian.net/wiki/display/TECH/Issues+List+For+Service+maintainnce
Issue Summary:
The issue happened in 2014/07/11. Vicente Goetten, Denny Zhang, Kung Wang , Shivang Shah and some other colleagues are involved.
Monitoring system complain one vm(172.20.16.18) have only ~160MB free memory.
Here is the observation for memory usage:
- each process of "java -jar ../dist/VABuildScript.jar" takes ~100 MB memory. And we have 27 processes like that.
- Jenkins takes 400MB.
Improvement points:
Details: Related email
RE: [2014-07-11_15:10] Health Check Of Fluig Servers Has Failed: One VM(172.20.16.18) run to low memory
Denny Zhang
To:
Kung Wang‎; Shivang Shah‎; Bill Nguyen‎; Vicente Goetten
Now free memory drops to 162 MB.
,-----------
| root@fluig-id-cdn-02:~# free -ml
| total used free shared buffers cached
| Mem: 3947 3827 119 0 0 41
| Low: 3947 3827 119
| High: 0 0 0
| -/+ buffers/cache: 3785 162
| Swap: 3854 613 3241
`-----------

________________________________________
From: Denny Zhang
Sent: Friday, July 11, 2014 10:25 AM
To: Kung Wang; Shivang Shah; Bill Nguyen; Vicente Goetten
Subject: RE: [2014-07-11_15:10] Health Check Of Fluig Servers Has Failed: One VM(172.20.16.18) run to low memory
Hi all
Monitoring system complain one vm(172.20.16.18) have only ~400MB free memory.
Do we need to evaluate the case? If it's by design, we may need to upgrade the vm, or migrate some service to other node.
Here is my observation for memory usage:
- each process of "java -jar ../dist/VABuildScript.jar" takes ~100 MB memory. And we have 27 processes like that.
- Jenkins takes 400MB.
Regards,
Denny
________________________________________
From: dennyzhang@openstacker.org [dennyzhang@openstacker.org]
Sent: Friday, July 11, 2014 10:10 AM
Subject: [2014-07-11_15:10] Health Check Of Fluig Servers Has Failed
"[2014-07-11 15:10:02] Tests Begins\n========== Check 172.20.16.18 failed ==========\nok
[2014-07-11 15:08:44] ps aux | grep jenkins
[2014-07-11 15:08:45] cat /proc/loadavg | awk -F' ' '{print 2}'
[2014-07-11 15:08:45] free -ml | grep 'buffers/cache' | awk -F' ' '{print }'
[2014-07-11 15:08:45] Error: Low memory. Free memory is 462 MB, which is lower than 1024 MB
[2014-07-11 15:08:45] df | grep ' /$' | awk -F' ' '{print }'
[2014-07-11 15:08:45] Error: some checks fail\nError to run: curl http:// 172.20.18.13:9281\n[2014-07-11 15:10:04] Tests end\n"

LikeBe the first to like this
No labels Edit Labels
User icon: Denny
Write a comment…
Powered by Atlassian | Terms of Use | Answers | Maintenance Schedule

#+END_EXAMPLE
** DONE Issue: QA1B is reinstalled, because of disk partition messup
  CLOSED: [2015-03-06 Fri 13:25]
#+BEGIN_EXAMPLE
Skip to content
Skip to breadcrumbs
Skip to header menu
Skip to action menu
Skip to quick search
Linked Applications
Confluence
Spaces
People
 Create
Quick Search
0


TechOps
Configure
 Edit  Watch  Share
Pages  TechOps Home  Issues List For Service Maintainnce
Skip to end of banner
Go to start of banner
Issue: 2014/07/14 QA1B is reinstalled, because of disk partition messup
Skip to end of metadata
Created by Denny Zhang, last modified on Jul 31, 2014 Go to start of metadata
See the list of all issues here: https://totvslab.atlassian.net/wiki/display/TECH/Issues+List+For+Service+maintainnce
Issue Summary:
The issue happened in 2014/07/14. Vicente Goetten, Denny Zhang, Kung Wang  and some other colleagues are involved.
When I resize disk of QA1B, I make some mistake, which resulted in disk partition mess up.
We tried to fix. But it seems to take too much effort, thus we reinstalled the VM.
Improvement points:
Take snapshots for VM. When do critical changes or things you're not that sure, BE ALERTED, DO BACKUP AND PROVIDE ESCAPE PLAN if possible.

Details:
From: Denny Zhang <filebat.mark@gmail.com>
Subject: Ask help about one fdisk issue
To: kung.wang@totvs.com
Date: Mon, 14 Jul 2014 08:09:11 -0400
User-Agent: Gnus/5.13 (Gnus v5.13) Emacs/24.3 (darwin)
Hi Kung
I seems to mess up the disk partition table for one ubuntu server.
Would you please help to take a look? Thanks.
=========================================================
Previously /dev/sda looks like this:
Disk /dev/sda: 268.4 GB, 268435456000 bytes
255 heads, 63 sectors/track, 32635 cylinders, total 524288000 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x000d2aaf
Device Boot Start End Blocks Id System
/dev/sda1 * 2048 499711 248832 83 Linux
/dev/sda2 501758 52426751 25962497 5 Extended
/dev/sda3 52426752 209715199 78644224 8e Linux LVM
/dev/sda5 501760 52426751 25962496 8e Linux LVM
========================================================
Now it looks like this
Device Boot Start End Blocks Id System
/dev/sda1 * 2048 499711 248832 83 Linux
/dev/sda3 52426752 209715199 78644224 8e Linux LVM
=========================================================
So I just need to create /dev/sda2 and /dev/sda3 manually.
I input below
- sudo fdisk /dev/sda
- n (new partition)
- e (extend)
- 501758 (start block)
- 52426751 (end block)
So far /de/sda2 is created exactly as I suppose, then I try to create /dev/sda5.
- n (new partition)
- l (logical)
- I suppose to input start block with 501760.
But it complains: first sector (503806-52426751, default 503806): 501760
Value out of range.
=========================================================
This means I fail to create /dev/sda5, with the exact start sector.
I'm not sure when I create /dev/sda5, whether I shall specify the
partition type as "p"(primary)? Or there is any wrong choice I made
above, or missing part. Like I shall change the partition id of
/dev/sda2, etc.
Thanks for your help.
LikeBe the first to like this
No labels Edit Labels
2 Comments
 User icon: kung.wang
Kung Wang
After fact note:
Please backup databases and keystore file before any partition operations.
The backup data should be moved out of that server immediate after backup.

ReplyDeleteLikeJul 16, 2014
 User icon: Denny
Denny Zhang
Yes, agree. The key is do the backup, before do anything stupid.
ReplyEditDeleteLikeJul 16, 2014
User icon: Denny
Write a comment…
Powered by Atlassian | Terms of Use | Answers | Maintenance Schedule
#+END_EXAMPLE
** DONE Issue: tomcat run into "java.lang.OutOfMemoryError: PermGen space"
  CLOSED: [2015-03-06 Fri 13:25]
#+BEGIN_EXAMPLE
Skip to content
Skip to breadcrumbs
Skip to header menu
Skip to action menu
Skip to quick search
Linked Applications
Confluence
Spaces
People
 Create
Quick Search
0


TechOps
Configure
 Edit  Watch  Share
Pages  TechOps Home  Issues List For Service Maintainnce
Skip to end of banner
Go to start of banner
Issue: 2014/07/18 Fluig of QA1B is not accessible, while tomcat complains "java.lang.OutOfMemoryError: PermGen space"
Skip to end of metadata
Created by Denny Zhang, last modified on Jul 31, 2014 Go to start of metadata
See the list of all issues here: https://totvslab.atlassian.net/wiki/display/TECH/Issues+List+For+Service+maintainnce
Issue Summary:
The issue happened in 2014/07/18. Bill Nguyen, Fellipe Augusto da Silva, Denny Zhang,  Shivang Shah and some other colleagues are involved.
Fellipe told me there is something wrong with QA1B.
And we found url of QA1B is not accessible. https://qa1b.thecloudpass.com/cloudpass/
Tomcat complained "java.lang.OutOfMemoryError: PermGen space".
Then Bill helped to workaround this issue, by enlarging memory of tomcat configuration.
Improvement points:
Currently, it's a workaround. We need to find out the root cause.
Monitor system to find out whose memory is rising very fast. And how memory changes for significant processes.
We've changed setenv.sh of tomcat to workaround this issue. Do we need to check-in that to git?

Details:
[7/18/14, 11:00:09] Bill Nguyen: so what i did was to change the settings for setenv.sh file
[7/18/14, 11:00:20] Bill Nguyen: /usr/share/tomcat7/bin
[7/18/14, 11:00:23] Bill Nguyen: export JAVA_OPTS="-server -Xms1024m -Xmx4096m -XX:MaxPermSize=1024m -XX:PermSize=512m -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=11999 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false"
[7/18/14, 11:08:46]
[7/18/14, 11:45:08] denny: Bill, do we need to checkin above change of tomcat's setenv.sh to git?
[7/18/14, 12:04:27] denny: Here is my observation for today's issue, which confuses me.
1. I manually flushed the cached OS memory, so the free memory is guaranteed to be over 6 GB.
2. I stop and start tomcat. But it still complains PermGen space out of memory.
3. Xmx of tomcat is 2048M
So my question is OS have 6G memory, why restart tomcat still run into that problem.
@Bill, would you please help me to understand this?

Summary Email:
Hi all
This morning, feline told me there is something wrong with QA1B.
And we found url of QA1B is not accessible.
https://qa1b.thecloudpass.com/cloudpass/
And tomcat complains "java.lang.OutOfMemoryError: PermGen space".
I tried to restart tomcat twice, but it doesn't work.
It looks like low memory issue. So I manually checked the free memory is 7.4 G(547 MB free + 6.7G cached).
So it should be fine.
Guys, any input for this?
====================================
,-----------
| fluig-id-qa-02:/var/log/tomcat7# free -ml
| free -ml
|              total       used       free     shared    buffers     cached
| Mem:         16050      15503        547          0        208       6737
| Low:         16050      15503        547
| High:            0          0          0
| -/+ buffers/cache:       8557       7493
| Swap:        12998          0      12998
`-----------
Checking "/var/log/tomcat7/cloudpass.log", we all error message like below:
,-----------
| at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:133)
| at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:153)
| at org.codehaus.groovy.grails.plugins.web.taglib.SitemeshTagLib$_closure1.doCall(SitemeshTagLib.groovy:114)
| at sun.reflect.GeneratedMethodAccessor409.invoke(Unknown Source)
| at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
| at java.lang.reflect.Method.invoke(Method.java:606)
| at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)
| at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:233)
| at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1082)
| at groovy.lang.ExpandoMetaClass.invokeMethod(ExpandoMetaClass.java:1106)
| at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:906)
| at groovy.lang.Closure.call(Closure.java:412)
| at org.codehaus.groovy.grails.web.pages.GroovyPage.invokeTag(GroovyPage.java:399)
| at org.codehaus.groovy.grails.web.pages.GroovyPage$invokeTag.callCurrent(Unknown Source)
| at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:49)
| at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:133)
| at gsp_cloudpasserror_gsp.run(gsp_cloudpasserror_gsp.groovy:31)
| at org.codehaus.groovy.grails.web.pages.GroovyPageWritable.writeTo(GroovyPageWritable.java:218)
| at org.codehaus.groovy.grails.web.servlet.view.GroovyPageView.renderWithTemplateEngine(GroovyPageView.java:148)
| ... 60 more
| Caused by: org.codehaus.groovy.runtime.InvokerInvocationException: java.lang.OutOfMemoryError: PermGen space
| at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:97)
| at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:233)
| at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1082)
| at groovy.lang.ExpandoMetaClass.invokeMethod(ExpandoMetaClass.java:1106)
| at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:906)
| at groovy.lang.Closure.call(Closure.java:412)
| at org.codehaus.groovy.grails.web.pages.GroovyPage.invokeTag(GroovyPage.java:399)
| ... 127 more
| Caused by: java.lang.OutOfMemoryError: PermGen space
`-----------

LikeBe the first to like this
No labels Edit Labels
1 Comment
 User icon: kung.wang
Kung Wang
export JAVA_HOME="/opt/jdk"
export JAVA_OPTS="-server -Xms1024m -Xmx4096m -XX:MaxPermSize=1024m -XX:PermSize=512m
-XX:+CMSClassUnloadingEnabled -XX:+CMSPermGenSweepingEnabled
-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=11999 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false"

The option environment variables are good for Maven only, so, please use this for JAVA_OPTS.
ReplyDeleteLikeOct 29, 2014
User icon: Denny
Write a comment…
Powered by Atlassian | Terms of Use | Answers | Maintenance Schedule

#+END_EXAMPLE
** Issue: QA1B fluig website complains "Internal Server Error"
https://totvslab.atlassian.net/wiki/pages/viewpage.action?pageId=38076426
#+BEGIN_EXAMPLE
Skip to content
Skip to breadcrumbs
Skip to header menu
Skip to action menu
Skip to quick search
Linked Applications
Confluence
Spaces
People
 Create
Quick Search
0


TechOps
Configure
 Edit  Watch  Share
Pages  TechOps Home  Issues List For Service Maintainnce
Skip to end of banner
Go to start of banner
Issue: 2014/07/21 QA1B fluig website complains "Internal Server Error"
Skip to end of metadata
Created by Denny Zhang, last modified on Jul 31, 2014 Go to start of metadata
See the list of all issues here: https://totvslab.atlassian.net/wiki/display/TECH/Issues+List+For+Service+maintainnce
Issue Summary:
The issue happened in 2014/07/21. Fellipe Augusto da Silva, Denny Zhang and some other colleagues are involved.
Fellipe told me website of QA1B run to error of "Internal Server Error".
I manually checked the url of https://qa1b.thecloudpass.com/cloudpass/ and performed all known checks.
It looks fine.
Check tomcat log by: grep -i error -C 3 /var/log/tomcat7 -r | grep '2014-07-21'
Two types of errors are found:
"ERROR saml2.SPInitRedirectController  - Exception processing SAML: null"
      2. "StackTrace  - Full Stack Trace:"
Improvement points:
Suspicious error messages in log:
fluig-id-qa-02:/var/log/tomcat7# grep -i error -C 3 /var/log/tomcat7 -r | grep '2014-07-21'
<rep -i error -C 3 /var/log/tom4-07-21'
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:12:29,372 [ajp-bio-8009-exec-9] INFO binding.AuthnRequestProcessor - Request: <?xml version="1.0" encoding="UTF-8"?>
/var/log/tomcat7/cloudpass.log.1-<saml2p:AuthnRequest AssertionConsumerServiceURL="http://cassino.jv01.local:8180/datasul/ACS" ID="_c3a801feaf68b0b062e1ec435fd67737" IssueInstant="2014-07-21T13:13:47.634Z" ProtocolBinding="urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST" ProviderName="TotvsLabs" Version="2.0" xmlns:saml2p="urn:oasis:names:tc:SAML:2.0:protocol"><saml2:Issuer Format="urn:oasis:names:tc:SAML:2.0:nameid-format:entity" xmlns:saml2="urn:oasis:names:tc:SAML:2.0:assertion">Datasul</saml2:Issuer><saml2p:NameIDPolicy Format="urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress"/></saml2p:AuthnRequest>
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:12:29,373 [ajp-bio-8009-exec-9] INFO binding.AuthnRequestProcessor - SAML Request is valid....will be processed
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:12:29,376 [ajp-bio-8009-exec-9] ERROR saml2.SPInitRedirectController - Exception processing SAML: null
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:12:29,842 [ajp-bio-8009-exec-9] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user ricardo.p@totvs.com.br
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:12:31,475 [ajp-bio-8009-exec-1] WARN cloudpass.LoginController - Login redirect user to: https://joinville.thecloudpass.com/cloudpass/launchpad/launchAppList
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:12:32,307 [ajp-bio-8009-exec-6] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user tatiana.estevao@totvs.com.br
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:14:40,697 [ajp-bio-8009-exec-4] INFO binding.AuthnRequestProcessor - Request: <?xml version="1.0" encoding="UTF-8"?>
/var/log/tomcat7/cloudpass.log.1-<saml2p:AuthnRequest AssertionConsumerServiceURL="http://cassino.jv01.local:8180/datasul/ACS" ID="_96ab2357442aa4caedeb0bb143249686" IssueInstant="2014-07-21T13:18:03.162Z" ProtocolBinding="urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST" ProviderName="TotvsLabs" Version="2.0" xmlns:saml2p="urn:oasis:names:tc:SAML:2.0:protocol"><saml2:Issuer Format="urn:oasis:names:tc:SAML:2.0:nameid-format:entity" xmlns:saml2="urn:oasis:names:tc:SAML:2.0:assertion">Datasul</saml2:Issuer><saml2p:NameIDPolicy Format="urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress"/></saml2p:AuthnRequest>
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:14:40,697 [ajp-bio-8009-exec-4] INFO binding.AuthnRequestProcessor - SAML Request is valid....will be processed
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:14:40,700 [ajp-bio-8009-exec-4] ERROR saml2.SPInitRedirectController - Exception processing SAML: null
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:14:41,130 [ajp-bio-8009-exec-4] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user marcelo.stanislaski@totvs.com.br
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:14:46,488 [ajp-bio-8009-exec-4] WARN cloudpass.LoginController - Add cookie domain: .thecloudpass.com
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:14:51,119 [ajp-bio-8009-exec-4] INFO binding.HttpRedirectBindingAdapter - decoding using HttpRedirect...
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:15:03,964 [ajp-bio-8009-exec-6] INFO binding.AuthnRequestProcessor - Request: <?xml version="1.0" encoding="UTF-8"?>
/var/log/tomcat7/cloudpass.log.1-<saml2p:AuthnRequest AssertionConsumerServiceURL="http://cassino.jv01.local:8180/datasul/ACS" ID="_8b83449dec843a0c9a70485a426d624f" IssueInstant="2014-07-21T13:18:13.741Z" ProtocolBinding="urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST" ProviderName="TotvsLabs" Version="2.0" xmlns:saml2p="urn:oasis:names:tc:SAML:2.0:protocol"><saml2:Issuer Format="urn:oasis:names:tc:SAML:2.0:nameid-format:entity" xmlns:saml2="urn:oasis:names:tc:SAML:2.0:assertion">Datasul</saml2:Issuer><saml2p:NameIDPolicy Format="urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress"/></saml2p:AuthnRequest>
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:15:03,964 [ajp-bio-8009-exec-6] INFO binding.AuthnRequestProcessor - SAML Request is valid....will be processed
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:15:03,968 [ajp-bio-8009-exec-6] ERROR saml2.SPInitRedirectController - Exception processing SAML: null
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:15:04,360 [ajp-bio-8009-exec-4] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user marcelo.stanislaski@totvs.com.br
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:15:19,554 [ajp-bio-8009-exec-6] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user elton.costa@totvs.com.br
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:15:30,832 [ajp-bio-8009-exec-6] WARN cloudpass.LaunchpadController - set user context to: v544ngmlzu4m0qs81405619580011
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:17:17,517 [ajp-bio-8009-exec-4] INFO binding.SSOHandler - Saml response sent
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:17:17,673 [ajp-bio-8009-exec-3] ERROR StackTrace - Full Stack Trace:
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:17:17,676 [ajp-bio-8009-exec-5] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user jairo.silva@totvs.com.br
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:17:17,676 [ajp-bio-8009-exec-3] ERROR StackTrace - Full Stack Trace:
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:17:17,683 [ajp-bio-8009-exec-3] ERROR StackTrace - Full Stack Trace:
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:17:17,683 [ajp-bio-8009-exec-3] ERROR StackTrace - Full Stack Trace:
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:18:15,180 [ajp-bio-8009-exec-6] INFO binding.AuthnRequestProcessor - Request: <?xml version="1.0" encoding="UTF-8"?>
/var/log/tomcat7/cloudpass.log.1-<saml2p:AuthnRequest AssertionConsumerServiceURL="http://cassino.jv01.local:8180/datasul/ACS" ID="_bfcc2fc7b5265170aba2950146268a89" IssueInstant="2014-07-21T13:20:18.777Z" ProtocolBinding="urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST" ProviderName="TotvsLabs" Version="2.0" xmlns:saml2p="urn:oasis:names:tc:SAML:2.0:protocol"><saml2:Issuer Format="urn:oasis:names:tc:SAML:2.0:nameid-format:entity" xmlns:saml2="urn:oasis:names:tc:SAML:2.0:assertion">Datasul</saml2:Issuer><saml2p:NameIDPolicy Format="urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress"/></saml2p:AuthnRequest>
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:18:15,180 [ajp-bio-8009-exec-6] INFO binding.AuthnRequestProcessor - SAML Request is valid....will be processed
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:18:15,183 [ajp-bio-8009-exec-6] ERROR saml2.SPInitRedirectController - Exception processing SAML: null
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:18:15,188 [ajp-bio-8009-exec-7] WARN cloudpass.RmiService - RmiSerivce -- getAllApplicationsForCompany -- userId: kixz274w8f8cn7621405554582395, userRole: COMPANY_ADMIN, companyId: pl622a90e1xt274n1405551958681
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:18:15,904 [ajp-bio-8009-exec-6] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user giovanny.scholz@totvs.com.br
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:18:22,280 [ajp-bio-8009-exec-6] WARN cloudpass.LaunchpadController - Saml redirect to: https://joinville.thecloudpass.com/cloudpass/IDPInitSSO/receiveSSORequest?appId=lyp4vfhtz1a31x471405906959231
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:18:23,451 [ajp-bio-8009-exec-7] INFO binding.SSOHandler - Saml response sent
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:18:24,178 [ajp-bio-8009-exec-4] ERROR StackTrace - Full Stack Trace:
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:18:24,186 [ajp-bio-8009-exec-4] ERROR StackTrace - Full Stack Trace:
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:18:24,188 [ajp-bio-8009-exec-7] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user giovanny.scholz@totvs.com.br
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:18:24,193 [ajp-bio-8009-exec-4] ERROR StackTrace - Full Stack Trace:
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:18:24,194 [ajp-bio-8009-exec-4] ERROR StackTrace - Full Stack Trace:
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:18:41,671 [ajp-bio-8009-exec-4] INFO binding.SSOHandler - Saml response sent
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:18:42,810 [ajp-bio-8009-exec-7] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user giovanny.scholz@totvs.com.br
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:18:42,852 [ajp-bio-8009-exec-2] ERROR StackTrace - Full Stack Trace:
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:18:42,855 [ajp-bio-8009-exec-2] ERROR StackTrace - Full Stack Trace:
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:18:42,860 [ajp-bio-8009-exec-2] ERROR StackTrace - Full Stack Trace:
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:18:42,861 [ajp-bio-8009-exec-2] ERROR StackTrace - Full Stack Trace:
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:22:45,145 [ajp-bio-8009-exec-5] INFO binding.AuthnRequestProcessor - Request: <?xml version="1.0" encoding="UTF-8"?>
/var/log/tomcat7/cloudpass.log.1-<saml2p:AuthnRequest AssertionConsumerServiceURL="http://cassino.jv01.local:8180/datasul/ACS" ID="_85d45b179e340e17bd5e32815e619882" IssueInstant="2014-07-21T13:26:07.608Z" ProtocolBinding="urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST" ProviderName="TotvsLabs" Version="2.0" xmlns:saml2p="urn:oasis:names:tc:SAML:2.0:protocol"><saml2:Issuer Format="urn:oasis:names:tc:SAML:2.0:nameid-format:entity" xmlns:saml2="urn:oasis:names:tc:SAML:2.0:assertion">Datasul</saml2:Issuer><saml2p:NameIDPolicy Format="urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress"/></saml2p:AuthnRequest>
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:22:45,145 [ajp-bio-8009-exec-5] INFO binding.AuthnRequestProcessor - SAML Request is valid....will be processed
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:22:45,148 [ajp-bio-8009-exec-5] ERROR saml2.SPInitRedirectController - Exception processing SAML: null
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:22:45,558 [ajp-bio-8009-exec-5] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user ricardo.p@totvs.com.br
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:22:47,680 [ajp-bio-8009-exec-4] WARN cloudpass.LoginController - Login redirect user to: https://uxtotvs.thecloudpass.com/cloudpass/launchpad/launchAppList
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:22:48,314 [ajp-bio-8009-exec-6] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user jairo.silva@totvs.com.br
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:23:28,703 [ajp-bio-8009-exec-6] INFO binding.AuthnRequestProcessor - Request: <?xml version="1.0" encoding="UTF-8"?>
/var/log/tomcat7/cloudpass.log.1-<saml2p:AuthnRequest AssertionConsumerServiceURL="http://moitas:8380/portal/idp/ACS" Destination="https://joinville.thecloudpass.com/cloudpass/SPInitPost/receiveSSORequest/v544ngmlzu4m0qs81405619580011/42" ID="_4671b642fea1cfdde3c17232952e7ccc" IssueInstant="2014-07-21T13:26:51.765Z" ProtocolBinding="urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST" ProviderName="TotvsLabs" Version="2.0" xmlns:saml2p="urn:oasis:names:tc:SAML:2.0:protocol"><saml2:Issuer Format="urn:oasis:names:tc:SAML:2.0:nameid-format:entity" xmlns:saml2="urn:oasis:names:tc:SAML:2.0:assertion">TotvsLabs</saml2:Issuer><saml2p:NameIDPolicy Format="urn:oasis:names:tc:SAML:2.0:nameid-format:transient"/></saml2p:AuthnRequest>
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:23:28,703 [ajp-bio-8009-exec-6] INFO binding.AuthnRequestProcessor - SAML Request is valid....will be processed
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:23:28,707 [ajp-bio-8009-exec-6] ERROR saml2.SPInitPostController - Exception processing SAML: null
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:23:29,672 [ajp-bio-8009-exec-6] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user marcelo.stanislaski@totvs.com.br
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:23:36,943 [ajp-bio-8009-exec-1] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user marcelo.stanislaski@totvs.com.br
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:23:37,043 [ajp-bio-8009-exec-1] ERROR StackTrace - Full Stack Trace:
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:23:37,046 [ajp-bio-8009-exec-1] ERROR StackTrace - Full Stack Trace:
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:23:37,050 [ajp-bio-8009-exec-1] ERROR StackTrace - Full Stack Trace:
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:23:37,050 [ajp-bio-8009-exec-1] ERROR StackTrace - Full Stack Trace:
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:25:05,311 [ajp-bio-8009-exec-5] INFO binding.SSOHandler - Saml response sent
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:25:48,766 [ajp-bio-8009-exec-9] WARN cloudpass.LoginController - redirect to /SPInitPost/receiveSSORequest/oppt2js0psff4nbi1405552238716/42 after login.
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:25:48,852 [ajp-bio-8009-exec-9] INFO binding.HttpPostBindingAdapter - decoding using HttpPostDecoder...
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:25:48,852 [ajp-bio-8009-exec-9] ERROR binding.AuthnRequestProcessor - Exception extracting SAML message from the request: This message decoder only supports the HTTP POST method
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:25:48,852 [ajp-bio-8009-exec-9] ERROR saml2.SPInitPostController - Exception processing SAML: Exception extracting SAML message from the request: This message decoder only supports the HTTP POST method
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:25:51,710 [ajp-bio-8009-exec-9] WARN cloudpass.LaunchpadController - Saml redirect to: http://fluig.bh01.local:12012/portal/idp
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:25:52,180 [ajp-bio-8009-exec-9] INFO binding.HttpPostBindingAdapter - decoding using HttpPostDecoder...
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:25:52,182 [ajp-bio-8009-exec-9] DEBUG PROTOCOL_MESSAGE -
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:38:06,671 [ajp-bio-8009-exec-20] INFO binding.HttpPostBindingAdapter - message decoded...
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:38:06,678 [ajp-bio-8009-exec-20] INFO binding.AuthnRequestProcessor - Relay State: null
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:38:06,678 [ajp-bio-8009-exec-20] ERROR saml2.SPInitPostController - Exception processing SAML: null
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:38:25,293 [ajp-bio-8009-exec-26] INFO binding.HttpPostBindingAdapter - decoding using HttpPostDecoder...
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:38:25,298 [ajp-bio-8009-exec-26] DEBUG PROTOCOL_MESSAGE -
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:38:25,298 [ajp-bio-8009-exec-26] INFO binding.HttpPostBindingAdapter - message decoded...
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:38:25,303 [ajp-bio-8009-exec-26] INFO binding.AuthnRequestProcessor - Relay State: null
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:38:25,303 [ajp-bio-8009-exec-26] ERROR saml2.SPInitPostController - Exception processing SAML: null
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:39:15,806 [ajp-bio-8009-exec-1] WARN cloudpass.UserController - Add app: lyp4vfhtz1a31x471405906959231 to user abuux41k0ma7txq51405949656546, company
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:39:15,817 [ajp-bio-8009-exec-15] WARN cloudpass.UserController - Add app: lyp4vfhtz1a31x471405906959231 to user sw10ej633csgwzd41405949655989, company
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:39:15,854 [ajp-bio-8009-exec-1] WARN cloudpass.RmiService - Adding app lyp4vfhtz1a31x471405906959231 to user abuux41k0ma7txq51405949656546, true
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:40:54,172 [ajp-bio-8009-exec-12] WARN cloudpass.LoginController - Add cookie domain: .thecloudpass.com
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:41:09,120 [ajp-bio-8009-exec-8] WARN cloudpass.LoginController - redirect to /SPInitPost/receiveSSORequest/pl622a90e1xt274n1405551958681/42 after login.
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:41:09,227 [ajp-bio-8009-exec-8] INFO binding.HttpPostBindingAdapter - decoding using HttpPostDecoder...
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:41:09,227 [ajp-bio-8009-exec-8] ERROR binding.AuthnRequestProcessor - Exception extracting SAML message from the request: This message decoder only supports the HTTP POST method
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:41:09,227 [ajp-bio-8009-exec-8] ERROR saml2.SPInitPostController - Exception processing SAML: Exception extracting SAML message from the request: This message decoder only supports the HTTP POST method
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:41:11,271 [ajp-bio-8009-exec-1] WARN cloudpass.LaunchpadController - Saml redirect to: http://experiencias.fluig.com/portal/idp
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:41:12,528 [ajp-bio-8009-exec-1] INFO binding.HttpPostBindingAdapter - decoding using HttpPostDecoder...
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:41:12,530 [ajp-bio-8009-exec-1] DEBUG PROTOCOL_MESSAGE -
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:45:30,426 [ajp-bio-8009-exec-20] WARN filters.SecurityFilters - No session user. forward to /SPInitRedirect/receiveSSORequest/v544ngmlzu4m0qs81405619580011/lyp4vfhtz1a31x471405906959231?SAMLRequest=hZJfT8IwFMXf%2FRRL3%2FenZbLZsJEJIZKgEhg%2B%2BGK6rkjN1mJvt8i3dzBI1Ad8bc6955zf7Wj8VVdOKwxIrRKEvQA5QnFdSvWeoE0%2Bc2M0Tm9GwOqK7GnW2J1aic9GgHUyAGFsNzfRCppamLUwreRis1okaGftnvo%2BZwBSae%2BjDbBXac4qGuM48EtmGTSVn03WyJlPE%2FQ2JEXIGR4QQopiG0bBYDsIhiHhUcSiAvNOBtCIuQLLlE0QCXDoBpFLcI4HNIzpLfHi6O4VOUujrea6upeqr9EYRTUDCVSxWgC1nK6zxwUlXkCLXgT0Ic%2BX7vJ5nZ8WtLIU5qlTJyjXtoUFKwA5LxdO5MipI6eA9mSum%2BzPiVDag6SnKsaZaVMze332%2BCJLd3uSUqGstIdf3tfH2eVIKJ32zEf%2Bzwzp5bTHsvPpUleSH%2F4Nhj38N1jNZJWVpREAyE%2FPJr9%2FTPoN&RelayState=%3Fjosso_back_to%3Dhttp%3A%2F%2Fcassino%3A8180%2Fdatasul%2Fjosso_security_check
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:45:30,534 [ajp-bio-8009-exec-20] WARN cloudpass.LoginController - Add cookie domain: .thecloudpass.com
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:45:31,773 [ajp-bio-8009-exec-12] WARN cloudpass.LoginController - Login redirect user to: https://joinville.thecloudpass.com/cloudpass/launchpad/launchAppList
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:45:38,502 [ajp-bio-8009-exec-18] ERROR cloudpass.LoginController - Could not set new password for lab.felipe@joinville.com.
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:45:39,289 [ajp-bio-8009-exec-18] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user guilherme.eduardo@totvs.com.br
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:45:39,599 [ajp-bio-8009-exec-6] WARN cloudpass.LoginController - Login redirect user to: https://joinville.thecloudpass.com/cloudpass/launchpad/launchAppList
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:45:40,050 [ajp-bio-8009-exec-12] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user lab.kindlmann@joinville.com
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:47:37,855 [ajp-bio-8009-exec-23] WARN cloudpass.LoginController - Login redirect user to: https://joinville.thecloudpass.com/cloudpass/launchpad/launchAppList
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:47:38,214 [ajp-bio-8009-exec-23] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user lab.julio@joinville.com
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:47:38,805 [ajp-bio-8009-exec-8] WARN cloudpass.LoginController - Login redirect user to: https://joinville.thecloudpass.com/cloudpass/launchpad/launchAppList
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:47:38,934 [ajp-bio-8009-exec-12] ERROR cloudpass.LoginController - Could not set new password for lab.ricardo2@joinville.com.br.
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:47:39,147 [ajp-bio-8009-exec-1] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user lab.jairo@joinville.com
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:47:40,199 [ajp-bio-8009-exec-23] WARN cloudpass.LaunchpadController - Saml redirect to: http://moitas:8380/portal/idp
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:47:40,457 [ajp-bio-8009-exec-23] INFO binding.HttpPostBindingAdapter - decoding using HttpPostDecoder...
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:47:44,315 [ajp-bio-8009-exec-8] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user lab.rubens@joinville.com
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:47:46,046 [ajp-bio-8009-exec-15] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user lab.julio@joinville.com
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:47:48,383 [ajp-bio-8009-exec-24] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user guilherme.eduardo@totvs.com.br
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:47:48,588 [ajp-bio-8009-exec-23] ERROR cloudpass.LoginController - Could not set new password for lab.ricardo2@joinville.com.br.
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:47:52,777 [ajp-bio-8009-exec-24] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user lab.julio@joinville.com
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:47:53,500 [ajp-bio-8009-exec-23] WARN cloudpass.LoginController - Add cookie domain: .thecloudpass.com
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:47:55,213 [ajp-bio-8009-exec-23] WARN cloudpass.UserController - Add app: 42 to user oddznl7oxm0fawj01405949656326, browsable
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:48:11,894 [ajp-bio-8009-exec-12] WARN filters.SecurityFilters - Unauthorized accesss to configuration-getLocalizedMessages, redirecting user lab.marcelo@joinville.com.br
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:48:14,135 [ajp-bio-8009-exec-1] WARN cloudpass.RmiService - RmiSerivce -- getAllApplicationsForCompany -- userId: h148hp0gwirbvgux1405946926466, userRole: COMPANY_ADMIN, companyId: v544ngmlzu4m0qs81405619580011
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:48:15,180 [ajp-bio-8009-exec-12] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user lab.felipe@joinville.com
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:48:19,086 [ajp-bio-8009-exec-15] ERROR cloudpass.LoginController - Could not set new password for lab.ricardo2@joinville.com.br.
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:48:19,541 [ajp-bio-8009-exec-8] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user lab.felipe@joinville.com
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:48:24,790 [ajp-bio-8009-exec-15] WARN filters.SecurityFilters - No session user. forward to /launchpad/launchAppList
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:48:24,833 [ajp-bio-8009-exec-15] WARN cloudpass.LoginController - Add cookie domain: .thecloudpass.com
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:50:29,670 [ajp-bio-8009-exec-20] INFO binding.AuthnRequestProcessor - Request: <?xml version="1.0" encoding="UTF-8"?>
/var/log/tomcat7/cloudpass.log.1-<saml2p:AuthnRequest AssertionConsumerServiceURL="http://cassino.jv01.local:8180/datasul/ACS" ID="_3f5fb8e2bcdca9e114cbb759edf5d018" IssueInstant="2014-07-21T13:53:52.120Z" ProtocolBinding="urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST" ProviderName="TotvsLabs" Version="2.0" xmlns:saml2p="urn:oasis:names:tc:SAML:2.0:protocol"><saml2:Issuer Format="urn:oasis:names:tc:SAML:2.0:nameid-format:entity" xmlns:saml2="urn:oasis:names:tc:SAML:2.0:assertion">Datasul</saml2:Issuer><saml2p:NameIDPolicy Format="urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress"/></saml2p:AuthnRequest>
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:50:29,670 [ajp-bio-8009-exec-20] INFO binding.AuthnRequestProcessor - SAML Request is valid....will be processed
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:50:29,672 [ajp-bio-8009-exec-20] ERROR saml2.SPInitRedirectController - Exception processing SAML: null
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:50:30,446 [ajp-bio-8009-exec-20] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user marcelo.stanislaski@totvs.com.br
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:50:32,318 [ajp-bio-8009-exec-1] WARN cloudpass.RmiService - RmiSerivce -- getAllApplicationsForCompany -- userId: h148hp0gwirbvgux1405946926466, userRole: COMPANY_ADMIN, companyId: v544ngmlzu4m0qs81405619580011
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:50:54,574 [ajp-bio-8009-exec-18] WARN cloudpass.LoginController - redirect to /SPInitRedirect/receiveSSORequest/v544ngmlzu4m0qs81405619580011/lyp4vfhtz1a31x471405906959231?SAMLRequest=hZJfb4IwFMXf9ylI3%2FlTUGGNYJjGzMRtRHAPe1lKqbMLtK63kPntp6LJ3IN7bc6955zf7Xjy3dRWxzUIJWOEHQ9ZXDJVCfkRo3UxtyM0Se7GQJva35G0NVu54l8tB2OlAFybw9xUSWgbrnOuO8H4erWM0daYHXFdRgGEVM5n52GnVozWJMKR51bUUGhrN53myFrMYvSOS8aiIKpoee%2BzzTDwOItCfzTEEQt5GEYHGUDLFxIMlSZGvocHthfaPi5wQIYBGYycURi%2BISvTyiim6gch%2BxqtlkRREEAkbTgQw0iePi2J73ik7EVAHosis7OXvDgt6ETF9fNBHaNCmQ6WtARkvV44%2BUdOB3ISSE%2FmtsnunAglPUhyqqKtudINNbdnjy%2BisjcnKeHSCLO%2F8r49Ti9HQsmsZz52f2dILqc9ll3MMlULtv83GHbw32ANFXVaVZoDIDc5m1z%2FmOQH&RelayState=%3Fjosso_back_to%3Dhttp%3A%2F%2Fcassino%3A8180%2Fdatasul%2Fjosso_security_check after login.
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:54:37,982 [ajp-bio-8009-exec-32] WARN filters.SecurityFilters - Unauthorized accesss to configuration-getLocalizedMessages, redirecting user guilherme.eduardo@totvs.com.br
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:54:44,372 [ajp-bio-8009-exec-26] WARN cloudpass.LaunchpadController - set user context to: pl622a90e1xt274n1405551958681
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:54:44,692 [ajp-bio-8009-exec-34] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user guilherme.eduardo@totvs.com.br
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:54:45,429 [ajp-bio-8009-exec-28] ERROR cloudpass.LoginService - Reset password failed for kelvin.medeiros@totvs.com.br
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:54:51,151 [ajp-bio-8009-exec-28] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user guilherme.eduardo@totvs.com.br
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:54:51,237 [ajp-bio-8009-exec-32] WARN filters.SecurityFilters - Unauthorized accesss to configuration-getLocalizedMessages, redirecting user guilherme.eduardo@totvs.com.br
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:54:52,484 [ajp-bio-8009-exec-28] WARN cloudpass.LoginController - Add cookie domain: .thecloudpass.com
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:55:24,368 [ajp-bio-8009-exec-26] INFO binding.AuthnRequestProcessor - Request: <?xml version="1.0" encoding="UTF-8"?>
/var/log/tomcat7/cloudpass.log.1-<saml2p:AuthnRequest AssertionConsumerServiceURL="http://cassino.jv01.local:8180/datasul/ACS" ID="_12447591e2910362b9b7dcaa74f0737c" IssueInstant="2014-07-21T13:58:46.793Z" ProtocolBinding="urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST" ProviderName="TotvsLabs" Version="2.0" xmlns:saml2p="urn:oasis:names:tc:SAML:2.0:protocol"><saml2:Issuer Format="urn:oasis:names:tc:SAML:2.0:nameid-format:entity" xmlns:saml2="urn:oasis:names:tc:SAML:2.0:assertion">Datasul</saml2:Issuer><saml2p:NameIDPolicy Format="urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress"/></saml2p:AuthnRequest>
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:55:24,369 [ajp-bio-8009-exec-26] INFO binding.AuthnRequestProcessor - SAML Request is valid....will be processed
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:55:24,390 [ajp-bio-8009-exec-26] ERROR saml2.SPInitRedirectController - Exception processing SAML: null
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:55:24,979 [ajp-bio-8009-exec-26] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user romulo.klaus@totvs.com.br
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:55:25,569 [ajp-bio-8009-exec-28] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user guilherme.eduardo@totvs.com.br
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:55:25,630 [ajp-bio-8009-exec-34] WARN filters.SecurityFilters - Unauthorized accesss to configuration-getLocalizedMessages, redirecting user guilherme.eduardo@totvs.com.br
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:55:27,885 [ajp-bio-8009-exec-39] ERROR cloudpass.LoginService - Reset password failed for super@totvs.com.br
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:55:33,238 [ajp-bio-8009-exec-33] WARN cloudpass.LaunchpadController - set user context to: pl622a90e1xt274n1405551958681
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:55:33,689 [ajp-bio-8009-exec-33] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user guilherme.eduardo@totvs.com.br
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:55:36,760 [ajp-bio-8009-exec-32] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user guilherme.eduardo@totvs.com.br
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:56:56,066 [ajp-bio-8009-exec-40] WARN cloudpass.RmiService - RmiSerivce -- getAllApplicationsForCompany -- userId: h148hp0gwirbvgux1405946926466, userRole: COMPANY_ADMIN, companyId: v544ngmlzu4m0qs81405619580011
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:57:11,218 [ajp-bio-8009-exec-47] WARN cloudpass.LoginController - Add cookie domain: .thecloudpass.com
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:57:13,003 [ajp-bio-8009-exec-27] WARN cloudpass.LoginController - Add cookie domain: .thecloudpass.com
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:57:15,102 [ajp-bio-8009-exec-27] ERROR StackTrace - Full Stack Trace:
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:57:15,104 [ajp-bio-8009-exec-27] ERROR StackTrace - Full Stack Trace:
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:57:15,104 [ajp-bio-8009-exec-27] ERROR cloudpass.LaunchpadController - This application is not available. There is no login information for this application. h148hp0gwirbvgux1405946926466, 42
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:58:07,584 [ajp-bio-8009-exec-39] INFO binding.AuthnRequestProcessor - Request: <?xml version="1.0" encoding="UTF-8"?>
/var/log/tomcat7/cloudpass.log.1-<saml2p:AuthnRequest AssertionConsumerServiceURL="http://moitas:8380/portal/idp/ACS" Destination="https://joinville.thecloudpass.com/cloudpass/SPInitPost/receiveSSORequest/v544ngmlzu4m0qs81405619580011/42" ID="_4248061b3f4db940eb228212f75f8b51" IssueInstant="2014-07-21T14:01:30.292Z" ProtocolBinding="urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST" ProviderName="TotvsLabs" Version="2.0" xmlns:saml2p="urn:oasis:names:tc:SAML:2.0:protocol"><saml2:Issuer Format="urn:oasis:names:tc:SAML:2.0:nameid-format:entity" xmlns:saml2="urn:oasis:names:tc:SAML:2.0:assertion">TotvsLabs</saml2:Issuer><saml2p:NameIDPolicy Format="urn:oasis:names:tc:SAML:2.0:nameid-format:transient"/></saml2p:AuthnRequest>
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:58:07,585 [ajp-bio-8009-exec-39] INFO binding.AuthnRequestProcessor - SAML Request is valid....will be processed
/var/log/tomcat7/cloudpass.log.1:2014-07-21 13:58:07,603 [ajp-bio-8009-exec-39] ERROR saml2.SPInitPostController - Exception processing SAML: null
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:58:08,352 [ajp-bio-8009-exec-49] WARN cloudpass.LoginController - Add cookie domain: .thecloudpass.com
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:58:08,406 [ajp-bio-8009-exec-27] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user ricardo.peixoto@totvs.com.br
/var/log/tomcat7/cloudpass.log.1-2014-07-21 13:58:11,327 [ajp-bio-8009-exec-42] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user ricardo.peixoto@totvs.com.br
/var/log/tomcat7/localhost_access_log.2014-07-21.txt-10.80.140.131 - - [21/Jul/2014:12:08:03 +0000] "GET /cloudpass/notification/getNewCount HTTP/1.1" 200 15
/var/log/tomcat7/localhost_access_log.2014-07-21.txt-10.80.140.131 - - [21/Jul/2014:12:08:03 +0000] "GET /cloudpass/launchpad/launchAppList HTTP/1.1" 200 205
/var/log/tomcat7/localhost_access_log.2014-07-21.txt-10.80.140.131 - - [21/Jul/2014:12:08:04 +0000] "GET /cloudpass/user/getAccounts HTTP/1.1" 200 2036
/var/log/tomcat7/localhost_access_log.2014-07-21.txt:10.80.140.131 - - [21/Jul/2014:12:08:05 +0000] "GET /cloudpass/asset/applauncher?errorPage=%2Fcloudpass%2Fuser%2FprofileSettings HTTP/1.1" 302 -
/var/log/tomcat7/localhost_access_log.2014-07-21.txt-10.80.140.131 - - [21/Jul/2014:12:08:08 +0000] "GET /cloudpass/notification/getNewCount HTTP/1.1" 200 14
/var/log/tomcat7/localhost_access_log.2014-07-21.txt-10.80.140.131 - - [21/Jul/2014:12:08:08 +0000] "GET /cloudpass/notification/getNewCount HTTP/1.1" 200 14
/var/log/tomcat7/localhost_access_log.2014-07-21.txt-187.94.63.65 - - [21/Jul/2014:12:08:10 +0000] "GET /cloudpass/asset/image/company/small/0/default.png HTTP/1.1" 200 3262
/var/log/tomcat7/localhost.2014-07-21.log-Jul 21, 2014 1:05:16 PM org.apache.catalina.core.ApplicationDispatcher invoke
/var/log/tomcat7/localhost.2014-07-21.log:SEVERE: Servlet.service() for servlet grails-errorhandler threw exception
/var/log/tomcat7/localhost.2014-07-21.log:org.codehaus.groovy.grails.web.pages.exceptions.GroovyPagesException: Error applying layout : main
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.sitemesh.SpringMVCViewDecorator.render(SpringMVCViewDecorator.java:74)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.sitemesh.SpringMVCViewDecorator.render(SpringMVCViewDecorator.java:52)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.sitemesh.GrailsPageFilter.doFilter(GrailsPageFilter.java:161)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.core.StandardHostValve.custom(StandardHostValve.java:453)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.core.StandardHostValve.status(StandardHostValve.java:324)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:193)
/var/log/tomcat7/localhost.2014-07-21.log: at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:98)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:927)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)
/var/log/tomcat7/localhost.2014-07-21.log- at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
/var/log/tomcat7/localhost.2014-07-21.log- at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
/var/log/tomcat7/localhost.2014-07-21.log- at java.lang.Thread.run(Thread.java:745)
/var/log/tomcat7/localhost.2014-07-21.log:Caused by: org.codehaus.groovy.grails.web.pages.exceptions.GroovyPagesException: Error processing GroovyPageView: Error executing tag <g:render>: Cannot get property 'loginMode' on null object
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.servlet.view.GroovyPageView.createGroovyPageException(GroovyPageView.java:205)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.servlet.view.GroovyPageView.handleException(GroovyPageView.java:181)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.servlet.view.GroovyPageView.renderWithTemplateEngine(GroovyPageView.java:152)
/var/log/tomcat7/localhost.2014-07-21.log- at org.springframework.web.servlet.view.AbstractView.render(AbstractView.java:262)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.sitemesh.SpringMVCViewDecorator.render(SpringMVCViewDecorator.java:67)
/var/log/tomcat7/localhost.2014-07-21.log- ... 49 more
/var/log/tomcat7/localhost.2014-07-21.log:Caused by: org.codehaus.groovy.grails.web.taglib.exceptions.GrailsTagException: Error executing tag <g:render>: Cannot get property 'loginMode' on null object
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.pages.GroovyPage.throwRootCause(GroovyPage.java:464)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.pages.GroovyPage.invokeTag(GroovyPage.java:452)
/var/log/tomcat7/localhost.2014-07-21.log- at sun.reflect.GeneratedMethodAccessor216.invoke(Unknown Source)
/var/log/tomcat7/localhost.2014-07-21.log- ... 111 more
/var/log/tomcat7/localhost.2014-07-21.log-
/var/log/tomcat7/localhost.2014-07-21.log-Jul 21, 2014 1:05:16 PM org.apache.catalina.core.StandardHostValve custom
/var/log/tomcat7/localhost.2014-07-21.log:SEVERE: Exception Processing ErrorPage[errorCode=404, location=/grails-errorhandler]
/var/log/tomcat7/localhost.2014-07-21.log:org.codehaus.groovy.grails.web.pages.exceptions.GroovyPagesException: Error applying layout : main
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.sitemesh.SpringMVCViewDecorator.render(SpringMVCViewDecorator.java:74)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.sitemesh.SpringMVCViewDecorator.render(SpringMVCViewDecorator.java:52)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.sitemesh.GrailsPageFilter.doFilter(GrailsPageFilter.java:161)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.core.StandardHostValve.custom(StandardHostValve.java:453)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.core.StandardHostValve.status(StandardHostValve.java:324)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:193)
/var/log/tomcat7/localhost.2014-07-21.log: at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:98)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:927)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)
/var/log/tomcat7/localhost.2014-07-21.log- at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
/var/log/tomcat7/localhost.2014-07-21.log- at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
/var/log/tomcat7/localhost.2014-07-21.log- at java.lang.Thread.run(Thread.java:745)
/var/log/tomcat7/localhost.2014-07-21.log:Caused by: org.codehaus.groovy.grails.web.pages.exceptions.GroovyPagesException: Error processing GroovyPageView: Error executing tag <g:render>: Cannot get property 'loginMode' on null object
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.servlet.view.GroovyPageView.createGroovyPageException(GroovyPageView.java:205)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.servlet.view.GroovyPageView.handleException(GroovyPageView.java:181)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.servlet.view.GroovyPageView.renderWithTemplateEngine(GroovyPageView.java:152)
/var/log/tomcat7/localhost.2014-07-21.log- at org.springframework.web.servlet.view.AbstractView.render(AbstractView.java:262)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.sitemesh.SpringMVCViewDecorator.render(SpringMVCViewDecorator.java:67)
/var/log/tomcat7/localhost.2014-07-21.log- ... 49 more
/var/log/tomcat7/localhost.2014-07-21.log:Caused by: org.codehaus.groovy.grails.web.taglib.exceptions.GrailsTagException: Error executing tag <g:render>: Cannot get property 'loginMode' on null object
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.pages.GroovyPage.throwRootCause(GroovyPage.java:464)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.pages.GroovyPage.invokeTag(GroovyPage.java:452)
/var/log/tomcat7/localhost.2014-07-21.log- at sun.reflect.GeneratedMethodAccessor216.invoke(Unknown Source)
/var/log/tomcat7/localhost.2014-07-21.log- ... 111 more
/var/log/tomcat7/localhost.2014-07-21.log-
/var/log/tomcat7/localhost.2014-07-21.log-Jul 21, 2014 1:05:20 PM org.apache.catalina.core.ApplicationDispatcher invoke
/var/log/tomcat7/localhost.2014-07-21.log:SEVERE: Servlet.service() for servlet grails-errorhandler threw exception
/var/log/tomcat7/localhost.2014-07-21.log:org.codehaus.groovy.grails.web.pages.exceptions.GroovyPagesException: Error applying layout : main
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.sitemesh.SpringMVCViewDecorator.render(SpringMVCViewDecorator.java:74)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.sitemesh.SpringMVCViewDecorator.render(SpringMVCViewDecorator.java:52)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.sitemesh.GrailsPageFilter.doFilter(GrailsPageFilter.java:161)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.core.StandardHostValve.custom(StandardHostValve.java:453)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.core.StandardHostValve.status(StandardHostValve.java:324)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:193)
/var/log/tomcat7/localhost.2014-07-21.log: at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:98)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:927)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)
/var/log/tomcat7/localhost.2014-07-21.log- at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
/var/log/tomcat7/localhost.2014-07-21.log- at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
/var/log/tomcat7/localhost.2014-07-21.log- at java.lang.Thread.run(Thread.java:745)
/var/log/tomcat7/localhost.2014-07-21.log:Caused by: org.codehaus.groovy.grails.web.pages.exceptions.GroovyPagesException: Error processing GroovyPageView: Error executing tag <g:render>: Cannot get property 'loginMode' on null object
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.servlet.view.GroovyPageView.createGroovyPageException(GroovyPageView.java:205)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.servlet.view.GroovyPageView.handleException(GroovyPageView.java:181)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.servlet.view.GroovyPageView.renderWithTemplateEngine(GroovyPageView.java:152)
/var/log/tomcat7/localhost.2014-07-21.log- at org.springframework.web.servlet.view.AbstractView.render(AbstractView.java:262)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.sitemesh.SpringMVCViewDecorator.render(SpringMVCViewDecorator.java:67)
/var/log/tomcat7/localhost.2014-07-21.log- ... 49 more
/var/log/tomcat7/localhost.2014-07-21.log:Caused by: org.codehaus.groovy.grails.web.taglib.exceptions.GrailsTagException: Error executing tag <g:render>: Cannot get property 'loginMode' on null object
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.pages.GroovyPage.throwRootCause(GroovyPage.java:464)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.pages.GroovyPage.invokeTag(GroovyPage.java:452)
/var/log/tomcat7/localhost.2014-07-21.log- at sun.reflect.GeneratedMethodAccessor216.invoke(Unknown Source)
/var/log/tomcat7/localhost.2014-07-21.log- ... 111 more
/var/log/tomcat7/localhost.2014-07-21.log-
/var/log/tomcat7/localhost.2014-07-21.log-Jul 21, 2014 1:05:20 PM org.apache.catalina.core.StandardHostValve custom
/var/log/tomcat7/localhost.2014-07-21.log:SEVERE: Exception Processing ErrorPage[errorCode=404, location=/grails-errorhandler]
/var/log/tomcat7/localhost.2014-07-21.log:org.codehaus.groovy.grails.web.pages.exceptions.GroovyPagesException: Error applying layout : main
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.sitemesh.SpringMVCViewDecorator.render(SpringMVCViewDecorator.java:74)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.sitemesh.SpringMVCViewDecorator.render(SpringMVCViewDecorator.java:52)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.sitemesh.GrailsPageFilter.doFilter(GrailsPageFilter.java:161)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.core.StandardHostValve.custom(StandardHostValve.java:453)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.core.StandardHostValve.status(StandardHostValve.java:324)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:193)
/var/log/tomcat7/localhost.2014-07-21.log: at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:98)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:927)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)
/var/log/tomcat7/localhost.2014-07-21.log- at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
/var/log/tomcat7/localhost.2014-07-21.log- at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
/var/log/tomcat7/localhost.2014-07-21.log- at java.lang.Thread.run(Thread.java:745)
/var/log/tomcat7/localhost.2014-07-21.log:Caused by: org.codehaus.groovy.grails.web.pages.exceptions.GroovyPagesException: Error processing GroovyPageView: Error executing tag <g:render>: Cannot get property 'loginMode' on null object
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.servlet.view.GroovyPageView.createGroovyPageException(GroovyPageView.java:205)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.servlet.view.GroovyPageView.handleException(GroovyPageView.java:181)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.servlet.view.GroovyPageView.renderWithTemplateEngine(GroovyPageView.java:152)
/var/log/tomcat7/localhost.2014-07-21.log- at org.springframework.web.servlet.view.AbstractView.render(AbstractView.java:262)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.sitemesh.SpringMVCViewDecorator.render(SpringMVCViewDecorator.java:67)
/var/log/tomcat7/localhost.2014-07-21.log- ... 49 more
/var/log/tomcat7/localhost.2014-07-21.log:Caused by: org.codehaus.groovy.grails.web.taglib.exceptions.GrailsTagException: Error executing tag <g:render>: Cannot get property 'loginMode' on null object
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.pages.GroovyPage.throwRootCause(GroovyPage.java:464)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.pages.GroovyPage.invokeTag(GroovyPage.java:452)
/var/log/tomcat7/localhost.2014-07-21.log- at sun.reflect.GeneratedMethodAccessor216.invoke(Unknown Source)
/var/log/tomcat7/localhost.2014-07-21.log-
/var/log/tomcat7/localhost.2014-07-21.log-Jul 21, 2014 2:04:38 PM org.apache.catalina.core.StandardWrapperValve invoke
/var/log/tomcat7/localhost.2014-07-21.log-SEVERE: Servlet.service() for servlet [default] in context with path [/cloudpass] threw exception
/var/log/tomcat7/localhost.2014-07-21.log:org.codehaus.groovy.grails.web.pages.exceptions.GroovyPagesException: Error applying layout : main
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.sitemesh.SpringMVCViewDecorator.render(SpringMVCViewDecorator.java:74)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.sitemesh.SpringMVCViewDecorator.render(SpringMVCViewDecorator.java:52)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.sitemesh.GrailsPageFilter.doFilter(GrailsPageFilter.java:161)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:224)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:169)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:168)
/var/log/tomcat7/localhost.2014-07-21.log: at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:98)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:927)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)
/var/log/tomcat7/localhost.2014-07-21.log- at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
/var/log/tomcat7/localhost.2014-07-21.log- at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
/var/log/tomcat7/localhost.2014-07-21.log- at java.lang.Thread.run(Thread.java:745)
/var/log/tomcat7/localhost.2014-07-21.log:Caused by: org.codehaus.groovy.grails.web.pages.exceptions.GroovyPagesException: Error processing GroovyPageView: Error executing tag <g:render>: Cannot get property 'loginMode' on null object
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.servlet.view.GroovyPageView.createGroovyPageException(GroovyPageView.java:205)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.servlet.view.GroovyPageView.handleException(GroovyPageView.java:181)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.servlet.view.GroovyPageView.renderWithTemplateEngine(GroovyPageView.java:152)
/var/log/tomcat7/localhost.2014-07-21.log- at org.springframework.web.servlet.view.AbstractView.render(AbstractView.java:262)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.sitemesh.SpringMVCViewDecorator.render(SpringMVCViewDecorator.java:67)
/var/log/tomcat7/localhost.2014-07-21.log- ... 55 more
/var/log/tomcat7/localhost.2014-07-21.log:Caused by: org.codehaus.groovy.grails.web.taglib.exceptions.GrailsTagException: Error executing tag <g:render>: Cannot get property 'loginMode' on null object
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.pages.GroovyPage.throwRootCause(GroovyPage.java:464)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.pages.GroovyPage.invokeTag(GroovyPage.java:452)
/var/log/tomcat7/localhost.2014-07-21.log- at sun.reflect.GeneratedMethodAccessor216.invoke(Unknown Source)
/var/log/tomcat7/localhost.2014-07-21.log- ... 115 more
/var/log/tomcat7/localhost.2014-07-21.log-
/var/log/tomcat7/localhost.2014-07-21.log-Jul 21, 2014 2:04:38 PM org.apache.catalina.core.ApplicationDispatcher invoke
/var/log/tomcat7/localhost.2014-07-21.log:SEVERE: Servlet.service() for servlet grails-errorhandler threw exception
/var/log/tomcat7/localhost.2014-07-21.log:org.codehaus.groovy.grails.web.pages.exceptions.GroovyPagesException: Error applying layout : main
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.sitemesh.SpringMVCViewDecorator.render(SpringMVCViewDecorator.java:74)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.sitemesh.SpringMVCViewDecorator.render(SpringMVCViewDecorator.java:52)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.sitemesh.GrailsPageFilter.doFilter(GrailsPageFilter.java:161)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.core.StandardHostValve.status(StandardHostValve.java:324)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.core.StandardHostValve.throwable(StandardHostValve.java:415)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:191)
/var/log/tomcat7/localhost.2014-07-21.log: at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:98)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:927)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)
/var/log/tomcat7/localhost.2014-07-21.log- at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
/var/log/tomcat7/localhost.2014-07-21.log- at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
/var/log/tomcat7/localhost.2014-07-21.log- at java.lang.Thread.run(Thread.java:745)
/var/log/tomcat7/localhost.2014-07-21.log:Caused by: org.codehaus.groovy.grails.web.pages.exceptions.GroovyPagesException: Error processing GroovyPageView: Error executing tag <g:render>: Cannot get property 'loginMode' on null object
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.servlet.view.GroovyPageView.createGroovyPageException(GroovyPageView.java:205)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.servlet.view.GroovyPageView.handleException(GroovyPageView.java:181)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.servlet.view.GroovyPageView.renderWithTemplateEngine(GroovyPageView.java:152)
/var/log/tomcat7/localhost.2014-07-21.log- at org.springframework.web.servlet.view.AbstractView.render(AbstractView.java:262)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.sitemesh.SpringMVCViewDecorator.render(SpringMVCViewDecorator.java:67)
/var/log/tomcat7/localhost.2014-07-21.log- ... 50 more
/var/log/tomcat7/localhost.2014-07-21.log:Caused by: org.codehaus.groovy.grails.web.taglib.exceptions.GrailsTagException: Error executing tag <g:render>: Cannot get property 'loginMode' on null object
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.pages.GroovyPage.throwRootCause(GroovyPage.java:464)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.pages.GroovyPage.invokeTag(GroovyPage.java:452)
/var/log/tomcat7/localhost.2014-07-21.log- at sun.reflect.GeneratedMethodAccessor216.invoke(Unknown Source)
/var/log/tomcat7/localhost.2014-07-21.log- ... 110 more
/var/log/tomcat7/localhost.2014-07-21.log-
/var/log/tomcat7/localhost.2014-07-21.log-Jul 21, 2014 2:04:38 PM org.apache.catalina.core.StandardHostValve custom
/var/log/tomcat7/localhost.2014-07-21.log:SEVERE: Exception Processing ErrorPage[errorCode=500, location=/grails-errorhandler]
/var/log/tomcat7/localhost.2014-07-21.log:org.codehaus.groovy.grails.web.pages.exceptions.GroovyPagesException: Error applying layout : main
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.sitemesh.SpringMVCViewDecorator.render(SpringMVCViewDecorator.java:74)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.sitemesh.SpringMVCViewDecorator.render(SpringMVCViewDecorator.java:52)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.sitemesh.GrailsPageFilter.doFilter(GrailsPageFilter.java:161)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.core.StandardHostValve.status(StandardHostValve.java:324)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.core.StandardHostValve.throwable(StandardHostValve.java:415)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:191)
/var/log/tomcat7/localhost.2014-07-21.log: at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:98)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:927)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)
/var/log/tomcat7/localhost.2014-07-21.log- at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)
/var/log/tomcat7/localhost.2014-07-21.log- at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
/var/log/tomcat7/localhost.2014-07-21.log- at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
/var/log/tomcat7/localhost.2014-07-21.log- at java.lang.Thread.run(Thread.java:745)
/var/log/tomcat7/localhost.2014-07-21.log:Caused by: org.codehaus.groovy.grails.web.pages.exceptions.GroovyPagesException: Error processing GroovyPageView: Error executing tag <g:render>: Cannot get property 'loginMode' on null object
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.servlet.view.GroovyPageView.createGroovyPageException(GroovyPageView.java:205)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.servlet.view.GroovyPageView.handleException(GroovyPageView.java:181)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.servlet.view.GroovyPageView.renderWithTemplateEngine(GroovyPageView.java:152)
/var/log/tomcat7/localhost.2014-07-21.log- at org.springframework.web.servlet.view.AbstractView.render(AbstractView.java:262)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.sitemesh.SpringMVCViewDecorator.render(SpringMVCViewDecorator.java:67)
/var/log/tomcat7/localhost.2014-07-21.log- ... 50 more
/var/log/tomcat7/localhost.2014-07-21.log:Caused by: org.codehaus.groovy.grails.web.taglib.exceptions.GrailsTagException: Error executing tag <g:render>: Cannot get property 'loginMode' on null object
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.pages.GroovyPage.throwRootCause(GroovyPage.java:464)
/var/log/tomcat7/localhost.2014-07-21.log- at org.codehaus.groovy.grails.web.pages.GroovyPage.invokeTag(GroovyPage.java:452)
/var/log/tomcat7/localhost.2014-07-21.log- at sun.reflect.GeneratedMethodAccessor216.invoke(Unknown Source)
/var/log/tomcat7/cloudpass.log-2014-07-21 14:01:53,987 [ajp-bio-8009-exec-69] WARN filters.SecurityFilters - No session user. forward to /application/getAppResources/lyp4vfhtz1a31x471405906959231
/var/log/tomcat7/cloudpass.log-2014-07-21 14:03:35,431 [ajp-bio-8009-exec-73] WARN cloudpass.UserController - Add app: 42 to user xu61rwb4ousyk4rn1405725189939, browsable
/var/log/tomcat7/cloudpass.log-2014-07-21 14:04:37,935 [ajp-bio-8009-exec-73] WARN cloudpass.RmiService - Adding app 42 to user xu61rwb4ousyk4rn1405725189939, true
/var/log/tomcat7/cloudpass.log:2014-07-21 14:04:38,028 [ajp-bio-8009-exec-28] ERROR StackTrace - Full Stack Trace:
/var/log/tomcat7/cloudpass.log:2014-07-21 14:04:38,033 [ajp-bio-8009-exec-28] ERROR StackTrace - Full Stack Trace:
/var/log/tomcat7/cloudpass.log:2014-07-21 14:04:38,035 [ajp-bio-8009-exec-28] ERROR StackTrace - Full Stack Trace:
/var/log/tomcat7/cloudpass.log:2014-07-21 14:04:38,079 [ajp-bio-8009-exec-28] ERROR StackTrace - Full Stack Trace:
/var/log/tomcat7/cloudpass.log:2014-07-21 14:04:38,080 [ajp-bio-8009-exec-28] ERROR StackTrace - Full Stack Trace:
/var/log/tomcat7/cloudpass.log:2014-07-21 14:04:38,080 [ajp-bio-8009-exec-28] ERROR StackTrace - Full Stack Trace:
/var/log/tomcat7/cloudpass.log-2014-07-21 14:04:38,106 [ajp-bio-8009-exec-35] WARN cloudpass.LoginController - redirect to /launchpad/launchAppList after login.
/var/log/tomcat7/cloudpass.log:2014-07-21 14:04:38,289 [ajp-bio-8009-exec-28] ERROR StackTrace - Full Stack Trace:
/var/log/tomcat7/cloudpass.log:2014-07-21 14:04:38,291 [ajp-bio-8009-exec-28] ERROR StackTrace - Full Stack Trace:
/var/log/tomcat7/cloudpass.log:2014-07-21 14:04:38,292 [ajp-bio-8009-exec-28] ERROR StackTrace - Full Stack Trace:
/var/log/tomcat7/cloudpass.log:2014-07-21 14:04:38,310 [ajp-bio-8009-exec-28] ERROR StackTrace - Full Stack Trace:
/var/log/tomcat7/cloudpass.log:2014-07-21 14:04:38,311 [ajp-bio-8009-exec-28] ERROR StackTrace - Full Stack Trace:
/var/log/tomcat7/cloudpass.log-2014-07-21 14:14:59,666 [ajp-bio-8009-exec-138] INFO binding.AuthnRequestProcessor - Request: <?xml version="1.0" encoding="UTF-8"?>
/var/log/tomcat7/cloudpass.log-<saml2p:AuthnRequest AssertionConsumerServiceURL="http://cassino.jv01.local:8180/datasul/ACS" ID="_b3bc1ac3d867fac0af831bde8823798b" IssueInstant="2014-07-21T14:12:54.159Z" ProtocolBinding="urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST" ProviderName="TotvsLabs" Version="2.0" xmlns:saml2p="urn:oasis:names:tc:SAML:2.0:protocol"><saml2:Issuer Format="urn:oasis:names:tc:SAML:2.0:nameid-format:entity" xmlns:saml2="urn:oasis:names:tc:SAML:2.0:assertion">Datasul</saml2:Issuer><saml2p:NameIDPolicy Format="urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress"/></saml2p:AuthnRequest>
/var/log/tomcat7/cloudpass.log-2014-07-21 14:14:59,666 [ajp-bio-8009-exec-138] INFO binding.AuthnRequestProcessor - SAML Request is valid....will be processed
/var/log/tomcat7/cloudpass.log:2014-07-21 14:14:59,695 [ajp-bio-8009-exec-138] ERROR saml2.SPInitRedirectController - Exception processing SAML: null
/var/log/tomcat7/cloudpass.log-2014-07-21 14:15:05,770 [ajp-bio-8009-exec-140] INFO binding.HttpRedirectBindingAdapter - decoding using HttpRedirect...
/var/log/tomcat7/cloudpass.log-2014-07-21 14:15:05,775 [ajp-bio-8009-exec-140] DEBUG PROTOCOL_MESSAGE -
/var/log/tomcat7/cloudpass.log-2014-07-21 14:29:52,996 [ajp-bio-8009-exec-86] INFO binding.AuthnRequestProcessor - Request: <?xml version="1.0" encoding="UTF-8"?>
/var/log/tomcat7/cloudpass.log-<saml2p:AuthnRequest AssertionConsumerServiceURL="http://moitas:8380/portal/idp/ACS" Destination="https://joinville.thecloudpass.com/cloudpass/SPInitPost/receiveSSORequest/v544ngmlzu4m0qs81405619580011/42" ID="_4faf72e795c9de7f9b2915da9eb61c7a" IssueInstant="2014-07-21T14:33:16.122Z" ProtocolBinding="urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST" ProviderName="TotvsLabs" Version="2.0" xmlns:saml2p="urn:oasis:names:tc:SAML:2.0:protocol"><saml2:Issuer Format="urn:oasis:names:tc:SAML:2.0:nameid-format:entity" xmlns:saml2="urn:oasis:names:tc:SAML:2.0:assertion">TotvsLabs</saml2:Issuer><saml2p:NameIDPolicy Format="urn:oasis:names:tc:SAML:2.0:nameid-format:transient"/></saml2p:AuthnRequest>
/var/log/tomcat7/cloudpass.log-2014-07-21 14:29:52,997 [ajp-bio-8009-exec-86] INFO binding.AuthnRequestProcessor - SAML Request is valid....will be processed
/var/log/tomcat7/cloudpass.log:2014-07-21 14:29:53,036 [ajp-bio-8009-exec-86] ERROR saml2.SPInitPostController - Exception processing SAML: null
/var/log/tomcat7/cloudpass.log-2014-07-21 14:30:44,342 [ajp-bio-8009-exec-33] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user lab.mensor@joinville.com
/var/log/tomcat7/cloudpass.log-2014-07-21 14:30:51,194 [ajp-bio-8009-exec-190] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user lab.mensor@joinville.com
/var/log/tomcat7/cloudpass.log-2014-07-21 14:30:59,154 [ajp-bio-8009-exec-190] WARN cloudpass.LoginController - Add cookie domain: .thecloudpass.com
/var/log/tomcat7/cloudpass.log-2014-07-21 14:34:04,701 [ajp-bio-8009-exec-81] INFO binding.AuthnRequestProcessor - Request: <?xml version="1.0" encoding="UTF-8"?>
/var/log/tomcat7/cloudpass.log-<saml2p:AuthnRequest AssertionConsumerServiceURL="http://moitas:8380/portal/idp/ACS" Destination="https://joinville.thecloudpass.com/cloudpass/SPInitPost/receiveSSORequest/v544ngmlzu4m0qs81405619580011/42" ID="_b05bef332d4b8f8984ac38222a2c7397" IssueInstant="2014-07-21T14:37:27.858Z" ProtocolBinding="urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST" ProviderName="TotvsLabs" Version="2.0" xmlns:saml2p="urn:oasis:names:tc:SAML:2.0:protocol"><saml2:Issuer Format="urn:oasis:names:tc:SAML:2.0:nameid-format:entity" xmlns:saml2="urn:oasis:names:tc:SAML:2.0:assertion">TotvsLabs</saml2:Issuer><saml2p:NameIDPolicy Format="urn:oasis:names:tc:SAML:2.0:nameid-format:transient"/></saml2p:AuthnRequest>
/var/log/tomcat7/cloudpass.log-2014-07-21 14:34:04,701 [ajp-bio-8009-exec-81] INFO binding.AuthnRequestProcessor - SAML Request is valid....will be processed
/var/log/tomcat7/cloudpass.log:2014-07-21 14:34:04,720 [ajp-bio-8009-exec-81] ERROR saml2.SPInitPostController - Exception processing SAML: null
/var/log/tomcat7/cloudpass.log-2014-07-21 14:34:07,003 [ajp-bio-8009-exec-193] WARN cloudpass.RmiService - RmiSerivce -- getAllApplicationsForCompany -- userId: h148hp0gwirbvgux1405946926466, userRole: COMPANY_ADMIN, companyId: v544ngmlzu4m0qs81405619580011
/var/log/tomcat7/cloudpass.log-2014-07-21 14:34:09,224 [ajp-bio-8009-exec-193] WARN cloudpass.LoginController - Login redirect user to: https://joinville.thecloudpass.com/cloudpass/launchpad/launchAppList
/var/log/tomcat7/cloudpass.log-2014-07-21 14:34:12,120 [ajp-bio-8009-exec-194] WARN cloudpass.LoginController - Login redirect user to: https://joinville.thecloudpass.com/cloudpass/launchpad/launchAppList
/var/log/tomcat7/cloudpass.log-2014-07-21 14:35:16,381 [ajp-bio-8009-exec-79] INFO binding.AuthnRequestProcessor - Request: <?xml version="1.0" encoding="UTF-8"?>
/var/log/tomcat7/cloudpass.log-<saml2p:AuthnRequest AssertionConsumerServiceURL="http://moitas:8380/portal/idp/ACS" Destination="https://joinville.thecloudpass.com/cloudpass/SPInitPost/receiveSSORequest/v544ngmlzu4m0qs81405619580011/42" ID="_b701b6f05da1b509b18e0216cf2d3b7f" IssueInstant="2014-07-21T14:38:39.582Z" ProtocolBinding="urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST" ProviderName="TotvsLabs" Version="2.0" xmlns:saml2p="urn:oasis:names:tc:SAML:2.0:protocol"><saml2:Issuer Format="urn:oasis:names:tc:SAML:2.0:nameid-format:entity" xmlns:saml2="urn:oasis:names:tc:SAML:2.0:assertion">TotvsLabs</saml2:Issuer><saml2p:NameIDPolicy Format="urn:oasis:names:tc:SAML:2.0:nameid-format:transient"/></saml2p:AuthnRequest>
/var/log/tomcat7/cloudpass.log-2014-07-21 14:35:16,381 [ajp-bio-8009-exec-79] INFO binding.AuthnRequestProcessor - SAML Request is valid....will be processed
/var/log/tomcat7/cloudpass.log:2014-07-21 14:35:16,409 [ajp-bio-8009-exec-79] ERROR saml2.SPInitPostController - Exception processing SAML: null
/var/log/tomcat7/cloudpass.log-2014-07-21 14:35:17,368 [ajp-bio-8009-exec-79] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user ricardo.peixoto@totvs.com.br
/var/log/tomcat7/cloudpass.log-2014-07-21 14:35:19,892 [ajp-bio-8009-exec-185] WARN cloudpass.LaunchpadController - Saml redirect to: http://moitas:8380/portal/idp
/var/log/tomcat7/cloudpass.log-2014-07-21 14:35:20,181 [ajp-bio-8009-exec-185] INFO binding.HttpPostBindingAdapter - decoding using HttpPostDecoder...
fluig-id-qa-02:/var/log/tomcat7#

LikeBe the first to like this
No labels Edit Labels
User icon: Denny
Write a comment…
Powered by Atlassian | Terms of Use | Answers | Maintenance Schedule

#+END_EXAMPLE
** Issue: LoadBalance doesn't work for sticky sessions, if we don't restart apache services at the same time
#+BEGIN_EXAMPLE
Skip to content
Skip to breadcrumbs
Skip to header menu
Skip to action menu
Skip to quick search
Linked Applications
Confluence
Spaces
People
 Create
Quick Search
0


TechOps
Configure
 Edit  Watch  Share
Pages  TechOps Home  Issues List For Service Maintainnce
Skip to end of banner
Go to start of banner
Issue: 2014/07/23 LoadBalance doesn't work for sticky sessions, if we don't restart apache services at the same time
Skip to end of metadata
Created by Denny Zhang, last modified on Jul 31, 2014 Go to start of metadata
See the list of all issues here: https://totvslab.atlassian.net/wiki/display/TECH/Issues+List+For+Service+maintainnce
Issue Summary:
The issue happened in 2014/07/23. Shivang Shah, Kung Wang , Bill Nguyen, Vicente Goetten, Denny Zhang and some other colleagues are involved.
LoadBalance send request only to one Adsync service, which result significant performance penalty to customers.
Only if we restart all apaches instances at the same time, LoadBalance works again.
Improvement points:
Detail:
[7/23/14, 13:35:16] Vicente Goetten: Vicente Goetten added Bill Nguyen, denny, kungchaowang to this conversation
[7/23/14, 13:35:16] Vicente Goetten: denny needs to update Skype to participate in this chat.
Help by sending them to http://www.skype.com/updateme.
Learn more about new group chat.
[7/23/14, 13:35:27] Vicente Goetten: Guys, as you know we had an incident with the Load Balancer today
[7/23/14, 13:35:51] Vicente Goetten: I need your guys evaluation on EC2 if we move to EC2, would we have the same issue?
[7/23/14, 13:35:59] Vicente Goetten: or their Load Balancer would work better for us?
[7/23/14, 13:37:34] Bill Nguyen: Hi Vicente, I am having the network guys looking into the PROD load balancer status, right now I can not point the fingers to the Load Balancer until I could understand what Shivang is doing on the software level
[7/23/14, 13:38:34] Bill Nguyen: I can start bring up EC2 ENV to test but it makes more sense to have QA env in NIMBvs data center
[7/23/14, 13:38:35] Bill Nguyen: ?
[7/23/14, 13:39:07] Bill Nguyen: ENV was working fine until last night?
[7/23/14, 13:39:17] Bill Nguyen: what change in the code?
[7/23/14, 13:39:19] Vicente Goetten: let me add Shivang here
[7/23/14, 13:39:25] Vicente Goetten: Vicente Goetten added Shivang to this conversation
[7/23/14, 13:39:46] Vicente Goetten: So Shivang told me that until last night everything was fine because we started the servers at the exact same tie
[7/23/14, 13:39:47] Vicente Goetten: time
[7/23/14, 13:40:01] Vicente Goetten: but if we don't the LB cannot actually do its job that is to load the balance
[7/23/14, 13:43:08] Bill Nguyen: Shivang, please explain?
[7/23/14, 13:43:56] Vicente Goetten: he's probably in a meeting now
[7/23/14, 13:44:07] Vicente Goetten: but this is exactly what he did a few minutes ago
[7/23/14, 13:44:13] Vicente Goetten: started the two servers at the exact same time
[7/23/14, 13:44:20] Vicente Goetten: than it is loading the balance
[7/23/14, 13:48:35] Shivang: here's what happened
[7/23/14, 13:48:43] Shivang: when the deployment happened yesterday
[7/23/14, 13:49:02] Shivang: the apache servers were started one after the otehr .. and that's natural to reduce the amount of downtime
[7/23/14, 13:49:18] Shivang: but becuase of that .. all the smartsync load when to one server (app01)
[7/23/14, 13:49:32] Shivang: and eventually the load started backing up .. to a point where
[7/23/14, 13:49:36] Shivang: it was just TOO SLOW to return back
[7/23/14, 13:49:59] Shivang: the responses
[7/23/14, 13:50:38] Shivang: the problem that the users had .. was because of the fact that the requests took too long to come back .. because 1 adsync cannot handle all the load
[7/23/14, 13:51:08] Shivang: it worked before yesterday deployment BECAUSE I remember restarting apache servers at the EXACT SAME TIME last time we deployed
[7/23/14, 13:51:12] Shivang: and I just did the same thing again .
[7/23/14, 13:51:23] Shivang: and the adsync load is balanced again
[7/23/14, 13:51:29] Shivang: (almost balanced)
[7/23/14, 13:51:52] Shivang: that's what happened
[7/23/14, 13:52:09] Bill Nguyen: how much time do i have between services restart on app servers?
[7/23/14, 13:52:44] Shivang: load balancer is dependent of apache being up or down .. not the services
[7/23/14, 13:53:00] Shivang: so basically restarting apache at the same time on both app servers .. did the trick .. FOR NOW .
[7/23/14, 13:53:26] Bill Nguyen: and adsync?
[7/23/14, 13:53:31] Bill Nguyen: later?
[7/23/14, 13:53:55] Shivang: huh?
[7/23/14, 13:54:05] Shivang: you can start ALL the services ..
[7/23/14, 13:54:10] Shivang: on both the servers
[7/23/14, 13:54:19] Shivang: and eventually start both apaches at the same time
[7/23/14, 13:54:19] Bill Nguyen: ok at the same time?
[7/23/14, 13:54:20] Shivang: that's all
[7/23/14, 13:57:57] denny: Two questions:
1. Anyone can dig out why the load balance requires us to do the apache restart at the same time?
If something wrong with one instance of apache later in prod env, we may run into this issue again.
2. Is there any simple procedure to identify whether load balance is not balancing for us?
[7/23/14, 13:58:22] Shivang: yes. because I said so :)
[7/23/14, 13:58:25] Shivang: LOL .. just kidding
[7/23/14, 13:58:32] Shivang: we use sticky sessions on load balancer
[7/23/14, 13:58:42] Shivang: it load balances ONLY IF YOU START THE SAME TIME
[7/23/14, 13:58:53] Shivang: because if one server is up before the other (one apache is up before the other)
[7/23/14, 13:59:02] Shivang: than load balancer is going to send all the requests to
[7/23/14, 13:59:13] Shivang: the server thats up .. because well .. that's what load balancers do ..
[7/23/14, 13:59:25] Shivang: but because of the STICKY SESSIONs .. the session sticks to that server
[7/23/14, 13:59:37] Shivang: and than never ever gets load balanced .. even though the second server has come up
[7/23/14, 14:00:09] Shivang: so in regards to your questions
[7/23/14, 14:00:17] Shivang: 1) the why? I just mentioned to you
[7/23/14, 14:00:23] Shivang: 2) it is load balancing
[7/23/14, 14:00:26] Shivang: just not the way we want it
[7/23/14, 14:01:32] denny: So if something wrong with one instance of apache later in prod env, we may run into this issue again. Right?
[7/23/14, 14:01:44] Shivang: most definitely
[7/23/14, 14:01:52] Shivang: because one app server is not enough for our loads anymore
[7/23/14, 14:02:12] Shivang: especially the SS load .. unless we find a better architectural way to handle it .. I have some ideas, but not time to implement them
[7/23/14, 14:04:30] denny: Then, we may see this kind of LB escalation issues quite often.
[7/23/14, 14:05:14] Bill Nguyen: I have a solution but i need to work with Denny yet to test and let you know
[7/23/14, 14:05:23] Shivang: and what's the solution ?
[7/23/14, 14:05:30] Shivang: can you share with us so we can give our inputs
[7/23/14, 14:05:50] Bill Nguyen: load balance your adsync server with non sticky sessions
[7/23/14, 14:05:55] Bill Nguyen: will that help?
[7/23/14, 14:08:00] Bill Nguyen: i am heading to the office now thanks for your information Shivang
[7/23/14, 14:08:09] Shivang: ya .. i was thinking more on the sides of "how"
[7/23/14, 14:08:34] Bill Nguyen: let's test it first with you codes and will show you how?
[7/23/14, 14:10:24] denny: Cool.
For question2: Is there any simple procedure to identify whether load balance is not balancing for us?
Will it work, if:
- Keep login the fluig GUI multiple times by scripts
- Tail adsync.log of all adsync service instances.
- If only one log is changed, the load balance is not working.
Any better approach?
[7/23/14, 14:11:24] Shivang: let me think about that for a minute
[7/23/14, 14:12:07] Bill Nguyen: Denny has great questions, we, devops, need to know when the adsyc is not load balance?
[7/23/14, 14:12:26] kungchaowang: Shivang, one question, is the user can not login because of AD server time-out or our adsync server can not react?
[7/23/14, 14:13:09] Shivang: response don't back for 2 minutes
[7/23/14, 14:13:17] kungchaowang: response from where?
[7/23/14, 14:13:30] Shivang: the response is pushed from SS --> adsync
[7/23/14, 14:13:40] Shivang: and adsync cannot handle it because it's already handling other requests
[7/23/14, 14:14:48] kungchaowang: yes, but adsync can not handle it is because the request is still in process, and the reason why it is still in process is because?
(1) waiting from AD server?
(2) waitting for Couchbase to persist?
(3) program run time?
[7/23/14, 14:15:01] Shivang: # 1
[7/23/14, 14:15:30] Shivang: I am throwing 100 balls at you every one second .. and you are able to catch only 90 requests a second
[7/23/14, 14:15:50] Shivang: over time, you will have 10 * number of seconds number of balls
[7/23/14, 14:15:52] Shivang: in your court
[7/23/14, 14:16:25] kungchaowang: ok, if we are always waiting from AD server instead of lacking ADSync CPU power, then if load balancer does work, will the AD server be able to react to both servers?
[7/23/14, 14:16:57] Shivang: ys .. right now the load balancer IS correctly load balancing
[7/23/14, 14:16:59] Shivang: and everything is fine
[7/23/14, 14:18:05] kungchaowang: everything is fine is because of ?
(1) now AD server can react faster?
(2) or is because our internal logic that will be able to allow them to make multiple request while waiting for AD server?
[7/23/14, 14:18:20] Shivang: because now 100 balls are split into 50 balls each
[7/23/14, 14:18:27] Shivang: and each of the servers can handle 50 balls just fine
[7/23/14, 14:18:27] kungchaowang: so, it is (2)
[7/23/14, 14:18:38] Shivang: not OUR internal logic
[7/23/14, 14:18:47] Shivang: its just how dropwizard is working i am guessing
[7/23/14, 14:18:53] Shivang: the internals of dropwizard and jetty
[7/23/14, 14:19:48] kungchaowang: because in the end, we only have one AD server to authenticate for each user anyway, so even we have 100 ADSync server on our side, the response from AD server is constrained I believe.
[7/23/14, 14:20:10] kungchaowang: if that's drop wizard problem, then we should fix drop wizard as well.
[7/23/14, 14:20:37] Shivang: sure .. OR .. don't care about the internals of the services that are already working .. and figure out an issue that we can easily look at
[7/23/14, 14:20:45] Shivang: there is so much you will be able to do at application level kung
[7/23/14, 14:20:56] Shivang: I hope we start looking at this from a higher level perspective
[7/23/14, 14:21:11] kungchaowang: yes, I do agree that we can do something to load balancer
[7/23/14, 14:21:24] Shivang: I am trying to push for this AD refractoring with this team here
[7/23/14, 14:21:26] Shivang: as much as I can
[7/23/14, 14:21:41] Shivang: so when and if we move adsync to load balancer WITHOUT sticky sessions .. we will be able to handle it
[7/23/14, 14:23:17] kungchaowang: maybe first we can do is:
(1) see if there is a setting to expire user's session to server table in load balancer in like 30 minutes.
(2) see if we can have path matching while doing load balancing, so we can have them not sticky session /adsync for load balancing.
[7/23/14, 14:23:57] Shivang: sure ..
[7/23/14, 14:24:15] Shivang: another idea is to have a dedicated env for multiple adsync servers .. and let apache on THAT server
[7/23/14, 14:24:22] Shivang: do the load balancing between all the instances
[7/23/14, 14:24:29] Shivang: WITHIN that physical server ..
[7/23/14, 14:24:39] Shivang: it will work beautifully AFTER we are done with this refractoring
[7/23/14, 14:25:11] Shivang: you see what I am saying ?
[7/23/14, 14:25:21] kungchaowang: Bill, can you help verify if our Brazil IT team can do any of these two things?
(1) see if there is a setting to expire user's session to server table in load balancer in like 30 minutes.
(2) see if we can have path matching while doing load balancing, so we can have them not sticky session /adsync for load balancing.
[7/23/14, 14:25:28] kungchaowang: Shivang, I see what you say
[7/23/14, 14:25:45] kungchaowang: but that means we again have a single point of failure if that server does not work
[7/23/14, 14:25:46] Shivang: but it will only work perfectly AFTER we are done with all commands refractoring
[7/23/14, 14:25:52] Shivang: no .. not true
[7/23/14, 14:25:56] Shivang: we can have multiple servers
[7/23/14, 14:26:41] kungchaowang: yes, I mean the one that handle the distribution, which is apache server
[7/23/14, 14:26:52] Shivang: but we can have multiples of that too
[7/23/14, 14:26:58] Shivang: basically we have 2 app servers
[7/23/14, 14:27:03] Shivang: and on both app servers we have
[7/23/14, 14:27:07] Shivang: 2 adsync servers each
[7/23/14, 14:27:09] Shivang: that's 4 of thedm
[7/23/14, 14:27:10] Shivang: them(
[7/23/14, 14:27:12] Shivang: them*
[7/23/14, 14:28:22] kungchaowang: we can give it a try and see if that would work.
Bill and Denny, do you have any experience on setting up apache load balancer module?
[7/23/14, 14:29:28] Shivang: we want round robin on those .. which basically means ..
[7/23/14, 14:29:38] Shivang: on app01.1 at t=0
[7/23/14, 14:29:43] Shivang: and app01.2 at t=1
[7/23/14, 14:29:45] Bill Nguyen: i don't, i am thinking about other balancers without using sticky session
[7/23/14, 14:29:56] Shivang: remember .. we do need sticky session
[7/23/14, 14:29:58] Shivang: for our users
[7/23/14, 14:30:00] Shivang: no matter what
[7/23/14, 14:30:13] Bill Nguyen: not for adsync right?
[7/23/14, 14:30:21] Shivang: specific to adsync .. no
[7/23/14, 14:30:42] Bill Nguyen: we can route any traffic any way you want?
[7/23/14, 14:30:42] Shivang: if we can turn off for adsync only .. that's even better
[7/23/14, 14:30:55] Bill Nguyen: yes
[7/23/14, 14:30:56] Shivang: can we? i thought load balancer is not allowing you to
[7/23/14, 14:31:05] Bill Nguyen: that is what I am thinking
[7/23/14, 14:31:09] Shivang: have balancing with and without sticky session together
[7/23/14, 14:31:25] Shivang: oh .. ok .. i thought our LB doesn't allow that feature
[7/23/14, 14:31:45] Bill Nguyen: that is what i am checking with the network team right now
[7/23/14, 14:31:51] Shivang: ok .. good
[7/23/14, 14:31:55] Shivang: let us know what you find ..
[7/23/14, 14:33:09] Bill Nguyen: yes that is what i am researching right now
[7/23/14, 14:35:05] kungchaowang: so Bill, here are what we can do for Nimbvs load balanacer:
1) see if there is a setting to expire user's session to server table in load balancer in like 30 minutes.
(2) see if we can have path matching while doing load balancing, so we can have them not sticky session /adsync for load balancing.
second option, for you and Denny, configure apache load balancer to distribute /adsync load into two servers running inside the machine with different ports
[7/23/14, 14:36:36] denny: Kung & Bill, I haven't play apache for that before, but I can have a try this week, and get back to you guys.
[7/23/14, 14:37:36] Bill Nguyen: Denny, I have not either, let's learn it, this is P1?
[7/23/14, 14:37:51] denny: np
[7/23/14, 14:38:22] kungchaowang: yes, you can try on your local VM and see if it would work, since it's internal redirect, just one VM is enough to see if it's working or not.
[7/23/14, 14:39:17] Bill Nguyen: that is what i am thinking
[7/23/14, 14:40:54] Shivang: ok .. i am going for some presentations
[7/23/14, 14:40:59] Shivang: to the team .. i will see you guys in a while
[7/23/14, 14:41:08] Bill Nguyen: have fun
[7/23/14, 14:41:11] Bill Nguyen: see ya
[7/23/14, 14:55:05] Bill Nguyen: @kung: 1) see if there is a setting to expire user's session to server table in load balancer in like 30 minutes. YES, they can set user's session to 30 minutes
[7/23/14, 14:56:11] kungchaowang: Bill, we only expire that session to server load balance table(not expire user's session), if they can do that, please have them set it to 30 mins
[7/23/14, 15:02:28] Bill Nguyen: they can do it right now, why expire the session in 30 minutes would help adsync?
[7/23/14, 15:03:46] kungchaowang: because them it may re-distribute user's session to another server or the same server, give the chance for re-distribution. now it always stick to the same server forever.
[7/23/14, 15:04:31] Bill Nguyen: user will need to relogin if their session expires?
[7/23/14, 15:06:26] kungchaowang: we are not expiring user's session, we are expiring user's session to which machine in the load balancer
[7/23/14, 15:06:59] Bill Nguyen: correct makes sense, requesting now
[7/23/14, 15:07:57] kungchaowang: so Bill, are you sure they can do this in their load balancer? Not expiring user's session, but the info of session to machine redirection
[7/23/14, 15:08:45] Bill Nguyen: yes they can
[7/23/14, 15:09:27] Bill Nguyen: expire the load balancer session we manage our session management ?
[7/23/14, 15:10:17] kungchaowang: Bill, you know we have session management in tomcat
[7/23/14, 15:11:33] kungchaowang: Bill, if you are chatting them on the Lync, please include me and Denny, so I can see if they do understand it. Let me login into lync
[7/23/14, 15:17:52] Bill Nguyen: see my invites?
[7/23/14, 15:17:54] Bill Nguyen: kung
[7/23/14, 17:01:56] Vicente Goetten: Bill, after the change on the Load Balancer
[7/23/14, 17:01:58] Vicente Goetten: how do we look?
[7/23/14, 17:02:19] Shivang: we changed load balancer?
[7/23/14, 17:02:30] Shivang: someone want to fill me in with this? incase something happens I would be aware of the change
[7/23/14, 17:03:19] Bill Nguyen: Shivang, I had the loadbalancer set to 30 minutes "see if there is a setting to expire user's session to server table in load balancer in like 30 minutes."
[7/23/14, 17:03:23] Bill Nguyen: per Kung's request
[7/23/14, 17:03:43] Shivang: so user's wil be logged out every 30 minutes?
[7/23/14, 17:03:55] Bill Nguyen: early in our discussions
[7/23/14, 17:04:07] Shivang: so this potentially still could happen .. every time we start the server .. because till 30 minutes, the sessions will be sticky?
[7/23/14, 17:04:23] kungchaowang: yes, it still stay for 30 mins
[7/23/14, 17:04:41] kungchaowang: do you think we should change it to shorter time?
[7/23/14, 17:04:51] Bill Nguyen: @Shivang, please explain to me how I monitor this adsync?
[7/23/14, 17:05:12] kungchaowang: the one we expire is the table of "what session is directed to what server" in load balancer
[7/23/14, 17:05:47] Shivang: I think i am still missing what will that "exactly" do .. but if you guys think it's good .. i am ok
[7/23/14, 17:05:51] Shivang: i just needed to knwo .. that's all
[7/23/14, 17:06:15] Shivang: and @Bill: The easiest way is pick one AD Token .. and start making the GET call through CURL .. like the way you see in the logs every second
[7/23/14, 17:06:20] Shivang: atleast for now
[7/23/14, 17:06:32] kungchaowang: be honest, I am not sure if 30 mins is good or bad, but we a # to get started, so I pick 30 mins
[7/23/14, 17:07:10] Bill Nguyen: it is a good starting point
[7/23/14, 17:07:23] Shivang: that's fine .. I think we should still work on the apache load balance module if we get a chance .. that will definitely be a lot more stable
[7/23/14, 17:07:30] Shivang: there will be just so much we can do
[7/23/14, 17:07:32] Shivang: in LB
[7/23/14, 17:10:21] denny: @Kung, I personally like 15 min better than 30 min.
It's shorter, to avoid manual intervene sometime.
[7/23/14, 17:20:32] kungchaowang: we can do that, let's see if Lucas can do it

LikeBe the first to like this
No labels Edit Labels
User icon: Denny
Write a comment…
Powered by Atlassian | Terms of Use | Answers | Maintenance Schedule
#+END_EXAMPLE
** Issue: env of BACKEND_HOME is incorrect in fluig-id-messaging-01 node, which caused services fail to start
https://totvslab.atlassian.net/wiki/pages/viewpage.action?pageId=38076684
#+BEGIN_EXAMPLE
Skip to content
Skip to breadcrumbs
Skip to header menu
Skip to action menu
Skip to quick search
Linked Applications
Confluence
Spaces
People
 Create
Quick Search
0


TechOps
Configure
 Edit  Watch  Share
Pages  TechOps Home  Issues List For Service Maintainnce
Skip to end of banner
Go to start of banner
Issue: 2014/07/26 env of BACKEND_HOME is incorrect in fluig-id-messaging-01 node, which caused services fail to start
Skip to end of metadata
Created by Denny Zhang, last modified on Jul 31, 2014 Go to start of metadata
See the list of all issues here: https://totvslab.atlassian.net/wiki/display/TECH/Issues+List+For+Service+maintainnce
Issue Summary:
The issue happened in 2014/07/26. Kung Wang , Bill Nguyen, Denny Zhang and some other colleagues are involved.
Env of BACKEND_HOME was incorrect in fluig-id-messaging-01 node, for some unknown reason.
As a result, we could not start fluig services.
Improvement points:
Detail:
Hi Guys

Just noticed rest and search service is down. I've backup the log, and restart the services.

Two issues here:
1. I noticed BACKEND_HOME env is incorrect! This issue has happened once before.
2. Why rest and search service are down? search.log report some related info, but doesn't tell why.
3. When I check the system, the unallocated free memory is 175MB, while 14GB memory cached.

,-----------
| root@fluig-id-messaging-01:/data/fluigidentity-logs# echo $BACKEND_HOME
| echo $BACKEND_HOME
| /cloudpass/backend
`-----------

,-----------
| root@fluig-id-messaging-01:/data/fluigidentity-logs# free -ml
| free -ml
|              total       used       free     shared    buffers     cached
| Mem:         16043      15868        175          0        281      14547
| Low:         16043      15868        175
| High:            0          0          0
| -/+ buffers/cache:       1039      15003
| Swap:        15293          0      15293
`-----------


,-----------
| root@fluig-id-messaging-01:/data/fluigidentity-logs# tail search.log.bak
| tail search.log.bak
| INFO  [2014-07-26 06:00:11,326] com.totvslabs.idm.service.search.managed.SearchCUDConsumerManager: out: SearchCUDConsumerManager: stop
| DEBUG [2014-07-26 06:00:11,340] com.totvslabs.idm.service.search.managed.GlobalSearchManager:  ================= STOPPING REOPEN THREAD ===============
| DEBUG [2014-07-26 06:00:11,341] com.totvslabs.idm.service.search.core.GlobalSearchCore: stop global search core =========================
| DEBUG [2014-07-26 06:00:11,341] com.totvslabs.idm.service.search.core.GlobalSearchCore: GLOBAL-SEARCH: reopenThread close
| DEBUG [2014-07-26 06:00:11,341] com.totvslabs.idm.service.search.core.GlobalSearchCore: GLOBAL-SEARCH: nrtManager close
| DEBUG [2014-07-26 06:00:11,341] com.totvslabs.idm.service.search.core.GlobalSearchCore: GLOBAL-SEARCH: forceMergeDeletes
| DEBUG [2014-07-26 06:00:12,229] com.totvslabs.idm.service.search.core.GlobalSearchCore: GLOBAL-SEARCH: waitForMerges
| DEBUG [2014-07-26 06:00:12,230] com.totvslabs.idm.service.search.core.GlobalSearchCore: GLOBAL-SEARCH: close
| DEBUG [2014-07-26 06:00:12,350] com.totvslabs.idm.service.search.core.GlobalSearchCore: GLOBAL-SEARCH: indexDirectory close
| DEBUG [2014-07-26 06:00:12,351] com.totvslabs.idm.service.search.managed.ConnectionFactoryManager: HornetQ ConnectionFactoryManager: stop
| root@fluig-id-messaging-01:/data/fluigidentity-logs#
`-----------


________________________________________
From: dennyzhang@openstacker.org [dennyzhang@openstacker.org]
Sent: Saturday, July 26, 2014 1:05 AM
Subject: [2014-07-26_06:05] Health Check Of Fluig Servers Has Failed

"[2014-07-26 06:05:01] Tests Begins\n========== Check 172.20.16.16 failed ==========\n[2014-07-26 06:00:15] ps aux | grep cloud.*search
[2014-07-26 06:00:15] Error: process for given pattern is not running
[2014-07-26 06:00:15] ps aux | grep cloud.*rest
[2014-07-26 06:00:16] Error: process for given pattern is not running
[2014-07-26 06:00:16] ps aux | grep hornetq
[2014-07-26 06:00:16] cat /proc/loadavg | awk -F' ' '{print 4}'
[2014-07-26 06:00:16] free -ml | grep 'buffers/cache' | awk -F' ' '{print }'
[2014-07-26 06:00:16] df | grep ' /$' | awk -F' ' '{print }'
[2014-07-26 06:00:16] Error: some checks fail\n[2014-07-26 06:05:06] Tests end\n"

LikeBe the first to like this
No labels Edit Labels
User icon: Denny
Write a comment…
Powered by Atlassian | Terms of Use | Answers | Maintenance Schedule

#+END_EXAMPLE
** Issue: rmi@app02 use too much cpu
https://totvslab.atlassian.net/wiki/pages/viewpage.action?pageId=41713673
#+BEGIN_EXAMPLE
Skip to content
Skip to breadcrumbs
Skip to header menu
Skip to action menu
Skip to quick search
Linked Applications
Confluence
Spaces
People
 Create
Quick Search
0


TechOps
Configure
 Edit  Watch  Share
Pages  TechOps Home  Issues List For Service Maintainnce
Skip to end of banner
1 JIRA link
Go to start of banner
Issue: 2014/09/11 rmi@app02 use too much cpu
Skip to end of metadata
Created by Denny Zhang on Sep 16, 2014 Go to start of metadata
See the list of all issues here: https://totvslab.atlassian.net/wiki/display/TECH/Issues+List+For+Service+maintainnce
JIRA ticket:   UE-625 - GUI of QA1B runs into 501 error RESOLVED
Issue Summary:
The issue happened in 2014/09/11.  Denny Zhang,  Bill Nguyen and some other colleagues are involved.
rmi service of app02 in prod env looks abnormal.
The CPU usage of rmi jump to 1187%. After several seconds, it drops back to 120%. Then up, then down, then up, etc.

Improvement points:
Detail:
[9/11/14, 10:02:54] denny: denny added Bill Nguyen, kungchaowang, Shivang, Vicente Goetten to this conversation
[9/11/14, 10:13:16] denny: Morning, All.
rmi service of app02 in prod env looks abnormal.
The CPU usage of rmi jump to 1187%. After several seconds, it drops back to 120%. Then up, then down, then up, etc.

@Bill, I'm suspecting it may be the NFS issue. Please find out what's root password of nfs server.
@Shivang, please confirm whether rmi service has something wrong. The log files looks fine to me.
Timestamp is "11 Sep 2014;14:11:44.437"
[9/11/14, 10:14:36] denny: denny set topic to “prod env: RMI @app02”
[9/11/14, 10:14:51] denny: denny set topic to “Prod env: RMI @app02”
[9/11/14, 10:38:13] Bill Nguyen: @denny please show me how you got a report of ap02 rmi service cpu usage jumped to 1187%?
[9/11/14, 10:38:37] denny: Run: watch top
[9/11/14, 10:38:57] Vicente Goetten: Another thing, on qa1b no one que launch app from LaunchPad
[9/11/14, 10:40:14] denny: Vicente, I shall run out of time to track this feature failure today.
Anyone else can help on this?
[9/11/14, 10:41:53] Vicente Goetten: Denny
Let Bill check with us
[9/11/14, 10:44:57] denny: @Bill, would you please help me to get the root password of nfs server?
Let me track the prod env issue.
[9/11/14, 11:04:45] Bill Nguyen: i am deploying new code to app.qa and app.ps service
[9/11/14, 11:06:23] Bill Nguyen: please investigate into this Denny please show me our script and i am not aware of which tools you are using let's talk in private?
[9/11/14, 11:09:01] denny: Sure, just ping me privately.
Also let's talk with John and Suresh, when we have time next time.
- How to automate our release and deploy process for QA envs by jenkins.
[9/11/14, 12:14:01] Shivang: # 1: Need more data than the fact that it jumped to 1187% .. Not sure why that would happen
[9/11/14, 12:14:05] Shivang: is it still like that?
[9/11/14, 12:14:20] Shivang: Bill Denny?
[9/11/14, 12:14:33] Bill Nguyen: yep
[9/11/14, 12:15:30] Bill Nguyen: i am requesting denny for more data to support his stats but have not heard back
[9/11/14, 12:15:32] Shivang: when you say
[9/11/14, 12:15:37] Shivang: it jumped up in %
[9/11/14, 12:15:44] Shivang: 1187% of CPU usage?
[9/11/14, 12:15:49] Shivang: or 1187% of its previous usage?
[9/11/14, 12:16:17] Shivang: 8430 root 20 0 12.6g 4.3g 16m S 62 13.7 8889:50 java
[9/11/14, 12:16:26] Shivang: that doesn't look so bad
[9/11/14, 12:17:17] denny: Yes, 1187% this morning
[9/11/14, 12:17:35] denny: cpu
[9/11/14, 12:17:46] Shivang: % of hwat?
[9/11/14, 12:17:49] Shivang: previous runtime
[9/11/14, 12:17:54] Shivang: of cpu runtime
[9/11/14, 12:17:58] Shivang: i am looking at top now
[9/11/14, 12:18:01] Shivang: app02: 8430 root 20 0 12.6g 4.3g 16m S 45 13.7 8890:34 java
[9/11/14, 12:18:11] Shivang: app01: 49774 root 20 0 12.6g 4.3g 16m S 63 13.2 4462:31 java
[9/11/14, 12:18:25] Shivang: they both don't look too different
[9/11/14, 12:19:26] denny: When I checked this morning, the rest process takes 1187% CPU. Then jump up and down. Now its pretty low
[9/11/14, 12:21:25] Shivang: rest on production?
[9/11/14, 12:21:26] Shivang: or rmi?
[9/11/14, 12:21:31] denny: I'm guessing NSF issue. Bill have u got the password of NSF server yet?
[9/11/14, 12:21:39] denny: Rmi
[9/11/14, 12:22:46] Shivang: the load is dependent on the users logging in and stuff
[9/11/14, 12:22:55] Shivang: so if you think our processors are not able to handle it
[9/11/14, 12:23:05] Shivang: i suggest we ask for better processing power
[9/11/14, 12:24:23] denny: This didn't happen before, not even close this
[9/11/14, 12:24:35] Shivang: tell me about it .. load can happen any time
[9/11/14, 12:24:44] Shivang: how was the app01 at the exact same time do you know?
[9/11/14, 12:24:52] Shivang: and loadbalancer .. where were all the requests going
[9/11/14, 12:24:52] denny: It's fine
[9/11/14, 12:25:16] Shivang: interesting
[9/11/14, 12:25:19] Shivang: give me the exact time
[9/11/14, 12:25:23] Shivang: maybe I can see what was going on
[9/11/14, 12:25:26] Shivang: in the logs at that time
[9/11/14, 12:25:43] denny: Morning, All.
rmi service of app02 in prod env looks abnormal.
The CPU usage of rmi jump to 1187%. After several seconds, it drops back to 120%. Then up, then down, then up, etc.

@Bill, I'm suspecting it may be the NFS issue. Please find out what's root password of nfs server.
@Shivang, please confirm whether rmi service has something wrong. The log files looks fine to me.
Timestamp is "11 Sep 2014;14:11:44.437"
[9/11/14, 12:26:22] Shivang: whats NFS?
[9/11/14, 12:27:53] Shivang: in the logs atleast
[9/11/14, 12:28:02] Shivang: nothing looks out of the ordinary during that minute
[9/11/14, 12:28:03] Shivang: 261006:[11 Sep 2014;14:11:44.033] - [INFO ] [UserServiceInterfaceImpl:1715] - EXTERNAL AUTHENTICATION RESPONSE: true
261007:[11 Sep 2014;14:11:44.034] - [INFO ] [UserServiceInterfaceImpl:1610] - SUCCESS - User successfully validated through External authentication through appId: y6k661wf5a5vh9u11405012401405 and email: ! aluizio.silva@unimedjf.coop.br
261008:[11 Sep 2014;14:11:44.035] - [INFO ] [CompanyServiceInterfaceImpl:204] - GET COMPANY - companyId: zf0y84vo717g8hjx
261009:[11 Sep 2014;14:11:44.040] - [INFO ] [DBUserServiceImpl:707] - GET COMPANY USER - userId: wuorbzxzna3egi7a | companyId: 1
261010:[11 Sep 2014;14:11:44.048] - [INFO ] [CompanyServiceInterfaceImpl:208] - SUCCESS - Company found with companyId: zf0y84vo717g8hjx
261011:[11 Sep 2014;14:11:44.074] - [INFO ] [CompanyServiceInterfaceImpl:619] - GET APPLICATION FOR COMPANY - companyId: zf0y84vo717g8hjx | appId: zuzd6b5526ixu3mp
261012:[11 Sep 2014;14:11:44.096] - [INFO ] [UserServiceInterfaceImpl:872] - GET USER APPLICATION LOGIN NO LAUNCH - userId: wn6tq0wz2g7p94e7 | appId: zuzd6b5526ixu3mp
261013:[11 Sep 2014;14:11:44.099] - [INFO ] [DBUserServiceImpl:707] - GET COMPANY USER - userId: wn6tq0wz2g7p94e7 | companyId: zf0y84vo717g8hjx
261014:[11 Sep 2014;14:11:44.119] - [INFO ] [CompanyServiceInterfaceImpl:619] - GET APPLICATION FOR COMPANY - companyId: zf0y84vo717g8hjx | appId: y6k661wf5a5vh9u11405012401405
261015:[11 Sep 2014;14:11:44.141] - [INFO ] [UserServiceInterfaceImpl:872] - GET USER APPLICATION LOGIN NO LAUNCH - userId: tyuvvpzcdh59pe511404756614395 | appId: y6k661wf5a5vh9u11405012401405
261016:[11 Sep 2014;14:11:44.144] - [INFO ] [UserServiceInterfaceImpl:882] - SUCCESS - User Application Login found with userId: wn6tq0wz2g7p94e7 and appId: zuzd6b5526ixu3mp
261017:[11 Sep 2014;14:11:44.145] - [INFO ] [DBUserServiceImpl:707] - GET COMPANY USER - userId: tyuvvpzcdh59pe511404756614395 | companyId: zf0y84vo717g8hjx
261018:[11 Sep 2014;14:11:44.171] - [INFO ] [DBUserServiceImpl:707] - GET COMPANY USER - userId: wn6tq0wz2g7p94e7 | companyId: zf0y84vo717g8hjx
261019:[11 Sep 2014;14:11:44.178] - [INFO ] [CompanyServiceInterfaceImpl:665] - GET COMPANY CERTIFICATE - companyId: zf0y84vo717g8hjx
261020:[11 Sep 2014;14:11:44.179] - [INFO ] [CompanyServiceInterfaceImpl:1495] - GET PRIVATE KEY - companyId: zf0y84vo717g8hjx
261021:[11 Sep 2014;14:11:44.179] - [INFO ] [DBCompanyServiceImpl:1932] - INFO - GET Key Store - alias (companyId): zf0y84vo717g8hjx
261022:[11 Sep 2014;14:11:44.183] - [INFO ] [UserServiceInterfaceImpl:882] - SUCCESS - User Application Login found with userId: tyuvvpzcdh59pe511404756614395 and appId: y6k661wf5a5vh9u11405012401405
261023:[11 Sep 2014;14:11:44.201] - [INFO ] [DBUserServiceImpl:707] - GET COMPANY USER - userId: tyuvvpzcdh59pe511404756614395 | companyId: zf0y84vo717g8hjx
261024:[11 Sep 2014;14:11:44.205] - [INFO ] [DBUserServiceImpl:707] - GET COMPANY USER - userId: wn6tq0wz2g7p94e7 | companyId: zf0y84vo717g8hjx
261025:[11 Sep 2014;14:11:44.205] - [INFO ] [CompanyServiceInterfaceImpl:665] - GET COMPANY CERTIFICATE - companyId: zf0y84vo717g8hjx
261026:[11 Sep 2014;14:11:44.206] - [INFO ] [CompanyServiceInterfaceImpl:1495] - GET PRIVATE KEY - companyId: zf0y84vo717g8hjx
261027:[11 Sep 2014;14:11:44.206] - [INFO ] [DBCompanyServiceImpl:1932] - INFO - GET Key Store - alias (companyId): zf0y84vo717g8hjx
261028:[11 Sep 2014;14:11:44.228] - [INFO ] [DBUserServiceImpl:707] - GET COMPANY USER - userId: tyuvvpzcdh59pe511404756614395 | companyId: zf0y84vo717g8hjx
261029:[11 Sep 2014;14:11:44.434] - [INFO ] [UserServiceInterfaceImpl:1108] - GET USER BY EMAIL ADDRESS (MULTI-CONTEXT-PERSONAL) - emailAddress: carina.capuci@braile.com.br
261030:[11 Sep 2014;14:11:44.437] - [INFO ] [UserServiceInterfaceImpl:1118] - SUCCESS - User found with email address: carina.capuci@braile.com.br
261031:[11 Sep 2014;14:11:44.466] - [INFO ] [UserServiceInterfaceImpl:1436] - VALIDATE USER (MULTI-CONTEXT-PERSONAL)- emailAddress: carina.capuci@braile.com.br | domain: totvs.fluigidentity.com
261032:[11 Sep 2014;14:11:44.475] - [INFO ] [UserServiceInterfaceImpl:1448] - Cannot validate user with personal credentials .. Checking to see if user has AD account with one of the contexts ..
261033:[11 Sep 2014;14:11:44.476] - [INFO ] [UserServiceInterfaceImpl:1108] - GET USER BY EMAIL ADDRESS (MULTI-CONTEXT-PERSONAL) - emailAddress: carina.capuci@braile.com.br
261034:[11 Sep 2014;14:11:44.482] - [INFO ] [UserServiceInterfaceImpl:1118] - SUCCESS - User found with email address: carina.capuci@braile.com.br
261035:[11 Sep 2014;14:11:44.491] - [INFO ] [CompanyServiceInterfaceImpl:638] - GET COMPLETE APPLICATION FOR COMPANY - companyId: zf0y84vo717g8hjx | appId: 42
261036:[11 Sep 2014;14:11:44.507] - [ERROR] [UserServiceInterfaceImpl:1621] - FAILURE - User cannot be validated with personal credentials AND user does not have Active Directory account linked with any company contexts. Please check username/password: carina.capuci@braile.com.br
261037:[11 Sep 2014;14:11:44.510] - [INFO ] [CompanyServiceInterfaceImpl:638] - GET COMPLETE APPLICATION FOR COMPANY - companyId: zf0y84vo717g8hjx | appId: 42
[9/11/14, 12:28:09] Shivang: very straight forward calls
[9/11/14, 12:28:53] denny: When NSF has problems, CPU is extremely high, due to io fail. This has happened twice for prod env.
[9/11/14, 12:29:35] denny: So Bill, we need password of NSF server. Or who I shall ask to get it?
[9/11/14, 12:37:39] Bill Nguyen: hi denny please send your request to sp datacenter
[9/11/14, 12:38:37] denny: Ok
[9/11/14, 14:57:24] kungchaowang: Denny, from my pass experience, usually this is caused by NFS, same as your assumption as well. Please send our DC team in Brazil and see what they would say.
[9/11/14, 14:57:54] denny: Yes, just did. Thanks, Kung.
LikeBe the first to like this
No labels Edit Labels
User icon: Denny
Write a comment…
Powered by Atlassian | Terms of Use | Answers | Maintenance Schedule
#+END_EXAMPLE
** #  --8<-------------------------- separator ------------------------>8--
** Issue: GUI of QA1B runs into 501 error
https://totvslab.atlassian.net/wiki/pages/viewpage.action?pageId=40599570
#+BEGIN_EXAMPLE
Skip to content
Skip to breadcrumbs
Skip to header menu
Skip to action menu
Skip to quick search
Linked Applications
Confluence
Spaces
People
 Create
Quick Search
0


TechOps
Configure
 Edit  Watch  Share
Pages  TechOps Home  Issues List For Service Maintainnce
Skip to end of banner
1 JIRA link
Go to start of banner
Issue: 2014/09/02 GUI of QA1B runs into 501 error
Skip to end of metadata
Created by Denny Zhang, last modified on Sep 02, 2014 Go to start of metadata
See the list of all issues here: https://totvslab.atlassian.net/wiki/display/TECH/Issues+List+For+Service+maintainnce
JIRA ticket:   UE-625 - GUI of QA1B runs into 501 error RESOLVED
Issue Summary:
The issue happened in 2014/09/02.  Denny Zhang,  Bill Nguyen and some other colleagues are involved.
When opening https://totvs.thecloudpass.com/cloudpass, it runs into 501 errors.

Observations:
apache fail to talk to tomcat, for the GUI login request
apache has some errors messages for rest requests.
rmi.log show two kinds of different exceptions, when handling the request of "GET COMPANY USER"
"Failed to get stats for app  java.lang.NullPointerException: null"
"java.lang.IllegalArgumentException: Key must contain at least one character."

Did a tomcat restart, the problem is gone.
Improvement points:
Nagios monitor tomcat closely: 8009 port, the count of opened file handle
Detail:
qa1b:/var/log/apache2# tail mod_jk.log
tail mod_jk.log
[Tue Sep 02 19:08:10.352 2014] [30617:140169621473024] [error] ajp_service::jk_ajp_common.c (2626): (worker1) connecting to tomcat failed.
[Tue Sep 02 19:08:10.352 2014] [30617:140169621473024] [info] jk_handler::mod_jk.c (2678): Service error=0 for worker=worker1
[Tue Sep 02 19:08:11.008 2014] [30589:140169697007360] [warn] ajp_get_endpoint::jk_ajp_common.c (3185): Unable to get the free endpoint for worker worker1 from 10 slots
[Tue Sep 02 19:08:11.008 2014] [30589:140169697007360] [error] jk_handler::mod_jk.c (2612): Could not get endpoint for worker=worker1
[Tue Sep 02 19:08:11.009 2014] [30589:140169697007360] [info] jk_handler::mod_jk.c (2678): Service error=0 for worker=worker1
[Tue Sep 02 19:08:18.989 2014] [30589:140169579509504] [info] ajp_connection_tcp_get_message::jk_ajp_common.c (1274): (worker1) can't receive the response header message from tomcat, network problems or tomcat (127.0.0.1:8009) is down (errno=11)
[Tue Sep 02 19:08:18.989 2014] [30589:140169579509504] [error] ajp_get_reply::jk_ajp_common.c (2118): (worker1) Tomcat is down or refused connection. No response has been sent to the client (yet)
[Tue Sep 02 19:08:18.989 2014] [30589:140169579509504] [info] ajp_service::jk_ajp_common.c (2607): (worker1) sending request to tomcat failed (recoverable), (attempt=2)
[Tue Sep 02 19:08:18.989 2014] [30589:140169579509504] [error] ajp_service::jk_ajp_common.c (2626): (worker1) connecting to tomcat failed.
[Tue Sep 02 19:08:18.989 2014] [30589:140169579509504] [info] jk_handler::mod_jk.c (2678): Service error=0 for worker=worker1

qa1b:/var/log/apache2# tail qa1b.thecloudpass.com_ssl_error.log
tail qa1b.thecloudpass.com_ssl_error.log
[Tue Sep 02 19:16:14 2014] [error] [client 189.89.45.5] (70007)The timeout specified has expired: proxy: error reading status line from remote server 127.0.0.1:18090
[Tue Sep 02 19:16:14 2014] [error] [client 189.89.45.5] proxy: Error reading from remote server returned by /rest/v2/scim/v2/extensions/Resources/Companies/mdk5ky0ay2hrsqtg1409081369485/Applications/xf8ruwja97b7ohei1409252280094/bb13c6baa0ef4b1e48f2b15347b1124a/link
[Tue Sep 02 19:16:45 2014] [error] [client 189.89.45.5] (70007)The timeout specified has expired: proxy: error reading status line from remote server 127.0.0.1:18090
[Tue Sep 02 19:16:45 2014] [error] [client 189.89.45.5] proxy: Error reading from remote server returned by /rest/v2/scim/v2/extensions/Resources/Companies/mdk5ky0ay2hrsqtg1409081369485/Applications/xf8ruwja97b7ohei1409252280094/a8202e501a37185473a53005a56094db/link
[Tue Sep 02 19:17:16 2014] [error] [client 189.89.45.5] (70007)The timeout specified has expired: proxy: error reading status line from remote server 127.0.0.1:18090
[Tue Sep 02 19:17:16 2014] [error] [client 189.89.45.5] proxy: Error reading from remote server returned by /rest/v2/scim/v2/extensions/Resources/Companies/mdk5ky0ay2hrsqtg1409081369485/Applications/xf8ruwja97b7ohei1409252280094/a8202e501a37185473a53005a56094db/link
[Tue Sep 02 19:17:48 2014] [error] [client 189.89.45.5] (70007)The timeout specified has expired: proxy: error reading status line from remote server 127.0.0.1:18090
[Tue Sep 02 19:17:48 2014] [error] [client 189.89.45.5] proxy: Error reading from remote server returned by /rest/v2/scim/v2/extensions/Resources/Companies/mdk5ky0ay2hrsqtg1409081369485/Applications/xf8ruwja97b7ohei1409252280094/dde81ead1ae451ae984068929c886d6f/link
[Tue Sep 02 19:18:19 2014] [error] [client 189.89.45.5] (70007)The timeout specified has expired: proxy: error reading status line from remote server 127.0.0.1:18090
[Tue Sep 02 19:18:19 2014] [error] [client 189.89.45.5] proxy: Error reading from remote server returned by /rest/v2/scim/v2/extensions/Resources/Companies/mdk5ky0ay2hrsqtg1409081369485/Applications/xf8ruwja97b7ohei1409252280094/dde81ead1ae451ae984068929c886d6f/link

qa1b:/data/fluigidentity-logs# tail -n 1000 rmi.log | grep -i exception -C 5
[02 Sep 2014;19:20:34.409] - [INFO ] [DBUserServiceImpl:722] - GET COMPANY USER - userId: 3m91aehoo0cqiuuf1408622800308 | companyId: oppt2js0psff4nbi1405552238716
[02 Sep 2014;19:20:34.427] - [ERROR] [UserServiceInterfaceImpl:203] - FAILURE - System error occured while trying to retrieve user application logins for user with userId: 3m91aehoo0cqiuuf1408622800308 java.lang.NullPointerException: null
at com.totvslabs.idm.db.services.DBUserServiceImpl.getAllUserApplicationLoginsMap(DBUserServiceImpl.java:1517)
at com.totvslabs.idm.db.services.DBUserServiceImpl.getAllUserApplicationLogins(DBUserServiceImpl.java:1377)
at com.totvslabs.idm.rmi.service.impl.UserServiceInterfaceImpl.getUserApplicationLogins(UserServiceInterfaceImpl.java:199)
at sun.reflect.GeneratedMethodAccessor39.invoke(Unknown Source)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
--
[02 Sep 2014;19:20:51.059] - [INFO ] [CompanyServiceInterfaceImpl:667] - GET COMPANY CERTIFICATE - companyId: pl622a90e1xt274n1405551958681
[02 Sep 2014;19:20:51.060] - [INFO ] [CompanyServiceInterfaceImpl:1497] - GET PRIVATE KEY - companyId: pl622a90e1xt274n1405551958681
[02 Sep 2014;19:20:51.062] - [INFO ] [DBCompanyServiceImpl:2150] - INFO - GET Key Store - alias (companyId): pl622a90e1xt274n1405551958681
[02 Sep 2014;19:20:51.073] - [INFO ] [CompanyServiceInterfaceImpl:235] - SUCCESS - Metadata found for companyId: pl622a90e1xt274n1405551958681 appId: obhvmvitkcnrnlv91408969489584
[02 Sep 2014;19:20:54.115] - [INFO ] [UserServiceInterfaceImpl:1112] - GET USER BY EMAIL ADDRESS (MULTI-CONTEXT-PERSONAL) - emailAddress:
java.lang.IllegalArgumentException: Key must contain at least one character.
at net.spy.memcached.util.StringUtils.validateKey(StringUtils.java:73)
at net.spy.memcached.MemcachedConnection.enqueueOperation(MemcachedConnection.java:745)
at net.spy.memcached.MemcachedClient.asyncGet(MemcachedClient.java:952)
at net.spy.memcached.MemcachedClient.get(MemcachedClient.java:1125)
at net.spy.memcached.MemcachedClient.get(MemcachedClient.java:1151)

LikeBe the first to like this
No labels Edit Labels
User icon: Denny
Write a comment…
Powered by Atlassian | Terms of Use | Answers | Maintenance Schedule

#+END_EXAMPLE
** Issue: QA1B is slow, while rest service and tomcat service are abnormal

#+BEGIN_EXAMPLE
Skip to content
Skip to breadcrumbs
Skip to header menu
Skip to action menu
Skip to quick search
Linked Applications
Confluence
Spaces
People
 Create
Quick Search
0


TechOps
Configure
 Edit  Watch  Share
Pages  TechOps Home  Issues List For Service Maintainnce
Skip to end of banner
Go to start of banner
Issue: 2014/09/01 QA1B is slow, while rest service and tomcat service are abnormal
Skip to end of metadata
Created by Denny Zhang, last modified on Sep 01, 2014 Go to start of metadata
See the list of all issues here: https://totvslab.atlassian.net/wiki/display/TECH/Issues+List+For+Service+maintainnce
Issue Summary:
The issue happened in 2014/09/01.  Kung Wang, Denny Zhang,  Vicente Goetten and some other colleagues are involved.

The QA1B env of fluig is very slow:
Rest service takes 6.8 G memory and 900% CPU, which is way too much.
Tomcat fail to operate, thus GUI login failed.
Improvement points:

Nagios improvement: monitor fd count for 8009 port of tomcat.
Detail:
[9/1/14, 8:20:57] denny: Morning, Kung
[9/1/14, 8:21:53] denny: For the problem of QA1B reported by Alex and Geny:
Rest service looks a bit strange: It's takes 6.7G memory, and our nagios alerting emails also report very slow response of rest
[9/1/14, 8:22:51] denny: And rest service takes 900% CPU.
[9/1/14, 8:53:43] denny: ==============================
Kung, looks like the problem rely on the code. We shall need the dev support for this issue.
[9/1/14, 10:53:09] denny: ========================
Guys, in QA1B apache fail to talk with tomcat, thus fluig GUI fail to load
"https://totvs.thecloudpass.com/cloudpass"
,----------- /var/log/apache2/mod_jk.log
| [Mon Sep 01 14:47:00.370 2014] [477:139910870083328] [info] ajp_connection_tcp_get_message::jk_ajp_common.c (1274): (worker1) can't receive the response header message from tomcat, network problems or tomcat (127.0.0.1:8009) is down (errno=104)
`-----------
[9/1/14, 10:53:22] denny: I'm gonna to restart apache and tomcat, right now.
[9/1/14, 10:58:44] denny: =====================================
Right now, the failure looks like this.
Tomcat fail to contact backend service, thus tomcat refuse connection from apache.
[9/1/14, 10:59:21] denny: @Bill, please monitor the count of opened connection for tomcat, in nagios.
[9/1/14, 10:59:33] denny: Below commands can help: lsof -i tcp:8009 | wc -l
[9/1/14, 11:01:02] denny: @Kung, right now, rest service is still suffering.
Should I restart it? This problem looks like the one happened last Friday.
1. Do you need to keep the env untouched, so you can better trouble shooting the problem?
2. Will restart lead to data inconsistency?
[9/1/14, 11:01:34] Vicente Goetten: it seems that we will need to restart rest
[9/1/14, 11:01:44] Vicente Goetten: I can get resources for the RAC module
[9/1/14, 11:03:35] denny: Vicente, should I restart rest right now, or wait till Kung's response?
[9/1/14, 11:06:27] denny: No significant errors are found in log files. And the system is quite slow


LikeBe the first to like this
No labels Edit Labels
User icon: Denny
Write a comment…
Powered by Atlassian | Terms of Use | Answers | Maintenance Schedule

#+END_EXAMPLE
** Issue: app01 get no ad requests today
https://totvslab.atlassian.net/wiki/pages/viewpage.action?pageId=40599556
#+BEGIN_EXAMPLE
Skip to content
Skip to breadcrumbs
Skip to header menu
Skip to action menu
Skip to quick search
Linked Applications
Confluence
Spaces
People
 Create
Quick Search
0


TechOps
Configure
 Edit  Watch  Share
Pages  TechOps Home  Issues List For Service Maintainnce
Skip to end of banner
Go to start of banner
Issue: 2014/09/01 app01 get no ad requests today
Skip to end of metadata
Created by Denny Zhang, last modified on Sep 01, 2014 Go to start of metadata
See the list of all issues here: https://totvslab.atlassian.net/wiki/display/TECH/Issues+List+For+Service+maintainnce
Issue Summary:
The issue happened in 2014/09/01.  Bill Nguyen, Kung Wang, Denny Zhang, Shivang Shah and some other colleagues are involved.

The prod env are suffering two issues. So far we can login to the fluig GUI with no problems.
Currently app01 gets no ad requests
Both app01 and app02 has some json exceptions in rmi.log
Improvement points:
Detail:

[9/1/14, 7:46:22] denny: Happy Monday, guys!
Looks like app01 get no ad requests, while app02 get 602 requests today.
And I can login to the fluig GUI well.

[9/1/14, 7:56:13] denny:
Morning guys.
I noticed some Json exceptions of rmi.log in app01 and app02.
So far, the system looks good without critical issues.
To see what I'm saying, please run below command:
tail -n 1000 /data/flui*/rmi.log | grep -C 4 'Caused by: com.google.gson.stream.MalformedJsonException'
>,-----------
| root@app1:/data/fluigidentity-logs# tail -n 1000 /data/flui*/rmi.log | grep -C 4 'Caused by: com.google.gson.stream.MalformedJsonException'
| <4 'Caused by: com.google.gson.stream.MalformedJsonException'
| at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:670)
| at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
| at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
| at java.lang.Thread.run(Thread.java:724)
| Caused by: com.google.gson.stream.MalformedJsonException: Expected ':' at line 1 column 27
| at com.google.gson.stream.JsonReader.syntaxError(JsonReader.java:1310)
| at com.google.gson.stream.JsonReader.objectValue(JsonReader.java:762)
| at com.google.gson.stream.JsonReader.peek(JsonReader.java:380)
| at com.google.gson.stream.JsonReader.advance(JsonReader.java:426)
`-----------

LikeBe the first to like this
No labels Edit Labels
User icon: Denny
Write a comment…
Powered by Atlassian | Terms of Use | Answers | Maintenance Schedule

#+END_EXAMPLE
** #  --8<-------------------------- separator ------------------------>8--
** Issue:  Issue with AD - Call with Oncoclinicas
#+BEGIN_EXAMPLE
Skip to content
Skip to breadcrumbs
Skip to header menu
Skip to action menu
Skip to quick search
Linked Applications
Confluence
Spaces
People
 Create
Quick Search
0


TechOps
Configure
 Edit  Watch  Share
Pages  TechOps Home  Issues List For Service Maintainnce
Skip to end of banner
Go to start of banner
Issue: 2014/07/09 Issue with AD - Call with Oncoclinicas
Skip to end of metadata
Created by Denny Zhang, last modified on Jul 31, 2014 Go to start of metadata
See the list of all issues here: https://totvslab.atlassian.net/wiki/display/TECH/Issues+List+For+Service+maintainnce
Issue Summary:
The issue happened in 2014/07/09. Shivang Shah, Don Hu, Vicente Goetten, Denny Zhang and some other colleagues are involved.
This morning Vicente reported an urgent issue to me. He asked me to restart adsync servers.
I've backup adsync log to /data/fluigidentity-logs/adsync.log.bak on app1 and app2.
Then restart adsync servers. After that, I checked adsync.log.bak. But no apparent errors are found.
Improvement points:
It looks like some logic error or corner case of adsync service. Shall we provide a CLI to detect this kind of adsync issue automatically?
Quoted from Vicente's email
Team,
As you may know, (very) early this morning we had another issue with the AD Auth. I’ve just had a call with the CIO from on of our most important customers (Oncoclinicas), where I explained him the situation and what was causing the issue.
I’ve made the following commitments with him:
We will monitor the integration between Fluig Identity and their AD’s every 5’ (Fellipe now has a script that is doing this verification). If there is any issue, we will receive an email. The AD’s for TOTVS SA are also being monitored now.
Tonight we will release to production a fix to the root cause for this issue. I’ll send him an email as soon as we have pushed the fix to prod. I believe Don and Shivang are working on this.
Thanks
Vicente Goetten
+1 650 933-4902   -   goetten@totvs.com
Details:
,----------- Some errors are found in app2, but they don't look like to be a big issue.
| root@app2:/data/fluigidentity-logs# grep -i error adsync.log.bak
| grep -i error adsync.log.bak
| ERROR [2014-07-09 03:07:03,476] com.totvslabs.idm.ldap.adsync.resources.SocialECMResourcesV1: FAILURE - Error occured
| ERROR [2014-07-09 04:56:46,405] com.totvslabs.idm.ldap.adsync.resources.SocialECMResourcesV1: FAILURE - Error occured
| ERROR [2014-07-09 11:25:52,777] com.totvslabs.idm.ldap.adsync.resources.SocialECMResourcesV1: FAILURE - Error occured
| ERROR [2014-07-09 12:49:23,224] com.totvslabs.idm.ldap.adsync.resources.SocialECMResourcesV1: FAILURE - Error occured
| ERROR [2014-07-09 12:56:26,374] com.totvslabs.idm.ldap.adsync.resources.SocialECMResourcesV1: FAILURE - Error occured
| ERROR [2014-07-09 12:56:55,659] com.totvslabs.idm.ldap.adsync.resources.SocialECMResourcesV1: FAILURE - Error occured
| ERROR [2014-07-09 12:57:11,719] com.totvslabs.idm.ldap.adsync.resources.SocialECMResourcesV1: FAILURE - Error occured
| ERROR [2014-07-09 12:57:35,624] com.totvslabs.idm.ldap.adsync.resources.SocialECMResourcesV1: FAILURE - Error occured
| ERROR [2014-07-09 12:58:12,969] com.totvslabs.idm.ldap.adsync.resources.SocialECMResourcesV1: FAILURE - Error occured
| ERROR [2014-07-09 13:00:36,552] com.totvslabs.idm.ldap.adsync.resources.SocialECMResourcesV1: FAILURE - Error occured
`-----------
Related discussion
[7/9/14, 10:24:49] Shivang: no porbem
[7/9/14, 10:24:50] Shivang: all good
[7/9/14, 10:24:59] Shivang: vicente .. can you tell me which user worked and which didn't pleasE?
[7/9/14, 10:25:06] Shivang: do you have a user that worked?
[7/9/14, 10:25:14] Shivang: so i can compare logs from both?
[7/9/14, 10:25:20] Vicente Goetten: goetten@totvs.com was working
[7/9/14, 10:25:27] Vicente Goetten: fluig.jv@totvs.com.br
[7/9/14, 10:25:29] Vicente Goetten: wasn't working
[7/9/14, 10:25:37] Vicente Goetten: and ALL the users on Oncoclinicas
[7/9/14, 10:26:54] Shivang: PS: It wasn't the load balancer
[7/9/14, 10:27:05] Vicente Goetten: what was it?
[7/9/14, 10:27:44] Shivang: remember we had this issue where a message producer thread died ? which is when I proposed a whole new model to redesign ADSync ?
[7/9/14, 10:27:58] Vicente Goetten: [7/9/14, 5:51:18 AM] Fellipe Augusto da Silva: checked TOTVS SS logs, the requests are ok on SmartSync and the push back is being made
[7/9/14, 5:51:21 AM] Fellipe Augusto da Silva: so the prob is adsync
[7/9/14, 10:28:07] Shivang: that is correct
[7/9/14, 10:28:09] Shivang: the problem is adysnc
[7/9/14, 10:28:27] Shivang: INFO [2014-07-09 04:33:15,014] com.totvslabs.idm.ldap.adsync.resources.ADSyncResource: RESULT GOT FROM SMART SYNC: [goetten@totvs.com, T]
INFO [2014-07-09 04:33:15,059] com.totvslabs.idm.ldap.adsync.managed.ADSyncResultTimerManager: * AD Authentication Result: goetten@totvs.com : true
INFO [2014-07-09 12:47:54,942] com.totvslabs.idm.ldap.adsync.resources.ADSyncResource: RESULT GOT FROM SMART SYNC: [goetten@totvs.com, T]
INFO [2014-07-09 12:47:54,951] com.totvslabs.idm.ldap.adsync.managed.ADSyncResultTimerManager: * AD Authentication Result: goetten@totvs.com : true
[7/9/14, 10:28:32] Shivang: tht's you .. when you were able to login
[7/9/14, 10:28:42] Shivang: INFO [2014-07-09 12:34:36,011] com.totvslabs.idm.ldap.adsync.resources.ADSyncResource: RESULT GOT FROM SMART SYNC: [fluig.jv@totvs.com.br, T]
INFO [2014-07-09 12:38:08,514] com.totvslabs.idm.ldap.adsync.resources.ADSyncResource: RESULT GOT FROM SMART SYNC: [fluig.jv@totvs.com.br, T]
INFO [2014-07-09 12:53:36,219] com.totvslabs.idm.ldap.adsync.resources.ADSyncResource: RESULT GOT FROM SMART SYNC: [fluig.jv@totvs.com.br, T]
[7/9/14, 10:28:48] Shivang: thats fluig.jv when it wasn't able to login
[7/9/14, 10:28:59] Shivang: see the difference? your result came back to
[7/9/14, 10:29:01] Shivang: app02
[7/9/14, 10:29:16] Shivang: and it worked because it produced the message just fine (using this com.totvslabs.idm.ldap.adsync.managed.ADSyncResultTimerManager)
[7/9/14, 10:29:38] Shivang: but fluig.jv came back to app01 where this thread has died and thus the message was't produced
[7/9/14, 10:29:51] Vicente Goetten: so what is the issue?
[7/9/14, 10:29:59] Shivang: and if the message is not produced, the authentication result is not send to the core server
[7/9/14, 10:30:23] Shivang: the message producer thread died (or something related to that) .. the very first issue we saw when you were on vacation
[7/9/14, 10:30:25] Yaodong Hu: Hmm
[7/9/14, 10:30:55] Vicente Goetten: Vicente Goetten added Fellipe Augusto da Silva to this conversation
[7/9/14, 10:32:23] Yaodong Hu: So the message client has recovery problem
[7/9/14, 10:33:02] Yaodong Hu: Do we have deadlock?
[7/9/14, 10:33:12] Shivang: message client? not sure what that means .. but from what I think, its the SyncResultTimeManager .. which i am guessing picks up the result from the map every second or so and produces the message
[7/9/14, 10:33:20] Shivang: its not the actual "producer" thats the problem
[7/9/14, 10:33:34] Yaodong Hu: If one client die, the rest should continue working?
[7/9/14, 10:33:34] Shivang: its the timer that GETS THE RESULT and produces the message that's the problem i think
[7/9/14, 10:33:48] Shivang: It's the TimerManager that failed
[7/9/14, 10:34:08] Shivang: and I think there is only one timermanager if I am not mistaken ..
[7/9/14, 10:34:24] Shivang: we have 2 options
[7/9/14, 10:34:28] Shivang: 1) we debug
[7/9/14, 10:34:36] Shivang: 2) we redesign (as we talked Don)
[7/9/14, 10:34:43] Shivang: what do you suggest
[7/9/14, 10:35:02] Yaodong Hu: Debug first?
[7/9/14, 10:36:58] Shivang: definitely ..
[7/9/14, 10:37:09] Shivang: I won't be able to debug much looking at the logs
[7/9/14, 10:37:26] Shivang: all i can tell you is the problem is that timerManager
[7/9/14, 10:37:44] Yaodong Hu: What you mean it failed
[7/9/14, 10:37:57] Shivang: I just showed you the log
[7/9/14, 10:38:02] Shivang: it means that the TimerManager thread
[7/9/14, 10:38:08] Yaodong Hu: Can not send out message?
[7/9/14, 10:38:22] Shivang: no .. it didn't enve PICK UP the result from the inmemory result map
[7/9/14, 10:38:27] Shivang: forget about producing
[7/9/14, 10:38:53] Shivang: A timermanager thread picks up the results from the in memory result map
[7/9/14, 10:38:58] Shivang: and produces the message
[7/9/14, 10:39:07] Shivang: it looks in the inmemory result map every second
[7/9/14, 10:39:20] Shivang: now if the timer manager thread somehow dies
[7/9/14, 10:39:31] Shivang: there is no one to pickup the results from the inmemory map
[7/9/14, 10:40:20] Shivang: does that make sense to you don?
[7/9/14, 10:42:14] Yaodong Hu: Can we debug why the thread is dead
[7/9/14, 10:43:16] Shivang: denny .. would you mind getting the logs downloaded for adsync that you backed up only for app01 and send it over to don please?
LikeBe the first to like this
No labels Edit Labels
User icon: Denny
Write a comment…
Powered by Atlassian | Terms of Use | Answers | Maintenance Schedule
#+END_EXAMPLE
** Issue: fluig-id-cdn-01run to low disk capacity, due to too many directories like /tmp/tmp*
#+BEGIN_EXAMPLE
Skip to content
Skip to breadcrumbs
Skip to header menu
Skip to action menu
Skip to quick search
Linked Applications
Confluence
Spaces
People
 Create
Quick Search
0


TechOps
Configure
 Edit  Watch  Share
Pages  TechOps Home  Issues List For Service Maintainnce
Skip to end of banner
Go to start of banner
Issue: 2014/08/06 fluig-id-cdn-01run to low disk capacity, due to too many directories like /tmp/tmp*
Skip to end of metadata
Created by Denny Zhang, last modified on Aug 07, 2014 Go to start of metadata
See the list of all issues here: https://totvslab.atlassian.net/wiki/display/TECH/Issues+List+For+Service+maintainnce
Issue Summary:
The issue happened in 2014/08/05. Kung Wang , Denny Zhang and some other colleagues are involved.
Only 17% free disk capacity in fluig-id-cdn-01(172.20.16.13).

There're 95485 directories like /tmp/tmpoDJk4j, which consume 33MB or 7.9MB disk.
The generating rate of /tmp/tmp* is every 5 minutes.

The root cause is: we have a nagios check which will simulate GUI login every 5 minutes.
The code will call selenium to do the job, which will create a tmp directory every time.
We should delete the tmp directory after the test.
Improvement points:
Bug fix: https://github.com/TOTVS/devop/commit/927fa8c456b0d5f4e841d3b36704858e49847bb4

Detail:
root@fluig-id-cdn-01:~# df -h
df -h
Filesystem Size Used Avail Use% Mounted on
/dev/sda1 99G 83G 12G 89% /
udev 989M 12K 989M 1% /dev
tmpfs 400M 736K 399M 1% /run
none 5.0M 0 5.0M 0% /run/lock
none 998M 0 998M 0% /run/shm
root@fluig-id-cdn-01:~#

root@fluig-id-cdn-01:~# ls -lth /tmp/tmp* | wc -l
ls -lth /tmp/tmp* | wc -l
95485

root@fluig-id-cdn-01:~# du -h -d 1 /tmp
du -h -d 1 /tmp
7.9M /tmp/tmpCtL2p2
7.9M /tmp/tmp7MkJjI
33M /tmp/tmp8hFiu5
7.9M /tmp/tmpCfGLAZ
7.9M /tmp/tmpnhj_BE
7.9M /tmp/tmpbeICiu
7.9M /tmp/tmpngYB_a
7.9M /tmp/tmpcHVE9t
7.9M /tmp/tmp0c1C80
7.9M /tmp/tmp9jzUaQ
7.9M /tmp/tmpNxN2dA
7.9M /tmp/tmpmjzbkh
35M /tmp/tmpoDJk4j
7.9M /tmp/tmpa0Ix9B
7.9M /tmp/tmpvQbqzc
7.9M /tmp/tmp6z01XL
7.9M /tmp/tmpwcRrM1
33M /tmp/tmpVI3WLy
...
...
root@fluig-id-cdn-01:~# tree /tmp/tmp7MkJjI
tree /tmp/tmp7MkJjI
/tmp/tmp7MkJjI
├── amd64
│   └── x_ignore_nofocus.so
├── extensions
│   └── fxdriver@googlecode.com
│   ├── chrome.manifest
│   ├── components
│   │   ├── bad_cert_listener.js
│   │   ├── command_processor.js
│   │   ├── driver_component.js
│   │   ├── httpd.js
│   │   ├── modifier_keys.js
│   │   ├── nsICommandProcessor.xpt
│   │   ├── nsIHttpServer.xpt
│   │   ├── nsINativeEvents.xpt
│   │   ├── nsINativeIME.xpt
│   │   ├── nsINativeKeyboard.xpt
│   │   ├── nsINativeMouse.xpt
│   │   ├── nsIResponseHandler.xpt
│   │   ├── prompt_service.js
│   │   ├── session.js
│   │   ├── session_store.js
│   │   ├── synthetic_mouse.js
│   │   ├── wdICoordinate.xpt
│   │   ├── wdIModifierKeys.xpt
│   │   ├── wdIMouse.xpt
│   │   └── wdIStatus.xpt
│   ├── content
│   │   ├── dommessenger.js
│   │   ├── fx4driver.xul
│   │   ├── fxdriver.xul
│   │   └── server.js
│   ├── install.rdf
│   ├── platform
│   │   ├── Linux_x86_64-gcc3
│   │   │   └── components
│   │   │   ├── libwebdriver-firefox-esr-latest.so
│   │   │   ├── libwebdriver-firefox-esr-previous.so
│   │   │   ├── libwebdriver-firefox-latest.so
│   │   │   └── libwebdriver-firefox-previous.so
│   │   ├── Linux_x86-gcc3
│   │   │   └── components
│   │   │   ├── libwebdriver-firefox-esr-latest.so
│   │   │   ├── libwebdriver-firefox-esr-previous.so
│   │   │   ├── libwebdriver-firefox-latest.so
│   │   │   └── libwebdriver-firefox-previous.so
│   │   └── WINNT_x86-msvc
│   │   └── components
│   │   ├── imehandler.dll
│   │   ├── webdriver-firefox-esr-latest.dll
│   │   ├── webdriver-firefox-esr-previous.dll
│   │   ├── webdriver-firefox-latest.dll
│   │   └── webdriver-firefox-previous.dll
│   └── resource
│   ├── evaluate.js
│   ├── json2.js
│   └── modules
│   ├── timer.js
│   └── web_element_cache.js
├── user.js
└── x86
└── x_ignore_nofocus.so
15 directories, 46 files
root@fluig-id-cdn-01:~# tree /tmp/tmpCtL2p2
tree /tmp/tmpoDJk4j
/tmp/tmpoDJk4j
├── amd64
│   └── x_ignore_nofocus.so
├── blocklist.xml
├── bookmarkbackups
├── browser_log1285160515615.txt
├── Cache
│   ├── 0
│   │   ├── 1C
│   │   │   └── EF820d01
│   │   ├── BF
│   │   │   └── DDC02d01
│   │   └── EF
│   │   └── BAA4Bd01
│   ├── 1
│   ├── 2
│   ├── 3
│   ├── 4
│   │   ├── 3D
│   │   │   └── B020Dd01
│   │   └── 7B
│   │   └── EB0CEd01
│   ├── 5
│   │   └── 47
│   │   └── B8648d01
│   ├── 6
│   ├── 7
│   ├── 8
│   ├── 9
│   ├── A
│   ├── B
│   ├── C
│   ├── _CACHE_001_
│   ├── _CACHE_002_
│   ├── _CACHE_003_
│   ├── _CACHE_MAP_
│   ├── D
│   ├── E
│   │   └── 6F
│   │   └── 016C8d01
│   └── F
├── cache2
│   ├── doomed
│   └── entries
├── _CACHE_CLEAN_
├── cert8.db
├── compatibility.ini
├── content-prefs.sqlite
├── cookies.sqlite
├── driver_log407529123381.txt
├── extensions
│   └── fxdriver@googlecode.com
│   ├── chrome.manifest
│   ├── components
│   │   ├── bad_cert_listener.js
│   │   ├── command_processor.js
│   │   ├── driver_component.js
│   │   ├── httpd.js
│   │   ├── modifier_keys.js
│   │   ├── nsICommandProcessor.xpt
│   │   ├── nsIHttpServer.xpt
│   │   ├── nsINativeEvents.xpt
│   │   ├── nsINativeIME.xpt
│   │   ├── nsINativeKeyboard.xpt
│   │   ├── nsINativeMouse.xpt
│   │   ├── nsIResponseHandler.xpt
│   │   ├── prompt_service.js
│   │   ├── session.js
│   │   ├── session_store.js
│   │   ├── synthetic_mouse.js
│   │   ├── wdICoordinate.xpt
│   │   ├── wdIModifierKeys.xpt
│   │   ├── wdIMouse.xpt
│   │   └── wdIStatus.xpt
│   ├── content
│   │   ├── dommessenger.js
│   │   ├── fx4driver.xul
│   │   ├── fxdriver.xul
│   │   └── server.js
│   ├── install.rdf
│   ├── platform
│   │   ├── Linux_x86_64-gcc3
│   │   │   └── components
│   │   │   ├── libwebdriver-firefox-esr-latest.so
│   │   │   ├── libwebdriver-firefox-esr-previous.so
│   │   │   ├── libwebdriver-firefox-latest.so
│   │   │   └── libwebdriver-firefox-previous.so
│   │   ├── Linux_x86-gcc3
│   │   │   └── components
│   │   │   ├── libwebdriver-firefox-esr-latest.so
│   │   │   ├── libwebdriver-firefox-esr-previous.so
│   │   │   ├── libwebdriver-firefox-latest.so
│   │   │   └── libwebdriver-firefox-previous.so
│   │   └── WINNT_x86-msvc
│   │   └── components
│   │   ├── imehandler.dll
│   │   ├── webdriver-firefox-esr-latest.dll
│   │   ├── webdriver-firefox-esr-previous.dll
│   │   ├── webdriver-firefox-latest.dll
│   │   └── webdriver-firefox-previous.dll
│   └── resource
│   ├── evaluate.js
│   ├── json2.js
│   └── modules
│   ├── timer.js
│   └── web_element_cache.js
├── extensions.ini
├── extensions.json
├── key3.db
├── localstore.rdf
├── mimeTypes.rdf
├── minidumps
├── permissions.sqlite
├── places.sqlite
├── prefs.js
├── profiler_log1163819175156.txt
├── safebrowsing
│   ├── test-malware-simple.cache
│   ├── test-malware-simple.pset
│   ├── test-malware-simple.sbstore
│   ├── test-phish-simple.cache
│   ├── test-phish-simple.pset
│   └── test-phish-simple.sbstore
├── search.json
├── secmod.db
├── sessionCheckpoints.json
├── sessionstore.js
├── startupCache
│   └── startupCache.8.little
├── thumbnails
├── user.js
├── webapps
│   └── webapps.json
├── webappsstore.sqlite
└── x86
└── x_ignore_nofocus.so
48 directories, 87 files
root@fluig-id-cdn-01:~# tree /tmp/tmp7MkJjI
tree /tmp/tmp7MkJjI
/tmp/tmp7MkJjI
├── amd64
│   └── x_ignore_nofocus.so
├── extensions
│   └── fxdriver@googlecode.com
│   ├── chrome.manifest
│   ├── components
│   │   ├── bad_cert_listener.js
│   │   ├── command_processor.js
│   │   ├── driver_component.js
│   │   ├── httpd.js
│   │   ├── modifier_keys.js
│   │   ├── nsICommandProcessor.xpt
│   │   ├── nsIHttpServer.xpt
│   │   ├── nsINativeEvents.xpt
│   │   ├── nsINativeIME.xpt
│   │   ├── nsINativeKeyboard.xpt
│   │   ├── nsINativeMouse.xpt
│   │   ├── nsIResponseHandler.xpt
│   │   ├── prompt_service.js
│   │   ├── session.js
│   │   ├── session_store.js
│   │   ├── synthetic_mouse.js
│   │   ├── wdICoordinate.xpt
│   │   ├── wdIModifierKeys.xpt
│   │   ├── wdIMouse.xpt
│   │   └── wdIStatus.xpt
│   ├── content
│   │   ├── dommessenger.js
│   │   ├── fx4driver.xul
│   │   ├── fxdriver.xul
│   │   └── server.js
│   ├── install.rdf
│   ├── platform
│   │   ├── Linux_x86_64-gcc3
│   │   │   └── components
│   │   │   ├── libwebdriver-firefox-esr-latest.so
│   │   │   ├── libwebdriver-firefox-esr-previous.so
│   │   │   ├── libwebdriver-firefox-latest.so
│   │   │   └── libwebdriver-firefox-previous.so
│   │   ├── Linux_x86-gcc3
│   │   │   └── components
│   │   │   ├── libwebdriver-firefox-esr-latest.so
│   │   │   ├── libwebdriver-firefox-esr-previous.so
│   │   │   ├── libwebdriver-firefox-latest.so
│   │   │   └── libwebdriver-firefox-previous.so
│   │   └── WINNT_x86-msvc
│   │   └── components
│   │   ├── imehandler.dll
│   │   ├── webdriver-firefox-esr-latest.dll
│   │   ├── webdriver-firefox-esr-previous.dll
│   │   ├── webdriver-firefox-latest.dll
│   │   └── webdriver-firefox-previous.dll
│   └── resource
│   ├── evaluate.js
│   ├── json2.js
│   └── modules
│   ├── timer.js
│   └── web_element_cache.js
├── user.js
└── x86
└── x_ignore_nofocus.so
15 directories, 46 files
root@fluig-id-cdn-01:~#


LikeBe the first to like this
No labels Edit Labels
User icon: Denny
Write a comment…
Powered by Atlassian | Terms of Use | Answers | Maintenance Schedule
#+END_EXAMPLE
** Issue: Can't ssh to servers
#+BEGIN_EXAMPLE
Skip to content
Skip to breadcrumbs
Skip to header menu
Skip to action menu
Skip to quick search
Linked Applications
Confluence
Spaces
People
 Create
Quick Search
0


TechOps
Configure
 Edit  Watch  Share
Pages  TechOps Home  Issues List For Service Maintainnce
Skip to end of banner
Go to start of banner
Issue: 2014/08/01 Can't ssh to servers
Skip to end of metadata
Created by Denny Zhang, last modified on Aug 01, 2014 Go to start of metadata
See the list of all issues here: https://totvslab.atlassian.net/wiki/display/TECH/Issues+List+For+Service+maintainnce
Issue Summary:
The issue happened in 2014/08/01.  Bill Nguyen, Denny Zhang, and some other colleagues are involved.
We can't ssh to servers of prod env.

Improvement points:


Detail:
From: Willian Antonio Guedes dos Santos <willian.guedes@totvs.com.br>
Subject: RES: Can't ssh to fluig servers of prod env
To: Paulo Roberto Nobuo Maekawa <nobuo@totvs.com.br>, Denny Zhang
<denny.zhang@totvs.com>, sp.datacenter.gc <sp.datacenter.gc@totvs.com.br>,
Christopher Giese <christopher.giese@totvs.com.br>, Lucas Ciriaco dos Santos
<lucas.ciriaco@totvs.com.br>
CC: Bill Nguyen <bill.nguyen@totvs.com>, Kung Wang <kung.wang@totvs.com>
Date: Fri, 01 Aug 2014 06:38:27 -0500
Good morning,
Configured access. Please test.
Regards,
http:// http:// http:// http://
images.zartana.com/137/ images.zartana.com/ images.zartana.com/137 images.zartana.com/
assinaturaformspring.jpg 137/ / 137/
assinaturatwitter.jpg assinaturafacebook.jpg assinaturayoutube.jpg

TOTVS Willian Guedes
TOTVS IDSI – Infraestrutura,
Datacenters e Segurança da
Informação
willian.guedes@totvs.com.br
Tel +55 11 2099 8274

Cel +55 11 99156 3102
De: Paulo Roberto Nobuo Maekawa
Enviada em: sexta-feira, 1 de agosto de 2014 08:16
Para: Denny Zhang; sp.datacenter.gc; Christopher Giese; Willian Antonio Guedes dos Santos; Lucas
Ciriaco dos Santos
Cc: Bill Nguyen; Kung Wang
Assunto: RES: Can't ssh to fluig servers of prod env
Christopher / Lucas / Willian
Cay you verify this problem?
cid:image001.png@01CF160E.33FDFBB0 Paulo Roberto Nobuo Maekawa
IDSI – Infraestrutura, Datacenter e Segurança da
Informação
paulo.maekawa@totvs.com.br

Cel +55 11 99977 3614 / +55 11 99197 9869
De: Denny Zhang
Enviada em: sexta-feira, 1 de agosto de 2014 02:19
Para: sp.datacenter.gc
Cc: Bill Nguyen; Kung Wang; Denny Zhang
Assunto: Can't ssh to fluig servers of prod env
Hi Guys
We can't ssh to any servers of prod env. Would you please help to figure out why?
Half an hour ago, I can. But now I can't.
,-----------
| ➜ ~ ssh root@172.20.16.13
| ssh: connect to host 172.20.16.13 port 22: Operation timed out
`-----------
Regards,
Denny
LikeBe the first to like this
No labels Edit Labels
User icon: Denny
Write a comment…
Powered by Atlassian | Terms of Use | Answers | Maintenance Schedule

#+END_EXAMPLE
** Issue: www.fluigidentity.com and app.fluigidentity.com DOWN
#+BEGIN_EXAMPLE
Skip to content
Skip to breadcrumbs
Skip to header menu
Skip to action menu
Skip to quick search
Linked Applications
Confluence
Spaces
People
 Create
Quick Search
0


TechOps
Configure
 Edit  Watch  Share
Pages  TechOps Home  Issues List For Service Maintainnce
Skip to end of banner
Go to start of banner
Issue: 2014/08/17 www.fluigidentity.com and app.fluigidentity.com DOWN
Skip to end of metadata
Created by Denny Zhang, last modified by Bill Nguyen on Aug 17, 2014 Go to start of metadata
Bill,
I have escalated this. Whenever they reply to you, please forward to me and Kung.
Thanks
Vicente Goetten
+1 650 933-4902   -   goetten@totvs.com
From: Bill Nguyen <bill.nguyen@totvs.com>
Organization: Totvs
Reply-To: Bill Nguyen <bill.nguyen@totvs.com>
Date: Sunday, August 17, 2014 at 2:57 AM
To: Vicente Goetten <goetten@totvs.com>, Kung Wang <kung.wang@totvs.com>
Cc: Denny Zhang <denny.zhang@totvs.com>, Bill Nguyen <bill.nguyen@totvs.com>
Subject: Fluigidentity was down
Hi Vicente/Kung:

fluigIdentity was DOWN    @12:46 AM-PST 08/17 and UP @02:40AM-PST 08/17 due to network issues.  Alex and Network team were able to bring the network up at 1:58AM.
Alex will send me status on what happened.

All our services were up and running but I restart frontend services just case.  I have LIVE status for fluigidentity.
In Additions, the connectivity from totvslabs to Nimbvs was also down.  This is third time in less than 10 days.

Thanks,
-Bill

##### TODO
        * Following up with Alex and network for what happened
        * Devops needs to have direct VPN to NIMBVS data center
LikeBe the first to like this
No labels Edit Labels
User icon: Denny
Write a comment…
Powered by Atlassian | Terms of Use | Answers | Maintenance Schedule

#+END_EXAMPLE
** Issue: Not a single AD request happen in both app01 and app02
#+BEGIN_EXAMPLE
Skip to content
Skip to breadcrumbs
Skip to header menu
Skip to action menu
Skip to quick search
Linked Applications
Confluence
Spaces
People
 Create
Quick Search
0


TechOps
Configure
 Edit  Watch  Share
Pages  TechOps Home  Issues List For Service Maintainnce
Skip to end of banner
Go to start of banner
Issue: 2014/08/11 Not a single AD request happen in both app01 and app02
Skip to end of metadata
Created by Denny Zhang, last modified on Aug 12, 2014 Go to start of metadata
See the list of all issues here: https://totvslab.atlassian.net/wiki/display/TECH/Issues+List+For+Service+maintainnce
Issue Summary:
The issue happened in 2014/08/11.  Bill Nguyen, Kung Wang, Denny Zhang and some other colleagues are involved.

When users have adsync request, in adsync.log, we will have logs like "RESULT GOT FROM SMART SYNC".
But we didn't find even one XX.XX@XX.XX happen in both app01 and app02 for today.
Run this: "tail -n 100000 /data/fluigidentity-logs/adsync.log | grep '2014-08-11.*RESULT GOT FROM SMART SYNC' | awk -F ':' '{print $5}' | sort | uniq"

Improvement points:
Detail:
root@app1:~# tail -n 100000 /data/fluigidentity-logs/adsync.log | grep '2014-08-11' | wc -l
< /data/fluigidentity-logs/adsync.log | grep '2014-08-11' | wc -l
17602

root@app2:~# tail -n 100000 /data/fluigidentity-logs/adsync.log | grep '2014-08-11' | wc -l
< /data/fluigidentity-logs/adsync.log | grep '2014-08-11' | wc -l
54088

root@app1:~# tail -n 10000 /var/log/apache2/www.fluigidentity.com_ssl_access.log | grep "11/Aug/2014" | grep "adcommand/get" | cut -d" " -f1 | sort | uniq -c
<rep "adcommand/get" | cut -d" " -f1 | sort | uniq -c
5893 177.43.102.244
27 189.3.5.210
27 200.216.73.130
27 201.31.227.162
807 201.44.251.2
2002 201.48.226.194

root@app2:~# tail -n 10000 /var/log/apache2/www.fluigidentity.com_ssl_access.log | grep "11/Aug/2014" | grep "adcommand/get" | cut -d" " -f1 | sort | uniq -c
<rep "adcommand/get" | cut -d" " -f1 | sort | uniq -c
176 187.115.142.221
2291 187.94.61.249
172 201.18.224.190


root@app1:~# tail -n 100000 /data/fluigidentity-logs/adsync.log | grep '2014-08-11.*RESULT GOT FROM SMART SYNC' | awk -F ':' '{print $5}' | sort | uniq
<-11.*RESULT GOT FROM SMART SYNC' | awk -F ':' '{print $5}' | sort | uniq
[adriana.ferreira@totvs.com.br, T]
[adriana.goncalves@totvs.com.br, T]
[adriana.soares@totvs.com.br, T]
[adriano.deus@totvs.com.br, T]
[adriano.oliveira@totvs.com.br, T]
[agda.gill@totvs.com.br, T]
[aguinaldo.neto@totvs.com.br, F]
[aguinaldo.neto@totvs.com.br, F, andre.balieiro@totvs.com.br, T]
[aida.matos@totvs.com.br, T, ana.roque@totvs.com.br, T]
[ailton.santos@totvs.com.br, T]
[alan.sousa@totvs.com.br, T]
[alberth.santos@totvs.com.br, T, felipe.chagas@totvs.com.br, T]
[alcinei@totvs.com.br, F]
[alcinei@totvs.com.br, T]
[aldo.marini@totvs.com.br, T]
[alessandra.castro@totvs.com.br, T]
[alexandre.chiari@totvs.com.br, T]
[alexandre.figueira@totvs.com.br, T]
[alexandre.horvath@totvs.com.br, T]
[alexandre.kuhnen@totvs.com.br, T]
[alexandre.lavrador@totvs.com.br, T]
[alexandre.lelis@totvs.com.br, T]
[alexandre.lelis@totvs.com.br, T, matheus.balbi@totvs.com.br, F]
[alexandreoliveira@totvs.com.br, T]
[alexandre.smelo@totvs.com.br, F]
[alex.lima@totvs.com.br, T]
[alexneves@totvs.com.br, F]
[alexneves@totvs.com.br, T]
[alex.reis@totvs.com.br, T]
[alexsandra.silva@totvs.com.br, T]
[alfredo@totvs.com.br, F]
[aline.correa@totvs.com.br, T]
[aline.freitas@totvs.com.br, T]
[aline.mafra@totvs.com.br, T]
[aline.muslera@totvs.com.br, T]
[aline.silverio@totvs.com.br, T]
[aline.ssa@totvs.com.br, F]
[alison.goncalves@totvs.com.br, T]
[alisson.pinheiro@totvs.com.br, T]
[allan.jordao@totvs.com.br, F]
[almirveridiano@totvs.com.br, T]
[alr@totvs.com.br, T]
[altamir.silva@totvs.com.br, T]
[altenir.gama@totvs.com.br, T]
[aluisio.mathias@totvs.com.br, T]
[alvaro.bessa@totvs.com.br, T]
[amanda.araujo@totvs.com.br, F]
[amanda.araujo@totvs.com.br, T]
[amanda.souza@totvs.com.br, T]
[ana.branco@totvs.com.br, T]
[anacristina.lima@totvs.com.br, T]
[ana.fsouza@totvs.com.br, F]
[ana.lucia@totvs.com.br, T]
[ana.medeiros@totvs.com.br, T]
[ana.puga@totvs.com.br, T]
[ana.roque@totvs.com.br, F, lilian.dutra@totvs.com.br, T]
[anderson.brito@totvs.com.br, T]
[anderson.ceribele@totvs.com.br, T]
[anderson.ciriaco@totvs.com.br, T]
[anderson.francisco@totvs.com.br, T]
[anderson.scheppa@totvs.com.br, T]
[andrea.gaspar@totvs.com.br, F]
[andrea.gaspar@totvs.com.br, T]
[andre.campos@totvs.com.br, T]
[andre.franca@totvs.com.br, T]
[andrei.passos@totvs.com.br, F, angelica.rodrigues@totvs.com.br, F]
[andrei.passos@totvs.com.br, T, paulo.cjunior@totvs.com.br, T]
[andremaia@guarany.com.br, F]
[andremaia@guarany.com.br, T]
[andre.moraes@totvs.com.br, T]
[andre.osilva@totvs.com.br, T]
[andressa.rovaron@totvs.com.br, T]
[andre.ssilva@totvs.com.br, T]
[andre.s@totvs.com.br, T]
[andre.tavares@totvs.com.br, F]
[andre.tavares@totvs.com.br, T]
[andre.trindade@totvs.com.br, T]
[angela.alves@totvs.com.br, T]
[angela.ferreira@totvs.com.br, F]
[angela.ferreira@totvs.com.br, T]
[angelica.rodrigues@totvs.com.br, F]
[angelica.rodrigues@totvs.com.br, T]
[antonio.maria@totvs.com.br, F]
[antonio.seroque@totvs.com.br, T]
[antonio.tartari@totvs.com.br, T]
[apjr@totvs.com.br, T]
[ariclenes.costa@totvs.com.br, T]
[arnaldo.germanio@totvs.com.br, F]
[arnaldo.germanio@totvs.com.br, T]
[aron.constantino@totvs.com.br, T]
[arquimedes.pires@totvs.com.br, T]
[athos.camargo@totvs.com.br, T]
[atus.rodrigues@totvs.com.br, T]
[barbara.silva@fluig.com, F]
[beatriz.basilio@totvs.com.br, T]
[beatriz.dutra@totvs.com.br, T]
[beatriz.santiago@totvs.com.br, T]
[beatriz.sousa@totvs.com.br, T]
[beatriz.vilar@totvs.com.br, T]
[benedet@totvs.com.br, T]
[bianca.goncalves@totvs.com.br, T]
[bianca.marques@totvs.com.br, T]
[bruna.beserra@totvs.com.br, T]
[bruna.sena@totvs.com.br, T]
[bruno.arquinto@totvs.com.br, F]
[bruno.diniz@totvs.com.br, F]
[bruno.diniz@totvs.com.br, T]
[bruno.dossantos@totvs.com.br, T]
[bruno.erdei@totvs.com.br, T]
[bruno.faria@totvs.com.br, T]
[bruno.ferreira@totvs.com.br, T]
[bruno.holanda@totvs.com.br, T]
[bruno.marcondes@totvs.com.br, T]
[bruno.oliveira@totvs.com.br, T]
[bruno.pinheiro@totvs.com.br, T]
[bruno.possamai@totvs.com.br, T]
[bruno.riali@totvs.com.br, T]
[bruno.sousa@totvs.com.br, T]
[bruno.viana@totvs.com.br, T]
[caio.araujo@fluig.com, T]
[caio.pereira@totvs.com.br, T]
[cals@totvs.com.br, T]
[camila.maior@totvs.com.br, T]
[camila.norberto@totvs.com.br, T]
[carla.castro@totvs.com.br, T]
[carlos.asantos@totvs.com.br, F]
[carlos.costa@totvs.com.br, T]
[carlos.guedes@totvs.com.br, F]
[carlos.guedes@totvs.com.br, T]
[carlos.henrique2@totvs.com.br, T]
[carlos.lemes@totvs.com.br, T]
[carlos.mancini@totvs.com.br, T]
[carlos.niemeyer@totvs.com.br, T]
[carlos.pestana@totvs.com.br, T]
[carlos.peteruci@totvs.com.br, T]
[carlos.prais@totvs.com.br, T]
[carlos.souza@totvs.com.br, F]
[carlos.souza@totvs.com.br, T]
[carmeliza.almeida@totvs.com.br, T]
[carmem.ferreira@totvs.com.br, T]
[carolina.darre@totvs.com.br, T]
[carolina.nascimento@totvs.com.br, T]
[caroline.almeida@totvs.com.br, T]
[caroline.bernardo@totvs.com.br, T]
[caroliny@totvs.com.br, T]
[cassia.bezerra@totvs.com.br, F]
[cassio@totvs.com.br, T]
[cbarao@totvs.com.br, T]
[cecilia.bortoleto@totvs.com.br, F]
[cecilia.bortoleto@totvs.com.br, T]
[celi.miyuki@totvs.com.br, F]
[celi.miyuki@totvs.com.br, T]
[celso.carneiro@totvs.com.br, F]
[celso.carneiro@totvs.com.br, T]
[cepferreira@totvs.com.br, T, josiane.neves@totvs.com.br, F]
[cesar.nascimento@totvs.com.br, T]
[charles.resin@totvs.com.br, T]
[cintia.dias@totvs.com.br, F]
[cintia.dias@totvs.com.br, T]
[clara.jesus@totvs.com.br, T]
[claudia.mazanati@totvs.com.br, F]
[claudia.salib@totvs.com.br, T]
[claudiney.coelho@totvs.com.br, T]
[claudio.manccini@totvs.com.br, T]
[claudiomiro.walter@totvs.com.br, T]
[claudio.moreno@totvs.com.br, F]
[claudio.moreno@totvs.com.br, T]
[claudio.silva@totvs.com.br, T]
[claudirene.ferreira@totvs.com.br, T]
[clea.brena@totvs.com.br, T]
[cleber.costa@totvs.com.br, F]
[cleber.manocchi@totvs.com.br, F, cassio@totvs.com.br, T]
[cleber.manocchi@totvs.com.br, T]
[cleber.silva@totvs.com.br, T]
[cleberson.silva@totvs.com.br, F]
[cleberson.silva@totvs.com.br, T]
[clovism@totvs.com.br, T]
[conrado.gomes@totvs.com.br, T]
[consoni@totvs.com.br, T]
[cps.dellano@totvs.com.br, T]
[cristiane.araki@totvs.com.br, F]
[cristiane.silva@totvs.com.br, T]
[cristiano.pedroni@totvs.com.br, T]
[cristiano.peiter@totvs.com.br, T]
[cristiano.peiter@totvs.com.br, T, domenica.castro@totvs.com.br, T]
[cristian.verneque@totvs.com.br, T]
[cristina.magalhaes@totvs.com.br, T]
[dalila.alvarez@totvs.com.br, T]
[daniela.afonso@totvs.com.br, T]
[daniela.conoratte@totvs.com.br, T]
[daniela.faciroli@totvs.com.br, T]
[daniela.fontoura@totvs.com.br, T]
[daniela.gomes@totvs.com.br, T]
[daniela.paiva@totvs.com.br, T]
[daniel.bergmann@totvs.com.br, T]
[daniel.braga@totvs.com.br, T]
[daniel.cembranelli@totvs.com.br, T]
[daniele.csilva@totvs.com.br, T]
[danielfs.ssa@totvs.com.br, T]
[daniel.hwang@totvs.com.br, T]
[daniel.jacob@totvs.com.br, T]
[daniel.nugas@totvs.com.br, F]
[daniel.poliveira@totvs.com.br, T]
[daniel.sacramento@oncoclinicas.com, T]
[daniel.stori@fluig.com, T]
[daniel.vitor@totvs.com.br, T]
[danilo.medeiros@totvs.com.br, T]
[danilom@totvs.com.br, T]
[danilo.vieira@totvs.com.br, F]
[dani@totvs.com.br, T]
[david.fernandes@totvs.com.br, T]
[david.ramalho@totvs.com.br, T]
[david.rodrigues@totvs.com.br, T, mara.morais@totvs.com.br, F]
[david.soliveira@totvs.com.br, T]
[david.vasquez@totvs.com.br, F]
[davi.manzano@totvs.com.br, F]
[davi.manzano@totvs.com.br, T]
[dayane.spiagori@totvs.com.br, T]
[dday@totvs.com.br, F]
[dday@totvs.com.br, T]
[debora.cristina@totvs.com.br, T]
[deiani.machado@totvs.com.br, T]
[deise.silva@totvs.com.br, T]
[denise.bento@totvs.com.br, T]
[denis.galvani@fluig.com, T]
[denis.silva@totvs.com.br, T]
[denis.souza@totvs.com.br, T]
[denys.moleta@totvs.com.br, T]
[deyse.alves@totvs.com.br, T]
[diego.argolo@totvs.com.br, F]
[diego.argolo@totvs.com.br, T]
[diego.fausto@totvs.com.br, T, carlos.costa@totvs.com.br, T]
[diego.gameiro@totvs.com.br, T]
[diego.peruzzo@totvs.com.br, T]
[diego.rosa@totvs.com.br, T]
[diego.tatsch@totvs.com.br, T]
[diogo.dantas@totvs.com.br, T]
[diogo.david@totvs.com.br, T]
[diogo.melo@totvs.com.br, T]
[domenica.castro@totvs.com.br, T]
[douglas.bichir@totvs.com.br, T]
[douglas.brito@totvs.com.br, F]
[douglas.brito@totvs.com.br, T, liamara.romanini@totvs.com.br, T]
[douglas.galera@totvs.com.br, T]
[easouza@totvs.com.br, T]
[eder.cirico@totvs.com.br, F]
[eder.cirico@totvs.com.br, T]
[eder.lopes@totvs.com.br, T]
[ederson.carvalho@totvs.com.br, T]
[edersonguerra@totvs.com.br, F]
[edersonguerra@totvs.com.br, T]
[edilberto.ferreira@totvs.com.br, T]
[edison.lara@totvs.com.br, T]
[edison.silva@totvs.com.br, F]
[edison.silva@totvs.com.br, T]
[edivaldo.santos@totvs.com.br, T]
[edivaldo.silva@totvs.com.br, T]
[edmar.lima@totvs.com.br, T]
[edmar.rodrigues@totvs.com.br, T]
[edna.carmo@totvs.com.br, T]
[edson.assis@totvs.com.br, T]
[edson.moraes@totvs.com.br, T]
[eduardo.carvalho@totvs.com.br, T]
[eduardo.coimbra@totvs.com.br, T]
[eduardo.coimbra@totvs.com.br, T, anisio.cunha@totvs.com.br, T]
[eduardo.gomes@totvs.com.br, T]
[eduardo.henrique@totvs.com.br, T]
[eduardojs@totvs.com.br, T]
[eduardo.martinez@totvs.com.br, T]
[eduardo.osantos@totvs.com.br, F]
[eduardo.osantos@totvs.com.br, T]
[eduardo.otani@totvs.com.br, T, fernando.kruszynski@totvs.com.br, T]
[eduardo.ramos@totvs.com.br, T]
[eduardo.rocha@totvs.com.br, T]
[eduardo.rosa@totvs.com.br, T]
[eduardo.wallace@totvs.com.br, T]
[edvaldo.reis@totvs.com.br, T]
[elaine.casagrande@totvs.com.br, T]
[elaine.dobrawolske@totvs.com.br, T]
[elaine.pessoa@oncoclinicas.com, T]
[elenice.laumann@totvs.com.br, F]
[elenice.laumann@totvs.com.br, F, felipe.nascimento@totvs.com.br, F]
[eliana.oliveira@totvs.com.br, T]
[eliandro.martins@totvs.com.br, F, william.barbosa@totvs.com.br, T]
[eliandro.martins@totvs.com.br, T]
[elias.silva@totvs.com.br, T]
[elicris@totvs.com.br, T]
[elisabete.silva@totvs.com.br, F]
[elisabete.silva@totvs.com.br, T]
[elisangela.alves@totvs.com.br, T]
[elisangela.bastos@totvs.com.br, T]
[elis.costa@totvs.com.br, T]
[elivelton.morais@totvs.com.br, T]
[ellen.sousa@totvs.com.br, T]
[ellen.sumensari@totvs.com.br, T]
[eloisa.rodrigues@totvs.com.br, T]
[elton.alves@totvs.com.br, T]
[ely.berro@totvs.com.br, F]
[ely.berro@totvs.com.br, T]
[emanuel.guedes@totvs.com.br, T]
[emerson.campos@totvs.com.br, F]
[emerson.campos@totvs.com.br, F, daniel.hwang@totvs.com.br, T]
[emerson.campos@totvs.com.br, F, renan.borges@totvs.com.br, T]
[emerson.natali@totvs.com.br, T]
[emerson.siqueira@totvs.com.br, T]
[enilton.oliveira@totvs.com.br, T]
[enrico.gelfusa@totvs.com.br, T]
[eregina@totvs.com.br, T]
[erica.santos@totvs.com.br, T]
[erick.moraes@totvs.com.br, T]
[erlon.benites@totvs.com.br, T]
[esther.viveiro@totvs.com.br, T]
[evandro.antonio@totvs.com.br, T]
[evandro.botacini@totvs.com.br, T]
[evandro.soares@totvs.com.br, F]
[evandro.soares@totvs.com.br, T]
[eveline.silva@totvs.com.br, T]
[evelyn.boroni@totvs.com.br, T]
[fabbio.marteli@totvs.com.br, T]
[fabiana.goncalves@totvs.com.br, T]
[fabiana.moncao@totvs.com.br, T]
[fabiano.albuquerque@totvs.com.br, T]
[fabiano.farias@totvs.com.br, T]
[fabiano.jose@totvs.com.br, T]
[fabiano.rosa@totvs.com.br, T]
[fabio.almeida@totvs.com.br, F]
[fabio.almeida@totvs.com.br, T]
[fabio.baggio@totvs.com.br, F]
[fabio.baggio@totvs.com.br, F, claudio.ramos@totvs.com.br, T]
[fabio.baggio@totvs.com.br, F, fernando.ciarelli@totvs.com.br, F, pedro.franco@totvs.com.br, F]
[fabio.baggio@totvs.com.br, T]
[fabio.carvalho@totvs.com.br, T]
[fabio.chagas@totvs.com.br, T]
[fabio.dasilva@totvs.com.br, F]
[fabio.dasilva@totvs.com.br, F, matheus.balbi@totvs.com.br, F]
[fabio.fernando@totvs.com.br, T]
[fabio.fini@totvs.com.br, T, roseli.araujo@totvs.com.br, T, fabiano.rosa@totvs.com.br, T]
[fabio.lemos@totvs.com.br, T]
[fabio.nsilva@totvs.com.br, T]
[fabio.pereira@totvs.com.br, T]
[fabio.santos@totvs.com.br, T]
[fabricio.alves@totvs.com.br, T]
[fabricio.goncalves@totvs.com.br, T]
[fanni.schettini@totvs.com.br, T]
[farid.filho@totvs.com.br, T]
[fausto.donadel@totvs.com.br, T]
[fchristofoletti@totvs.com.br, T]
[felipe.carmello@totvs.com.br, T]
[felipe.conti@totvs.com.br, F]
[felipe.conti@totvs.com.br, T]
[felipe.csilva@totvs.com.br, F]
[felipe.fernandes@totvs.com.br, T]
[felipe.inacio@totvs.com.br, F]
[felipe.inacio@totvs.com.br, F, easouza@totvs.com.br, F]
[felipe.inacio@totvs.com.br, T]
[felipe.limas@totvs.com.br, T]
[felipe.mari@totvs.com.br, F]
[felipe.mari@totvs.com.br, T, mara.morais@totvs.com.br, F]
[felipe.nascimento@totvs.com.br, T]
[felipe.rosa@totvs.com.br, T]
[felipi.silva@totvs.com.br, T]
[fernanda.bimbato@totvs.com.br, T]
[fernanda.fornaziero@totvs.com.br, F]
[fernanda.fornaziero@totvs.com.br, T]
[fernanda.kafka@totvs.com.br, T]
[fernanda.maltas@totvs.com.br, T]
[fernanda.marinho@totvs.com.br, T]
[fernanda.nicolino@totvs.com.br, T]
[fernanda.salerno@totvs.com.br, T, heidi.valle@totvs.com.br, F]
[fernando.brito@totvs.com.br, T]
[fernando.ciarelli@totvs.com.br, F]
[fernando.ciarelli@totvs.com.br, F, elisangela.tolentino@totvs.com.br, T]
[fernando.ciarelli@totvs.com.br, F, pedro.franco@totvs.com.br, F]
[fernando.coronado@totvs.com.br, T]
[fernando.luiz@totvs.com.br, T]
[fernando.mendes@totvs.com.br, T]
[fernando.moraes@totvs.com.br, T]
[fernando.nascimento@totvs.com.br, T]
[fernando.teodoro@totvs.com.br, F]
[fernando.teodoro@totvs.com.br, F, veronica.donnianni@totvs.com.br, T]
[filipe.olegini@totvs.com.br, T]
[flavia.bachir@totvs.com.br, T]
[flavia.monzano@totvs.com.br, T]
[flavia.pitta@totvs.com.br, T]
[flavio.vera@totvs.com.br, T]
[fluigid.sp@totvs.com.br, T]
[francelia@totvs.com.br, T]
[francilene.lucena@totvs.com.br, T, felipe.limas@totvs.com.br, T]
[francisco.junior@totvs.com.br, T]
[francis.macedo@totvs.com.br, T]
[frank.falcao@totvs.com.br, T]
[frederico.madeira@totvs.com.br, T]
[gabriela.benzi@totvs.com.br, T]
[gabriela.rocha@totvs.com.br, T]
[gabriel.avolio@totvs.com.br, T]
[gabriel.cisneiro@totvs.com.br, T]
[gabriel.rocha@totvs.com.br, F]
[gabriel.rocha@totvs.com.br, F, bruno.htavares@totvs.com.br, T]
[gabriel.rocha@totvs.com.br, F, edmar.lima@totvs.com.br, T]
[gaynor.marques@totvs.com.br, T]
[genilson.santos@totvs.com.br, T]
[geovana.bonoto@totvs.com.br, F]
[geovana.bonoto@totvs.com.br, T]
[giancarlo.silva@totvs.com.br, T]
[giancarlo.winckler@totvs.com.br, T]
[gilberto.suzart@totvs.com.br, T]
[gilcelia.cardoso@totvs.com.br, T]
[gileno@totvs.com.br, T]
[gilsinei.hansen@totvs.com.br, T]
[gioconda.blasio@totvs.com.br, F]
[giovana.zattera@totvs.com.br, T]
[gisele.david@totvs.com.br, T]
[gisele.nuncherino@totvs.com.br, F]
[gisele.nuncherino@totvs.com.br, T]
[giselle.radlov@totvs.com.br, T]
[gislanealves@totvs.com.br, T]
[glailson.braga@totvs.com.br, T]
[glaucia.pongelli@totvs.com.br, F]
[glaucia.pongelli@totvs.com.br, T]
[gleice.rodrigues@totvs.com.br, T]
[glopes@totvs.com.br, T]
[gmg@totvs.com.br, T]
[gpraxedes@totvs.com.br, T]
[gracielly.santos@totvs.com.br, T]
[guilherme.alves@totvs.com.br, T]
[guilherme.caseli@totvs.com.br, T]
[guilherme.chaves@totvs.com.br, F]
[guilherme.chaves@totvs.com.br, T]
[guilherme.marquete@totvs.com.br, T]
[guilherme.mendonca@totvs.com.br, T]
[guilherme.sitta@totvs.com.br, T]
[gustavo.gaino@totvs.com.br, T]
[heidi.valle@totvs.com.br, F]
[heidi.valle@totvs.com.br, T]
[heitor.martins@totvs.com.br, T]
[helda.santos@totvs.com.br, T]
[helder.souza@totvs.com.br, F]
[helder.souza@totvs.com.br, T]
[helio.oliveira@totvs.com.br, T]
[hellen.fernandes@totvs.com.br, T]
[helmar.junior@totvs.com.br, T]
[helmer.aguiar@totvs.com.br, T]
[henrique.lira@totvs.com.br, T]
[henrique.neto@totvs.com.br, T]
[henrique.santos@totvs.com.br, F]
[henrique.santos@totvs.com.br, T]
[heraildo.freitas@totvs.com.br, T]
[hercules.santos@fluig.com, T]
[higor.miranda@totvs.com.br, T, anderson.marques@totvs.com.br, T]
[hildo.junior@totvs.com.br, F]
[hildo.junior@totvs.com.br, T]
[hugo.silva@totvs.com.br, T]
[humberto.oliveira@totvs.com.br, F]
[humberto.oliveira@totvs.com.br, F, fernanda.nicolino@totvs.com.br, T]
[humberto.reis@totvs.com.br, T]
[igor.coltro@totvs.com.br, T]
[igor.freitas@totvs.com.br, F]
[igor.freitas@totvs.com.br, T]
[igor.freitas@totvs.com.br, T, vicente.simoes@totvs.com.br, T]
[ingrid.luta@totvs.com.br, T]
[ismael.machado@totvs.com.br, T]
[iuri@nob-ba.com.br, T]
[ivan.neto@totvs.com.br, T]
[ivan.rech@totvs.com.br, T]
[jacke@totvs.com.br, T]
[jair.junior@totvs.com.br, T]
[jalves@totvs.com.br, T]
[jaqueline.adami@totvs.com.br, T]
[jaqueline.faria@totvs.com.br, T]
[jaqueline.souza@totvs.com.br, T]
[jaylson.ribeiro@totvs.com.br, T]
[jcastro@totvs.com.br, T]
[jeane.aguiar@totvs.com.br, T]
[jean.gomes@totvs.com.br, T]
[jean.justino@totvs.com.br, F]
[jean.justino@totvs.com.br, T]
[jean.masson@totvs.com.br, T]
[jeanpr@totvs.com.br, T]
[jean.reis@totvs.com.br, T]
[jean.santos@totvs.com.br, T]
[jeferson.martins@totvs.com.br, T]
[jeferson.mattar@totvs.com.br, T]
[jeferson.smartins@totvs.com.br, T]
[jefferson.moreno@totvs.com.br, F]
[jefo@totvs.com.br, T]
[jessica.rangel@totvs.com.br, T]
[jessy.jardim@totvs.com.br, T]
[joao.alvarenga@oncoclinicas.com, T]
[joao.antonio@totvs.com.br, T]
[joao.junior@totvs.com.br, T]
[joao.ponte@totvs.com.br, T]
[joao.venturini@totvs.com.br, T]
[jocimar.santos@totvs.com.br, T]
[joice.principe@totvs.com.br, F]
[joice.principe@totvs.com.br, T]
[jo.martins@totvs.com.br, T]
[jonil.arruda@totvs.com.br, T]
[jorge.luis@totvs.com.br, T]
[jorge.souza@totvs.com.br, T]
[joricardo@totvs.com.br, T]
[josane.queiroz@totvs.com.br, T]
[jose.alvares@totvs.com.br, T]
[jose.alves@totvs.com.br, T, michel.david@totvs.com.br, T]
[jose.araujo@totvs.com.br, T]
[jose.barros@totvs.com.br, F]
[jose.campos@totvs.com.br, T]
[jose.junior@totvs.com.br, T]
[jose.molla@totvs.com.br, T]
[jose.nascimento@totvs.com.br, T]
[jose.sneto@totvs.com.br, T]
[josiane.dutra@totvs.com.br, F]
[josiane.neves@totvs.com.br, F]
[josiane.neves@totvs.com.br, F, henrique.neto@totvs.com.br, T]
[jozias.nunes@totvs.com.br, T]
[jsalvador@totvs.com.br, F]
[jsalvador@totvs.com.br, T]
[juarez.junior@totvs.com.br, T]
[jucimeire.moraes@totvs.com.br, T]
[juliana.cunha@totvs.com.br, T]
[juliana.nogueira@totvs.com.br, T]
[juliana.ramos@fluig.com, T]
[juliana.schulz@totvs.com.br, T]
[juliano.araujo@totvs.com.br, T]
[juliano.bobbio@totvs.com.br, T]
[juliano.teixeira@totvs.com.br, T, mauro.rizzo@totvs.com.br, T]
[juliany.santos@totvs.com.br, T]
[juliele.silva@totvs.com.br, T]
[julio.csilva@totvs.com.br, T]
[julio.kessler@totvs.com.br, F]
[julio.kessler@totvs.com.br, T]
[julio.lisboa@totvs.com.br, T]
[julio.llanos@totvs.com.br, F]
[julio.llanos@totvs.com.br, F, douglas.brito@totvs.com.br, F]
[julio.llanos@totvs.com.br, T]
[julio.negri@totvs.com.br, T]
[julio.teixeira@totvs.com.br, T]
[julio.zarnitz@totvs.com.br, T, glaucia.pongelli@totvs.com.br, F, carlos.caeiro@totvs.com.br, T]
[junio.silva@oncoclinicas.com, T]
[jussara.vilela@oncoclinicas.com, F]
[jussara.vilela@oncoclinicas.com, T]
[kae.okawa@totvs.com.br, T]
[karel.kadlec@totvs.com.br, T]
[karina.olier@totvs.com.br, T]
[karinap@totvs.com.br, T]
[karinap@totvs.com.br, T, patricia.silva@totvs.com.br, T]
[karine.martins@totvs.com.br, T]
[karla.santos@totvs.com.br, T]
[karlo.santos@totvs.com.br, T]
[kbalbo@totvs.com.br, T]
[keila.prado@totvs.com.br, F]
[kleber.camargo@totvs.com.br, T]
[laerte.bentes@totvs.com.br, T]
[lafilho@totvs.com.br, T]
[leandra.russo@totvs.com.br, T]
[leandro.chaves@totvs.com.br, T]
[leandro.prado@totvs.com.br, T]
[leandro.thomaz@totvs.com.br, T]
[leidimara.faust@totvs.com.br, T]
[leila.dantas@totvs.com.br, T]
[leonardo.bolsoni@totvs.com.br, F]
[leonardo.bolsoni@totvs.com.br, T]
[leonardo.fagundes@totvs.com.br, T]
[leonardo.fonseca@totvs.com.br, T]
[leonardo.garcez@totvs.com.br, T]
[leonardo.lacerda@totvs.com.br, F]
[leonardol@totvs.com.br, F]
[leonardol@totvs.com.br, T]
[leticia.biguetti@totvs.com.br, T]
[leticia.chagas@totvs.com.br, T]
[leticia.morais@totvs.com.br, T]
[liara.bonifacio@totvs.com.br, F]
[liara.bonifacio@totvs.com.br, T]
[ligia.serra@totvs.com.br, T]
[liziane.gil@totvs.com.br, T]
[lorenzetti@totvs.com.br, T]
[lsouza@totvs.com.br, F]
[lsouza@totvs.com.br, T]
[luana.tavares@totvs.com.br, T]
[luana.weissheimer@totvs.com.br, T]
[luan.xavier@totvs.com.br, T]
[lucas.cesar@totvs.com.br, T]
[lucas.macedo@totvs.com.br, T]
[lucas.nascimento@totvs.com.br, T]
[lucas.souza@totvs.com.br, T]
[lucas.weslley@totvs.com.br, T]
[luciana.mestriner@totvs.com.br, T]
[luciana.ribeiro@totvs.com.br, T]
[luciano.marson@totvs.com.br, T]
[luciano.mentz@totvs.com.br, T]
[luciano.poletto@totvs.com.br, T]
[lucio.peixoto@totvs.com.br, T]
[luene.ferreira@totvs.com.br, T]
[luigi.bertoni@totvs.com.br, F]
[luis.faria@totvs.com.br, T]
[luis.lamb@totvs.com.br, T]
[luis.martins@totvs.com.br, F]
[luis.skueresky@totvs.com.br, F]
[luis.skueresky@totvs.com.br, F, italo.mota@totvs.com.br, T]
[luis.skueresky@totvs.com.br, T]
[luiz.bandeira@totvs.com.br, F]
[luiz.bandeira@totvs.com.br, T]
[luiz.eduardo@totvs.com.br, T]
[luiz.freire@totvs.com.br, T]
[luiz.gomes@totvs.com.br, T]
[luiz.milei@totvs.com.br, T]
[luiz.neto@totvs.com.br, T]
[luiz.romagnoli@totvs.com.br, T]
[luiz.taira@fluig.com, T, julio.lisboa@totvs.com.br, F]
[luvanio@faeg.com.br, F]
[luvanio@faeg.com.br, T]
[manuellapm@totvs.com.br, T]
[mara.morais@totvs.com.br, F]
[mara.morais@totvs.com.br, T]
[marcela.cravo@totvs.com.br, T]
[marcello.werthmuller@totvs.com.br, T]
[marcelo.beu@totvs.com.br, F]
[marcelo.beu@totvs.com.br, T]
[marcelo.brietzke@totvs.com.br, T]
[marcelo.luzia@totvs.com.br, F]
[marcelo.luzia@totvs.com.br, T]
[marcelo.miguel@totvs.com.br, T]
[marcelo.rego@totvs.com.br, T]
[marcia.correia@totvs.com.br, F]
[marcia.correia@totvs.com.br, T, leonardo.lacerda@totvs.com.br, T, carlos.valle@totvs.com.br, F]
[marcio.alexandre@totvs.com.br, T]
[marcio.oliveira@totvs.com.br, T]
[marcio.ossi@totvs.com.br, F]
[marcio.pinheiro@totvs.com.br, T]
[marcio.rodrigo@totvs.com.br, F]
[marcio.rodrigo@totvs.com.br, T]
[marcio.rodrigo@totvs.com.br, T, aline.rocha@totvs.com.br, T]
[marco.rocha@totvs.com.br, T]
[marcos.alberto@totvs.com.br, T]
[marco.santos@totvs.com.br, T]
[marcos.araujo@totvs.com.br, T]
[marcos.biazi@totvs.com.br, T]
[marcos.damata@totvs.com.br, T]
[marcos.godoi@totvs.com.br, T]
[marcos.godoy@totvs.com.br, T]
[marcos.goncalves@totvs.com.br, T]
[marcos.guarana@totvs.com.br, F]
[marcos.lichtnow@totvs.com.br, T]
[marcos.nascimento@totvs.com.br, T]
[marcos.rsilva@totvs.com.br, F]
[marcos.rsilva@totvs.com.br, T]
[marcos.santiago@totvs.com.br, T]
[marcus.barbosa@totvs.com.br, T]
[marcus.campos@totvs.com.br, T]
[maria.avelino@totvs.com.br, T]
[maria.elisabete@totvs.com.br, F]
[maria.elisabete@totvs.com.br, T]
[maria.jesus@totvs.com.br, T]
[maria.leal@totvs.com.br, F]
[maria.leal@totvs.com.br, T]
[maria.monteiro@totvs.com.br, T, elisabete.silva@totvs.com.br, T]
[maria.morato@totvs.com.br, T]
[mariana.alves@totvs.com.br, T]
[maria.teles@totvs.com.br, T]
[marina.mello@totvs.com.br, T]
[marina.stubert@totvs.com.br, F]
[marina.stubert@totvs.com.br, T]
[marines.sales@totvs.com.br, F]
[marines.sales@totvs.com.br, T]
[marli.oliveira@totvs.com.br, T]
[martha.salgado@totvs.com.br, T]
[mary.sousa@totvs.com.br, T]
[mateus.oliveira@totvs.com.br, F]
[mateus.oliveira@totvs.com.br, F, david.vasquez@totvs.com.br, T]
[mateus.oliveira@totvs.com.br, F, debora.lima@totvs.com.br, T]
[mateus.oliveira@totvs.com.br, T]
[matheus.balbi@totvs.com.br, F]
[matheus.muchinelli@totvs.com.br, T, diorgenes.postol@totvs.com.br, T]
[matheus.raimundo@totvs.com.br, T]
[mauricio.barbosa@totvs.com.br, T]
[mauricio.couto@totvs.com.br, T]
[mauro.goncalves@totvs.com.br, T]
[mauro.rizzo@totvs.com.br, F]
[max.caldas@totvs.com.br, T]
[maximiliano.neves@totvs.com.br, T]
[mdemetroff@totvs.com.br, T]
[mdomingos@totvs.com.br, T]
[michael.rodrigues@totvs.com.br, F]
[michael.rodrigues@totvs.com.br, T]
[michele.laurindo@totvs.com.br, T]
[michele.oliveira@totvs.com.br, T]
[michele.santos@totvs.com.br, T]
[michele.zannon@totvs.com.br, T]
[michelle.ennes@totvs.com.br, T]
[moises.cardoso@totvs.com.br, T]
[monica.restrepo@totvs.com.br, T]
[mpsilva@totvs.com.br, T]
[murilo.silva@totvs.com.br, F]
[murilo.silva@totvs.com.br, F, luis.skueresky@totvs.com.br, F]
[najara.teodoro@totvs.com.br, F]
[najara.teodoro@totvs.com.br, T]
[natalia.baggio@totvs.com.br, T]
[nei.umberto@totvs.com.br, T]
[nidia.villar@totvs.com.br, T]
[nrocha@totvs.com.br, T]
[null, F]
[odelia.silva@totvs.com.br, T]
[otaviano.neto@totvs.com.br, T]
[pablo.favero@totvs.com.br, T]
[pablo.ssa@totvs.com.br, T, alexandro.santos@totvs.com.br, T]
[pagotto@totvs.com.br, T]
[pamela.santos@totvs.com.br, T]
[pamela.vinhas@totvs.com.br, T]
[panseri@totvs.com.br, T, helder.souza@totvs.com.br, T]
[paola.olivieri@totvs.com.br, T]
[patidu@totvs.com.br, T]
[patricia.gomes@totvs.com.br, T]
[patricia.silva@totvs.com.br, F]
[patricia.silva@totvs.com.br, T]
[patricia.soares@totvs.com.br, T]
[patricia.teixeira@totvs.com.br, T]
[patricia.vilela@totvs.com.br, T]
[patrick.favero@totvs.com.br, T]
[patrick.ramos@totvs.com.br, F]
[patrick.ramos@totvs.com.br, T]
[paula.lopes@totvs.com.br, T]
[paula.pastor@totvs.com.br, T]
[paula.santiago@totvs.com.br, T]
[paulo.baueb@totvs.com.br, T]
[paulo.cesar@totvs.com.br, T]
[paulo.cjunior@totvs.com.br, T]
[paulo.dellagnolo@totvs.com.br, T]
[paulodonizeti@totvs.com.br, T]
[paulo.eduardo@totvs.com.br, T, matheus.balbi@totvs.com.br, F]
[paulo.lima@totvs.com.br, T]
[paulo.mendonca@totvs.com.br, T]
[paulo.morais@totvs.com.br, T]
[paulo.oliveira@totvs.com.br, T]
[paulo.soliveira@totvs.com.br, T, keila.prado@totvs.com.br, T]
[paulo.teodoro@totvs.com.br, T]
[paulo.uehara@totvs.com.br, T]
[pedro.franco@totvs.com.br, F]
[pedro.przewodowski@totvs.com.br, T]
[priscila.henriques@totvs.com.br, T]
[priscila.oliveira@totvs.com.br, T]
[rachel.loureto@totvs.com.br, T]
[rafaela.nogueira@totvs.com.br, F]
[rafaela.nogueira@totvs.com.br, T]
[rafael.augusto@totvs.com.br, T]
[rafael.azevedo@totvs.com.br, T]
[rafael.lucatto@totvs.com.br, T]
[rafael.rodrigues@totvs.com.br, T]
[rafaelsantiago.ssa@totvs.com.br, T]
[rafael.silverio@totvs.com.br, T]
[rafael.ssilva@totvs.com.br, T]
[rafael.ssouza@totvs.com.br, T]
[rafael.villar@totvs.com.br, T]
[ralmeida@totvs.com.br, T]
[raoni.barbosa@totvs.com.br, T]
[raphael.garcia@totvs.com.br, T]
[raphael.leite@totvs.com.br, T]
[rayra.freitas@totvs.com.br, T]
[reges.werlang@totvs.com.br, T]
[renan.ferreira@totvs.com.br, F]
[renan.lisboa@totvs.com.br, T]
[renan.sanssanovicz@totvs.com.br, T]
[renata.baptistioli@totvs.com.br, F]
[renata.borba@totvs.com.br, T]
[renata.guerra@totvs.com.br, T]
[renatam@totvs.com.br, T]
[renato.cunha@totvs.com.br, T]
[renato.freire@totvs.com.br, T]
[renato.pianta@totvs.com.br, T]
[renato.santos@totvs.com.br, T]
[ricardo.batista@totvs.com.br, F]
[ricardo.batista@totvs.com.br, T]
[ricardo.hernandes@totvs.com.br, T]
[ricardo.luna@totvs.com.br, T]
[ricardo.pmartins@totvs.com.br, T]
[ricardo.rampazzo@totvs.com.br, T]
[ricardo.shikota@totvs.com.br, T]
[ricardo.zattera@totvs.com.br, T]
[richard.telles@totvs.com.br, T]
[rizza.silva@totvs.com.br, F]
[rlima@totvs.com.br, T]
[roberta.campos@totvs.com.br, T]
[roberta.lima@totvs.com.br, T]
[roberta.medeiros@totvs.com.br, T]
[roberta.pardal@totvs.com.br, T]
[roberta.santos@totvs.com.br, T]
[robertha.saenz@totvs.com.br, F]
[robertha.saenz@totvs.com.br, T]
[robert.jesus@totvs.com.br, T]
[roberto.lins@totvs.com.br, T]
[roberto.thomaz@totvs.com.br, T]
[robson.canto@totvs.com.br, T]
[robson.carlos@totvs.com.br, T]
[robson.gomes@totvs.com.br, T]
[robson.mazzarotto@totvs.com.br, T]
[robson.moura@totvs.com.br, T, marco.santos@totvs.com.br, T, vanessa.karla@totvs.com.br, T]
[robson.neves@totvs.com.br, F]
[robson.silva@totvs.com.br, T]
[rodolfo.gaboardi@totvs.com.br, T]
[rodrigo.baldo@totvs.com.br, T]
[rodrigo.batista@totvs.com.br, T]
[rodrigo.boito@totvs.com.br, T]
[rodrigo.cesar@totvs.com.br, T]
[rodrigo.coelho@totvs.com.br, F]
[rodrigo.correa@totvs.com.br, T]
[rodrigo.exterkoetter@totvs.com.br, T]
[rodrigo.kunrath@totvs.com.br, T]
[rodrigo.malmeida@totvs.com.br, T]
[rodrigo.prates@totvs.com.br, T]
[rodrigo.rondon@totvs.com.br, T]
[rodrigo.silveira@totvs.com.br, T]
[rogerio.moreira@totvs.com.br, T]
[rogero.silva@totvs.com.br, T]
[romilda.camboim@totvs.com.br, F]
[ronald.barbosa@totvs.com.br, F]
[ronald.barbosa@totvs.com.br, T]
[ronildo.gama@totvs.com.br, T]
[rosangela.rossi@totvs.com.br, T]
[roseli.araujo@totvs.com.br, T]
[rsilva@totvs.com.br, T]
[rsoares@totvs.com.br, F]
[rsoares@totvs.com.br, T]
[ruyter.junior@totvs.com.br, T]
[sabrina.lima@totvs.com.br, T]
[sadiomar@totvs.com.br, T]
[safira.yang@totvs.com.br, T]
[samara.peixoto@totvs.com.br, F]
[samara.peixoto@totvs.com.br, T]
[samira.rodrigues@totvs.com.br, T]
[samuel.alonso@totvs.com.br, T]
[sandra.jesus@totvs.com.br, T]
[sandra.sousa@totvs.com.br, T]
[sandra.varollo@totvs.com.br, T]
[sandro.costa@totvs.com.br, T]
[sandro.silveira@totvs.com.br, F]
[sandro.silveira@totvs.com.br, T]
[sandro.virgens@totvs.com.br, T]
[saulo.martins@totvs.com.br, T]
[saulo.rosa@totvs.com.br, T]
[sergio.almeida@totvs.com.br, T]
[sergioribeiro@totvs.com.br, T]
[sergio.se@totvs.com.br, F]
[sergio.shoji@totvs.com.br, T]
[sharlene.destefani@totvs.com.br, T]
[shirlei.alves@totvs.com.br, T]
[silas.carvalho@totvs.com.br, T]
[silvia.gregorio@totvs.com.br, T]
[simone.weber@totvs.com.br, T]
[solange.koch@totvs.com.br, T]
[sonia.kodaira@totvs.com.br, F]
[staguti@totvs.com.br, T]
[suelen.cabral@totvs.com.br, T]
[sueli.clementino@totvs.com.br, F]
[sueli.clementino@totvs.com.br, F, tiago.fermin@totvs.com.br, T]
[sueli.clementino@totvs.com.br, T]
[sueli.silva@totvs.com.br, T]
[suziane.lima@totvs.com.br, T]
[sylvain.panneau@totvs.com.br, F]
[sylvain.panneau@totvs.com.br, T]
[tailanas@totvs.com.br, T]
[tais.mota@totvs.com.br, T]
[tais.viali@totvs.com.br, F]
[tais.viali@totvs.com.br, F, antonio.maria@totvs.com.br, T]
[tais.viali@totvs.com.br, T]
[tamara.fonseca@fluig.com, T]
[tamires.almeida@totvs.com.br, T]
[tamiris.costa@totvs.com.br, T]
[tania.martins@totvs.com.br, T, gioconda.blasio@totvs.com.br, F]
[tarcisio.sobrinho@totvs.com.br, T]
[tatiana.alencar@totvs.com.br, F]
[tatiana.alencar@totvs.com.br, F, mara.morais@totvs.com.br, F]
[tatiana.alencar@totvs.com.br, T]
[tatiana.amaral@totvs.com.br, T]
[tatiana.peig@totvs.com.br, T]
[tatiane.barros@totvs.com.br, T]
[tatiane.gallina@totvs.com.br, F]
[tatiane.gallina@totvs.com.br, T]
[tatyarak@totvs.com.br, T]
[tereza.sousa@totvs.com.br, T]
[testoni@totvs.com.br, T]
[thaisa.costa@totvs.com.br, T]
[thais.capucci@totvs.com.br, F]
[thais.capucci@totvs.com.br, T]
[thais.oliveira@totvs.com.br, T, tiago.correa@totvs.com.br, T]
[thais.silva@totvs.com.br, T]
[thays.vieira@totvs.com.br, T]
[thiago.antonio@totvs.com.br, T]
[thiago.borges@totvs.com.br, F]
[thiago.borges@totvs.com.br, T]
[thiago.florindo@totvs.com.br, T]
[thiago.fonseca@totvs.com.br, T]
[thiago.fonseca@totvs.com.br, T, sabrina.aleixo@totvs.com.br, T]
[thiago.letra@totvs.com.br, T]
[thiago.tadeu@totvs.com.br, T]
[thiago.viana@totvs.com.br, T]
[tiago.araujo@totvs.com.br, F]
[tiago.camargos@totvs.com.br, T]
[tiago.correa@totvs.com.br, T]
[tiago.costa@totvs.com.br, T]
[tiago.fermin@totvs.com.br, T]
[tiago.ponte@totvs.com.br, T]
[tiago.rodrigues@totvs.com.br, T, rodrigo.cuinto@totvs.com.br, T]
[tmoraes@totvs.com.br, F]
[tmoraes@totvs.com.br, T]
[tranquilo.neto@totvs.com.br, F]
[tranquilo.neto@totvs.com.br, T]
[ulisses.jose@totvs.com.br, T]
[valdemar.roberto@totvs.com.br, T]
[valdemir.botelho@totvs.com.br, T]
[valdenir.santos@totvs.com.br, T]
[valdir.pereira@totvs.com.br, T]
[vanduir.silva@fluig.com, T]
[vanessa.karla@totvs.com.br, T]
[vanessa.mello@totvs.com.br, T]
[vanessa.sassoon@totvs.com.br, T]
[vanessa.silva@totvs.com.br, T]
[vanessa.souza@totvs.com.br, T, arnaldo.ribeiro@totvs.com.br, T]
[vanessa.tonini@totvs.com.br, T]
[vera@totvs.com.br, T]
[victor.ourique@totvs.com.br, T]
[victor.ourique@totvs.com.br, T, flavia.monzano@totvs.com.br, F]
[victor.pires@totvs.com.br, T]
[victor.vieira@totvs.com.br, T]
[vinicios.lopes@totvs.com.br, T]
[vinicius.faria@oncoclinicas.com, T]
[vinicius.gargantini@totvs.com.br, T]
[vinicius.miranda@totvs.com.br, T]
[vivaldo.lopes@totvs.com.br, F]
[vivaldo.lopes@totvs.com.br, T]
[vivian.barrionuevo@totvs.com.br, T]
[viviane.almeida@totvs.com.br, T]
[viviane.theodoro@totvs.com.br, T, osvaldo.neto@totvs.com.br, T]
[vlima@totvs.com.br, F]
[vlima@totvs.com.br, T, diego.argolo@totvs.com.br, T]
[wagner.feijo@totvs.com.br, T]
[wagner.luiz@totvs.com.br, F, amunerato@totvs.com.br, T]
[wagner.luiz@totvs.com.br, T]
[wagner.luiz@totvs.com.br, T, glaucia.pongelli@totvs.com.br, F]
[wagner.roberto@totvs.com.br, F]
[wagner.roberto@totvs.com.br, T]
[waldir.baldin@totvs.com.br, F]
[waldir.junior@totvs.com.br, T]
[walquiria@totvs.com.br, T]
[wander.silva@totvs.com.br, T]
[wania@totvs.com.br, T]
[welley.cirilo@totvs.com.br, T]
[wellington.felipe@totvs.com.br, F]
[wellington.felipe@totvs.com.br, T]
[wellington.goncalves@totvs.com.br, T]
[wellington.vasque@totvs.com.br, T]
[wesley.fernandes@totvs.com.br, F]
[wilk.lima@totvs.com.br, F]
[william.barbosa@totvs.com.br, F]
[william.barbosa@totvs.com.br, T]
[willian.doerner@totvs.com.br, T]
[willian.scarvalho@totvs.com.br, T]
[wilson.araujo@totvs.com.br, T]
[wilson.carneiro@totvs.com.br, T]
[wilson.rosa@fluig.com, T]
[yuri.rezende@totvs.com.br, T]
[yuri.silva@totvs.com.br, F]
[yves.oliveira@totvs.com.br, T]
[zelide@totvs.com.br, T]
[zenon.junior@totvs.com.br, F]
[zenon.junior@totvs.com.br, T]
root@app1:~#
root@app2:~# tail -n 100000 /data/fluigidentity-logs/adsync.log | grep '2014-08-11.*RESULT GOT FROM SMART SYNC' | awk -F ':' '{print $5}' | sort | uniq
<-11.*RESULT GOT FROM SMART SYNC' | awk -F ':' '{print $5}' | sort | uniq
[adalberto.moreira@totvs.com.br, T]
[adalberto.palma@totvs.com.br, T]
[adriana.dasilva@totvs.com.br, F, felipe.strebe@totvs.com.br, T]
[adriana.dasilva@totvs.com.br, T]
[adrianosilva@totvs.com.br, T]
[agoretec@totvs.com.br, T]
[alan.bernardo@totvs.com.br, T]
[aldemirio.xavier@totvs.com.br, T]
[alejandra.nino@totvs.com.br, T]
[alejandro.ferreira@totvs.com.br, F]
[alejandro.ferreira@totvs.com.br, T]
[alejandro.medina@totvs.com.br, T]
[alessandro.sales@totvs.com.br, T]
[alexandre.rosa@fluig.com, F]
[alexandre.rosa@fluig.com, T]
[alexandre.santos@totvs.com.br, T]
[alex.teixeira@totvs.com.br, T]
[alice.machado@totvs.com.br, T]
[aline.pereira@totvs.com.br, T]
[allan@totvs.com.br, T]
[altamir.borba@totvs.com.br, T]
[alysson.savassi@totvs.com.br, T]
[anabella.martinez@totvs.com.br, T]
[ana.lins@totvs.com.br, T]
[anderson.campos@totvs.com.br, T]
[andre.antonio@totvs.com.br, T]
[andre.caetano@totvs.com.br, T]
[andreia.pinto@totvs.com.br, T]
[andre.riba@totvs.com.br, T]
[andre.ribeiro@totvs.com.br, T]
[andressa.caixeta@totvs.com.br, T]
[angelina.pedri@totvs.com.br, T]
[angelita.silva@totvs.com.br, T]
[arabelle.kamei@totvs.com.br, T]
[arielson.pimmel@totvs.com.br, T]
[arlindo.moreira@totvs.com.br, T]
[atavares@totvs.com.br, T]
[barbara.escher@totvs.com.br, T]
[beatriz.medeiros@totvs.com.br, F]
[benigno.romero@totvs.com.br, T]
[breno.notaro@totvs.com.br, T]
[breno.safar@totvs.com.br, T]
[brigida.antunes@totvs.com.br, T]
[bruna.roberta@totvs.com.br, F]
[bruna.roberta@totvs.com.br, T]
[bruno.branco@totvs.com.br, F]
[bruno.branco@totvs.com.br, T]
[bruno.leal@totvs.com.br, T]
[bruno.pimentel@totvs.com.br, T]
[bruno.salviete@totvs.com.br, T]
[caio.gomes@totvs.com.br, F]
[caio.gomes@totvs.com.br, T]
[caio.soares@totvs.com.br, T]
[camilla.maia@totvs.com.br, T]
[candelario.morales@totvs.com.br, F]
[carina.jacob@totvs.com.br, T]
[carlos.anderson@totvs.com.br, T]
[carlos.f@totvs.com.br, T]
[carlos.gregorio@totvs.com.br, T]
[carlosh@totvs.com.br, T]
[carlos.moura@totvs.com.br, T]
[carlos.oettel@totvs.com.br, F]
[carlos.oettel@totvs.com.br, T]
[carlos.pinheiro@totvs.com.br, T]
[carlos.rindel@totvs.com, T]
[carlos.zen@totvs.com.br, T]
[caroline.jandrey@totvs.com.br, T]
[caroline.miranda@totvs.com.br, T]
[Carolsoares@totvs.com.br, T]
[cassia.alves@totvs.com.br, T]
[cassio.lauar@totvs.com.br, F]
[cecilia.acosta@totvs.com.br, T]
[celso.nogueira@totvs.com.br, T]
[celso.silva@totvs.com.br, T]
[cesar.alexandre@totvs.com.br, T]
[cesar.pereiro@totvs.com.br, T]
[cezar.maciel@totvs.com.br, T]
[chalton@totvs.com.br, T]
[cintia.gaspar@totvs.com.br, T]
[claudia.crucci@totvs.com.br, T]
[claudia.narloch@fluig.com, T]
[claudias@totvs.com.br, T]
[claudina.ferreira@totvs.com.br, T]
[claudio.cruz@totvs.com.br, T]
[clayton@totvs.com.br, T]
[cleonice.waiczyk@totvs.com.br, T]
[crisleyne.nunes@totvs.com.br, T]
[cristiane.lilian@totvs.com.br, T]
[cristian.miranda@totvs.com.br, T]
[cristiano.santos@totvs.com.br, T]
[cristiano.schneider@totvs.com.br, T]
[cristian.pranteda@totvs.com.br, T]
[daiane.carboni@totvs.com.br, T]
[daiane.fracaro@totvs.com.br, T]
[damian.malfatti@totvs.com.br, T]
[daniela.braga@totvs.com.br, T]
[daniela.valcanaia@totvs.com.br, T]
[daniel.luciano@totvs.com.br, T]
[danielly.silva@totvs.com.br, T]
[daniel.nunes@totvs.com.br, T]
[daniel.ribeiro@totvs.com.br, T]
[daniel.santos@totvs.com.br, T]
[darine.monteiro@totvs.com.br, T]
[david.castro@totvs.com.br, T]
[dayse.nunes@totvs.com.br, T]
[deboratl@totvs.com.br, T]
[denise.boegershausen@totvs.com.br, T]
[denise.rocha@totvs.com.br, T]
[diego.abel@totvs.com.br, F]
[diego.abel@totvs.com.br, T]
[diego.branco@totvs.com.br, F]
[diego.branco@totvs.com.br, T]
[diego.serafina@totvs.com.br, T]
[diogo.boegershausen@fluig.com, T]
[edeilson.santos@totvs.com.br, T]
[eder@totvs.com.br, T]
[edilene.lopes@totvs.com.br, T]
[edinea.alves@totvs.com.br, T]
[edson.oliveira@totvs.com.br, T]
[eduardo.guizzo@totvs.com.br, T]
[eduardo.inacio@totvs.com.br, T]
[eduardo.mira@totvs.com.br, T]
[edvaldo.junior@totvs.com.br, F]
[edvaldo.junior@totvs.com.br, T]
[elaine.azevedo@totvs.com.br, T]
[elaine.dasilva@totvs.com.br, T]
[elaine.rosa@totvs.com.br, T]
[elder.perdigao@totvs.com.br, T]
[eldon.oliveira@totvs.com.br, T]
[elienay.tacchi@totvs.com.br, T]
[elis.ferreira@totvs.com.br, T]
[eloa.silva@totvs.com.br, T]
[eloisa.jimenez@totvs.com.br, F]
[espinosa.qro@totvs.com.br, T]
[evandro.filho@totvs.com.br, T]
[evelise.franca@totvs.com.br, T]
[fabiana.becatini@totvs.com.br, T]
[fabio.assis@totvs.com.br, T]
[fabio.cortes@totvs.com.br, F]
[fabio.urbano@totvs.com.br, T]
[fabricio.freitag@totvs.com.br, T]
[fabricio.santos@totvs.com.br, T]
[felipe.antunes@totvs.com.br, T]
[felipe.francisco@totvs.com.br, T]
[felipe.graziuso@totvs.com.br, T]
[felipe.perin@totvs.com.br, T]
[fernanda.cenci@totvs.com.br, F]
[fernanda.cenci@totvs.com.br, T]
[fernanda.moliveira@totvs.com.br, T]
[fernanda.ribeiro@totvs.com.br, F]
[fernando.coelho@totvs.com.br, T]
[fernando.paiva@totvs.com.br, T]
[fernando.rodrigo@totvs.com.br, F]
[fernando.rodrigo@totvs.com.br, T]
[fernando.tronca@totvs.com.br, F]
[fernando.tronca@totvs.com.br, T]
[filipe.baumeister@totvs.com.br, F]
[filipe.baumeister@totvs.com.br, T]
[flavia.rangel@totvs.com.br, F]
[flavia.rangel@totvs.com.br, T]
[flavio.tavares@totvs.com.br, T]
[fluigid.arg@totvs.com.br, T]
[fluigid.bh@totvs.com.br, T]
[fluigid.df@totvs.com.br, T]
[fluigid.eua@totvs.com.br, T]
[fluigid.jv@totvs.com.br, T]
[fluigid.mex@totvs.com.br, T]
[fluigid.poa@totvs.com.br, T]
[fluigid.rec@totvs.com.br, T]
[fluigid.rjo@totvs.com.br, T]
[fluig.mex@totvs.com.br, T]
[franciene.barcelos@totvs.com.br, T]
[francisco.araujo@totvs.com.br, T]
[francisco.nunes@totvs.com.br, F]
[francisco.nunes@totvs.com.br, T]
[frederico.sarinho@totvs.com.br, T]
[gabriela.demarchi@totvs.com.br, T]
[geizon.balsanelli@totvs.com.br, T]
[gerson.borba@totvs.com.br, T]
[gilberto.aguiar@totvs.com.br, T]
[gilmo.gomes@totvs.com.br, F]
[gilmo.gomes@totvs.com.br, T]
[gilson.venturi@totvs.com.br, T]
[gisele.gomes@totvs.com.br, T]
[giselle.froes@totvs.com.br, T]
[glauton@totvs.com.br, T]
[glayce.araujo@totvs.com.br, T]
[glaysson@totvs.com.br, T]
[goetten@totvs.com, T]
[graciele.deus@totvs.com.br, T]
[graziely.lima@totvs.com.br, T]
[guido.zilli@totvs.com.br, T]
[guilherme.marques@totvs.com.br, T]
[guilherme.nass@totvs.com.br, T]
[gustavo.avila@totvs.com.br, T]
[gustavo.carvalho@totvs.com.br, T]
[gustavo.giori@totvs.com.br, T]
[gyan.silva@totvs.com.br, T]
[heber.rodrigues@totvs.com.br, T]
[helena.leao@totvs.com.br, T]
[helena.leao@totvs.com.br, T, morgana.souza@totvs.com.br, T]
[helio.junior@totvs.com.br, T]
[henrique.eger@totvs.com.br, T]
[herculano.santos@totvs.com.br, T]
[hermes.machado@totvs.com.br, F]
[hugo.paiva@totvs.com.br, T]
[iago.passos@totvs.com.br, F]
[iago.passos@totvs.com.br, T]
[iara.silva@totvs.com.br, T]
[igor.cardoso@totvs.com.br, T]
[ilza.santos@totvs.com.br, T]
[irene@totvs.com.br, T]
[israel.fonseca@fluig.com, F]
[israel.fonseca@fluig.com, T]
[ivan.barcala@totvs.com.br, T]
[jackson.correa@totvs.com.br, T]
[jacqueline.melo@totvs.com.br, T]
[jaime.dambros@totvs.com.br, T]
[jaime.lima@totvs.com.br, F]
[jaime.lima@totvs.com.br, T]
[jairo.guimaraes@totvs.com.br, T]
[janaina.andrade@totvs.com.br, T]
[jandira.silva@totvs.com.br, F]
[jandira.silva@totvs.com.br, T]
[janete.fagundes@totvs.com.br, T]
[jaqueline.brum@totvs.com.br, T]
[jaqueline.orben@totvs.com.br, T]
[jean.eichholz@totvs.com.br, F]
[jean.eichholz@totvs.com.br, T]
[jean.v@totvs.com.br, T]
[jessica.gomes@totvs.com.br, T]
[jessyca.nobrega@totvs.com.br, T]
[jimena.hurtado@totvs.com.br, T]
[joane.setin@totvs.com.br, T]
[joao.carlos@totvs.com.br, T]
[joao.ferreira@totvs.com.br, T]
[jonatas.santos@totvs.com.br, F]
[jonatas.santos@totvs.com.br, T]
[jonathan.pereira@totvs.com.br, T]
[jorgej@totvs.com.br, T]
[jose.cavalcanti@totvs.com.br, T]
[jose.leme@totvs.com.br, T]
[joselita.henrique@totvs.com.br, T]
[josep.junior@totvs.com.br, F]
[josep.junior@totvs.com.br, T]
[josiane.vasconcelos@totvs.com.br, T]
[juan.barbosa@totvs.com.br, T]
[juan.guzman@totvs.com.br, T]
[juan.vila@totvs.com.br, T]
[juliana.brambatti@totvs.com.br, T]
[juliana.oliveira@totvs.com.br, T]
[juliana.sebastiao@totvs.com.br, T]
[juliane.souza@totvs.com.br, T]
[julio.lidani@totvs.com.br, T]
[julio.mansur@totvs.com.br, T]
[julio.zimmermann@totvs.com.br, T]
[junea@totvs.com.br, F]
[junea@totvs.com.br, T]
[karine.cardoso@totvs.com.br, T]
[karine.macaneiro@totvs.com.br, T]
[karin.schroder@totvs.com.br, T]
[karla.klemke@totvs.com.br, T]
[karla.sanchez@totvs.com.br, T]
[kayonne.reis@totvs.com.br, T]
[kenia.muniz@totvs.com.br, F]
[kenia.muniz@totvs.com.br, T]
[koppany.marcondes@totvs.com.br, T]
[laissa.barros@totvs.com.br, T]
[larissa.costa@totvs.com.br, T]
[lauan.coelho@totvs.com.br, T]
[lauren.barbosa@totvs.com.br, F]
[layla.vilela@totvs.com.br, T]
[leandro.alves@totvs.com.br, T]
[leandro.gimenez@totvs.com.br, T]
[leandro.saldanha@totvs.com.br, T]
[leandro.santana@totvs.com.br, F]
[leandro.vale@totvs.com.br, T]
[lea@totvs.com.br, T]
[leonardo.caselli@totvs.com.br, F]
[leonardo.caselli@totvs.com.br, F, ricart.monachesi@totvs.com.br, T]
[leonardo.giovelli@totvs.com.br, T]
[leonardo.miguel@totvs.com.br, T]
[leonard.severo@totvs.com.br, T]
[leticia.bomfim@totvs.com.br, T]
[lidiomar.machado@totvs.com.br, T]
[lina.guimaraes@totvs.com.br, T]
[lisandra.santos@totvs.com.br, T]
[lopes@totvs.com.br, T]
[lorena.correa@totvs.com.br, T]
[lorena.reinoso@totvs.com.br, T]
[louize@totvs.com.br, T]
[lucas.raineri@totvs.com.br, F]
[lucas.raineri@totvs.com.br, T]
[lucas.santos@totvs.com.br, T]
[luciana.nogueira@totvs.com.br, T]
[luciane.gomes@totvs.com.br, T]
[luciane.martins@totvs.com.br, T]
[luighy.santos@totvs.com.br, F]
[luighy.santos@totvs.com.br, T]
[luis.lopes@totvs.com.br, T]
[luis.marques@totvs.com.br, T]
[luis.vindigni@totvs.com.br, T]
[luiz.aniceto@totvs.com.br, T]
[luiz.mantovani@totvs.com.br, T]
[luiz.papa@totvs.com.br, T]
[luzia.souza@totvs.com.br, T]
[maicon.lima@totvs.com.br, F]
[maicon.lima@totvs.com.br, T]
[maikon.passos@totvs.com.br, T]
[maisa.oliveira@totvs.com.br, T]
[manoel.pereira@totvs.com.br, T]
[marcelly.silva@totvs.com.br, T]
[marcelo.besteiro@totvs.com.br, T]
[marcelo.damaceno@totvs.com.br, T]
[marcelo.fontana@totvs.com.br, F]
[marcelo.kaique@totvs.com.br, T]
[marcelo.ledesma@totvs.com.br, T]
[marcio.prado@totvs.com.br, T]
[marconi.costa@totvs.com.br, T]
[marcos.casado@totvs.com.br, T]
[marco.scheidt@totvs.com.br, T]
[marcos.luiz@totvs.com.br, T]
[marcos.oliveira@totvs.com.br, T]
[marcus.brisolara@totvs.com.br, T]
[marcus.miranda@totvs.com.br, T]
[maria.andrade@totvs.com.br, T]
[maria.barreto@totvs.com.br, T]
[maria.lipinski@totvs.com.br, T]
[marianan@totvs.com.br, F]
[marianan@totvs.com.br, T, karine.macaneiro@totvs.com.br, T]
[mariana.vazquez@totvs.com, T]
[mariano.cuello@totvs.com.br, T]
[maria.paula@totvs.com.br, T]
[maria.rocha@totvs.com.br, F]
[maria.souza@totvs.com.br, T]
[marildo.mendonca@totvs.com.br, T]
[marina.mansur@totvs.com.br, F]
[marina.mansur@totvs.com.br, T]
[marlon.girardello@totvs.com.br, T]
[mateus.matos@totvs.com.br, F]
[mateus.matos@totvs.com.br, T]
[matheus.alves@totvs.com.br, F]
[matheus.alves@totvs.com.br, T]
[matheus.zenato@totvs.com.br, T]
[mauricio.assis@totvs.com.br, T]
[mauricio.balena@totvs.com.br, T]
[mauricio.bell@totvs.com.br, F]
[mauricio.bell@totvs.com.br, T]
[mauricio.cruz@totvs.com.br, F]
[mauricio.faoro@totvs.com.br, F]
[mauricio.faoro@totvs.com.br, T]
[mauricio.jesus@totvs.com.br, T]
[mauricio.obenaus@totvs.com.br, F]
[mauricio.obenaus@totvs.com.br, T]
[mauro.vilosio@totvs.com.br, T]
[mayra.araujo@totvs.com.br, T]
[mfiuza@totvs.com.br, T]
[mhsilva@totvs.com.br, T]
[michael.anderson@totvs.com.br, T]
[michele.silva@totvs.com.br, T]
[michelle.eger@totvs.com.br, F]
[michelle.silveira@totvs.com.br, F]
[michelle.silveira@totvs.com.br, T]
[michel.monich@totvs.com.br, F]
[michel.monich@totvs.com.br, T]
[mike.vieira@totvs.com.br, T]
[miriam.santos@totvs.com.br, T]
[monica.cananea@totvs.com.br, T]
[monica.moura@totvs.com.br, T]
[monique.freitas@totvs.com.br, F]
[monique.freitas@totvs.com.br, T]
[murilo.cardoso@totvs.com.br, T]
[natalia.silva@totvs.com.br, T]
[neomesio.silva@totvs.com.br, T]
[neuzir.silva@totvs.com.br, T]
[niara.caetano@totvs.com.br, T]
[nicolas.mendez@totvs.com.br, T]
[noeli.melo@totvs.com.br, T, jeferson.tornisielo@totvs.com.br, T]
[null, F]
[olavo.olivio@totvs.com.br, T]
[olinto.gomes@totvs.com.br, T]
[olivio.silva@totvs.com.br, T]
[orides.tomkiel@totvs.com.br, T]
[ovidio.negro@totvs.com.br, F]
[pablo.freitas@totvs.com.br, F]
[pablo.freitas@totvs.com.br, T]
[paula.maia@totvs.com.br, T]
[paulo.guilherme@totvs.com.br, T]
[paulo.miranda@totvs.com.br, T]
[paulo.rsouza@totvs.com.br, T]
[paulo.sardi@totvs.com.br, T]
[pedro.chagas@totvs.com.br, T]
[pedro.santos@totvs.com.br, T]
[piero.dallabona@totvs.com.br, T]
[pollyanna.carmel@totvs.com.br, T]
[polyana.pereira@totvs.com.br, T]
[priscila.amancio@totvs.com.br, T]
[priscila.martinez@totvs.com.br, T]
[priscilau@totvs.com.br, T]
[qenia.silva@totvs.com.br, F]
[qenia.silva@totvs.com.br, T]
[rafaelalmeida@totvs.com.br, T]
[rafaela.machado@totvs.com.br, T]
[rafael.balthar@totvs.com.br, F]
[rafael.balthar@totvs.com.br, T]
[rafael.borges@totvs.com.br, F]
[rafael.mendes@totvs.com.br, T]
[rafael.souza@totvs.com.br, T]
[rafael.suarez@totvs.com.br, T]
[rafael.timm@totvs.com.br, T]
[rafael.velloso@totvs.com.br, T]
[rafael.vitor@totvs.com.br, T]
[raissa.alves@totvs.com.br, T]
[ramon.dias@totvs.com.br, T]
[raphael.costa@totvs.com.br, T]
[raphael.neves@totvs.com.br, T]
[raphael.vitorino@totvs.com.br, T]
[reinaldo.junior@fluig.com, T]
[renan.daniel@totvs.com.br, T]
[renan.serpa@totvs.com.br, F]
[renan.serpa@totvs.com.br, T]
[renata.albergaria@totvs.com.br, T]
[renata.vasconcelos@totvs.com.br, T]
[renato.zattar@totvs.com.br, T]
[rene.ferrari@totvs.com.br, T]
[renivaldo.silva@totvs.com.br, T]
[ricardo.andrade@totvs.com.br, T]
[ricardo.menna@totvs.com.br, T]
[ricardo.sgomes@totvs.com.br, T]
[ricardo.s@totvs.com.br, T]
[richard.heiras@totvs.com.br, F]
[richard.heiras@totvs.com.br, T]
[ricielli.martins@totvs.com.br, F]
[ricielli.martins@totvs.com.br, T]
[roberson.silva@totvs.com.br, T]
[roberto.duessmann@totvs.com.br, T]
[roberto.marques@totvs.com.br, T]
[roberto.mendes@totvs.com.br, T]
[robert.santos@totvs.com.br, T]
[robson.oliveira@totvs.com.br, T]
[rocio.chousa@totvs.com.br, T]
[Rodrigo.Cardoso@totvs.com.br, T]
[rodrigo.carvalho@totvs.com.br, F]
[rodrigo.carvalho@totvs.com.br, T]
[rodrigo.chaves@totvs.com.br, T]
[rodrigo.cunha@totvs.com.br, T]
[rodrigo.dornelas@totvs.com.br, F]
[rodrigo.dornelas@totvs.com.br, T]
[rodrigo.grossi@totvs.com.br, T]
[rodrigo.marinho@totvs.com.br, T]
[rodrigo.neves@totvs.com.br, T, dorival.langer@totvs.com.br, T]
[rodrigo.nunes@totvs.com.br, F]
[rodrigo.pacheco@totvs.com.br, F]
[rodrigo.pacheco@totvs.com.br, T]
[rodrigo.salgado@totvs.com.br, T]
[rodrigo.sobral@totvs.com.br, T]
[rodrigo.storckmann@totvs.com.br, T]
[rodrigo.zuge@totvs.com.br, T]
[ronaldo.candido@totvs.com.br, F]
[roney.oliveira@totvs.com.br, T]
[rosana.santos@totvs.com.br, T]
[rosana.torchiana@totvs.com.br, T]
[rosangela.alecrim@totvs.com.br, T]
[rosenei.oliveira@totvs.com.br, T]
[sade@totvs.com.br, T]
[sandro.medeiros@totvs.com.br, T]
[savio.moura@totvs.com.br, T]
[sbali@totvs.com.br, F]
[sbali@totvs.com.br, T]
[scarlet.cardoso@totvs.com.br, F]
[selmo.cordeiro@totvs.com.br, T]
[sergio.carneiro@totvs.com.br, T]
[sergio.moreira@totvs.com.br, T]
[sheila.cyrillo@totvs.com.br, T]
[shyrley.oliveira@totvs.com.br, T]
[silvano.rocha@totvs.com.br, T]
[silvestre@totvs.com.br, T]
[silvia.cardoso@totvs.com.br, T]
[silvio.junior@totvs.com.br, T]
[solange.videira@totvs.com.br, T]
[stephanie.lovisolo@totvs.com.br, F]
[stephanie.lovisolo@totvs.com.br, T]
[sueli.barkemeyer@totvs.com.br, T]
[taciana.padilha@totvs.com.br, T]
[tales.siqueira@totvs.com.br, T]
[tatiana.antunes@totvs.com.br, T]
[tatiana.pereira@totvs.com.br, T]
[tatiana.turos@totvs.com.br, T]
[tatiane.f@totvs.com.br, T]
[tatiane.koslinsky@totvs.com.br, T]
[thiago.carvalho@totvs.com.br, T]
[thiago.lima@totvs.com.br, T]
[thiago.oliveira@totvs.com.br, T]
[thiago.portugal@totvs.com.br, T]
[thiago.venturelli@fluig.com, T]
[tiago.drehmer@totvs.com.br, F]
[Tiago.Santo@totvs.com.br, T]
[tldomingos@totvs.com.br, T]
[ubajara.lomando@totvs.com.br, T]
[ulisses.silva@totvs.com.br, T]
[uno.theilacher@totvs.com.br, T]
[valmire.ribeiro@totvs.com.br, T]
[valtrudes.witt@totvs.com.br, T]
[vandre.moraes@totvs.com.br, T]
[vanessa.batista@totvs.com.br, F]
[vanessa.batista@totvs.com.br, T]
[vanessa.petri@totvs.com.br, T]
[vanessa.suzuki@totvs.com.br, T]
[victoria.brizuela@totvs.com.br, T]
[vinicius.pagung@totvs.com.br, F]
[vinicius.pagung@totvs.com.br, T]
[vinicius.silva@totvs.com.br, T]
[vitor.barba@totvs.com.br, T]
[viviane.anjos@totvs.com.br, F]
[vivian.nogueira@totvs.com.br, T]
[wanderson.silva@totvs.com.br, T]
[wellington.leonotti@totvs.com.br, T]
[weniton.joaquim@totvs.com.br, T]
[wesley.amorim@totvs.com.br, T]
[wesley.vieira@totvs.com.br, T]
[william.oliveira@fluig.com, T]
[willian.anastacio@totvs.com.br, T]
[willian.fortunato@totvs.com.br, T]
[yanina.garcia@totvs.com.br, T]
[yttalo.martins@totvs.com.br, T]
[zaar.ribeiro@totvs.com.br, T]
root@app2:~#

LikeBe the first to like this
No labels Edit Labels
User icon: Denny
Write a comment…
Powered by Atlassian | Terms of Use | Answers | Maintenance Schedule
#+END_EXAMPLE
** Issue: qa1b tomcat errors
#+BEGIN_EXAMPLE
Skip to content
Skip to breadcrumbs
Skip to header menu
Skip to action menu
Skip to quick search
Linked Applications
Confluence
Spaces
People
 Create
Quick Search
0


TechOps
Configure
 Edit  Watch  Share
Pages  TechOps Home  Issues List For Service Maintainnce
Skip to end of banner
Go to start of banner
Issue: 2014/08/07 qa1b tomcat errors
Skip to end of metadata
Created by Denny Zhang, last modified on Aug 07, 2014 Go to start of metadata
See the list of all issues here: https://totvslab.atlassian.net/wiki/display/TECH/Issues+List+For+Service+maintainnce
Issue Summary:
The issue happened in 2014/08/07.  Bill Nguyen, Kung Wang, Denny Zhang and some other colleagues are involved.
Kung has reports that qa1b is not responding.  He had to restart tomcat to resolve issues.

Improvement points:
Need to look into tomcat log and push it back to frontend folks to investidate
Improve tomcat monitoring for errors such 500?

Detail:
fluig-id-qa-02:/var/log/tomcat7# grep -i exception -C 4 cloudpass.log
grep -i exception -C 4 cloudpass.log
2014-08-07 19:28:42,807 [ajp-bio-8009-exec-4] WARN cloudpass.LoginController - Add cookie domain: .thecloudpass.com
2014-08-07 19:29:01,930 [ajp-bio-8009-exec-21] WARN cloudpass.LoginController - Add cookie domain: .thecloudpass.com
2014-08-07 19:29:03,824 [ajp-bio-8009-exec-21] WARN cloudpass.LoginController - redirect to /SPInitPost/receiveSSORequest/v544ngmlzu4m0qs81405619580011/42 after login.
2014-08-07 19:29:03,915 [ajp-bio-8009-exec-21] INFO binding.HttpPostBindingAdapter - decoding using HttpPostDecoder...
2014-08-07 19:29:03,915 [ajp-bio-8009-exec-21] ERROR binding.AuthnRequestProcessor - Exception extracting SAML message from the request: This message decoder only supports the HTTP POST method
2014-08-07 19:29:03,916 [ajp-bio-8009-exec-21] ERROR saml2.SPInitPostController - Exception processing SAML: Exception extracting SAML message from the request: This message decoder only supports the HTTP POST method
2014-08-07 19:29:04,746 [ajp-bio-8009-exec-3] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user patricia.theilacker@totvs.com.br
2014-08-07 19:29:13,473 [ajp-bio-8009-exec-3] WARN cloudpass.LaunchpadController - Saml redirect to: http://moitas:8380/portal/idp
2014-08-07 19:29:13,805 [ajp-bio-8009-exec-3] INFO binding.HttpPostBindingAdapter - decoding using HttpPostDecoder...
2014-08-07 19:29:13,808 [ajp-bio-8009-exec-3] DEBUG PROTOCOL_MESSAGE -
--
2014-08-07 19:37:03,220 [ajp-bio-8009-exec-21] INFO binding.HttpPostBindingAdapter - message decoded...
2014-08-07 19:37:03,220 [ajp-bio-8009-exec-21] WARN filters.SecurityFilters - No session user. forward to /SPInitPost/receiveSSORequest/v544ngmlzu4m0qs81405619580011/ygarwo10jls8y4xk1406322214936
2014-08-07 19:37:04,162 [ajp-bio-8009-exec-21] WARN cloudpass.LoginController - Add cookie domain: .thecloudpass.com
2014-08-07 19:37:15,827 [ajp-bio-8009-exec-20] ERROR StackTrace - Full Stack Trace:
java.lang.IllegalStateException: Expected BEGIN_OBJECT but was STRING at line 1 column 26
at com.google.gson.stream.JsonReader.expect(JsonReader.java:339)
at com.google.gson.stream.JsonReader.beginObject(JsonReader.java:322)
at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:165)
at com.google.gson.Gson.fromJson(Gson.java:795)
--
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
at java.lang.Thread.run(Thread.java:745)
2014-08-07 19:37:15,828 [ajp-bio-8009-exec-20] ERROR StackTrace - Full Stack Trace:
java.lang.IllegalStateException: Expected BEGIN_OBJECT but was STRING at line 1 column 26
at com.google.gson.stream.JsonReader.expect(JsonReader.java:339)
at com.google.gson.stream.JsonReader.beginObject(JsonReader.java:322)
at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:165)
at com.google.gson.Gson.fromJson(Gson.java:795)
--
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
at java.lang.Thread.run(Thread.java:745)
2014-08-07 19:37:15,853 [ajp-bio-8009-exec-20] ERROR StackTrace - Full Stack Trace:
java.lang.IllegalStateException: Expected BEGIN_OBJECT but was STRING at line 1 column 26
at com.google.gson.stream.JsonReader.expect(JsonReader.java:339)
at com.google.gson.stream.JsonReader.beginObject(JsonReader.java:322)
at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:165)
at com.google.gson.Gson.fromJson(Gson.java:795)
--
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
at java.lang.Thread.run(Thread.java:745)
2014-08-07 19:37:15,853 [ajp-bio-8009-exec-20] ERROR StackTrace - Full Stack Trace:
java.lang.IllegalStateException: Expected BEGIN_OBJECT but was STRING at line 1 column 26
at com.google.gson.stream.JsonReader.expect(JsonReader.java:339)
at com.google.gson.stream.JsonReader.beginObject(JsonReader.java:322)
at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:165)
at com.google.gson.Gson.fromJson(Gson.java:795)
--
2014-08-07 19:40:13,630 [ajp-bio-8009-exec-26] INFO binding.HttpPostBindingAdapter - message decoded...
2014-08-07 19:40:13,631 [ajp-bio-8009-exec-26] WARN filters.SecurityFilters - No session user. forward to /SPInitPost/receiveSSORequest/gtv9ltuw29490s9o1405604385747/42
2014-08-07 19:40:13,670 [ajp-bio-8009-exec-26] WARN cloudpass.LoginController - Add cookie domain: .thecloudpass.com
2014-08-07 19:40:43,109 [ajp-bio-8009-exec-3] ERROR StackTrace - Full Stack Trace:
java.lang.ClassNotFoundException: com.sun.jersey.api.client.UniformInterfaceException (no security manager: RMI class loader disabled)
at sun.rmi.server.LoaderHandler.loadClass(LoaderHandler.java:393)
at sun.rmi.server.LoaderHandler.loadClass(LoaderHandler.java:185)
at java.rmi.server.RMIClassLoader$2.loadClass(RMIClassLoader.java:637)
at java.rmi.server.RMIClassLoader.loadClass(RMIClassLoader.java:264)
--
at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:369)
at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:109)
at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:83)
at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:381)
at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:97)
at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:381)
at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:78)
at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:381)
at org.springframework.security.web.authentication.rememberme.RememberMeAuthenticationFilter.doFilter(RememberMeAuthenticationFilter.java:112)
--
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
at java.lang.Thread.run(Thread.java:745)
2014-08-07 19:40:43,115 [ajp-bio-8009-exec-3] ERROR StackTrace - Full Stack Trace:
java.lang.ClassNotFoundException: com.sun.jersey.api.client.UniformInterfaceException (no security manager: RMI class loader disabled)
at java.rmi.server.RMIClassLoader$2.loadClass(RMIClassLoader.java:637)
at java.rmi.server.RMIClassLoader.loadClass(RMIClassLoader.java:264)
at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1612)
at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1517)
--
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
at java.lang.Thread.run(Thread.java:745)
2014-08-07 19:40:43,154 [ajp-bio-8009-exec-3] ERROR StackTrace - Full Stack Trace:
java.lang.ClassNotFoundException: com.sun.jersey.api.client.UniformInterfaceException (no security manager: RMI class loader disabled)
at java.rmi.server.RMIClassLoader$2.loadClass(RMIClassLoader.java:637)
at java.rmi.server.RMIClassLoader.loadClass(RMIClassLoader.java:264)
at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1612)
at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1517)
--
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
at java.lang.Thread.run(Thread.java:745)
2014-08-07 19:40:43,155 [ajp-bio-8009-exec-3] ERROR StackTrace - Full Stack Trace:
java.lang.ClassNotFoundException: com.sun.jersey.api.client.UniformInterfaceException (no security manager: RMI class loader disabled)
at java.rmi.server.RMIClassLoader$2.loadClass(RMIClassLoader.java:637)
at java.rmi.server.RMIClassLoader.loadClass(RMIClassLoader.java:264)
at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1612)
at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1517)
--
</saml2p:Response>
2014-08-07 19:43:34,878 [ajp-bio-8009-exec-21] INFO binding.SSOHandler - Saml response sent
2014-08-07 19:43:35,344 [ajp-bio-8009-exec-21] INFO binding.HttpPostBindingAdapter - decoding using HttpPostDecoder...
2014-08-07 19:43:35,344 [ajp-bio-8009-exec-21] ERROR binding.AuthnRequestProcessor - Exception extracting SAML message from the request: This message decoder only supports the HTTP POST method
2014-08-07 19:43:35,345 [ajp-bio-8009-exec-21] ERROR saml2.SPInitPostController - Exception processing SAML: Exception extracting SAML message from the request: This message decoder only supports the HTTP POST method
2014-08-07 19:43:51,490 [ajp-bio-8009-exec-21] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user patricia.theilacker@totvs.com.br
2014-08-07 19:43:58,406 [ajp-bio-8009-exec-21] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user patricia.theilacker@totvs.com.br
2014-08-07 19:43:58,487 [ajp-bio-8009-exec-4] WARN filters.SecurityFilters - Unauthorized accesss to configuration-getLocalizedMessages, redirecting user patricia.theilacker@totvs.com.br
2014-08-07 19:44:09,961 [ajp-bio-8009-exec-21] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user patricia.theilacker@totvs.com.br
--
2014-08-07 19:46:02,882 [ajp-bio-8009-exec-18] INFO binding.AuthnRequestProcessor - Incoming message was an AuthnRequest
2014-08-07 19:46:02,882 [ajp-bio-8009-exec-18] INFO binding.AuthnRequestProcessor - Request: <?xml version="1.0" encoding="UTF-8"?>
<saml2p:AuthnRequest AssertionConsumerServiceURL="http://experiencias.fluig.com/portal/idp/ACS" Destination="https://uxtotvs.thecloudpass.com/cloudpass/SPInitPost/receiveSSORequest/pl622a90e1xt274n1405551958681/42" ID="_9579e9e7d97c601afae5c5ad2327ead9" IssueInstant="2014-08-07T19:43:23.115Z" ProtocolBinding="urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST" ProviderName="TotvsLabs" Version="2.0" xmlns:saml2p="urn:oasis:names:tc:SAML:2.0:protocol"><saml2:Issuer Format="urn:oasis:names:tc:SAML:2.0:nameid-format:entity" xmlns:saml2="urn:oasis:names:tc:SAML:2.0:assertion">TotvsLabs</saml2:Issuer><saml2p:NameIDPolicy Format="urn:oasis:names:tc:SAML:2.0:nameid-format:transient"/></saml2p:AuthnRequest>
2014-08-07 19:46:02,883 [ajp-bio-8009-exec-18] INFO binding.AuthnRequestProcessor - SAML Request is valid....will be processed
2014-08-07 19:46:02,886 [ajp-bio-8009-exec-18] ERROR saml2.SPInitPostController - Exception processing SAML: null
2014-08-07 19:46:05,037 [ajp-bio-8009-exec-4] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user fluigbh@gmail.com
2014-08-07 19:46:08,672 [ajp-bio-8009-exec-21] WARN cloudpass.LaunchpadController - Saml redirect to: http://fluig.bh01.local:12012/portal/idp
2014-08-07 19:46:17,157 [ajp-bio-8009-exec-3] WARN cloudpass.LoginController - Add cookie domain: .thecloudpass.com
2014-08-07 19:46:24,443 [ajp-bio-8009-exec-3] WARN cloudpass.LoginController - Login redirect user to: https://uxtotvs.thecloudpass.com/cloudpass/launchpad/launchAppList
--
2014-08-07 19:46:58,929 [ajp-bio-8009-exec-4] INFO binding.SSOHandler - Saml response sent
2014-08-07 19:47:03,775 [ajp-bio-8009-exec-3] WARN cloudpass.LoginController - redirect to /SPInitPost/receiveSSORequest/v544ngmlzu4m0qs81405619580011/ygarwo10jls8y4xk1406322214936 after login.
2014-08-07 19:47:03,855 [ajp-bio-8009-exec-3] INFO binding.HttpPostBindingAdapter - decoding using HttpPostDecoder...
2014-08-07 19:47:03,856 [ajp-bio-8009-exec-3] ERROR binding.AuthnRequestProcessor - Exception extracting SAML message from the request: This message decoder only supports the HTTP POST method
2014-08-07 19:47:03,856 [ajp-bio-8009-exec-3] ERROR saml2.SPInitPostController - Exception processing SAML: Exception extracting SAML message from the request: This message decoder only supports the HTTP POST method
2014-08-07 19:47:04,451 [ajp-bio-8009-exec-21] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user rodrigo.reis@totvs.com.br
2014-08-07 19:47:07,004 [ajp-bio-8009-exec-3] WARN cloudpass.LaunchpadController - set user context to: v544ngmlzu4m0qs81405619580011
2014-08-07 19:47:07,571 [ajp-bio-8009-exec-18] WARN filters.SecurityFilters - No session user. forward to /launchpad/launchApp?id=p0yelbnhql77v1yh1406910584479&RelayState=module%3D815%26routine%3Dwms6202%26company%3D053113791001790_255721161_SP%26session%3DRKD1YJVZ%2B%2BLExipql6E%2BUDXD%26fluig%3D1
2014-08-07 19:47:07,628 [ajp-bio-8009-exec-4] WARN cloudpass.LoginController - Add cookie domain: .thecloudpass.com
--
2014-08-07 19:55:14,464 [ajp-bio-8009-exec-26] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user taise@totvs.com.br
2014-08-07 19:55:16,726 [ajp-bio-8009-exec-18] WARN cloudpass.LoginController - Add cookie domain: .thecloudpass.com
2014-08-07 19:55:20,727 [ajp-bio-8009-exec-13] WARN cloudpass.LoginController - redirect to /SPInitPost/receiveSSORequest/v544ngmlzu4m0qs81405619580011/ygarwo10jls8y4xk1406322214936 after login.
2014-08-07 19:55:20,833 [ajp-bio-8009-exec-13] INFO binding.HttpPostBindingAdapter - decoding using HttpPostDecoder...
2014-08-07 19:55:20,833 [ajp-bio-8009-exec-13] ERROR binding.AuthnRequestProcessor - Exception extracting SAML message from the request: This message decoder only supports the HTTP POST method
2014-08-07 19:55:20,833 [ajp-bio-8009-exec-13] ERROR saml2.SPInitPostController - Exception processing SAML: Exception extracting SAML message from the request: This message decoder only supports the HTTP POST method
2014-08-07 19:55:24,992 [ajp-bio-8009-exec-3] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user rodrigo.reis@totvs.com.br
2014-08-07 19:55:28,296 [ajp-bio-8009-exec-3] WARN cloudpass.LaunchpadController - set user context to: v544ngmlzu4m0qs81405619580011
2014-08-07 19:55:29,857 [ajp-bio-8009-exec-13] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user rodrigo.reis@totvs.com.br
2014-08-07 19:55:30,396 [ajp-bio-8009-exec-13] WARN filters.SecurityFilters - Unauthorized accesss to user-getNavAdminLinks, redirecting user rodrigo.reis@totvs.com.br
fluig-id-qa-02:/var/log/tomcat7#


LikeBe the first to like this
No labels Edit Labels
User icon: Denny
Write a comment…
Powered by Atlassian | Terms of Use | Answers | Maintenance Schedule
#+END_EXAMPLE
** Issue: Customers from JV domain could not log in, after restarting smartsync service it's fine
#+BEGIN_EXAMPLE
Skip to content
Skip to breadcrumbs
Skip to header menu
Skip to action menu
Skip to quick search
Linked Applications
Confluence
Spaces
People
 Create
Quick Search
0


TechOps
Configure
 Edit  Watch  Share
Pages  TechOps Home  Issues List For Service Maintainnce
Skip to end of banner
Go to start of banner
Issue: 2014/07/31 Customers from JV domain could not log in, after restarting smartsync service it's fine
Skip to end of metadata
Created by Denny Zhang, last modified on Jul 31, 2014 Go to start of metadata
See the list of all issues here: https://totvslab.atlassian.net/wiki/display/TECH/Issues+List+For+Service+maintainnce
Issue Summary:
The issue happened in 2014/07/31.  Bill Nguyen, Denny Zhang, and some other colleagues are involved.
Customers from JV domain could not log in, restarted smartsync server
Then it works.
Improvement points:
Still see a lots of adping in apache's log. Should we change the pull frequency of smartsync?
Loadbalance expiration doesn't work. No overlap client ip for app01 and app02 is found.


Detail:
root@app1:/data/fluigidentity-logs# tail -n 100000 /data/fluigidentity-logs/adsync.log | grep '2014-07-31.*RESULT GOT FROM SMART SYNC' | wc -l
860
root@app1:/data/fluigidentity-logs# tail -n 10000 /var/log/apache2/www.fluigidentity.com_ssl_access.log | grep "31/Jul/2014" | grep "adcommand/get" | cut -d" " -f1 | sort | uniq -c
8959 172.20.16.1
969 201.44.251.2
root@app1:/data/fluigidentity-logs#

root@app2:/data/fluigidentity-logs# tail -n 100000 /data/fluigidentity-logs/adsync.log | grep '2014-07-31.*RESULT GOT FROM SMART SYNC' | wc -l
42
root@app2:/data/fluigidentity-logs# tail -n 10000 /var/log/apache2/www.fluigidentity.com_ssl_access.log | grep "31/Jul/2014" | grep "adcommand/get" | cut -d" " -f1 | sort | uniq -c
6012 177.43.102.244
625 187.94.48.2
290 187.94.61.249
26 189.3.5.210
882 189.59.220.74
26 200.216.73.130
24 201.18.224.190
26 201.31.227.162
1776 201.48.226.194
root@app2:/data/fluigidentity-logs#
LikeBe the first to like this
No labels Edit Labels
User icon: Denny
Write a comment…
Powered by Atlassian | Terms of Use | Answers | Maintenance Schedule
#+END_EXAMPLE
** DONE Issue: Conf file(rmi.server.properties.local) is missing, which caused rest service misbehaves
  CLOSED: [2015-03-06 Fri 14:22]
#+BEGIN_EXAMPLE
Skip to content
Skip to breadcrumbs
Skip to header menu
Skip to action menu
Skip to quick search
Linked Applications
Confluence
Spaces
People
 Create
Quick Search
0


TechOps
Configure
 Edit  Watch  Share
Pages  TechOps Home  Issues List For Service Maintainnce
Skip to end of banner
Go to start of banner
Issue: 2014/07/30 Conf file(rmi.server.properties.local) is missing, which caused rest service misbehaves
Skip to end of metadata
Created by Denny Zhang, last modified on Jul 31, 2014 Go to start of metadata
See the list of all issues here: https://totvslab.atlassian.net/wiki/display/TECH/Issues+List+For+Service+maintainnce
Issue Summary:
The issue happened in 2014/07/30. Kung Wang , Bill Nguyen, Denny Zhang, Shivang Shah, Vicente Goetten and some other colleagues are involved.
A critical configuration file(rmi.server.properties.local) is missing. This caused rest service talks to the wrong rmi service instance.
Customers have identified this issue, before ourselves.
Improvement points:
The root cause seems to be manual misconfiguration for the conf file. We better use chef to maintain conf management, instead of human manual effort.
Improve nagios: Monitor logfiles for this exception
Email
From: Vicente Goetten <goetten@totvs.com>
Subject: REST Service issue
To: Bill Nguyen <bill.nguyen@totvs.com>, Denny Zhang <denny.zhang@totvs.com>, Kung Wang <kung.wang@totvs.com>
CC: Shivang Shah <shivang.shah@totvs.com>
Date: Wed, 30 Jul 2014 10:43:31 -0500
X-Priority: 1
Bill and Denny,
An issue with our rest service on production caused an impact in the integration with Moxtra and
with customers. It seems that the REST service could not connect to our RMI service after it was
stopped for the backup process.
We CAN NOT afford this kind of mistake! Aren’t we monitoring all the services? Why have we not
detected it? Again we were notified by our customers before we toke any action.
Kung
We need a meeting today to discuss this.
Thanks
Vicente Goetten
+1 650 933-4902 - goetten@totvs.com
Detail:
[7/30/14, 10:56:09] denny: denny added Bill Nguyen, kungchaowang, Shivang, Vicente Goetten to this conversation
[7/30/14, 10:59:12] denny: Guys, just got Vicente's email about rest service issue.
Our monitoring system status about this:
1. If rest service or rmi service are down, we get alerts emails
2. There're a period of 30 minutes downtime by design, which is caused by backup process. Thus we ignore alerts about that period.
From my observation, rest and rmi services were running in last night, except theses backup interval.
So anyone can give us more detail about this?
[7/30/14, 11:00:50] Vicente Goetten: the thing is
[7/30/14, 11:00:59] Vicente Goetten: for 30' the integration with moxtra didn't work in production
[7/30/14, 11:01:02] Vicente Goetten: Shivang has details
[7/30/14, 11:01:04] Vicente Goetten: I'm saying again
[7/30/14, 11:01:15] Vicente Goetten: we are in a situation where we can NOT afford this kind of mistakes
[7/30/14, 11:02:50] denny: Yes, agree.
After the case is clear, we will see what's the problem: Nagios check is not profound enough, or bugs in checks, or process problem, etc.
Shivang, would you please share with us more insights?
[7/30/14, 11:04:16] Shivang: you look at the rest logs .. this is the first time the error happened
[7/30/14, 11:04:16] Shivang: ERROR [2014-07-29 11:23:38,173] com.totvslabs.idm.rest.resources.OAuth2Resource: FAIURE - {"errorCode":500,"errorMessage":"System error occured","possibleResponsibleField":"Excepti
on - Lookup of RMI stub failed; nested exception is java.rmi.ConnectException: Connection refused to host: localhost; nested exception is: \n\tjava.net.ConnectException: Connection
refused"}
[7/30/14, 11:04:27] Shivang: which means it was not able ot connect to "localhost" host
[7/30/14, 11:04:32] Shivang: which means sense because rmi is NOT localhost
[7/30/14, 11:04:36] Shivang: its on a different server
[7/30/14, 11:04:59] denny: which server is the log from?
[7/30/14, 11:05:09] Shivang: and here's what I think happened (the theory that i shared with vicente)
[7/30/14, 11:05:09] Shivang: [7/30/14, 8:37:59 AM] Shivang: so .. the theory is
[7/30/14, 8:38:16 AM] Shivang: in general cases .. we have 2 config files (alteast I think we do)
[7/30/14, 8:38:23 AM] Shivang: rmi.server.properties
[7/30/14, 8:38:27 AM] Shivang: and rmi.server.properties.local
[7/30/14, 8:38:42 AM] Shivang: the .local file normally is specific to that server and during deployment it doesn't get overwritten
[7/30/14, 8:39:02 AM] Shivang: so it holds the configuraton (the rmi server ip) to connect to rmi from rest
[7/30/14, 8:39:12 AM] Shivang: now .. from what kung told me .. for backup .. we stop rest service every night
[7/30/14, 8:39:21 AM] Shivang: back it up .. and start again
[7/30/14, 8:39:42 AM] Shivang: now .. during this process .. somehow .. (and this is the theory) .. the .local file got deleted
[7/30/14, 8:40:00 AM] Shivang: and when it got deleted .. when the rest server starts up .. it picks up the .properties file
[7/30/14, 8:40:14 AM] Shivang: which has ip of localhost .. obviously the rmi server is not localhost
[7/30/14, 8:40:16 AM] Shivang: so it fails
[7/30/14, 8:40:33 AM] Shivang: that's the theory .. things I can't prove : 1) Was the file there before?
[7/30/14, 8:40:38 AM] Shivang: 2) If so, how was it deleted ..
[7/30/14, 8:40:56 AM] Shivang: if it wasn't there to start with, how did it even work before this failure (because it shouldn't work at all")
[7/30/14, 11:05:17] Shivang: this is msg01
[7/30/14, 11:06:54] Shivang: fair enough ?
[7/30/14, 11:07:13] denny: Yes, I understand what you're saying.
Thanks, Svhivang.
[7/30/14, 11:07:16] Bill Nguyen: Hi Shivang, My backup has been deploying and working in the last weeks and it does not touch any configuration files
[7/30/14, 11:07:34] Shivang: and that's why i said .. I can't prove anything .. i have no idea what happened
[7/30/14, 11:07:39] Shivang: all i can tell you what happened is
[7/30/14, 11:07:48] Shivang: rest configuration was pointing to localhost
[7/30/14, 11:07:51] Shivang: for rmi
[7/30/14, 11:10:51] denny: Yes, Shivang and Bill.
Let's explore the mystery together.
Question1: How to identify this kind of issue later? grep log for that exception?
*Currently nagios check WILL NOT find this problem.*
The service is running and ports is listening, though they don't functional work.
Functional test api of REST service is not working. @Kung and @Bill are working on that, based on the email.
[7/30/14, 11:17:29] denny: Question2: If we setup an inotify monitor for rmi.server.properties. Later if any process change that config file, we dump the process info in log.
So we can know which process change that, right?
[7/30/14, 11:34:00] Vicente Goetten: now I need to reply to an email that has been escalated to the stratosphere
[7/30/14, 11:34:03] Vicente Goetten: what should I say?
[7/30/14, 11:34:07] Vicente Goetten: what was the error?
[7/30/14, 11:34:30] denny: ===========================================
@Shivang & @Kung
Do you know why REST healthcheck fail? I noticed several error messages in the tail of rest.log.
root@fluig-id-messaging-01:~# curl http://localhost:18091/admin/healthcheck
curl http://localhost:18091/admin/healthcheck
{"Rest HealthyCheck":{"healthy":false,"message":"Rest Server is unhealthy."},"deadlocks":{"healthy":true}}
[7/30/14, 11:35:23] denny: ==============================================
@Vicente, an important configuration file is missing, which causes some service misbehaves?
[7/30/14, 11:36:20] Bill Nguyen: adsync and search are working
[7/30/14, 11:36:48] Shivang: vicenyw
[7/30/14, 11:37:10] Shivang: tell them we are working on some awesome monitoring tools and we will get this taken care of
[7/30/14, 11:37:32] Shivang: they wont understamd if you give twchnical error details anyways
[7/30/14, 11:44:30] denny: Yes, sorry for that, Vicente.
We guys may need to talk see what improvement we can make.
Say, if some critical errors/excpetions are found in log file, we shall raise alerts.
In current case, we can monitor rest.log for
"Lookup of RMI stub failed; nested exception is java.rmi.ConnectException: Connection refused to host: localhost; nested exception is".
Here is a list of errors/exceptions messages I tracked before. We can start from it.
https://totvslab.atlassian.net/wiki/display/TECH/Fluig+logging
[7/30/14, 12:49:50] kungchaowang: I believe this incident was happen yesterday right? because I only see that file got changed by me yesterday:
11419585 4 -rw-r--r-- 1 root root 1773 Jul 22 22:45 ./server.properties
11419665 4 -rw-r--r-- 1 root root 118 Jul 22 22:39 ./com/totvslabs/idm/locale/messages/sms.properties
11419664 12 -rw-r--r-- 1 root root 9237 Jul 22 22:39 ./com/totvslabs/idm/locale/messages/email_content_pt-br.properties
11419666 12 -rw-r--r-- 1 root root 9007 Jul 22 22:39 ./com/totvslabs/idm/locale/messages/email_content.properties
11419682 4 -rw-r--r-- 1 root root 1157 Jul 22 22:39 ./com/totvslabs/idm/search/lucene.hornetq.properties
11419671 4 -rw-r--r-- 1 root root 42 Jul 22 22:39 ./com/totvslabs/idm/messaging/common/hornetq.properties
11419669 4 -rw-r--r-- 1 root root 181 Jul 22 22:45 ./com/totvslabs/idm/messaging/common/hornetq.jndi.properties
11419660 4 -rw-r--r-- 1 root root 32 Jul 22 22:43 ./com/totvslabs/idm/rmi/client/scim/scim.rmi.server.properties
11406828 4 -rw-r--r-- 1 root root 33 Jul 29 18:27 ./com/totvslabs/idm/rmi/client/rmi.server.properties
11419675 4 -rw-r--r-- 1 root root 1652 Jul 22 22:39 ./com/totvslabs/idm/ad/adsync.hornetq.properties
11419620 4 -rw-r--r-- 1 root root 216 Jul 22 22:45 ./keystore.server.properties
11419638 4 -rw-r--r-- 1 root root 2185 Jul 22 22:39 ./couchbase_views.properties
11419702 4 -rw-r--r-- 1 root root 134 Jul 22 22:39 ./appId.properties
11419628 4 -rw-r--r-- 1 root root 645 Jul 22 22:39 ./clientSecrets.properties
root@fluig-id-messaging-01:/cloudpass/backend/build/config# more com/totvslabs/idm/rmi/client/rmi.server.properties
hostname=172.20.16.12
port=11111

LikeBe the first to like this
No labels Edit Labels
1 Comment
 User icon: bill.nguyen
Bill Nguyen
need to have chef to manage apache configurations, and all configurations should be in GIT


ReplyDeleteUnlike•You like thisJul 31, 2014
User icon: Denny
Write a comment…
Powered by Atlassian | Terms of Use | Answers | Maintenance Schedule

#+END_EXAMPLE
** Issue: RMI and couchbase communication problem caused slow login to fluig GUI
#+BEGIN_EXAMPLE
Skip to content
Skip to breadcrumbs
Skip to header menu
Skip to action menu
Skip to quick search
Linked Applications
Confluence
Spaces
People
 Create
Quick Search
0


TechOps
Configure
 Edit  Watch  Share
Pages  TechOps Home  Issues List For Service Maintainnce
Skip to end of banner
Go to start of banner
Issue: 2014/08/19 RMI and couchbase communication problem caused slow login to fluig GUI
Skip to end of metadata
Created by Denny Zhang, last modified on Aug 19, 2014 Go to start of metadata
[19 Aug 2014;13:16:21.978] - [ERROR] [IdmDistributedCacheClient:77] - Timeout waiting for value: waited 10,000 ms. Node status: Connection Status { 172.21.16.11/172.21.16.11:11210 active: true, authed: true, last read: 211,693 ms ago 172.21.16.12/172.21.16.12:11210 active: true, authed: true, last read: 211,697 ms ago }
SOLUTION:
      restart app02 services rmi/adsync/tomcat/apache


connection to couch base timing out between [19 Aug 2014;13:13:13.320] - [19 Aug 2014;13:37:02.162]


See the list of all issues here: https://totvslab.atlassian.net/wiki/display/TECH/Issues+List+For+Service+maintainnce
Issue Summary:

cloudpass.log
2014-08-19 20:39:19,017 [ajp-bio-8009-exec-1140] ERROR StackTrace - Full Stack Trace:
{"errorCode":500,"possibleResponsibleField":"SYSTEM_FAILURE"}
at com.totvslabs.idm.rmi.service.impl.UserServiceInterfaceImpl.validateUserNew(UserServiceInterfaceImpl.java:1684)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
at java.lang.Thread.run(Thread.java:724)
at java.rmi.server.RemoteObjectInvocationHandler.invokeRemoteMethod(RemoteObjectInvocationHandler.java:194)
at java.rmi.server.RemoteObjectInvocationHandler.invoke(RemoteObjectInvocationHandler.java:148)
at com.totvslabs.cloudpass.LaunchpadController.personalPwdChallenge(LaunchpadController.groovy:51)
at grails.plugin.cache.web.filter.PageFragmentCachingFilter.doFilter(PageFragmentCachingFilter.java:195)
at grails.plugin.cache.web.filter.AbstractFilter.doFilter(AbstractFilter.java:63)
at de.javakaffee.web.msm.RequestTrackingContextValve.invoke(RequestTrackingContextValve.java:99)
at de.javakaffee.web.msm.RequestTrackingHostValve.invoke(RequestTrackingHostValve.java:156)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
at java.lang.Thread.run(Thread.java:724)

The issue happened in 2014/08/15.  Bill Nguyen, Denny Zhang, and some other colleagues are involved.
This morning we found it very slow to login to "https://totvs.fluigidentity.com/cloudpass".

We noticed tomcat in app01 and app02 has some exceptions.
Bill has restarted both apache and tomcat in both nodes.

After restart, it's better and still very slow. And app01 looks fine, but app02 keep dumping NullPointerException exception, when it get request from /cloudpass URI.
The direct failure of tomcat is grails fail to call getCompanyBySubdomain.
After checking the code, getCompanyBySubdomain functions calls rmi service for this.

In rim's log file of app02, memcached throws exceptions when it tries to get something.
And we can see tons of messages like below:
WARNING: Node expected to receive data is inactive. This could be due to a failure within the cluster. Will check for updated configuration. Key without a configured node is: cmpy_all_9.

Improvement points:
Nagios Improvement: Check Apache and tomcat log for excpetions
Nagios improvement: Monitor response time for HTTP head request of https://totvs.fluigidentity.com/cloudpass
When restart tomcat, make sure logfile is not truncated
Nagios improvement: Perform read test for couchbase.
Nagios improvement: identity SS request not balanced.
rmi.log in app02 is over 6.5G. We need log rotate for this large log file.
Nagios improvement: grep exception for logfiles in /cloudpass/backend/build/bin/cloudpass_logs

Detail:
Tomcat(grails) in app2 get NullPointerException occurred when processing request: [GET] /cloudpass/
root@app2:/var/log/tomcat7# tail -f catalina.out
tail -f catalina.out
at de.javakaffee.web.msm.RequestTrackingHostValve.invoke(RequestTrackingHostValve.java:156)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
at java.lang.Thread.run(Thread.java:724)
set saml headers
filters.SecurityFilters No session user. forward to /user/getNavAccountsTpl
set saml headers
filters.SecurityFilters No session user. forward to /user/getNavAdminLinks
set saml headers
filters.SecurityFilters No session user. forward to /search/getSearchDropdownTpl
cloudpass.LoginController Add cookie domain: .fluigidentity.com
errors.GrailsExceptionResolver NullPointerException occurred when processing request: [GET] /cloudpass/
Stacktrace follows:
java.lang.NullPointerException
at com.totvslabs.idm.db.services.DBCompanyServiceImpl.getCompanyBySubdomain(DBCompanyServiceImpl.java:833)
at com.totvslabs.idm.rmi.service.impl.CompanyServiceInterfaceImpl.getCompanyBySubdomain(CompanyServiceInterfaceImpl.java:224)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
at java.lang.Thread.run(Thread.java:724)
at java.rmi.server.RemoteObjectInvocationHandler.invokeRemoteMethod(RemoteObjectInvocationHandler.java:194)
at java.rmi.server.RemoteObjectInvocationHandler.invoke(RemoteObjectInvocationHandler.java:148)
at com.totvslabs.cloudpass.LoginController.showSelfRegister(LoginController.groovy:340)
at com.totvslabs.cloudpass.LoginController.login(LoginController.groovy:304)
at grails.plugin.cache.web.filter.PageFragmentCachingFilter.doFilter(PageFragmentCachingFilter.java:195)
at grails.plugin.cache.web.filter.AbstractFilter.doFilter(AbstractFilter.java:63)
at de.javakaffee.web.msm.RequestTrackingContextValve.invoke(RequestTrackingContextValve.java:99)
at de.javakaffee.web.msm.RequestTrackingHostValve.invoke(RequestTrackingHostValve.java:156)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
at java.lang.Thread.run(Thread.java:724)
errors.GrailsExceptionResolver NullPointerException occurred when processing request: [GET] /cloudpass/
Stacktrace follows:
java.lang.NullPointerException
at com.totvslabs.idm.db.services.DBCompanyServiceImpl.getCompanyBySubdomain(DBCompanyServiceImpl.java:833)
at com.totvslabs.idm.rmi.service.impl.CompanyServiceInterfaceImpl.getCompanyBySubdomain(CompanyServiceInterfaceImpl.java:224)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
at java.lang.Thread.run(Thread.java:724)
at java.rmi.server.RemoteObjectInvocationHandler.invokeRemoteMethod(RemoteObjectInvocationHandler.java:194)
at java.rmi.server.RemoteObjectInvocationHandler.invoke(RemoteObjectInvocationHandler.java:148)
at com.totvslabs.cloudpass.LoginController.showSelfRegister(LoginController.groovy:340)
at com.totvslabs.cloudpass.LoginController.login(LoginController.groovy:304)
at grails.plugin.cache.web.filter.PageFragmentCachingFilter.doFilter(PageFragmentCachingFilter.java:195)
at grails.plugin.cache.web.filter.AbstractFilter.doFilter(AbstractFilter.java:63)
at de.javakaffee.web.msm.RequestTrackingContextValve.invoke(RequestTrackingContextValve.java:99)
at de.javakaffee.web.msm.RequestTrackingHostValve.invoke(RequestTrackingHostValve.java:156)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
at java.lang.Thread.run(Thread.java:724)
set saml headers
https://totvs.fluigidentity.com/cloudpass/SPInitPost/receiveSSORequest/zf0y84vo717g8hjx/y6k661wf5a5vh9u11405012401405
setting post messagecontext
binding.HttpPostBindingAdapter decoding using HttpPostDecoder...
PROTOCOL_MESSAGE
<?xml version="1.0" encoding="UTF-8"?>
<saml2p:AuthnRequest
AssertionConsumerServiceURL="https://suporte.totvs.com/group/portaldocliente"
Destination="https://totvs.fluigidentity.com/cloudpass/SPInitPost/receiveSSORequest/zf0y84vo717g8hjx/y6k661wf5a5vh9u11405012401405"
ID="_32e4c0369fd4ac612e675be6ea7aa2df"
IssueInstant="2014-08-19T13:51:57.611Z"
ProtocolBinding="urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST"
ProviderName="TotvsLabs" Version="2.0" xmlns:saml2p="urn:oasis:names:tc:SAML:2.0:protocol">
<saml2:Issuer
Format="urn:oasis:names:tc:SAML:2.0:nameid-format:entity" xmlns:saml2="urn:oasis:names:tc:SAML:2.0:assertion">TotvsLabs</saml2:Issuer>
<saml2p:NameIDPolicy Format="urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress"/>
</saml2p:AuthnRequest>
binding.HttpPostBindingAdapter message decoded...
filters.SecurityFilters No session user. forward to /SPInitPost/receiveSSORequest/zf0y84vo717g8hjx/y6k661wf5a5vh9u11405012401405
set saml headers
https://totvs.fluigidentity.com/cloudpass/SPInitPost/receiveSSORequest/zf0y84vo717g8hjx/y6k661wf5a5vh9u11405012401405

Apache in app1 complains maxclients reached.
root@app1:/var/log/apache2# tail error.log
tail error.log
[Sun Aug 17 06:38:05 2014] [notice] Apache/2.2.22 (Ubuntu) mod_jk/1.2.32 mod_ssl/2.2.22 OpenSSL/1.0.1 configured -- resuming normal operations
[Sun Aug 17 09:29:47 2014] [notice] caught SIGTERM, shutting down
[Sun Aug 17 09:31:04 2014] [notice] Apache/2.2.22 (Ubuntu) mod_jk/1.2.32 mod_ssl/2.2.22 OpenSSL/1.0.1 configured -- resuming normal operations
[Mon Aug 18 18:07:22 2014] [error] server reached MaxClients setting, consider raising the MaxClients setting
[Tue Aug 19 13:30:44 2014] [notice] caught SIGTERM, shutting down
[Tue Aug 19 13:30:45 2014] [notice] Apache/2.2.22 (Ubuntu) mod_jk/1.2.32 mod_ssl/2.2.22 OpenSSL/1.0.1 configured -- resuming normal operations
[Tue Aug 19 13:31:28 2014] [error] server reached MaxClients setting, consider raising the MaxClients setting
[Tue Aug 19 13:36:41 2014] [notice] caught SIGTERM, shutting down
LikeBe the first to like this
No labels Edit Labels
User icon: Denny
Write a comment…
Powered by Atlassian | Terms of Use | Answers | Maintenance Schedule
#+END_EXAMPLE
* TODO Project proposal for the DevOps Improvement
** Backup workflow: More secure and less down time
** Nagios improvement
- A long list of new checks to enforce
- Make sure all systems are monitored properly
- Resource planning and monitoring for Key processes
** AD Test automation
** TODO AD client test: automate the test
#+begin_example
[14-6-30 下午3:35:59] denny: Hi John, I'm Denny
[14-6-30 下午6:56:01] John Kaplan: John Kaplan has shared contact details with denny.
[14-6-30 下午6:56:12] John Kaplan: Hi Denny.
[14-6-30 下午6:56:16] denny: hi John
[14-6-30 下午6:56:41] John Kaplan: have you done much with Active Directory?
[14-6-30 下午6:57:15] denny: I have setup an Active Directory server before.

But don't know that deep.
[14-6-30 下午6:59:38] denny: :)
[14-6-30 下午6:59:40] John Kaplan: well I don't want to take you away from other things, but a quick question: we have a need to test our interface against about 10 AD instances. Do you have a feel for how involved it would be to run that many servers either temporariiy or permanantly?
[14-6-30 下午6:59:56] denny: Nice, let me see.
[14-6-30 下午7:00:14] John Kaplan: its a big need for us on the testing side
[14-6-30 下午7:01:17] denny: Glad you ask me for this, John

So we are talking about AD instances on windows OS or linux?
[14-6-30 下午7:01:57] John Kaplan: we are supporting only windows AD
[14-6-30 下午7:03:30] denny: I see. If linux, we can use ldap command line.
For windows, there should be some alternatives CLI.

What kind of test we are testing for AD instances? So that I can do some detail search.
[14-6-30 下午7:04:12] John Kaplan: we test our interface to import and edit from the Identiy product
[14-6-30 下午7:04:20] John Kaplan: it is a bi-directional interface
[14-6-30 下午7:04:29] John Kaplan: John Kaplan has shared contact details with denny.
[14-6-30 下午7:06:02] denny: John, suppose we've already found AD client command line in windows, then we can wrap some scripts to automate the parallel testing. Right?
[14-6-30 下午7:08:24] John Kaplan: Not sure about that. what we have in place now in production is several AD instances connected to our SmartSync app which talks to our Identity product. I want to duplicate that case
[14-6-30 下午7:09:46] denny: Yes, SmartSync app do part of jobs we are expecting.

So it should be feasible, since SmartSync works.
[14-6-30 下午7:12:20] John Kaplan: now our customers may have up to 15 AD instances connected thru our SmarSync agent to Identiy. The problem is having a test infrastructure that supports that many AD instances just for testing.
[14-6-30 下午7:13:44] John Kaplan: From what I read it means x number of windows servers with x number of AD instances, one for each.
[14-6-30 下午7:16:27] denny: John, so the problem is actually not about automate the AD test, but whether we need that much of windows servers. Correct?
[14-6-30 下午7:16:54] John Kaplan: yes
[14-6-30 下午7:19:08] denny: Windows may not support us to configure multiple AD clients in one OS.

So if we want to do parallel test for 15 AD instances, we may probably need to boot 15 windows instances.
[14-6-30 下午7:19:32] denny: Some methods can make it less pain, IMHO.
[14-6-30 下午7:22:27] denny: 1. If we have an OpenStack cluster, we can boot enough windows VM by cli temporarily.

2. If testing ladp in linux also verify the test, Docker can be our friend.    One linux OS can run multiple "light weight OS" with the help of Docker.
[14-6-30 下午7:24:00] denny: Some Docker intro, if you're interested: http://www.dennyzhang.com/docker_software_delivery/
[14-6-30 下午7:24:02] John Kaplan: 1. sounds interesting. 2.: not sure if linux would truly emulate the AD integration
[14-6-30 下午7:26:55] denny: I know your problem now. Will let you know, if I find some more inputs.

Haven't touch MS for 6 years~

Last time, I boot a windows 2012 server, it took me 3 hours to browse website in IE. (IE security prohibit some "unsafe" website, except bing.com...)
[14-6-30 下午7:28:07] John Kaplan: oh
[14-6-30 下午7:28:37] denny: Just notice, we can use vboxManager CLI of virtualbox to automate the management of multiple windows VM.
[14-6-30 下午7:29:08] denny: So if we have a powerful server, we can wrap the test right now.
[14-6-30 下午7:30:54] John Kaplan: Can you spec that out without interfering with the VApp project? I don't want to slow that down.
[14-6-30 下午7:31:26] denny: Sure.
[14-6-30 下午7:33:49] John Kaplan: ok thanks.
[14-6-30 下午7:34:45] denny: You're welcome. Looking forward to learning from you in the coming days.
#+end_example
** TODO [#A] [scenario] pushing to production env                 :IMPORTANT:
** TODO [#A] [scenario] replicate qa1b for production env         :IMPORTANT:
*** Vicente
[14-7-7 下午3:54:04] Vicente Goetten: we want QA1B to be similar to production
[14-7-7 下午3:56:33] denny: Vicente, what do you mean similar to production in details?
[14-7-7 下午3:57:09] Vicente Goetten: # of servers
[14-7-7 下午3:57:13] Vicente Goetten: configuration of servers
[14-7-7 下午4:08:20] denny: -----------------------------------------
Previously I've talked to Bill by email since he was quite busy.
From that email, I know some wiki like below.
-----------------------------------------

Unfortunately I lack of some necessary info here.

Below it's what I have:
1. I know fluig-id-qa-02 is a VM, which I can access.
2. Currently all I know about Production Env, is from this list
    https://totvslab.atlassian.net/wiki/display/TECH/EC2-FI-SERVERS

   It looks like multi-node env, while QA1B is a single node.

-----------------------------------------
I probably need to fetch Bill for a Skype concall tonight, for more details.
** Disater test for HA
** Stress test
* Risk from data center team/infra layer
** NFS server issues: when nfs is slow or offline, CPU of VM would be extremely high
** network inaccesiblity issues
** TODO Upgrade: Before doing the migration, perform sanity check first
** TODO Lesson learn: sync up before doing any migration, instead of changing to a new version
* TODO [#A] How to handle customer consultant project as a team?
** How to estimate workload, without under charing customers
** When charging customers, how to convince and make customers happy?
** How to react as one man to customers?
* #  --8<-------------------------- separator ------------------------>8--
* Nagios plugin I shared to exchange.nagios.org
http://exchange.nagios.org/directory/Plugins/System-Metrics/Memory/check_proc_mem-2Esh-3A-check-process-memory-usage/details
check_proc_mem.sh: check process memory usage
http://exchange.nagios.org/directory/Plugins/System-Metrics/CPU-Usage-and-Load/check_proc_cpu-2Esh-3A-check-process-cpu-usage/details
check_proc_cpu.sh: check process cpu usage
http://exchange.nagios.org/directory/Plugins/Clustering-and-High-2DAvailability/check_proc_fd-2Esh-3A-check-process-memory-usage/details
check_proc_fd.sh
* TODO [#A] Suggestions for education of support engineer
- Who to fetch helps: Training, trouble shooting, AD
- Review the support and guide document
- hold one or two times live demo session

Want to try by themselves.
* TODO [#A] About CI problem, how to differentiate an application bug from an environment problem?
* DevOps: Time To Market; Fewer downtime
- "Ops is a black box" VS "Devs do all ops"
- Reusable configuration modules doesn't solve all the problem: customization and debug the cookbooks
- Trouble shooting issue escalated from prod env
** 有相当比例的质量问题是在开发/测试阶段之后引入或发现的。造成这一现象的原因有：
http://www.infoq.com/cn/articles/thoughtworks-anthology-xj-devops-business-agile
- 开发人员对生产环境缺乏了解，在代码中引入了只有在生产环境才会暴露的缺陷。
- 开发人员对非功能性需求缺乏关注，并且没有相应验证环境，导致非功能性缺陷。
- 生产环境和测试环境缺乏有效管理，因为环境差异引入缺陷。
- 部署和维护工作缺乏自动化，在发布过程中手工操作引入缺陷。
- 缺乏针对生产环境的回归测试，导致缺陷不能及时被发现。
** web page: 左耳朵耗子谈云计算：拼的就是运维
http://www.infoq.com/cn/articles/chenhao-on-cloud
*** webcontent                                                     :noexport:
#+begin_example
Location: http://www.infoq.com/cn/articles/chenhao-on-cloud
BT

  * 投稿
  * 关于我们
  * 合作伙伴

  * 欢迎关注我们的：
  * [weibo_16x1]
  * [weixin_16_]
  * [rss]

InfoQ - 促进软件开发领域知识与创新的传播
[搜索关键词          ]  submit
登录
[logo_bigge]

  * En |
  * 中文 |
  * 日本 |
  * Fr |
  * Br

482,381 十二月独立访问用户

  * 语言 & 开发
      + Java
      + .Net
      + 云计算
      + 移动
      + HTML 5
      + JavaScript
      + Ruby
      + DSLs
      + Python
      + PHP
      + PaaS

    特别专题

    []

    浏览所有语言 & 开发
  * 架构 & 设计
      + 建模
      + 性能和可伸缩性
      + 领域驱动设计
      + AOP
      + 设计模式
      + 安全
      + 云计算
      + SOA

    特别专题

    []

    浏览所有架构 & 设计
  * 过程 & 实践
      + Agile
      + 领导能力
      + 团队协作
      + 敏捷技术
      + 方法论
      + 持续集成
      + 精益
      + 客户及需求

    特别专题

    []

    浏览所有过程 & 实践
  * 运维 & 基础架构
      + 性能和可伸缩性
      + 大数据
      + DevOps
      + 云计算
      + 虚拟化
      + NoSQL
      + 应用服务器
      + 运维

    特别专题

    []

    浏览所有运维 & 基础架构
  * 企业架构
      + 企业架构
      + 业务流程建模
      + 业务/IT整合
      + Integration (EAI)
      + 治理
      + Web 2.0
      + SOA

    特别专题

    []

    浏览所有企业架构

[20150104_b]

  * 移动
  * Docker
  * Node.js
  * 云计算
  * 大数据
  * 架构师
  * QCon
  * ArchSummit
  * AWS
  * Azure
  * Helion

全部话题
您目前处于： InfoQ首页文章左耳朵耗子谈云计算：拼的就是运维

左耳朵耗子谈云计算：拼的就是运维 [cloud_100]

作者陈皓发布于 2014年4月14日 |

  * 分享到：微博微信 Facebook Twitter 有道云笔记邮件分享
  * `稍后阅读'
  * `我的阅读清单'

本文根据InfoQ中文站跟陈皓（@左耳朵耗子）在2014年3月的一次聊天内容整理而成。在沟通中，陈皓分享了自己
对云计算的理解，包括云计算为什么会分三层，实现一个云平台的难点在什么地方，运维之于云计算的重要性，
电商云为什么有价值等。

嘉宾简介

陈皓（@左耳朵耗子），CoolShell.cn博主。15年软件开发相关工作经验，8年以上项目和团队管理经验。擅长底
层技术架构，团队建设，软件工程，软件研发咨询，以及全球软件团队协作管理。对高性能，高可用性，分布式
，高并发，以及大规模数据处理系统有一些经验和心得。喜欢关注底层技术平台和互联网行业应用。技术擅长C/
C++/Java和Unix/Linux/Windows。曾于Amazon中国任研发经理，负责电子商务全球化业务（全球开店）和全球库
存预测系统的研发。曾在阿里巴巴北京研发中心、商家业务部曾任资深专家一职，负责电商云平台、开放平台，
云监控和电商多媒体平台。现在阿里巴巴核心系统专家组从事阿里核心系统和阿里云ECS相关的虚拟化平台的开发
工作。

对云计算的定义

云计算其实跟PC机有一样的概念，有CPU、硬盘、操作系统、应用软件。云计算的计算节点（虚拟机）就是PC中的
CPU，数据缓存服务就是PC的内存，存储节点就是PC的硬盘，提供数据服务，让数据不丢、高可用，PC中的控制器
就是云计算的控制系统。PC机的硬件上面要有操作系统。操作系统很大一块是给开发人员提供系统的API接口，提
供系统监控以看运行情况，并且还要有系统管理——如用户账号的权限管理、备份恢复等等。操作系统上面要有应
用软件，这样才能服务于最终用户，应用软件就是真正落地的业务，这样才会有用户；有了用户，整个体系就运
转起来了。

相关厂商内容

Windows Azure从开发到部署的自动化进程

微软Windows Azure开启机器学习之旅

基于开源软件的Azure平台大规模系统构建

QCon北京2015 PHP开发组核心成员惠新宸

QCon北京2015讲师 Spark SQL开发者连城

相关赞助商

[100x50]

Windows Azure专区上线，全面了解云服务精彩呈现！

这就是工程师说的stack，也就是我们听到的IaaS、PaaS、SaaS三个层。IaaS层就像PC机的基础硬件加驱动程序，
PaaS层就像PC机上的操作系统——把基础硬件抽象、包起来并屏蔽硬件和硬件驱动细节、调度基础硬件，而SaaS层
就是PC机里的应用软件。另外，我们还得给开发人员提供各种开发框架、类库和开发环境，这就是为什么AWS还做
通知、消息、工作流，这是用于粘合操作系统和业务层的，比如可以让你方便地做水平扩展和分布式。云计算自
然也会像PC机一样，三个层上都会有用于控制和管理的系统。这就是为什么云计算会做成这个样子，其实计算机
的发展就在这个圈子里绕。

其实，最终用户基本并不关心你CPU用的啥，存储用的是啥，你用什么框架开发，他们关心更多的是可以解决什么
问题，有什么样的用户体验。像以前Windows用户体验之所以比Linux好，就是因为应用层用的舒服；而Linux对开
发者的用户体验比Windows好，就是因为其开放和可以让开发人员更灵活、更自由。我们可以看到SaaS层上有的像
SalesForce、Dropbox、Evernote、Netflix这样的给最终用户的服务，他们更倾向于最终用户和业务。

说到底，云计算的IaaS、PaaS、SaaS最后那个S都是Service。就是说，无论你云计算长成什么样，都得要向用户
提供“服务”而不仅仅是软硬件和各种资源。

云计算的技术难点

到今天，云计算的工业实现已经不太难了。现在有开源软件KVM和Xen，这两个东西基本把虚拟化搞定；而
OpenStack则把管理、控制系统搞定，也很成熟。PaaS也有相应的开源，比如OpenShift，而Java里也有N多的中间
件框架和技术。另外分布式文件系统GFS/TFS，分布式计算系统Hadoop/Hbase等等，分布式的东西都不神秘了。技
术的实现在以前可能是问题，现在不是了。

对于云计算工程方面，现在最难的是运维。管100台、1万台还是100万台机器，那是完全不同的。机器少你可以用
人管理，机器多是不可能靠人的。运维系统不属于功能性的东西，用户看不见，所以这是被大家严重低估的东西
。只要你做大了，就必然要在运维系统上做文章。数据中心/云计算拼的就是运维能力。

为什么我说运维比较复杂，原因有这么几个。

一方面，云计算要用廉价设备取代那些昂贵的解决方案。所谓互联网的文化就是屌丝文化，屌丝就是便宜，互联
网就是要用便宜的东西搭建出高质量的东西，硬件和资源一定不会走高端路线——比如EMC、IBM小型机、SGI超级计
算机等等，你如果用它去搭建云计算，成本太贵。用廉价的解决方案代替昂贵的解决方案是整个计算机发展史中
到今天唯一不变的事情。所以如果你要让夏利车跑出奔驰车的感觉，你需要自己动手做很多事，搭建一个智能的
系统。用廉价的东西做出高质量的东西，运维好廉价的设备其实是云计算工程里最大的挑战。

另一方面，因为你机器多了，然后你用的又不是昂贵的硬件，所以故障就变成了常态，硬盘、主板、网络天天坏
。所以，没什么好想的，运维就必须要跟上。云计算的目标是在故障成为常态的情况下保证高可用——也就是我们
所说的，你服务的可用性是3个9、4个9还是5个9。

最后，这一大堆机器和设备都放在一起，你的安全就是一个挑战，一方面是Security，另一方面是Safety，保证
数十台数百台的设备的安全还好说，但是对于数万数十万台的设计，就没有那么简单了。

所以，面对这样的难题，人是无法搞得定的，你只能依靠技术来管理和运维整个平台。比如必须有监控系统。这
跟操作系统一样，对资源的管理，对网络流量、CPU利用率、进程、内存等等的状态肯定要全部收集的。收集整个
集群各种节点的状态，是必然每个云计算都有的，都是大同小异的。

然后，你还要找到可用性更好的节点，这需要有一些故障自检的功能。比如阿里云就遇到过磁盘用到一定时候就
会莫名其妙的不稳定，有些磁盘的I/O会变慢。变慢的原因有可是硬盘不行了，于是硬盘控制器可能因为CRC校验
出错需要要多读几次，这就好比TCP的包传过来，数据出错了，需要重新传。在这种硬盘处理半死不活的状态时，
你肯定是需要一个自动检测或自动发现的程序去监控这种事情，当这个磁盘可能不行了，标记成坏磁盘，别用它
，到别的磁盘上读复本去。我们要有故障自动检测、预测的措施，才能驱动故障，而不是被动响应故障，用户体
验才会好。换句话说，我们需要自动化的、主动的运维。

为了数据的高可用性，你只能使用数据冗余，写多份到不同的节点——工业界标准写三份是安全。然而，你做了冗
余，又有数据一致性问题。为了解决冗余带来的一致性问题，才有了paxos的投票玩法，大家投票这个能不能改，
于是你就需要一个强大的控制系统来控制这些东西。

另外，公有云人来人往，里面的资源和服务今天用明天不用，有分配有释放，有冻结，你还要搞一个资源管理系
统来管理这些资源的生命状态。还有权限管理，就像AWS的IAM一样，如果没有像AWS的IAM权限管理系统，AWS可能
会不会像今天这样有很多大的公司来用。企业级的云平台，你需要有企业级的运维和管理能力。

云计算的门槛

为啥云计算有这么多开源的东西，却不是人人都能做？我觉得有以下原因：

一方面，这就跟盖楼一样。盖楼的技术没什么难的（当然，盖高楼是很难的），但是你没地你怎么盖？我觉得云
计算也一样，带宽的价格贵得就像土地的价格。其实云计算跟房地产一样，要占地、占机房、占带宽。如果能把
中国所有的机房、机柜、带宽资源都买了，你就不用做云计算了，卖土地就够了——因为这些是有限的。最简单的
例子，IP地址是有限的。你有带宽、有机房，但是如果你没有IP，这就不好玩了。尤其是你要提供CDN服务，这个
就更明显，因为有多少物理节点直接决定你的CDN服务质量。

另一方面，正如前面所说的，运维是件很难的事，运维这个事并不是一般人能搞的事。没有足够的场景、经验和
时间，这种能力很难出现。

从用户的角度来说呢，云计算是一种服务，你需要对用户企业内的解决方案要有很好的了解，这样才能提高很好
的服务。能提供“好服务”的通常都是把自己真正当成用户公司。

这跟做汽车一样，底层做引擎、轮子、油箱、控制系统，给你弄一堆零件，上层可以拼装。PaaS相当于给你一个
很快可以打造成的汽车的工作台。而SaaS就是成品——两厢、三厢、卡车、轿车，最终用户要的是这个。后面什么
Xen、存储、分布式，跟我一毛钱关系没有，我就要知道汽车是安全的，性能好的，省油的，不会抛锚、耐用的，
千万别速度快了或者坡度大了或是别的怎么样就失灵了。

卖汽车也是卖服务。造出汽车来，并不代表你搞定这个事了。如果没有公路、没有加油站、没有4s店、没有交通
管理、规则等等，你要么用不了，要么就是乱七八糟。不能只让用户在那看着你的汽车好牛啊，但是用户不知道
怎么用。所以说，云计算最终旁边必须要有一套服务设施，而这套服务设施也是今天被人低估的。

云计算有两个东西我觉得是被人低估的，一个是运维，一个是那堆服务。做服务的需要有生态环境，有人帮你做
。所以做云计算要落地并不简单。

这跟IBM一样。IBM有段时间也是快不行了，他们的CEO写了一本《谁说大象不能跳舞》，讲IBM的转型，从卖硬件
的转成卖服务、解决方案，有流程、咨询，顺便卖硬件，带着一堆系统集成商一起玩。我给你解决方案，谁来实
现呢，就是集成商帮你，然后顺便把硬件卖给你。一样。未来是什么样，历史上已经有了。你看，要干那么多事
，而且还不是用人堆就可以堆出来的。这就是云计算的门槛。

总之，云计算是需要吃自己的狗食才能吃出来的，绝不是像手机上的Apps一样，你想一想、试一试就能搞出来的
，你首先需要让自己有这样的场景，有这样的经历，你才可能会有这样的经验和能力。

云计算的市场细分

市场细分必然是市场来驱动的。市场变化太快，说不清楚，不过大的方向应该会是这样的：有类是需要玩计算密
集型的（比如大数据计算、网络游戏），有类是需要玩IO密集型的（比如视频网站），有类就是为了建网站的（
比如电子商务、门户网站、无线），有类是为了数据安全和保密的（比如金融数据）。

从更高的层面来看，社会也需要分工。有的人卖土地，有的人卖房子，有的人装修，有的人是中介。我相信没人
愿意把所有的赌注都押在一个地方。云计算也是一样。上面也说过，无论IaaS、PaaS、SaaS，后面的S都是
service，本质上都是提供服务。所以，我认为，市场的细分本质上就是服务的细分。

看看历史我们知道，细分永远是跟着行业走的，也是跟着业务走的，所以，在业务层会出现更多的细分。

对阿里云产业细分的看法

政府云、金融云不太清楚，不过我很清楚电商云——就是我之前负责的聚石塔。聚石塔时间不长，2012年9月正式上
线，去年是大发展的一年，作为垂直云解决的很好。天猫和淘宝做的都是下单前的东西，下单后，商家每天处理
好几百单，需要做订单合并、筛选，有的商家规模不大但订单很多。海尔有ERP，这些商家没有，但是每天也1000
多单，如果没有信息化的系统，人肉是处理不了的，必然要有ERP系统处理订单。另外还要管理用户，给用户做营
销、发展忠实用户。总之，都是卖东西以后的事情。咋办？

淘宝天猫给了一堆开放API，你可以调我的API接入，在你那边有ISV帮你做一套东西远程访问淘宝API，把订单拉
过去，仓库进货了之后，通过API把库存改一下，就可以连起来了。天猫用户下单，到他的系统、他的仓库，他就
发货了，仓库补完货，在他的系统里一改，自动就到天猫店了。这是电子信息化。

但是一到双十一就受不了：订单量太大。正好云平台出现了，再怎么样，阿里的运维能力也要比你商家的要强吧
。你看，聚石塔卖的是服务，不是主机。另外是数据安全：商家的系统天天被黑客盯着，如果我们把用户信息都
给商家，不是所有的商家的系统安全都做得很好，内部的人插个什么U盘，上面一堆木马，数据就被偷走了。偷走
了之后，别人还说是阿里搞丢的，这当然不行。所以，我们又要开放，还要保证安全，聚石塔这个云平台就这样
出来的：你来我这儿，我才开放给你，因为安全很重要。

保证性能和安全也是商家的利益诉求也在里面，商家也不希望用户数据被偷，他也希望双十一能抗住。

另外，很多商家自己不会做，所以要ISV（第三方软件开发商）来做，所以这个是卖解决方案，跟IBM很相似。银
行要一套系统，IBM提供硬件和解决方案，系统集成商来帮银行写代码和集成系统。聚石塔也很像，聚石塔提供
API、ECS、数据库，第三方的ISV进来帮商家集成一个系统。这是很经典的也是很传统的IBM的玩法，只不过是玩
在了云端。

你看，这也是做自己的长项做出来的细分市场。所以说，吃自己的狗食很重要。

对PaaS的看法

无论是Google的GAE还是新浪的SAE都是给个容器，给个容器的好处是不用管数据连接、CPU什么，程序一传就能用
，什么水平扩展都不用管。不爽的是，一个是在编程上限制太多：AppEngine总会阉割很多系统相关的功能，比如
Java、PHP、Python的很多系统调用都阉割了，因为如果给你这些系统调用，你就可以突破沙箱；另一个是有故障
的时候：技术人遇到问题都恨不得自己上去解决，想看看后面在忙啥，但是看不到，很无助，只能等你解决，就
看你的人解决的好不好、快不快。所以如果IaaS没做好，运维、故障自动处理、迁移没做好，出了问题用户只能
干瞪眼，PaaS必然不好用。当然IaaS层也有这个问题，但是至少你还可以登到机器上看一看，大不了重启一下。
像AWS，你重启一下就跑到别的物理机，问题也许就解决了。

其实，对于PaaS中间这层的确很尴尬。怎么解决？我觉得还是要依赖某种业务场景。单纯一个平台要阉割很多功
能，搞得用户不舒服，还不如干脆一步到位，根据业务场景给一个编程框架。比如SAE可以就做微博app，上来就
调API，数据库都ready；或者微信如果做个PaaS，上面只玩微信公众平台上的东西，也可以。我觉得PaaS层更贴
合业务会更成功。给新浪微博做个插件，你去买个VM、买数据库？这种时候很需要PaaS。我觉得PaaS层要成功就
要贴近业务场景。比如：腾讯的风铃系统（虽然不知道企业帐号看见是什么样的），就做无线建站，这样多好。
干巴巴的PaaS有点高不成低不就。

对SDN的看法

SDN其意图是想改变目前超级复杂的网络结构。意图是挺好的。想一想，如果以后我家的网络不用因为买个新的路
由器都要重新设计一把，只要一次设置，然后对所有的路由器都通过，的确是挺方便的，这点对企业非常好。不
过，不知道在操作上怎么做，也许会从企业内部开始这场革命，这个不得而知。

就像开车一样，机械式的方向盘和刹车油门系统这么多年都没什么变化，也提过很多更好更高科技的解决方案，
但是传统还是这样延续下来了。所以，SDN真不知道未来会怎么样。总之，一个老的事物到一个新的事物需要有一
个过程，这个过程中会出现很多过渡产品或是过渡方案，如果没有这些过渡产品和方案，也就没法达到新的事物
。未来是什么样，无法预知。

对私有云的看法

私有云跟公有云，都会存在。这跟人一样，私人生活和公众生活都会需要的。大公司有1万、2万人，这么多数据
，要存，需要一个很稳定的解决方案。要稳定可以买IBM，但是贵。云计算出来说，我可以写三份，但他不想上公
有云，我的数据放在别人那里，总感觉不好的，所以有了私有云做物理隔离，他觉得安全。

安全这个词对应两个英文，security和safety，其实security和safety不一样：云计算解决safety，保证数据不
丢；宁可数据丢也不让人看到，那是security。比如私人照片我更愿意存家里，有一个小的云存储，所有设备同
步，跟老家父母同步，这样比较好。放公网很恐怖。

一定会有公司不愿意上云的，比如金融方面的企业，他们觉得互联网不安全，他们要的更多的是安全。在公网上
你的系统的安全攻防能力都要跟上，但如果物理不通的话就不用考虑的太复杂。企业内部私有云肯定有市场。你
看，好些企业内部目前还被EMC、IBM所垄断着呢。计算机发展史就是廉价的东西取代昂贵的东西，所以私有云一
定没问题，而降低私有云的运维复杂度、提供一个或多个方便的运维系统和工具就是重中之重中。其中，SDN之类
的东西肯定会是其中一个很重要的一块。

另外，还是那句话，云就是服务，只要提供了好的服务，无论公有还是私有都是会有价值的。

---------------------------------------------------------------------------------------------------

感谢杨赛对本文的策划。

给InfoQ中文站投稿或者参与内容翻译工作，请邮件至editors@cn.infoq.com。也欢迎大家通过新浪微博（@InfoQ
）或者腾讯微博（@InfoQ）关注我们，并与我们的编辑和其他读者朋友交流。

  * 领域
  * 运维 & 基础架构
  * 架构 & 设计
  * 语言 & 开发
  * 专栏
  * 云计算
  * SDN
  * 阿里云
  * 运维
  * 阿里巴巴

相关内容

您好，朋友！

您需要注册一个InfoQ账号或者登录才能进行评论。在您完成注册后还需要进行一些设置。

获得来自InfoQ的更多体验。

告诉我们您的想法

[                    ] [                    ]

允许的HTML标签: a,b,br,blockquote,i,li,pre,u,ul,p

[ ] 当有人回复此评论时请E-mail通知我
发送信息
社区评论
不得不回一帖 by shi mike Posted
Re: 不得不回一帖 by 吴伟略 Posted
Re: 不得不回一帖 by junming lu Posted
受启发 by jing yun Posted
非常棒 by 黄超 Posted
不得不回一帖 by 张章鸥翔鱼游 Posted
不得不回 by 张章鸥翔鱼游 Posted
学习 by jiao nianhua Posted
透彻 by zhang lz Posted
分析的很到位 by Zhao Xingtao Posted
皓哥讲的真好，受教了 by 王勇 Posted

不得不回一帖 by `shi mike'

因为讲得太好了，哈哈

  * 回复
  * 回到顶部

受启发 by `jing yun'

企业级的云平台需要企业级的运维和管理能力，赞

  * 回复
  * 回到顶部

非常棒 by `黄超'

讲得非常棒，都在点子上了

  * 回复
  * 回到顶部

Re: 不得不回一帖 by `吴伟略'

分析很透彻，拜读了。

  * 回复
  * 回到顶部

Re: 不得不回一帖 by `junming lu'

收益匪浅，感谢

  * 回复
  * 回到顶部

不得不回一帖 by `张章鸥翔鱼游'

讲得非常棒，都在点子上

  * 回复
  * 回到顶部

不得不回 by `张章鸥翔鱼游'

讲得非常棒，都在点子上了

  * 回复
  * 回到顶部

学习 by `jiao nianhua'

说的很棒，比喻也非常的恰当，学习了。

  * 回复
  * 回到顶部

透彻 by `zhang lz'

挺透彻，什么是云计算看看这个了解就更深刻

  * 回复
  * 回到顶部

分析的很到位 by `Zhao Xingtao'

很棒赞

  * 回复
  * 回到顶部

皓哥讲的真好，受教了 by `王勇'

以前对云服务只是最皮毛的了解，虽然自己再用阿里云，但是还真不懂这云服务，会继续关注的。谢谢皓哥的无
私精神

  * 回复
  * 回到顶部

关闭

by

发布于

  * 查看
  * 回复
  * 回到顶部

关闭
主题 [                    ] 您的回复引用原消息 [                    ]

允许的HTML标签: a,b,br,blockquote,i,li,pre,u,ul,p

[ ] 当有人回复此评论时请E-mail通知我
发送信息    取消
关闭
主题 [                    ] 您的回复 [                    ]

允许的HTML标签: a,b,br,blockquote,i,li,pre,u,ul,p

[ ] 当有人回复此评论时请E-mail通知我

    取消
关闭

 OK
11 讨论

  * 热点内容
  * 10天
  * 40天
  * 近6个月

深度内容

  * 全部
  * 文章
  * 演讲
  * 访谈
  * 迷你书

互联网金融系统中的资金正确性保障

陆怡 1月28日

[luyi_100]

BaaS服务的定义、发展以及未来

郭蕾 1月28日

[cloud2]

从计划到进化

任鑫 1月28日

[renxin_100]

解读2014之安全篇：史诗级漏洞频发

黄丹 1月27日

[road]

Tower团队24个月的远程协作实践

沈学良 1月27日

[shenxuelia]

从360手机卫士的开发历程看如何实施大型移动应用开发

姚彤 1月27日

[yaotong_10]

  * 更早的 >

赞助商链接

InfoQ每周精要

通过个性化定制的新闻邮件、RSS Feeds和InfoQ业界邮件通知，保持您对感兴趣的社区内容的时刻关注。

[click2view]
[您的邮箱            ]  订阅
  * 首页
  * 全部话题
  * QCon全球软件开发大会
  * 关于我们
  * 投稿
  * 创建账号
  * 登录

  * 全球QCon
  * 伦敦 2015年3月2-6日
  * 圣保罗 2015年3月23-27日
  * 北京 2015年4月23-25日
  * 东京 2015年4月 21
  * 纽约 2015年6月8-12日
  * 里约 2015年8月24-28日
  * 上海 2015年10月15-17日
  * 旧金山 2015年11月16-20日

InfoQ每周精要

通过个性化定制的新闻邮件、RSS Feeds和InfoQ业界邮件通知，保持您对感兴趣的社区内容的时刻关注。

[click2view]
[您的邮箱            ]  订阅
  * 属于您的个性化RSS
  * InfoQ官方微博
  * InfoQ官方微信
  * 社区新闻和热点

特别专题

  * IBM
  * 技术社区活动日历
  * 百度技术沙龙
  * 月刊：《架构师》
  * 线下活动：QClub
  * AWS专区
  * 物联网大会

定制您感兴趣的技术领域

    [*] 语言 & 开发
    [*] 架构 & 设计
    [*] 过程 & 实践
    [*] 运维 & 基础架构
    [*] 企业架构

这会影响您在主页和RSS订阅中看到的内容。点击“偏好设置”可选择更多精彩定制内容。

                                                                                InfoQ.com及所有内容
                                                                                ，版权所有 ©
                                                                                2006-2015 C4Media
                                                                                Inc. InfoQ.com 服务
提供反馈              错误报告          商务合作           内容合作             器由 Contegix提供,
feedback@cn.infoq.com bugs@cn.infoq.com sales@cn.infoq.com editors@cn.infoq.com 我们最信赖的ISP伙伴
                                                                                。
                                                                                北京创新网媒广告有
                                                                                限公司京ICP备
                                                                                09022563号-7 隐私政
                                                                                策
BT
Close
E-mail [                    ] 密码 [                    ]  submit
使用Google账号登录
使用Microsoft账号登录

忘记密码？

InfoQ账号使用的E-mail [                    ] 发送邮件

重新登录

重新发送激活信息 [                    ] 重新发送

重新登录

没有用户名？

点击注册

#+end_example
** web page: DevOps的各个阶段
http://www.infoq.com/cn/articles/wide-range-devops
*** webcontent                                                     :noexport:
#+begin_example
Location: http://www.infoq.com/cn/articles/wide-range-devops
BT

  * 投稿
  * 关于我们
  * 合作伙伴

  * 欢迎关注我们的：
  * [weibo_16x1]
  * [weixin_16_]
  * [rss]

InfoQ - 促进软件开发领域知识与创新的传播
[搜索关键词          ]  submit
登录
[logo_bigge]

  * En |
  * 中文 |
  * 日本 |
  * Fr |
  * Br

482,381 十二月独立访问用户

  * 语言 & 开发
      + Java
      + .Net
      + 云计算
      + 移动
      + HTML 5
      + JavaScript
      + Ruby
      + DSLs
      + Python
      + PHP
      + PaaS

    特别专题

    []

    浏览所有语言 & 开发
  * 架构 & 设计
      + 建模
      + 性能和可伸缩性
      + 领域驱动设计
      + AOP
      + 设计模式
      + 安全
      + 云计算
      + SOA

    特别专题

    []

    浏览所有架构 & 设计
  * 过程 & 实践
      + Agile
      + 领导能力
      + 团队协作
      + 敏捷技术
      + 方法论
      + 持续集成
      + 精益
      + 客户及需求

    特别专题

    []

    浏览所有过程 & 实践
  * 运维 & 基础架构
      + 性能和可伸缩性
      + 大数据
      + DevOps
      + 云计算
      + 虚拟化
      + NoSQL
      + 应用服务器
      + 运维

    特别专题

    []

    浏览所有运维 & 基础架构
  * 企业架构
      + 企业架构
      + 业务流程建模
      + 业务/IT整合
      + Integration (EAI)
      + 治理
      + Web 2.0
      + SOA

    特别专题

    []

    浏览所有企业架构

[20150104_b]

  * 移动
  * Docker
  * Node.js
  * 云计算
  * 大数据
  * 架构师
  * QCon
  * ArchSummit
  * AWS
  * Azure
  * Helion

全部话题
您目前处于： InfoQ首页文章 DevOps的各个阶段

DevOps的各个阶段 [article-lo]

作者 Mitchell Hashimoto ，译者康锦龙发布于 2013年2月20日 |

  * 分享到：微博微信 Facebook Twitter 有道云笔记邮件分享
  * `稍后阅读'
  * `我的阅读清单'

本文基于我在瑞典DevOpsDays上发表的“DevOps是个阶段，而不是特定状态”演说整理。如有兴趣，可以在线观看
我的演说，不过在阅读本文时，无需事先观看。

在过去的几年里，我们不断的在文章、演讲、谈话中了解到DevOps这个词。DevOps声称能够在提升整体系统稳定
性的同时，建立更快的反馈回路，并降低产品迭代成本。DevOps的目标令人印象深刻，但作为新生概念，它无法
证明能够达到这种预期目标，所以相关的活动很容易会被忽视或是撤销。随着DevOps的发展，有不少公司因
DevOps获益，同时还出现大量采用DevOps的组织。现在，正是你调研并实践DevOps的好时机。

对外行来说，容易认为采用DevOps只是一个简单的变化，更像打开了灯泡的开关一样。从这种角度来看，实施这
样一个变化会是令人畏惧、可能是无法实现的任务。就像传统工程学一样，试图建立复杂事物而不经分解时，通
常结果就是失败。还好，DevOps可以分解成一系列的阶段。而各阶段内改变的内容和时限完全可以由你所在组织
自行掌控。

相关厂商内容

Windows Azure从开发到部署的自动化进程

微软Windows Azure开启机器学习之旅

基于开源软件的Azure平台大规模系统构建

QCon北京2015 PHP开发组核心成员惠新宸

QCon北京2015讲师 Spark SQL开发者连城

相关赞助商

[100x50]

Windows Azure专区上线，全面了解云服务精彩呈现！

为便于理解，这里用时间轴风格的图表来说明：横轴最左边表示传统运维方式，最右侧表示DevOps方式。这样，
就没人会提出“贵公司已经实施DevOps了吗？”的问题，而是更为精确的，如“能谈一下DevOps在贵公司的深入程度
吗？”

需要说明一下，本文中的观点和案例基于特定的组织结构，并非普遍适用。这些假设是基于我个人的经验——我曾
在多家公司中与运维和开发团队一同工作（运维团队要负责开发环境的维护），也曾做过几个项目。如果这些假
设如果和你的组织现状不同，那么观点可能就不适用了。当然，好处是这些观点都可以实际应用在类似的团队中
，它们结合了我们在多个工作环境中实际实施的经验。

DevOps的范围

为了更好的理解我们在实施DevOps过程中所跨越的阶段，很有必要详细谈一下时间轴最左边和最右边所表示的内
容。

最左边表示传统运维的文化和实践。

传统运维的一种极端情况可以被描述为“黑盒运维”。在这种文化中，运维与开发是分开的，相互间一般不合作，
就算合作，也是极为不情愿的。其特点就是开发和运维有着相反的目标。开发团队的任务是为产品增加新功能、
不断升级产品，并以此制定绩效。运维团队的目标，则是稳定第一。如果没有进行足够的沟通交流，两个团队就
会产生矛盾，当开发人员兴致勃勃的快速开发新功能的时候，运维人员可没什么心情去部署新功能。对稳定系统
实施任何类型的变更，都会导致系统产生隐患，因此运维人员会尽可能避免变更。

举个例子：应用开发人员提交了的代码中有一个bug，在特定的边界条件下会导致无限循环，而QA或测试人员均没
有发现这个问题。如果运维人员部署了这个变更，会导致一些服务器CPU飙升至100%，造成服务不稳定。如果运维
人员不去实施变更，那么就不会发生问题，至少是没有新问题。这就是最左边传统运维的理念。

最右边表示全面实现DevOps的情况，在这里开发和运维是一个角色。这时，开发就是运维，运维就是开发，团队
在的共同目标是既要增加新特性，又要确保一定程度的可靠性。

[1]

当了解了时间轴两边所表示内容时——特别强调下，两边都是极端——从一个极端跨越到另一个极端，看起来是很不
可思议的。但发生这种不可思议的情况是因为你认为这种转变是一气呵成的。如果把这个时间轴划分为不同个可
管理的子阶段，那么实施DevOps就会更容易，利益也更加明确，结果也是可以预期的。

DevOps中的文化与技术改变

DevOps需要在组织内部进行文化和技术的改变。从团队文化角度来说，运维和开发的传统思维需要改变，这样才
能更开诚布公的进行沟通，实现目标的统一。从技术角度来讲，开发人员需要了解运维团队的工作方式，并加深
对系统架构的认识。运维人员需要明白开发流程，并深入了解代码内容。

当把DevOps分解成各个阶段后，我发现通过文化和技术交替的改变来引入DevOps的观念要更加容易一些。后续的
工作都会以这种理念进行。这么做的理由是：改变是困难的，变革是几乎不可能的。通过交替的改变，每一个变
化将更容易被接受。所以不用进行变革，而是通过一系列文化和技术上交替的变化来进行，最终实现DevOps。通
过这种方式，团队不会感到环境一下子变得无法适应了。变化的发生更加自然，组织也更容易接受这些变化。

指标监控无处不在

向DevOps方向迈出的第一步，就是在组织内对架构和应用层面启用指标监控。或者，我更喜欢称之为：监控无处
不在。这里有很多演说讨论这个话题，但归根结底就是一个关键性的问题：我的代码到底做了什么？

对于这个问题，开发人员更乐意通过给你看代码的方式来回答。不幸的是，代码仅能反映出代码应该做什么，而
不能说明它实际做了什么。代码如同一本烹饪食谱：它记载着制作美味所需的步骤，但是并不能控制最终出产的
是不是美味佳肴。生活中，我们都曾按照食谱尝试过烹饪，但是结果却不尽人意。同样的，代码描述了实现期望
目标的过程，但是代码对系统的实际影响是不可从代码自身预测的。下例中，开发人员将缓存的过期时间从3600
秒修改到了1800秒。当然，这些变化显而易见，但是整个系统会受到什么影响就不得而知了。

[2]

运维人员解答这个问题的方式，是登陆入这台机器，从运行中的系统中获取内存利用率、CPU利用率等信息，来确
定缓存过期时间修改对整个系统的影响。这才是正确的方式！这种方式能够反映出代码修改对系统的真正影响。
运维人员通过更多的数据分析出具体的影响。这些数据为很多重要问题提供了答案，如“这个变更在系统层面上有
什么影响？”或“为什么服务X部署后，服务Y就慢下来了？”以前，开发人员在回答这些问题时，仅会考虑代码（在
理论上）是如何运行的。但是，实际的数据会比理论依据更有说服力。下图是运维人员所看到的数据：生产系统
的运行数据。

[3]

这里需要牢记我们在DevOps进程中所处的位置。我们只是从最左侧向DevOps迈进了一小步，仍旧处于传统运维的
环境中。因此，目前给开发人员访问生产环境的权限起不到什么作用。大部分开发人员不适应这个新环境，所以
他们自然而然的会回到原有的环境中，这是人的天性。在组织内部尝试改变的时候，如果不考虑人员的接受情况
，将没人支持这种改变，最终导致不得不回到原有的方式。

可以简单的使用一种对开发友好的方式来展现这些数据：图表。绘图技术发展了很多年，但是在前几年Graphite
和Statsd出现后才流行起来。在Graphite中监控系统指标，并提供开发人员相关的API，就能同时完成两件事：运
维人员能够展示系统指标，开发人员可以展示应用指标。开发人员除了查看应用登录登出等事件的统计数据外，
现在他们也可以查看CPU、内存利用率等数据了。

开发人员可以加入一行代码来计算相关监控指标：

[4]

根据监控数据，可以通过Graphite绘制出下述图像：

[5]

对于传统运维团队来说，搭建一个监控系统来展示这些指标数据是小菜一碟，而调用Statsd和Graphite的接口使
用起来是非常简单的，对于开发团队来说，只需几行代码。通过这些技术的变化，开发人员现在就能全面的了解
代码对系统的影响，并对运维工作有一个大致的了解。在这个阶段，开发和运维的合作已经开始了，虽然只是一
个小的方面，但可以说你们已经向DevOps迈进了一步。我们选择了一个合适的切入点，那么在此基础上继续发展
，未来这种合作会更加广泛。

基础架构的文档化

开发人员在了解生产系统性能及状态之后，会自然而然的对相关的底层系统产生兴趣。对于很多开发人员来说，
大规模的生产系统如同一个黑盒：输入一个请求进去，返回一个响应，但是完全不清楚究竟经过了哪些系统。

为了解决这个问题，基础架构应该被文档化。前期，可以使用通过基本的高阶流程图绘制请求处理流程，并反映
各种软件在各个环节对请求处理的情况。随着文档化进程的不断深入，文档中应当记录系统架构中每一个模块的
具体作用，以及该模块相比于其他方案的优势。除了特定的软件外，文档还应该记录新服务器的上线过程，潜在
故障和解决方案，Unix系统工具简介等等。文档中记录的这些内容，是为了让开发人员更容易的从较高层面了解
生产系统的架构。

有了这些文档，开发人员随时可以对系统架构进行更深入的了解。通过我们之前部署的监控系统，开发人员能够
以更简单的方式来了解系统的运行状态，所以他们更可能对基础架构产生兴趣。在设置了监控指标和记录文档之
后，运维黑盒的问题将逐渐解决。虽然目前两支团队之间协作仍不是很多，但是之间的隔阂正在很快消失。

让开发环境成为生产环境的镜像

到目前，开发和运维之间主要是通过监控的数据和文档进行沟通。基于这些认知，开发人员更希望能够在实际环
境上做一些测试，对系统的内部机制进行了解。在生产环境上进行这些操作不仅不现实，还会影响到系统的稳定
性。较好的方案是提供一些沙盒供开发人员测试。

以此为需求，出现了Vagrant这种工具，它能够以VirtualBox虚拟机的方式将开发环境打包并分发。这些虚拟机通
过标准的配置管理工具——如Chef，Puppet或最基础的shell脚本——建立。运维人员可以使用这些工具快速配置出和
生产环境相同的开发环境。开发人员很希望在这样的环境中工作，因为和生产环境基本一致。除此之外，开发人
员再也不用担心需要手动配置开发环境了，因为通过Vagrant这个工具，运维人员包揽了这些工作。

这种基于生产环境配置的开发环境，相当于为开发人员真实系统的沙盒。如果出现了任何问题，直接将虚拟机删
除然后重新建立一个即可。沙盒表面上很简单，但具体的配置过程使可以开发人员了解服务器的分配过程，运维
实施变更的过程，以及系统的实际架构。

DevOps的办公时间

开发人员现在有一个沙盒可以在“真正的系统”上进行测试，还可以通过文档去深入了解系统，更可以获取生产系
统的监控数据。尽管如此，运维工作仍然令开发人员望而却步。幸运的是，大家都很友善，而现在是两个团队真
正开始合作的时候了。合作可以源自论坛、帮助台，甚至是直接过去找某人交流。

关于这方面的实践，我发现在办公时间进行合作是最佳的方案。上班对于运维或开发工程师都是固定的日程安排
，此段时间可以用于解答任何类型的问题。这些问题可以简单到“我怎么在机器上搜索文件？”或是复杂到“你能解
释一下为什么要这么配置HAProxy的参数么？”办公时间的优势是，无论你问什么问题，别人都不会评论你。工程
师在办公时间内可以提出任何的相关问题而无需产生顾虑。

在这个阶段中，一个重要的里程碑已经达到了，那就是：沟通交流！开发和运维团队已经互相理解，他们相互沟
通，相互合作，相互影响。

规避开发团队进行运维工作的风险

在继续下一个环节之前，我需要指出，在当前阶段，你的组织中DevOps文化已经比大多数组织的要健全多了。到
这一个阶段为止，我们通过低风险的方式，缓慢的，有条不紊的引入了DevOps文化。接下来，我们即将达到前文
所述的DevOps时间轴的最右边。相比前面几个阶段，这一阶段会更加激进，而且尚未有完备的定义。但是，有些
组织已经完整的转变成为DevOps，并且也慢慢体会到这些变化的好处。

开发人员现在已经有了工具的支撑，开始进行真正的运维工作，并对其负责。和前面的阶段一样，这一阶段也可
以划分成更小的阶段，以规避风险，并使人们更容易接受。

第一步是用标准的开源模式进行变更：Pull请求和代码复审。当开发人员希望加入一些新东西时，他（或她）可
以直接进行变更并发布一个Pull请求。开发人员可以使用提前在Vagrant中配置好的虚拟机测试这些变更。 Pull
请求为运维团队提供了一个对这些变更进行审查和完备性测试的机会。如果有问题，反馈至开发人员，这样就可
以避免问题重复出现。最后，Pull请求被合并，这时，开发人员可以为实施一个变更而感到自信和骄傲，而运维
人员也会放心，因为变更的审查是由运维负责的。

第二步，这一步在本文撰写时仍具有实验性质：对运维进行一些持续集成。最基础的，是通过类似Jenkins的持续
集成服务器去验证运维人员用于创建沙盒环境（可能使用Vagrant管理）的脚本是否正确。也可以进行基本的冒烟
测试，如基础设施能够成功产生一个HTTP请求。

当上面的工作部分或全部都准备完成时，开发人员就可以安全的进行变更了。运维人员仍旧负责变更审查工作，
所以他们会对此放心。从现在开始，运维和开发的才真正共同工作，并共同承担责任。虽然开发和运维团队依然
存在一些区别，但是很快这种区别就会消失。

开发人员们：疯狂吧！

现在，我们准备进入DevOps时间线的最右端：开发团队负责所有运维工作。经过了前面的几个阶段，技术和文化
的改变已经使DevOps成为可能。实际情况中，这些阶段是连续的，即不断让两个独立的团队越来越多的在一起工
作。运维团队可以不断缩减，而开发团队可以不断扩大。开发人员在少数运维的指导下进行运维工作。在应对系
统中断时，开发人员应该随时待命，而运维人员则退居二线。

再次重申一下，能进入这个阶段的前提是前几个阶段的基础十分稳固。监控指标的数据收集是为了能够了解开发
的代码对系统整体的影响。文档化的工作使开发人员能够了解更多关于生产环境架构的信息，以便于更好的了解
不同变更对系统的影响。使用由自动配置脚本构建的虚拟机以及工作流系统不仅能够节约运维人员的时间，也为
开发人员提供了进行研究的沙盒环境。办公室或是论坛，都是开发和运维人员相互了解、学习的可靠环境，你可
以畅所欲言问你想要了解的问题。自动化架构测试以及代码审查给开发和运维增加了一层安全保障，降低了运维
人员变更的风险。最终的结果就是，团队之间的沟通更加自由，更加信任彼此，使得团队之间的界限更加模糊。

DevOps

采用DevOps的益处很多。首先，组织内的信任和合作将会更加广泛。新功能特性的交付频率也会更高，运维团队
不用再说“不”了——因为有更多的人参与运维，而且开发人员同样要对变更负责。DevOps同样能够提升系统稳定性
，信不信由你——因为现在有更多的人在关注变更对系统的影响。因为新功能特性的快速交付，需要停机进行大规
模升级的变更就会减少。相对的，变更的规模会更小，更可控，可能完全不需要停机了。

在这个时间轴上，你处于什么位置？你想到达什么位置？只要你不在最左边，那就说明你所在的组织已经开始向
DevOps迈进了。将DevOps分解成这些子阶段，是为了减少风险，并提升你的自信，如果你认为这些改变没有按照
预想中进行，也可以先退回至上一阶段，过段时间再进行尝试。

关于作者

[6]

Mitchell Hashimoto 是Vagrant的作者，同时他也是Kiip的运维人员。他热衷于运维和开源，喜欢投入业余时间
为开源社区做出贡献。另外，Mitchell喜欢在会议上和用户群组中谈论Vagrant。你可以在GitHub和Twitter上找
到Mitchell，他的ID是@mitchellh。

查看英文原文：The Wide Range of DevOps

---------------------------------------------------------------------------------------------------

感谢杨赛对本文的审校。

给InfoQ中文站投稿或者参与内容翻译工作，请邮件至editors@cn.infoq.com。也欢迎大家通过新浪微博（@InfoQ
）或者腾讯微博（@InfoQ）关注我们，并与我们的编辑和其他读者朋友交流。

  * 领域
  * 运维 & 基础架构
  * 专栏
  * 云计算
  * DevOps
  * 运维

相关内容

您好，朋友！

您需要注册一个InfoQ账号或者登录才能进行评论。在您完成注册后还需要进行一些设置。

获得来自InfoQ的更多体验。

告诉我们您的想法

[                    ] [                    ]

允许的HTML标签: a,b,br,blockquote,i,li,pre,u,ul,p

[ ] 当有人回复此评论时请E-mail通知我
发送信息
社区评论
好文。 by Zong Gang Posted
关注DevOps by Chen Zhen-bao Posted

好文。 by `Zong Gang'

研发和运维团队差异主要在技术和文化。

  * 回复
  * 回到顶部

关注DevOps by `Chen Zhen-bao'

我们基于开放工厂（iOpenWorks.com）平台实现了完全的DevOps。开发人员使用iOpenWorks提供的OSGi.NET模块
化框架构建应用系统，一键将模块最新版本发布到iOpenWorks插件仓库；部署的应用系统通过自动升级/降级机制
与插件仓库保持一致。

  * 回复
  * 回到顶部

关闭

by

发布于

  * 查看
  * 回复
  * 回到顶部

关闭
主题 [                    ] 您的回复引用原消息 [                    ]

允许的HTML标签: a,b,br,blockquote,i,li,pre,u,ul,p

[ ] 当有人回复此评论时请E-mail通知我
发送信息    取消
关闭
主题 [                    ] 您的回复 [                    ]

允许的HTML标签: a,b,br,blockquote,i,li,pre,u,ul,p

[ ] 当有人回复此评论时请E-mail通知我

    取消
关闭

 OK
2 讨论

  * 热点内容
  * 10天
  * 40天
  * 近6个月

深度内容

  * 全部
  * 文章
  * 演讲
  * 访谈
  * 迷你书

互联网金融系统中的资金正确性保障

陆怡 1月28日

[luyi_100]

BaaS服务的定义、发展以及未来

郭蕾 1月28日

[cloud2]

从计划到进化

任鑫 1月28日

[renxin_100]

解读2014之安全篇：史诗级漏洞频发

黄丹 1月27日

[road]

Tower团队24个月的远程协作实践

沈学良 1月27日

[shenxuelia]

从360手机卫士的开发历程看如何实施大型移动应用开发

姚彤 1月27日

[yaotong_10]

  * 更早的 >

赞助商链接

InfoQ每周精要

通过个性化定制的新闻邮件、RSS Feeds和InfoQ业界邮件通知，保持您对感兴趣的社区内容的时刻关注。

[click2view]
[您的邮箱            ]  订阅
  * 首页
  * 全部话题
  * QCon全球软件开发大会
  * 关于我们
  * 投稿
  * 创建账号
  * 登录

  * 全球QCon
  * 伦敦 2015年3月2-6日
  * 圣保罗 2015年3月23-27日
  * 北京 2015年4月23-25日
  * 东京 2015年4月 21
  * 纽约 2015年6月8-12日
  * 里约 2015年8月24-28日
  * 上海 2015年10月15-17日
  * 旧金山 2015年11月16-20日

InfoQ每周精要

通过个性化定制的新闻邮件、RSS Feeds和InfoQ业界邮件通知，保持您对感兴趣的社区内容的时刻关注。

[click2view]
[您的邮箱            ]  订阅
  * 属于您的个性化RSS
  * InfoQ官方微博
  * InfoQ官方微信
  * 社区新闻和热点

特别专题

  * IBM
  * 技术社区活动日历
  * 百度技术沙龙
  * 月刊：《架构师》
  * 线下活动：QClub
  * AWS专区
  * 物联网大会

定制您感兴趣的技术领域

    [*] 语言 & 开发
    [*] 架构 & 设计
    [*] 过程 & 实践
    [*] 运维 & 基础架构
    [*] 企业架构

这会影响您在主页和RSS订阅中看到的内容。点击“偏好设置”可选择更多精彩定制内容。

                                                                                InfoQ.com及所有内容
                                                                                ，版权所有 ©
                                                                                2006-2015 C4Media
                                                                                Inc. InfoQ.com 服务
提供反馈              错误报告          商务合作           内容合作             器由 Contegix提供,
feedback@cn.infoq.com bugs@cn.infoq.com sales@cn.infoq.com editors@cn.infoq.com 我们最信赖的ISP伙伴
                                                                                。
                                                                                北京创新网媒广告有
                                                                                限公司京ICP备
                                                                                09022563号-7 隐私政
                                                                                策
BT
Close
E-mail [                    ] 密码 [                    ]  submit
使用Google账号登录
使用Microsoft账号登录

忘记密码？

InfoQ账号使用的E-mail [                    ] 发送邮件

重新登录

重新发送激活信息 [                    ] 重新发送

重新登录

没有用户名？

点击注册

#+end_example
** web page: 访问及书评:DevOps中Linux服务器疑难追踪最佳实践
http://www.infoq.com/cn/articles/Book-Review-DevOps-Troubleshooting-Linux-Server
*** webcontent                                                     :noexport:
#+begin_example
Location: http://www.infoq.com/cn/articles/Book-Review-DevOps-Troubleshooting-Linux-Server
BT

  * 投稿
  * 关于我们
  * 合作伙伴

  * 欢迎关注我们的：
  * [weibo_16x1]
  * [weixin_16_]
  * [rss]

InfoQ - 促进软件开发领域知识与创新的传播
[搜索关键词          ]  submit
登录
[logo_bigge]

  * En |
  * 中文 |
  * 日本 |
  * Fr |
  * Br

482,381 十二月独立访问用户

  * 语言 & 开发
      + Java
      + .Net
      + 云计算
      + 移动
      + HTML 5
      + JavaScript
      + Ruby
      + DSLs
      + Python
      + PHP
      + PaaS

    特别专题

    []

    浏览所有语言 & 开发
  * 架构 & 设计
      + 建模
      + 性能和可伸缩性
      + 领域驱动设计
      + AOP
      + 设计模式
      + 安全
      + 云计算
      + SOA

    特别专题

    []

    浏览所有架构 & 设计
  * 过程 & 实践
      + Agile
      + 领导能力
      + 团队协作
      + 敏捷技术
      + 方法论
      + 持续集成
      + 精益
      + 客户及需求

    特别专题

    []

    浏览所有过程 & 实践
  * 运维 & 基础架构
      + 性能和可伸缩性
      + 大数据
      + DevOps
      + 云计算
      + 虚拟化
      + NoSQL
      + 应用服务器
      + 运维

    特别专题

    []

    浏览所有运维 & 基础架构
  * 企业架构
      + 企业架构
      + 业务流程建模
      + 业务/IT整合
      + Integration (EAI)
      + 治理
      + Web 2.0
      + SOA

    特别专题

    []

    浏览所有企业架构

[20150104_b]

  * 移动
  * Docker
  * Node.js
  * 云计算
  * 大数据
  * 架构师
  * QCon
  * ArchSummit
  * AWS
  * Azure
  * Helion

全部话题
您目前处于： InfoQ首页文章访问及书评:DevOps中Linux服务器疑难追踪最佳实践

访问及书评:DevOps中Linux服务器疑难追踪最佳实践 [logodevops]

作者 Aslan Brooke ，译者陈菲发布于 2013年10月15日 |

  * 分享到：微博微信 Facebook Twitter 有道云笔记邮件分享
  * `稍后阅读'
  * `我的阅读清单'

Kyle Rankin为在DevOps文化中面向Linux服务器的团队提供具有实践意义的故障排除建议和技术。本书目标对象
为那些对Linux服务器故障排除还有一定知识欠缺的系统工程师、开发者和QA工程师。富有经验的Linux系统工程
师会发现该书说明了在在交叉功能团队环境中应该分享一些内容新颖，并具有说明性的内容。当进行故障排除时,
老练的Linux工程师会把这本书作为一个在实验室帮助开发人员和QA同事的指导性手册.

Focusing on DevOps关注于DevOps

第一章为在DevOps文化中的每个人提供了一个故障排除的解决方法。DevOps处于最突出的位置，为有着不同专业
背景的个人有效地交互提供了舞台。第一章指导人们执行以下几件事：

  * 故障排除上采用分而治之的心态。
  * 在故障排除期间选择IRC或类似的基于文本的聊天技术
  * 故障排除时先由快速简单的测试开始，尽量避免慢并复杂的测试。
  * 首先使用已知的解决方案。
  * 文档记录故障排除经验，以及解决方案。
  * 首先从近期的修改开始考虑。
  * 逐步建立对系统如何工作和交互的知识和理解。
  * 只有特殊调查时才使用互联网。
  * 重启前，尽量多地收集与系统出问题相关的信息。

整本书中Kyle对作为DevOps文化中一个重要部分——常见基本故障排除技能做了陈述。他做了如下说明：

    “在一个DevOps组织中，所有团队间的协作依然困难，但是当遇到故障排除时，人们依然按照他们传统的角色
    来执行，尽管此刻并没有指责游戏。为什么？嗯，就算每个人都想很好地一起协作，但是可能并非每个人都
    有相同的故障排除技能和技巧，所有人可能依然期待别人去故障排除自己的那一部分。”

第二章至第十章则将Linux服务器上会存在的问题分为几个域。以下就是Kyle从Linux服务器故障排除角度所提出
的一个主题列表：服务器运行缓慢、引导、磁盘、网络、DNS、邮件、网站、数据库和硬件。

Server Slowness服务器运行缓慢

Linux服务器会在某些棘手的线程产生以下类型的高负荷时呈现出“慢”的状态：CPU、RAM或I/O。在故障排除过程
中，团队需要定位并停止这些线程以阻止该进程降低服务器性能。大多数Linux服务器都有判断问题及违规线程类
型的工具。命令行接口工具“uptime”（或者CLI）通过汇报最后1分钟，5分钟和15分钟的平均负载来帮助诊断CPU
负载问题。CLI工具“top”通过向控制台不断发布系统信息来帮助诊断CPU和RAM负载问题.CLI工具“iotop”用来诊断
I/O负载问题.之前提到的命令行分析工具是用来分析运行这些工具时是否存在问题，同事我们也需要不同的分析
工具来分析问题发生之后。“sysstat”工具包提供一整套工具通过可配置的时间间隔来收集数据并报告问题发生之
后的信息.Problems Booting引导问题

相关厂商内容

前JavaEye网站创始人范凯：一个程序员的创业寻梦坎坷之路

DevOps的概念与实践，InfoQ迷你书

QCon北京2015增至18个专题，八折报名中。

QCon北京2015 PHP开发组核心成员惠新宸

QCon北京2015讲师 Spark SQL开发者连城

相关赞助商

[QCon]

全球软件开发大会，4月23-25日，北京，敬请期待！

通过分别对经典的“System V Init”和“Upstart Init”进行描述，Kyle从bios到init覆盖了Linux启动流程。随后
，该书深入潜入到启动流程中可能会造成问题的各单独组成部分中，并讨论如何解决这些问题。该书涵盖了以下
内容：基本输入输出系统（BIOS），GRUB，禁用闪屏，安装根文件系统，以及安装二级文件系统。书中材料的安
排顺序允许读者对一个或多个潜在问题进行有序地分析和解决每个问题。

Disk Issues

读者将通过一系列的疑难排除实例来获取关于硬盘问题的知识。首先从如何管理一个满的硬盘开始，此时Linux已
经为根用户的登录和文档移动保留了足够的空间。该保留空间可以通过使用“tune2fs”功能来检测。然后通过“du”
指令协助跟踪那些最大目录。如果硬盘没被写满，却无法创建文件，那意味着没有多余的信息节点（inode）。利
用“df -i”指令来查看有多少节点正在被使用。另外一个硬盘问题是文件系统在遭遇一个错误后通过增加只读文件
数量来自我保护。通过使用“mount”功能指令来重置。当“/proc/mdstat”路径连接控制台时会见失败的硬盘在RAID
中显示出来。而“mdadm”指令则可将失败的影彷从RAID配置中移除，与此同时，在RAID配置中加入一个好的硬盘。

Networking Problems网络问题

当某一客户端电脑无法连接服务器时，从客户端开始的每个网络层都需一一分析。在客户端电脑从使用”ethtool“
命令开始来判断网络物理链接是否存在。一旦有链接被检测到，接下来就是判断其接口是否打开，及是否有IP地
址。“ifconfig”命令将回报接口状态和IP地址。然后，对默认网关进行带有“route”命令的检测，另外，“ping”命
令用来测试客户端与其他电脑的通信。当确保了基本的通信后，需要使用“nslookup”来测试DNS确保服务器名字已
经获取。使用“traceroute”来判断客户端沟通路径是否在连接服务器的路劲上分解下去了。一旦确认了连接机器
的路径，使用“telnet”功能检查远程端口是否打开。接着，使用SSH连接服务器，然后在服务器端本地使用
“netstat”命令，另外通过“iptables”命令来检测防火墙。使用“iftop”功能检测低性能网络。最后，如果需要分
析协议，可以使用“tcpdump”功能或“winshark”工具对服务器进行深层的由内而外的协议检测。

DNS Issues DNS问题

DNS问题存在于客户端和服务器端。在客户端，可以使用“nslookup”功能来判断问题是否是“/etc/resolv.conf”文
件错误设置引起的。另外一种情况是服务器可能通过回复客户端提示所查找主机还没被设置。“dig”功能非常强大
，能帮助检测服务器问题，其中包括：递归域名服务器，DNS缓存，TTL，区域语法错误和区域传输问题。

Email Issues邮箱问题

邮件是通常是通过那些常见的协议来发送的。其邮件头包含有它传输过程中的路线等重要信息。如果没有成功接
收到邮件，可以使用“telnet”来发送邮件，它通过连接接口25和输入SMTP协议相关字符数据来完成这一步骤。这
样从邮件服务器返回的代码号就可以用来分析存在问题。另外，“nmap”也会暴露出邮件服务器是否在侦听端口。
扫描日志文件及检查邮件服务器配置也可以进一步诊断邮件问题。

Website Down网站宕机

Nginx和Apache服务器提供的是类似的网站服务。网站的很大一部分责任在于接受请求和发送响应。当一个网站变
得不可用时，我们很快就能知晓。首先需要确认的是网站所需服务是否还在运行，可以通过“service”命令来检测
，另外，还需要使用“chkconfig”命令（或取决于Init系统的类似工具）来确保该服务的设置是在服务器启动时就
开始。命令行工具“wget”和“curl”使用http协议与网站沟通，用以快速检测其可用性。比如，为了跟踪web服务器
服务重启，可以使用各实用程序来确保特定的URL返回一条成功消息（状态码200）。网站服务请求使用HTTP协议
，该协议有一组众所周知的状态码。本书描述了该状态码范围及其相关涵义。同时Web服务器生产的日志也可以用
于检测错误。从日志中能找出最常见的错误包括配置错误和权限问题。此外，web服务器可以直接通过网页来报告
它的状态。Web服务器所报告的统计信息可以直接用来判断是否存在由于过大负荷所造成的延迟或错误。

Database Slow数据库缓慢

MySQL和PostgresSQL是两个工业级数据库技术。这两个数据库技术所提供的服务都可以通过之前提到过的
“service”和“chkconfig”命令来检测。检查数据库服务器的总体模式跟web服务器类似。对日志的检测可以显示之
前的问题，同样，数据库本身也会报告它们的当前状态。可以对日志进行特殊设置以用于特殊的记录，比如：跟
踪较慢的查询。此外，用于分析服务器缓慢和硬盘问题的工具同样适用于数据库故障排除。

Hardware Failure硬件故障

故障排除可能会检测出有故障的硬件。最常见的要数硬盘驱动器，但是以下其它硬件组件也可能存在有故障（或
者造成故障）：RAM，网卡，温度和电源。每个设备都会表现出其独有的症状，而有些症状则有不同的根源。

InfoQ与本书作者Kyle Rankin针对以下不同话题进行交流：

InfoQ：都有哪些其它的书帮助你（Kyle Rankin）成为Linux服务器专家的？为什么？

    Kyle：关于技术的书可以分为两种，一种放在家中的书架上，另外一种保证放在你的书桌上。我曾换过几个
    工作，我意识到有几本书总能保留到下个书桌：

    《DNS and BIND》和《Postfix the Definitive Guide》：出于同样的原因，我一直将这两本书置于我的身
    边。在我的工作中，我总是有DNS和邮件服务器打交道，而每当我遇到BIND或Postfix配置问题时，这两本书
    一直是我的第一手资料。

    《TCP/IP Illustrated, Vol 1》：该书用于从基本层面理解TCP/IP是如何工作的。在我的书中，经常强调理
    解事物是如何工作的会在故障排除时起到很大的帮助，该本书绝不仅仅简单地解释了3方TCP握手或什么是MAC
    地址，它深入地解释了所有主要低层协议。

    《Forensics Discovery》：我能想象到很多系统管理员在该书刚出来时就直接把它过掉了，因为他们假定该
    书主要目标是安全方面人员。而我对安全和辩论术有着浓厚的兴趣，在该书的开头几个章节为描述Linux文件
    系统如何在低层工作树立了良好的例子。与此同时，我也非常感激这是一本很薄的书。太多的作者通过填充
    长篇大论或大量引用材料来使书本加厚，而我则偏向于那些薄的、切入中心的书本。

InfoQ：你的书与其他Linux服务器及疑难排除书籍有什么区别？

    Kyle：首先你会意识到我的书并没有厚得跟电话簿一样。我认为总体上，已经有太多的技术书籍过多地关注
    如何加厚书本，他们往往大量引用可以从软件文档或个人主页获取的相关免费资料。或者，很多技术书籍过
    分努力想让读者觉得其更聪明或更技术化，当往往忽略了其可读性。我倾向于选择一个更简单，更实际的方
    式来进行疑难排除，讲述一般问题类型，以及如何使用常见工具来追寻根本原因。书中我有很多机会大可将
    书籍增厚，比如，花上个几页来记录每个MySQL或Postgres分析度量。但是，我选择尽量将内容精华到读者真
    正需要知道的范围。

InfoQ：对于个人来说，需要采取什么方式来帮助跨功能团队学习书中的资料呢？

    Kyle：向跨功能团队介绍本书最好的方法之一就是疑难排除一个非产品问题。这样，每个人都可以根据自己
    的时间一步一步来，也不用担心犯错。从团队中挑选出一人作为领队，他可以是传统团队中的开发或QA。另
    外一种方式则是在事后调查分析时，采用书中所说的疑难排除步骤。因此团队可以讨论他们在解决问题时所
    采用的步骤，并将它们与书中的步骤进行对比。

关于作者

[00070] Kyle Rankin目前是Artemis Internet, Inc.公司系统工程领导。除了《DevOps Troubleshooting》，他
还著写过《Knoppix Hacks》、《Knoppix Pocket Reference》、《Linux Multimedia Hacks》和《Ubuntu Hacks
》，并为多本其它书做出贡献。Rankin是Linux Journal一名优秀的专栏作家，曾发表于PC Magazine，
TechTarget网站和其他各类刊物。他经常演讲于开源软件，其中包括SCALE、OSCON、Linux World Expo、
Penguicon及一系列Linux用户组。

参考英文原文：Interview and Book Review: DevOps Troubleshooting: Linux® Server Best Practices

---------------------------------------------------------------------------------------------------

感谢陈菲对本文的审校。

给InfoQ中文站投稿或者参与内容翻译工作，请邮件至editors@cn.infoq.com。也欢迎大家通过新浪微博（@InfoQ
）或者腾讯微博（@InfoQ）关注我们，并与我们的编辑和其他读者朋友交流。

  * 领域
  * 运维 & 基础架构
  * 专栏
  * 云计算
  * DevOps
  * Linux
  * 最佳实践
  * 协作
  * 敏捷
  * 团队工作
  * 操作系统
  * 故障解决

相关内容

您好，朋友！

您需要注册一个InfoQ账号或者登录才能进行评论。在您完成注册后还需要进行一些设置。

获得来自InfoQ的更多体验。

告诉我们您的想法

[                    ] [                    ]

允许的HTML标签: a,b,br,blockquote,i,li,pre,u,ul,p

[ ] 当有人回复此评论时请E-mail通知我
发送信息
社区评论
常用的几件事 by Wong Peter Posted

常用的几件事 by `Wong Peter'

故障排除上采用分而治之的心态。
首先使用已知的解决方案。
文档记录故障排除经验，以及解决方案。
首先从近期的修改开始考虑。

  * 回复
  * 回到顶部

关闭

by

发布于

  * 查看
  * 回复
  * 回到顶部

关闭
主题 [                    ] 您的回复引用原消息 [                    ]

允许的HTML标签: a,b,br,blockquote,i,li,pre,u,ul,p

[ ] 当有人回复此评论时请E-mail通知我
发送信息    取消
关闭
主题 [                    ] 您的回复 [                    ]

允许的HTML标签: a,b,br,blockquote,i,li,pre,u,ul,p

[ ] 当有人回复此评论时请E-mail通知我

    取消
关闭

 OK
1 讨论

  * 热点内容
  * 10天
  * 40天
  * 近6个月

深度内容

  * 全部
  * 文章
  * 演讲
  * 访谈
  * 迷你书

开源公板——智能硬件开发的“加速器”

林建和 1月29日

[linjianhe_]

高效运维最佳实践（01）：七字诀，不再憋屈的运维

萧田国 1月29日

[liyi_logo]

互联网金融系统中的资金正确性保障

陆怡 1月28日

[luyi_100]

BaaS服务的定义、发展以及未来

郭蕾 1月28日

[cloud2]

从计划到进化

任鑫 1月28日

[renxin_100]

解读2014之安全篇：史诗级漏洞频发

黄丹 1月27日

[road]

  * 更早的 >

赞助商链接

InfoQ每周精要

通过个性化定制的新闻邮件、RSS Feeds和InfoQ业界邮件通知，保持您对感兴趣的社区内容的时刻关注。

[click2view]
[您的邮箱            ]  订阅
  * 首页
  * 全部话题
  * QCon全球软件开发大会
  * 关于我们
  * 投稿
  * 创建账号
  * 登录

  * 全球QCon
  * 伦敦 2015年3月2-6日
  * 圣保罗 2015年3月23-27日
  * 北京 2015年4月23-25日
  * 东京 2015年4月 21
  * 纽约 2015年6月8-12日
  * 里约 2015年8月24-28日
  * 上海 2015年10月15-17日
  * 旧金山 2015年11月16-20日

InfoQ每周精要

通过个性化定制的新闻邮件、RSS Feeds和InfoQ业界邮件通知，保持您对感兴趣的社区内容的时刻关注。

[click2view]
[您的邮箱            ]  订阅
  * 属于您的个性化RSS
  * InfoQ官方微博
  * InfoQ官方微信
  * 社区新闻和热点

特别专题

  * IBM
  * 技术社区活动日历
  * 百度技术沙龙
  * 月刊：《架构师》
  * 线下活动：QClub
  * AWS专区
  * 物联网大会

定制您感兴趣的技术领域

    [*] 语言 & 开发
    [*] 架构 & 设计
    [*] 过程 & 实践
    [*] 运维 & 基础架构
    [*] 企业架构

这会影响您在主页和RSS订阅中看到的内容。点击“偏好设置”可选择更多精彩定制内容。

                                                                                InfoQ.com及所有内容
                                                                                ，版权所有 ©
                                                                                2006-2015 C4Media
                                                                                Inc. InfoQ.com 服务
提供反馈              错误报告          商务合作           内容合作             器由 Contegix提供,
feedback@cn.infoq.com bugs@cn.infoq.com sales@cn.infoq.com editors@cn.infoq.com 我们最信赖的ISP伙伴
                                                                                。
                                                                                北京创新网媒广告有
                                                                                限公司京ICP备
                                                                                09022563号-7 隐私政
                                                                                策
BT
Close
E-mail [                    ] 密码 [                    ]  submit
使用Google账号登录
使用Microsoft账号登录

忘记密码？

InfoQ账号使用的E-mail [                    ] 发送邮件

重新登录

重新发送激活信息 [                    ] 重新发送

重新登录

没有用户名？

点击注册

#+end_example
* #  --8<-------------------------- separator ------------------------>8--
* Operate common services: Apache
** CANCELED disallow request from apache
  CLOSED: [2015-01-20 Tue 17:52]
[12/2/14, 10:59:53 PM] Shivang: root@app1:/cloudpass/backend/build/bin/cloudpass_logs# grep "VALIDATE USER (MULTI-CONTEXT-PERSONAL)- emailAddress: fluig@betunel.com.br" server.log |wc -l
44878
[12/2/14, 11:00:01 PM] Shivang: 44K logins for this user login
[12/2/14, 11:00:04 PM] Shivang: not sure what kind
[12/2/14, 11:00:43 PM] Shivang: 45019
Wed Dec  3 05:00:31 UTC 2014
root@app1:/cloudpass/backend/build/bin/cloudpass_logs# grep "VALIDATE USER (MULTI-CONTEXT-PERSONAL)- emailAddress: fluig@betunel.com.br" server.log |wc -l ; date
45024
Wed Dec  3 05:00:33 UTC 2014
[12/2/14, 11:00:53 PM] Shivang: it logs in 5 times every 2 seconds .. not sure why
[12/2/14, 11:01:14 PM] Shivang: and john now your stuff
[12/2/14, 11:01:17 PM] Shivang: let me see what's going on
[12/2/14, 11:01:56 PM] John Kaplan: ok
[12/2/14, 11:02:48 PM] Shivang: john which comapny
[12/2/14, 11:02:51 PM] Shivang: the only lock i see is this
** TODO Drop specific user request
#+BEGIN_EXAMPLE
[12/3/14, 8:00:36 AM] Shivang: if i ask you to drop a specific request
[12/3/14, 8:00:38 AM] Shivang: from apache
[12/3/14, 8:00:49 AM] Shivang: and restart the stack .. can you do it?
[12/3/14, 8:00:58 AM] Shivang: @vicente: we ok to restart the stack?
[12/3/14, 8:02:11 AM] denny: You’re talking about that strange user account?

I don’t know how to drop that. Need some time to research.
#+END_EXAMPLE
** TODO Kung SSL files
root@sf-fi-qa-01:/# ls -lth /etc/httpd/ssl
total 16K
-rw-r--r-- 1 root root 1.7K Oct 21 15:44 ssl.key
-rw-r--r-- 1 root root 1.9K Oct 21 15:44 ssl.crt
-rw-r--r-- 1 root root 4.7K Oct 21 15:44 DigiCertCA.crt

#+begin_example
[10/27/14, 14:05:55] kungchaowang: openssl pkcs12 -in file.pfx -out file.nokey.pem -nokeys
openssl pkcs12 -in file.pfx -out file.withkey.pem
openssl rsa -in file.withkey.pem -out file.key
cat file.nokey.pem file.key > file.combo.pem

The 1st step prompts you for the password to open the PFX.
The 2nd step prompts you for that plus also to make up a passphrase for the key.
The 3rd step prompts you to enter the passphrase you just made up to store decrypted.
The 4th puts it all together into 1 file.
[10/27/14, 14:06:31] kungchaowang: but, where to get file.withkey.pem? I believe they need to give you key file as well, which is your ssl.key file
[10/27/14, 14:06:56] denny sent a file to this group:
cer_identity_brin3.zip
[10/27/14, 14:06:59] denny: All I get is above
[10/27/14, 14:07:09] kungchaowang: let me try
#+end_example
*** TODO Apache key
#+begin_example
[10/27/14, 14:05:55] kungchaowang: openssl pkcs12 -in file.pfx -out file.nokey.pem -nokeys
openssl pkcs12 -in file.pfx -out file.withkey.pem
openssl rsa -in file.withkey.pem -out file.key
cat file.nokey.pem file.key > file.combo.pem

The 1st step prompts you for the password to open the PFX.
The 2nd step prompts you for that plus also to make up a passphrase for the key.
The 3rd step prompts you to enter the passphrase you just made up to store decrypted.
The 4th puts it all together into 1 file.
[10/27/14, 14:06:31] kungchaowang: but, where to get file.withkey.pem? I believe they need to give you key file as well, which is your ssl.key file
[10/27/14, 14:06:56] denny sent a file to this group:
cer_identity_brin3.zip
[10/27/14, 14:06:59] denny: All I get is above
[10/27/14, 14:07:09] kungchaowang: let me try
[10/27/14, 14:10:12] kungchaowang: can you ask them their password for Identity.pfx ?
[10/27/14, 14:10:22] kungchaowang: need that for importing keys to apache
[10/27/14, 14:10:40] kungchaowang: openssl pkcs12 -in Identity.pfx -clcerts -nokeys -out  Identity.cer1
Enter Import Password:
#+end_example
* [#A] Key parts of operating a complex service                   :IMPORTANT:
Like hadoop, elastic search
** How to deploy
** How to configure
** How to start/stop
** How to check status
** How to do HA
** How to backup and restore
* landscape for DevOps Positions
http://www.quora.com/As-a-software-engineer-how-do-I-shift-my-career-to-devops
* [#A] DevOps-As-A-Service                                   :IMPORTANT:
funny pictures: http://devopsreactions.tumblr.com

devops ppt: http://www.slideshare.net/jedi4ever/devops-with-the-s-for-sharing-14764362?utm_source=AppFirst+List&utm_campaign=0d7ef65b26-October_Newsletter10_26_2012&utm_medium=email

Startup/SMB:
- Setup Server: LAMP, FTP
- Monitoring
- Data Cleanup
- Backup
** wechat talk
#+begin_example
针对小型startup和SMB企业，经常会有些运维的需求。
10:44
kun
kun
调用python的api
denny
1. 类似装一个应用服务器LAMP, FTP, Database, etc； 2. 做一些系统监控，有问题后自动报警。 3. 核心数据的有效备份等等。

这些工作，对于startup来说，可能技术实力够，但时间不够。对SMB来说，可能是技术不够。

那我在想，能不能
老谭Kurt
老谭Kurt
就是fullstack一体机 然后在aws market上卖？
denny
能不能提供一个网站，里面列一个菜单，每一道菜就是要自动化运维做的事情。
denny
每道菜的实现后面就是一个chef cookbook或puppet module.
10:48
MING Z
MING Z
Check the VMware backup solution.
denny
然后，用户可以在网站上注册后，下单勾选要哪些“菜”，并做最基本的定制化。然后，在自己的目标机器运行chef-client。 这样就事情就搞定了。
MING Z
MING Z
Veeam
denny
所以，总结一句就是: DevOps-As-A-Service. 底层是chef cookbook.
denny
好，我的发言完毕。请点评和指正。
denny
好，我的发言完毕。请点评和指正。
老谭Kurt
老谭Kurt
@denny 跟rightscale的那套的区分？在湾区的时候，看到很多中小公司都有用它 你去大概了解一下
kun
kun
赵鹏那个创业公司有关注没？
denny
link?
kun
kun
visualo p s
老谭Kurt
老谭Kurt

10:51
denny
一个cookbook就一个自动化。这个网站兜售的就是这些cookbook。 有能力的开发者，也可以自己上传cookbook到这个网站。那就是AppStore的概念了。
denny
因为是突然萌发的想法，还没来得及做市场调研。

在我看来，这个系统有三点特别的地方
1. No-lockin issue: cookbook的实现代码，用户是可以下载到本地， offline运行的

2. 第三方开发者可以上传cookbook, 参与赢利

3. cookbook尽量做到跨平台，即支持：debian/redhat/mac/windows.
10:58
denny
@Kurt @Kun 还来得及试你们说的那两个现有系统。你们觉得上面三个特点，与现有系统相比，如何？
老谭Kurt
老谭Kurt
大手笔 市场上专门做chef cookbook定制的那些公司有末相应的套路？
黄皓桦
黄皓桦
我可以插一个具体问题么...为CIO/SA服务的框架, startup的时候, 如何说服对方试用呢?因为这些都和本地IT
MING Z
MING Z
Where to get money?
MING Z
MING Z
U business model
黄皓桦
黄皓桦
环境很相关, 多数开始的时候要定制
MING Z
MING Z
Or just get famous first like docker?
MING Z
MING Z
Why not a docker extension.
MING Z
MING Z
Then docker guy is going to buy u.
denny
关于docker
denny
1. docker目前，还只是一个技术产品，普通企业还比较难使用。
老谭Kurt
老谭Kurt
docker getting hit，但目前是没公司用于生产环境的
老谭Kurt
老谭Kurt
至少我们公司三拨人用了之后 都是这个想法
11:01
MING Z
MING Z
If you simplify docker u make money
denny
2 docker与真实机器相对，性能的损耗还是不少。

如果我一家小公司，只有几个机器，装几个服务，那么还不如直接有个人帮我们把这些理顺，而不是在VM和service中间，再加一层docker
MING Z
MING Z
I know more than one use docker actually
denny
我们这个系统就是相当于，上面说的"那个人“。User get more control for that, and keep consistent with their old way. Right?
denny
Any comments, Ming?
老谭Kurt
老谭Kurt
@denny 关于rightscale 聊了几家公司，都是他们用户，普遍感觉功能非常强，脚本和cookbook非常丰富，但太繁杂了，初一看 吓死人
老谭Kurt
老谭Kurt
那产品时候非常有经验的运帷人员
denny
这是个好问题。 如何简化配置项，提高用户体验。

这个我相信是可以优化到足够dummies能handle
11:05
老谭Kurt
老谭Kurt

老谭Kurt
老谭Kurt

denny
我能想到的是：1. cookbooks太多，用户不知道选哪一个。 2. 某个cookbook需要定制化的option太多，用户不知道如何customize.
老谭Kurt
老谭Kurt
好啦，scalr问题解决，原来是要先配普通用户
老谭Kurt
老谭Kurt
哈
denny
哈哈，@Kurt， 这个好跳跃
老谭Kurt
老谭Kurt
 brainstorm时间嘛
11:09
denny
关于@Ming的business model问题，我想的策略就是：做cookbook的平台，即AppStore策略。 开发者可以定义他上传的cookbook是免费还是收费。
denny
当然，初期我们会让一些起药引作用的免费cookbooks进去，以提升用户量。
denny
而且，初期人气不旺时，没有开发者会愿意花时间写cookbook，上传到我们这个平台来，以寄希望盈利。

所以，我们平台初期就充当于这个开发者角色。
denny
而且，初期人气不旺时，没有开发者会愿意花时间写cookbook，上传到我们这个平台来，以寄希望盈利。

所以，我们平台初期就充当于这个开发者角色。
老谭Kurt
老谭Kurt
这事情为什么opscode不做？ 还是他们已经做了？
11:12
denny
good question。Don't know yet
denny
你知道的啦。我手头上已经实现了四到五个这种cookbook，可以充当药引。所以，我特别想试一把。

求泼冷水。
denny
BTW, 底层不一定非要是chef, 也可以是puppet， salt, whatever。
denny
因为，我们中间会有一层包装。
11:16
老谭Kurt
老谭Kurt
想法不错，得攀个大树 你是想做平台 跟资源的依赖比较高
老谭Kurt
老谭Kurt
昨天看到fit2cloud的新闻，国内这块也渐渐起来咯
老谭Kurt
老谭Kurt
都是趋势
denny
你指是对什么资源的依赖
老谭Kurt
老谭Kurt
人气啊 就像cloudfoundry攀vmware这树一样
11:19
denny
Good point。 人气，还是大家让这个平台的信赖程度
MING Z
That is why docker.
MING Z
MING Z
Performance loss did u measure?
MING Z
MING Z
Linux container is low overhead.
denny
I didn't do the performance benchmark with and without docker.

It's said the main problem is IO downgrade.
黄皓桦
黄皓桦
我还是觉得, 初期的话, 要让SA让你进机房...不是铁杆还真难啊,哈哈,还要拿他们的数据来玩...估计SA有抗拒...其实问题的bottom是....求networking!
denny
Meanwhile the NAT network is a bit tricky for dummies.
denny
@黄皓桦 是的，所以，我们的做法是提供工具给SA，让他免费拿去用。
11:24
黄皓桦
黄皓桦
恩...酱紫...给SA做推广
denny
exactly
denny
牛的SA，还可以上传cookbook，赚钱或赚名声。平台的另一个side effect就是做SA领域的linkedin
#+end_example
** Baisc reading
https://www.atlassian.com/devops/

http://www.wired.com/2013/09/no-quick-fix-for-devops/

http://www.rackspace.com/knowledge_center/whitepaper/building-your-devops-engine-a-guide-to-tearing-down-organizational-silos-to-create-more
- Developers and Operations have opposing philosophies
- In practice, DevOps requires developers to pay closer attention to deployment scripts, configuration files, load and performance testing, and other activities usually associated with an Operations group.
- As the name suggests, however, DevOps is a two-way street: Operations gives the developers constant feedback, troubleshooting information, and other data from the production environment that shows how code performs in real-world conditions. Operations provides critical knowledge about an application’s impact on the business and end-user experience, and it works hand-in-hand with Development to resolve problems and deliver a quality product. This allows each party to learn more about the other’s job.
** 这事情为什么opscode不做
** 赵鹏那个创业公司: visualo p s
** RightSclae
** 得攀个大树 你是想做平台 跟资源的依赖比较高
** TODO competitors: http://www.visualops.io
** TODO competitors: http://www.staycloud.cn
** squid --> url 在layer 7, 不在layer 4
** useful link
http://geekpeek.net
** #  --8<-------------------------- separator ------------------------>8--
** ebook
http://it-ebooks.info/book/139/
Web Operations
** concept
http://theagileadmin.com/what-is-devops/

DevOps is fundamentally a mindset about how best to bring together two
completely different groups of IT people — developers, who create
applications; and IT operations, who deploy and manage those
applications.

In even the smallest organizations there is a disconnect between Dev
and Ops groups. This disconnect frequently breeds conflict and
inefficiency, exacerbated by numerous competing motivations and
processes.

For many organizations, a great starting point on the road to
effective DevOps is to find and fix the major bottlenecks between the
two groups.
http://www.wired.com/2013/09/no-quick-fix-for-devops/
http://www.rackspace.com/knowledge_center/whitepaper/building-your-devops-engine-a-guide-to-tearing-down-organizational-silos-to-create-more
** DONE Tool chains and roles of DevOps
   CLOSED: [2015-01-19 Mon 13:15]
http://systems_linux_network_and_security.quora.com/What-exactly-is-role-of-System-DevOps-engineer
http://www.quora.com/What-are-some-of-the-most-interesting-Open-Source-projects-in-the-DevOps-space
** DONE devops blogs
  CLOSED: [2015-01-19 Mon 12:53]
http://www.stackdriver.com/top-devops-influencers-blogs-follow/
http://www.quora.com/What-are-the-best-DevOps-blogs
http://www.scriptrock.com/blog/devops-resources-online
** Key functions
https://www.linkedin.com/jobs2/view/28133776?trk=vsrp_jobs_res_name&trkInfo=VSRPsearchId%3A820397671421765782484%2CVSRPtargetId%3A28133776%2CVSRPcmpt%3Aprimary

#+BEGIN_EXAMPLE
Responsibilities:
Identify and prioritize key work packages/task items with competing priorities such as project critical events in conjunction with DevOps infrastructure (ex. GitHub/Puppet/Artifactory/Relic/Docker upgrades, redundancy, etc
Manage day-to-day activities of a small team (five to seven resources)
Identify and mitigate key issues and risks
Produce and report weekly status (i.e., tasks completed, tasks planned, issues/risks, etc.)
Establish relationships and communication paths to collaborative teams (Cloud, Network, Constituents).
Establish strong relationship with home team of Directors & TPO’s who provide the incoming project requests – understand the projects to better facilitate the prioritization and overall infrastructure strategy for lab and production environments
Familiar with DevOps philosophies of Project Phoenix (book) or the Velocity conference.
#+END_EXAMPLE

#+BEGIN_EXAMPLE
Continuous Integration - Jenkins, Go - Continuous Delivery software , Vagrant (testing)
Configuration Management & Automation - CFEngine, Chef, Puppet, Ansible, SaltStack, RunDeck, Fabric
Monitoring and Root-Cause Analysis - Graphite, Nagis, Zabbix, Zenoss (I like tools that can kick of actions based on monitoring events),  logstash or logstash+elastic search+kibana, Page on logio.io
Provisioning - Cobbler (for Linux hosts), fpm(effing package manager), Docker (features of Docker make lifecycle management easier)
Source Control - This one is critical and overlooked. Checking in your changes into a source control library is consistent with good DevOps practices and should be part of the operations toolkit as much as the ops part. So Git, SVN or CVS though I lean towards git.
#+END_EXAMPLE
** [#A] Value demonstrated of DevOps Service                      :IMPORTANT:
*** sent to Jay
#+BEGIN_EXAMPLE
DevOps

DevOps approach span the entire delivery pipeline, it includes improved deployment frequency, which can lead to faster time to market, lower failure rate of new releases, shortened lead time between fixes, and faster mean time to recovery in the event of a new release crashing or otherwise disabling the current system. Also it gives the developers constant feedback, troubleshooting information, and other data from the production environment that shows how code performs in real-world conditions.

Why choose OSC consultants for your DevOps work? Our mindset are set for fully automation, identity potential risk, collect constant feedback for product improvement; We have deep first-hand experience with all major toolchains (Jenkins; Chef/Puppet; Nagios/Zabbix; OpenStack/Vargrant/Docker, etc); ; We're certified Chef master with several cookbooks contributed to Chef market.
#+END_EXAMPLE
*** ChaosMonkey Test
*** Add value: Log analysis to detect issues or interesting things
http://www.quora.com/Aside-from-debugging-how-are-you-using-logs-and-log-data
Performance evaluation
Memory leak monitoring
Verification and validation. (V&V)
** Risk management for DevOps
*** day-to-day operate takes energy
*** TODO Need to support 24 X 7
http://www.quora.com/Should-a-Developer-take-up-a-DevOps-opportunity
"Developer can finish coding and sleep without worries, DevOps are on work before, during and after the coding and be the face of the service/application 24x7".
#+BEGIN_EXAMPLE
[1/18/15, 2:45:26 AM] kungchaowang: let me do it
[1/18/15, 2:47:35 AM] denny: @Kung/@John, should we file tickets for these:
- 1. adsync is opening too many fd, if network turbulence?
- 2. Replace NFS mount in app01 and app02 with local storage + git?
- 3. When doing remote backup copy, don’t use NFS mount, but remote copy.
[1/18/15, 2:52:45 AM] denny: I’m suspecting, if some machines of the cluster are restarted, we will always need manual intervene right now. Like restart the whole service stack, even disaster recovery or trouble shooting.
[1/18/15, 2:53:46 AM] denny: @John, are you testing the prod env?
[1/18/15, 2:54:39 AM] denny: Kung/John, do you guys still need me online for this? If not, I’d like to take off and check about this tomorrow moring
[1/18/15, 2:55:20 AM] denny: The prod env looks good from nagios check, besides issues are reported.

The only open issue is search service fail to restart, which is somewhat known issue.
[1/18/15, 2:56:47 AM] kungchaowang: I have text John for him to test it
[1/18/15, 2:57:20 AM] kungchaowang: tonight we only have John to help us, I will send email to Fellipe and Andres for them to test after couple hours
[1/18/15, 2:57:39 AM] John Kaplan: I’ll give it a test
[1/18/15, 2:57:52 AM] denny: Thanks, Kung
[1/18/15, 3:01:21 AM] denny: Kung/John, do you guys still need me online for this?
[1/18/15, 3:02:44 AM] kungchaowang: Thank you John
[1/18/15, 3:02:53 AM] kungchaowang: we need you 24x7.
[1/18/15, 3:03:03 AM] kungchaowang: :D
[1/18/15, 3:03:17 AM] kungchaowang: you have a good night Denny, wonderful job. thank you very much
[1/18/15, 3:03:44 AM] John Kaplan: Looks good so far
[1/18/15, 3:03:59 AM] denny: Thanks, Kung

Also I’d suggest to file tickets I mentioned above.

Good to see tonight, we actually didn’t see any big new issues.
#+END_EXAMPLE
*** Trouble shooting requires deep linux skills + application layer knowledge
*** Avoid folks like below
p.s. - avoid folks who...
http://www.quora.com/As-a-software-engineer-how-do-I-shift-my-career-to-devops
# Codes quickly, but with terrible logging/error handling, or litters output files in codebase.
# Writes code in obfuscated way.
# Think maintenance of his/her "the Masterpiece" is not their concern.
# Makes a major change to the system architecture without notifying other folks of these changes (and I mean at the very least an email).
# Takes configuration shortcuts when the proper approach doesn't take all that much longer to do.
** web page: What DevOps means to me... – Kartar.Net
http://www.kartar.net/2010/02/what-devops-means-to-me/
*** webcontent                                                     :noexport:
#+begin_example
Location: http://www.kartar.net/2010/02/what-devops-means-to-me/
  * About
  * Posts
  * Books
  * Search

[                    ]

Kartar.Net logo

Kartar.Net

If I had my hand full of truth, I would take good care how I opened it

Puppet • sysadmin • devops • cliques • lifecycles

What DevOps means to me...

James Turnbull bio photo By James Turnbull February 19, 2010 Comment Tweet Like +1

Over the last year or so a bunch of presumptuous European sysadmins and developers, joined by some
of their American brethren and even a couple of us antipodeans (there are others too!) have been
talking about a concept called DevOps. DevOps is the merger of the realms of development and
operations (and if truth be told elements of product management, QA, and *winces* even sales should
be thrown into the mix too).

The Broken

So … why should we merge or bring together the two realms? Well there are lots of reasons but first
and foremost because what we’re doing now is broken. Really, really broken. In many shops the
relationship between development (or engineering) and operations is dysfunctional to the point of
occasional toxicity. Here’s an example I think everyone will be at least partially familiar with:
the minefield that is project to production software deployment. Curse along as I explain.
Development builds an application, the new hotness which promises customers all the whizz-bang
features and will make the company millions. It is built using cutting edge technology and a brand
new platform and it has got to be delivered right now. Development cuts code like crazy and gets
the product ready for market ahead of schedule. They throw their masterpiece over the fence to
Operations to implement and dash off to the pub for the wrap party. Operations catches the
deployment and is filled with horror.

[munch]

The Operations team summarizes their horror and says one or more of:

  * The wonder application won’t run on our infrastructure because {it’s too old, it doesn’t have
    capacity, we don’t support that version}
  * The architecture of the application doesn’t match our { storage, network, deployment, security
    } model
  * We weren’t consulted about the { reporting, security, monitoring, backup, provisioning } and it
    can’t be “productionised”.

But Operations persevere and install the new hotness - cursing and bitching throughout. Sadly,
after forcing the application onto infrastructure and bending and twisting the architecture to get
it running, the performance of the new application can be summed up as “epic fail”.

[epicfail-3]

The Operations sighs and starts logging problems and passing issues back to the Development team.
Their responses generally come from the following pool:

  * It’s not our fault, our code is perfect, it’s just been poorly implemented
  * Operations are stupid and don’t understand the new hotness! Why can’t they implement the
    cutting edge technology? Why are they so backward?
  * It runs fine on my machine…

The interactions between teams quickly becomes a toxic blame storm. The customers (and by extension
the shareholders, investors and management) then become the losers. The loop gets closed with the
company losing bucket loads of money and everyone losing their jobs. EPIC and FAIL.

What’s different about DevOps?

DevOps is all about trying to avoid that epic failure and working smarter and more efficiently at
the same time. It is a framework of ideas and principles designed to foster cooperation, learning
and coordination between development and operational groups. In a DevOps environment, developers
and sysadmins build relationships, processes, and tools that allow them to better interact and
ultimately better service the customer. DevOps is also more than just software deployment - it’s a
whole new way of thinking about cooperation and coordination between the people who make the
software and the people who run it. Areas like automation, monitoring, capacity planning &
performance, backup & recovery, security, networking and provisioning can all benefit from using a
DevOps model to enhance the nature and quality of interactions between development and operations
teams. Everyone in the DevOps community has a slightly different take on “What is DevOps?” We all
bring different experiences and focuses to the problem space. I personally see DevOps as having
four quadrants:

Simplicity

KISS is King and in that vein this section is simple too. Design simple, repeatable, and reusable
solutions. Simplicity saves documentation, training, and support time. Simplicity increases the
speed of communication, avoids confusion, and helps reduces the risk of development and operational
errors. Simplicity gets you to the pub faster.

Relationships

Engage early, engage often. Development teams need to embed operations people into their project
and development life cycles. Invite operational people to your scrum or development meetings. Share
ideas and information about product plans and new technologies. Gather operational requirements
when gathering functional ones. As a project progresses test deployment, backup, monitoring,
security and configuration management as well as application functionality. The more issues you fix
during the project the less issues you expose your customers to when the application is live.
Educate operations people about the applications architecture and the code base. The more
information operations people can feed you about a problem with the code the less trouble-shooting
you need to perform and the faster the problem can be fixed.

Operations people need to bring development people into the problem and change management space.
Invite developers into your team meetings. Share your roadmaps and upgrade plans. Understand where
future development is heading to better ensure infrastructure deployments match product
requirements. Developers also bring skills, knowledge and tools that can help make your environment
easier to manage, more efficient and cleaner. Learn to code or if you’re a hack-n-slash systems
programmer like me then learn to code better. Concepts like building tools with APIs rather than
closed interfaces, distributed version control, test driven development, and methodologies like
Agile Development, Kanban and Scrum can revolutionise operational practises in the same way they’ve
changed the way code is cut. Don’t be afraid of ideas and approaches from outside your domain - we
can all learn things, even if it’s “let’s never do it that way again…!”, from how others do things
and ultimately? Guess what? Yep, we’re all on the SAME team. Remember that interactions between
people rank, in decreasing order of effectiveness (in IMHO but backed by some research):

 1. Face to face
 2. Video conference
 3. Phone
 4. IM & IRC
 5. Email

Process & Automation

Automation

Automate, automate, automate. Build or make use of simple and extensible tools (make sure they have
APIs and machine readable input and output - see James White’s Infrastructure Manifesto). Use tools
like Puppet (or others) to manage your configuration. Remember to extend your automation umbrella
cross-domain and end-to-end in your environment - manage development, testing, staging and
production environments with the same tools and processes. Not only does this have economies of
scale benefits in support and management but it means you can test deployment and management
alongside functionality as your application and new codes rolls toward production. Finally, when
building process and automation always keep the KISS principle in mind. Complexity breeds
opportunities for error:

Build simple processes and tools that are easy to implement, manage and maintain.

Process

Don’t underestimate the power of process and automation. But stop treating processes as stand-alone
in your teams. Link process together across domains: software deployment, monitoring, capacity
planning and other “operational” processes have their start in the development world. Software
deployment is the logical conclusion of the software development life cycle and should be viewed as
such rather than a separate operational process. Another example is metrics and monitoring, it is
hard to measure anything without understanding the baselines and assumptions made in the
development domain. Joint processes also mean more opportunity for development and operations
interaction, understanding and joint accountability. Finally, joint process development means
single repositories for documentation and other opportunities for economies of scale.

Assume failure is the norm. Many shops do process engineering: ranging from hand-written lists to
ISO9001. Those processes generally have one key flaw: they focus on the outcome and its inevitable
success. A simple process might provision a host:

  * Step 1: Install
  * Step 2: Cable machine
  * Step 3: Install OS, etc, etc.

Assuming all goes to process then at the end of Step x you will have a fully provisioned host. But
what happens if it doesn’t go right? If your process breaks or you receive some anomalous output
how does your process deal with it? Instead think about process as a journey and map out the
potential pitfalls and obstacles. Treat your processes like applications and build error handling
into them. You can’t predict every application or operational pitfall or issue but you can ensure
that if you hit one your process isn’t derailed.

Continuous Improvement

Don’t stop innovating and learning. Technology moves fast. So do customer requirements. Build
continuous improvement and integration into your tools and processes. Here is a good place
operations people can learn from (good) developers about practises like test-driven development. A
good example here is to build tests for your software deployment process and infrastructure. They
are often an application in their own right and should be developed and maintained correctly. Your
monitoring could also be extended with behavioural testing to deliver better business value. Look
at using development domain tools, like Jenkins-CI for example, to explore and measure the
operational domain.

Learn from mistakes and from outages. Seek root cause aggressively AND cross-domain. If you have an
outage and a post-incident review then bring development and operational teams together to review
the incident. Sometimes some simple code refactoring can save making infrastructure changes. Work
together to fix root cause, treat it with the same process you develop to conduct project to
production software deployment, rather than relegating them to incident review reports or batting
issues between teams.

Me

Finally, for me DevOps is about people and nature of the environment you want to work in. The best
thing about the movement for me is that it is trying to foster behaviours and environments where
people work together towards joint goals rather than at cross-purposes or at odds. That’s a world
I’d much rather use my skills in.

Previous Next
© 2015 James Turnbull. Powered by Jekyll using the So Simple Theme.

Please enable JavaScript to view the comments powered by Disqus. comments powered by Disqus

#+end_example
* #  --8<-------------------------- separator ------------------------>8--
* Chef friends: talk with related experts
** svanzoest
https://github.com/svanzoest/ssmtp-cookbook/issues/19
** joshuacox
https://github.com/viverae-cookbooks/apache2/issues/310
https://github.com/joshuacox?tab=repositories
* TODO How to ensure a profound AD test cases
#+BEGIN_EXAMPLE
To identity AD problems or potential issues quickly and automatically, we need to enrich our test cases of AD service.

Testcase: Test whether users from different domains can login or not.

Code: https://github.com/TOTVS/qa/blob/master/selenium_scripts/AD/DomainLoginADContinuous.java
Test procedure:
#+END_EXAMPLE
* TODO Take snapshot for VM, as a routine job
#+BEGIN_EXAMPLE
Most of our system are running in VM, with not too much disk occupied.
We can take snapshot for all vm every month, and keep last 2 backups.
The benefit is:
- When things go wrong, we can have a escape plan
- Backup the whole system, including data.
#+END_EXAMPLE
* TODO When operate system, need to understand the system overview
https://totvslab.atlassian.net/wiki/display/TECH/System+Components+Overview
* TODO [#B] jstack monitoring
* TODO [#A] Easily use chef cookbook: easy to bootstrap, easy to customize node.json
#+BEGIN_EXAMPLE
# setup your local workstation
./setup_chef_admin_user_locally.sh 192.168.56.101 ~/.chef ~/chef-repo kungwang 111111


# bootstrap a clean ubuntu server and install NEO4j enterprise edition
knife bootstrap 192.168.56.106 \
      -P password1234 \
      -r ntp,java,neo4j-enterprise::tarball \
      --sudo --use-sudo-password password1234 \
      -x devop \
      -j "{\"java\": {\"install_flavor\": \"oracle\", \"jdk_version\": \"7\", \"oracle\": { \"accept_oracle_download_terms\": true }}}"


# neo4j cluster setup example:

knife bootstrap 192.168.56.108 \
-N kungneo4j1 \
-P password1234 \
-r ntp,java,neo4j-enterprise::tarball,chef-client::delete_validation,chef-client::init_service \
--sudo --use-sudo-password password1234 \
-x devop \
-j "{\"java\": {\"install_flavor\": \"oracle\", \"jdk_version\": \"7\", \"oracle\": { \"accept_oracle_download_terms\": true }}, \"neo4j\": { \"server\": { \"name\": \"kungneo4j1\", \"ha\": { \"server_id\": 1, \"initial_hosts\": \"kungneo4j1:5001\", \"cluster_server\": \"kungneo4j1:5001\", \"server\": \"192.168.56.108:6001\" } }}}"



knife bootstrap 192.168.56.109 \
-N kungneo4j2 \
-P password1234 \
-r ntp,java,neo4j-enterprise::tarball,chef-client::delete_validation,chef-client::init_service \
--sudo --use-sudo-password password1234 \
-x devop \
-j "{\"java\": {\"install_flavor\": \"oracle\", \"jdk_version\": \"7\", \"oracle\": { \"accept_oracle_download_terms\": true }}, \"neo4j\": { \"server\": { \"name\": \"kungneo4j2\", \"ha\": { \"server_id\": 2, \"initial_hosts\": \"kungneo4j2:5001\", \"cluster_server\": \"kungneo4j2:5001\", \"server\": \"192.168.56.109:6001\" } }}}"

knife bootstrap 192.168.56.110 \
-N kungneo4j3 \
-P password1234 \
-r ntp,java,neo4j-enterprise::tarball,chef-client::delete_validation,chef-client::init_service \
--sudo --use-sudo-password password1234 \
-x devop \
-j "{\"java\": {\"install_flavor\": \"oracle\", \"jdk_version\": \"7\", \"oracle\": { \"accept_oracle_download_terms\": true }}, \"neo4j\": { \"server\": { \"name\": \"kungneo4j3\", \"ha\": { \"server_id\": 3, \"initial_hosts\": \"kungneo4j3:5001\", \"cluster_server\": \"kungneo4j3:5001\", \"server\": \"192.168.56.110:6001\" } }}}"

============================================

knife bootstrap 192.168.56.108 \
-N kungneo4j1 \
-P password1234 \
-r ntp,java,neo4j-enterprise::tarball,chef-client::delete_validation,chef-client::init_service \
--sudo --use-sudo-password password1234 \
-x devop \
-j "{\"java\": {\"install_flavor\": \"oracle\", \"jdk_version\": \"7\", \"oracle\": { \"accept_oracle_download_terms\": true }}, \"neo4j\": { \"server\": { \"name\": \"kungneo4j1\", \"mode\": \"HA\", \"ha\": { \"server_id\": 1, \"initial_hosts\": \"192.168.56.108:5001,192.168.56.109:5001,192.168.56.110:5001\", \"cluster_server\": \"192.168.56.108:5001\", \"server\": \"192.168.56.108:6001\" } }}}"


knife bootstrap 192.168.56.109 \
-N kungneo4j2 \
-P password1234 \
-r ntp,java,neo4j-enterprise::tarball,chef-client::delete_validation,chef-client::init_service \
--sudo --use-sudo-password password1234 \
-x devop \
-j "{\"java\": {\"install_flavor\": \"oracle\", \"jdk_version\": \"7\", \"oracle\": { \"accept_oracle_download_terms\": true }}, \"neo4j\": { \"server\": { \"name\": \"kungneo4j2\", \"mode\": \"HA\", \"ha\": { \"server_id\": 2, \"initial_hosts\": \"192.168.56.108:5001,192.168.56.109:5001,192.168.56.110:5001\", \"cluster_server\": \"192.168.56.109:5001\", \"server\": \"192.168.56.108:6001\" } }}}"

knife bootstrap 192.168.56.110 \
-N kungneo4j3 \
-P password1234 \
-r ntp,java,neo4j-enterprise::tarball,chef-client::delete_validation,chef-client::init_service \
--sudo --use-sudo-password password1234 \
-x devop \
-j "{\"java\": {\"install_flavor\": \"oracle\", \"jdk_version\": \"7\", \"oracle\": { \"accept_oracle_download_terms\": true }}, \"neo4j\": { \"server\": { \"name\": \"kungneo4j3\", \"mode\": \"HA\", \"ha\": { \"server_id\": 3, \"initial_hosts\": \"192.168.56.108:5001,192.168.56.109:5001,192.168.56.110:5001\", \"cluster_server\": \"192.168.56.110:5001\", \"server\": \"192.168.56.108:6001\" } }}}"

#+END_EXAMPLE
* TODO My DevOps improvement are not reflect in the team's JIRA
- Find chance to share with team
- Whether your input align with Managers' goal. Even your manager can report better to customer
* #  --8<-------------------------- separator ------------------------>8--
* TODO Support SLA of customers' env
* TODO Learn how jax-rs works
* TODO [#B] Shoot a viedo for the chef
* TODO How to avoid configuration problem, fail upgrade again and again
* TODO How to limit the possiblity of false alarm for deploy issue
https://totvslab.atlassian.net/browse/CLOUDPASS-6539
#+BEGIN_EXAMPLE
Shivang Shah added a comment - 1 hour ago - edited
Denny Zhang: This seems to be a deployment issue (atleast from the last time I remember when the following exception happened)
errors.GrailsExceptionResolver ClassNotFoundException occurred when processing request: POST /cloudpass/application/syncRacToApp/5
com.sun.jersey.api.client.ClientHandlerException (no security manager: RMI class loader disabled). Stacktrace follows:
java.lang.ClassNotFoundException: com.sun.jersey.api.client.ClientHandlerException (no security manager: RMI class loader disabled)
at java.rmi.server.RMIClassLoader$2.loadClass(RMIClassLoader.java:637)
at java.rmi.server.RMIClassLoader.loadClass(RMIClassLoader.java:264)
at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1593)
at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1514)
at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1750)
at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1347)
at java.io.ObjectInputStream.readObject(ObjectInputStream.java:369)
at java.rmi.server.RemoteObjectInvocationHandler.invokeRemoteMethod(RemoteObjectInvocationHandler.java:194)
at java.rmi.server.RemoteObjectInvocationHandler.invoke(RemoteObjectInvocationHandler.java:148)
at com.totvslabs.cloudpass.ApplicationController.syncRacToApp(ApplicationController.groovy:1751)
at grails.plugin.cache.web.filter.PageFragmentCachingFilter.doFilter(PageFragmentCachingFilter.java:195)
at grails.plugin.cache.web.filter.AbstractFilter.doFilter(AbstractFilter.java:63)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
at java.lang.Thread.run(Thread.java:722)
This error per Kung Wang cannot be replicated on a local environment which confirms to the fact that it should be deployment problem. Suggest to do a fresh deployment on qafluigidentity and try the scenario again.
#+END_EXAMPLE
* TODO [#B] How to confirm whether it's a deployment problem
#+BEGIN_EXAMPLE
[1/20/15, 9:11:07 PM] denny: :)
[1/20/15, 9:11:43 PM] Shivang: org.apache.catalina.LifecycleException: Failed to stop component [StandardServer[8005]]
	at org.apache.catalina.util.LifecycleBase.stop(LifecycleBase.java:236)
[1/20/15, 9:15:09 PM] denny: http://stackoverflow.com/questions/8512588/tomcat-lifecycleexception-when-deploying
[1/20/15, 9:16:37 PM] Shivang: so i confirmed
[1/20/15, 9:16:39 PM] Shivang: it's # 1
[1/20/15, 9:16:41 PM] Shivang: not # 2
[1/20/15, 9:16:43 PM] Shivang: deployment looks ok ..
[1/20/15, 9:16:53 PM] denny: hmm, how do you confirm?
[1/20/15, 9:16:57 PM] Shivang: I am updating the ticket now .. thanks for the help as always :)
[1/20/15, 9:17:07 PM] Shivang: i put special catch statements
[1/20/15, 9:17:09 PM] Shivang: that helped
[1/20/15, 9:17:40 PM] denny: Nice. Good to know that.

See you tomorrow, Shivang
#+END_EXAMPLE
* #  --8<-------------------------- separator ------------------------>8--
* TODO [#A] Visualize Ops                                         :IMPORTANT:
* TODO Developers doesn't trust auto depoloyment, we may suspect bugs in there, thus they need manual deployment sometime
* TODO [#A] After upgrade, change bucket not able to be purged    :IMPORTANT:
* TODO [#A] Consuntaning for DevOps
- Can we handle the customers' request? Whether it's handled in a manaable way
- Where to find more customers?
- How to over satisfied the customers
** Key components of DevOps
| Name                       | Summary                            | Key tools                           |
|----------------------------+------------------------------------+-------------------------------------|
| Build                      | Code build; QA cycle               | Jenkins                             |
| Deploy                     | Reliable, rapid deploy             | Puppet/Chef                         |
|----------------------------+------------------------------------+-------------------------------------|
| Test env                   | create and maintain test envs      |                                     |
| Upgrade                    | Fast update; Few downtime          |                                     |
| Monitoring                 | Find problems as quick as possible | Zabbix/Nagios                       |
| disaster recovery          | Backup/Restore                     |                                     |
| Load Balancing             |                                    |                                     |
| High availability          | limit exposure to SPOF             |                                     |
| Performance                |                                    | Tsung; Jmeter                       |
| log management             |                                    | syslog; splunk                      |
| Security                   |                                    | iptables; access control;           |
| capacity planning          | Lower cost in AWS                  |                                     |
| Test simulation            |                                    | Selinum                             |
| Automation by requirements |                                    |                                     |
| Migration                  |                                    |                                     |
|----------------------------+------------------------------------+-------------------------------------|
| Testing                    |                                    | Vargrant; Docker                    |
| Cloud Env                  |                                    | OpenStack; AWS; Digital Ocean       |
| Common services            |                                    | Apache, Tomcat, Mongodb, Neo4j, etc |
| Trouble shooting           | Problem solving                    | Linux skills                        |
| Auto-scaling               |                                    |                                     |
| Risk Control of Envs       |                                    |                                     |
| VM management              |                                    | vargrant; Docker; KVM; VMware       |

- Extensive hands-on large-scale multi-tier SaaS web application experience
- Experience working in a zero-downtime environment
*** Build
http://www.thoughtworks.com/insights/blog/cloud-based-devops-possible-windows
Build is really made up of source control management (SCM), orchestration of compilation, testing and packaging your application for deployment.

For this you should choose tools that support the practice of continuous integration, allow you to manage your builds exactly how you want them, visualize at what stage your build is at and give the team immediate feedback if it is broken.

CI may only include your build tool and basic frameworks like .NET, but won’t need development tools or real external components and applications. Production-like environments will have real external components and systems, but won’t need build and development tools.
** How to build expertise to get more customers
| Name                           | Summary          |
|--------------------------------+------------------|
| Blogging with In-depth sharing |                  |
| Customer recommend to friends  |                  |
| Post certificates              | Chef certificate |
*** Topics: Chef cookbooks
*** Topic: track record
https://www.linkedin.com/jobs2/view/26980280?trk=vsrp_jobs_res_name&trkInfo=VSRPsearchId%3A820397671421378168992%2CVSRPtargetId%3A26980280%2CVSRPcmpt%3Aprimary
*** Topic: Enhanced monitoring
*** Topic: Jenkins for DevOps
https://www.linkedin.com/jobs2/view/39881630?trk=vsrp_jobs_res_name&trkInfo=VSRPsearchId%3A820397671421378168992%2CVSRPtargetId%3A39881630%2CVSRPcmpt%3Aprimary
You will be responsible for creating and maintaining the test environments, developing and implementing processes to automate the releases through continuous integration and manage the overall build and release process.
** Where to find more customers
*** Who can pay with a better price?
Silicon Valley
*** Linkedin search
** What services/values we offer
| Name                                           | Summary         |
|------------------------------------------------+-----------------|
| Setup the framework, then deliver to customers | Initial version |
| Good Documentation                             |                 |
** Good side
- Constantly get payed for support fee and infra upgrade fee
** Potential risks?
- Operate with urgent issues will run into urgent cases!
- How to avoid less value stuff: daily standup meeting
- Who to restart services or push update?
* TODO [#A] What tasks I should avoid to commit in TOTVS, to charge more :IMPORTANT:
* TODO Customer relationship: demo your skills in a better way
* web page: Release Engineer/DevOps at Curate Partners in San Jose, CA, US - Job | LinkedIn
https://www.linkedin.com/jobs2/view/39881630?trk=vsrp_jobs_res_name&trkInfo=VSRPsearchId%3A820397671421378168992%2CVSRPtargetId%3A39881630%2CVSRPcmpt%3Aprimary
** webcontent                     :noexport:
#+begin_example
Location: https://www.linkedin.com/jobs2/view/39881630?trk=vsrp_jobs_res_name&trkInfo=VSRPsearchId:820397671421378168992,VSRPtargetId:39881630,VSRPcmpt:primary
Skip to main content

LinkedIn Home

  * What is LinkedIn?
  * Join Today
  * Sign In

Main content starts below.
[10387dc]

Release Engineer/DevOps

Curate Partners - San Jose, CA, US

Posted 3 hours ago

  * Experience
    Entry level
  * Job function
    Engineering
  * Employment type
    Full-time

  * Industry
    Information Technology and Services
  * Employer job ID
    bullhorn-1802873
  * Job ID
    39881630

Other Details
View full job listing

This is a preview of the Release Engineer/DevOps job at Curate Partners. To view the full job
listing, join LinkedIn - its free!Join LinkedIn - its free!

About this job

Job description

Job Description

Release Engineer/DevOps

Job Description

  looking for enthusiastic and motivated people who want to be right in the middle of not just
cloud computing, but multi-cloud agility.  Release Engineer will work closely with the product
development team creating exciting new products that have the potential to change the dynamics of
the cloud service provider market.

 

Working with the development, QA and DevOps teams, the Release Engineer will lead the development
of a continuous build and release environment for  Cloud Migration SaaS.  You will be responsible
for creating and maintaining the test environments, developing and implementing processes to
automate the releases through continuous integration and manage the overall build and release
process.

 

You are a highly motivated team-player who can easily communicate your ideas, and have the
sensibility to listen to input from a variety of sources, be they creative or technical. You have a
dogged determination to get the job done and won't compromise on the quality of your work.

 

 

Major Responsibilities

  * Create and maintain testing environments (this includes local onsite lab, AWS EC2 management
    and potentially other clouds used for internal testing)
  * Monitor space/memory requirements and ensure environments are ready for regression and other
    testing
  * Automate provisioning and upgrade of environments using Chef
  * Develop strategies and supporting tools to create an efficient automated integration and
    release process (Jenkins, Chef/Puppet)
  * Prepare sources and targets for migration testing
  * Push code to test environment
  * Manage branching (github)

 

Required skills

  * 5+ years Linux/Unix system administration experience
  * 5+ years devops, release engineering and automation experience
  * Experience with source control (Git) and build management tools (Jenkins)
  * Experience with Agile development environments

 

Desired skills (not mandatory)

  * Experience with configuration management tools (Chef/Puppet)
  * Programming/Scripting experience (Python, shell)
  * Experience with public/private cloud technologies

  * Create and maintain testing environments (this includes local onsite lab, AWS EC2 management
    and potentially other clouds used for internal testing)
  * Monitor space/memory requirements and ensure environments are ready for regression and other
    testing
  * Automate provisioning and upgrade of environments using Chef
  * Develop strategies and supporting tools to create an efficient automated integration and
    release process (Jenkins, Chef/Puppet)
  * Prepare sources and targets for migration testing
  * Push code to test environment
  * Manage branching (github)

About this company

Curate Partners
Curate Partners is a specialist boutique IT consulting organization that helps our clients
transform their results by leveraging opportunities within Big Data, Mobility, Cloud and Security.
We have a unique operating model that focuses on innovative recruiting methodologies, in the
hottest technologies, and a desire to work with only the top 20 % of the talent in our respective
segments, "The Purple Squirrels". All while giving back to the communities in which we live.

Curate Partners derives its name from the Latin word "to care" (cura). Translated into the English
noun version, curate means "one who looks after souls". We have a firm belief that our
stakeholders--employees, candidates, clients and communities (charities) are treated as equals and
partners. People are the core of our business. Not numbers. Not spreadsheets. Not profits.

Curate Partners.
Real. Talented. People
www.curatepartners.com

Similar jobs

  * Macy's
    Release Engineer (macys.com)
    San Francisco, CA
    Posted 20 days ago
  * Guardian Analytics
    Build/Release Engineer
    San Francisco Bay Area
    Posted 6 days ago
  * Wipro
    Build and Release Engineer
    San Francisco…
    Posted 18 hours ago
  * ClearSlide, Inc.
    Build & Release Engineer
    San Francisco Bay Area
    Posted 10 days ago
  * Bill.com
    Senior Build and Release Engineer
    San Francisco Bay Area -…
    Posted 10 days ago
  * CRP- Realogy Operations LLC
    Development Operations/Release Engineer
    Emeryville, US-CA
    Posted 7 days ago
  * Nitro, Inc.
    Senior Build and Release Engineer
    San Francisco
    Posted 7 days ago
  * salesforce.com
    RelateIQ - DevOps Build and Release Engineer
    US - California - Palo…
    Posted 10 days ago
  * IGT
    Senior Release Engineer
    San Francisco, CA
    Posted 16 days ago
  * Okta, Inc.
    Senior Build & Release Engineer
    San Francisco, CA
    Posted 15 days ago

View all jobs like this
View full job listing

This is a preview of the Release Engineer/DevOps job at Curate Partners. To view the full job
listing, join LinkedIn - its free!Join LinkedIn - its free!

People also searched

  * Release Engineer Jobs
  * Jobs at Curate Partners
  * Information Technology and Services Jobs

People also viewed

  * Facebook
    Release Engineer
    San Francisco Bay Area
    Posted 11 days ago
  * Lookout
    Build and Release Engineer
    San Francisco Bay Area
    Posted 17 days ago
  * HP Autonomy
    Build and Release Engineer
    San Francisco Bay Area
    Posted 7 days ago
  * Adara Networks
    Software Build/Release Engineer
    San Francisco Bay Area
    Posted 9 days ago
  * Varian Medical Systems
    Build and Release Engineer
    San Francisco Bay Area
    Posted 8 days ago
  * Seagate Technology
    Release Engineer
    San Francisco Bay Area
    Posted 4 days ago
  * Apple
    Lead/Senior Build and Release…
    San Francisco Bay Area
    Posted 8 days ago
  * ToyTalk, Inc.
    Build and Release Engineer
    San Francisco Bay Area
    Posted 8 days ago
  * NVIDIA
    SR. SW BUILD AND RELEASE…
    San Francisco Bay Area
    Posted 11 days ago
  * Audience, Inc.
    Software Release Engineer
    San Francisco Bay Area
    Posted 7 days ago

  *
  * About
      + Press
      + Blog
      + Developers
  * Careers
  * Advertising
  * Talent Solutions
  * Sales Solutions
  * Small Business
  * Mobile
  * Language
      + Bahasa Indonesia
      + Bahasa Malaysia
      + Čeština
      + Dansk
      + Deutsch
      + English
      + Español
      + 正體中文
      + Français
      + 한국어
      + Italiano
      + 简体中文
      + Nederlands
      + 日本語
      + Norsk
      + Polski
      + Português
      + Română
      + Русский
      + Svenska
      + Tagalog
      + ภาษาไทย
      + Türkçe
  * SlideShare

  * LinkedIn Updates
  * LinkedIn Influencers
  * LinkedIn Jobs
  * Jobs Directory
  * Pulse Directory
  * Company Directory
  * Groups Directory
  * Universities Directory
  * Title Directory

LinkedIn Corporation © 2015

  * User Agreement
  * Privacy Policy
  * Community Guidelines
  * Cookie Policy
  * Copyright Policy
  * Unsubscribe

# * *

#+end_example
* #  --8<-------------------------- separator ------------------------>8--
* TODO [#B] proxy server to http server
* TODO Talk with Jeff
- 市场定位: well funding startup/中小企业
- 客户产品的形态：cloud solution
- 是否能怀客户一起 sustainable: 客户成长过后，就不再需要你了？
- 如何把握平衡点：对客户不能太有价值，否则客户自己做；不能太没有价值，否则没有必要找你
- 如何找到客户
- 中长期与家庭figure out一个plan
* TODO DevOps operation
ssh ubuntu@chef.fluigidentity.com -p 24075
** Amazon EC2
- Sao Paulo: spchef, sprepo
- N Canilifarnia: 11 ad machines for Suresh
** TODO Bill: SmartSync server
** TODO Try AD server in wiki
https://totvslab.atlassian.net/wiki/display/TECH/Fluig+Testbed+Env
[10/15/14, 17:03:36] kungchaowang: TOTVSLABS01\Administrator
[10/15/14, 17:03:40] kungchaowang: Foobar1!
** TODO Kung: Upgrade existing env to be managed by chef
** DONE ssh to chef.fluigidentity.com
   CLOSED: [2014-10-15 Wed 17:26]
[10/15/14, 16:59:52] denny: ➜  ~  ssh ubuntu@chef.fluigidentity.com date
ssh: connect to host chef.fluigidentity.com port 22: Connection refused
[10/15/14, 17:00:07] kungchaowang: Host fiprodchef¬
221 ▸ HostName ec2-54-221-238-95.compute-1.amazonaws.com¬
222 ▸ User ubuntu¬
223 ▸ Port 24075¬
224 ▸ ServerAliveInterval 30¬
225 ▸ ServerAliveCountMax 120¬
226 ▸ IdentityFile /Users/kungwang/.ssh/CloudpassServers.pem¬
** # --8<-------------------------- separator ------------------------>8--
** TODO Things: AD on amazon; On-premise deployment;
** TODO Kung: How we deploy the system
** TODO Kung: Upgrade on-premise deployment
** # --8<-------------------------- separator ------------------------>8--
** TODO Kung: mail server
** TODO Kung: HA
** TODO Kung: SSL certificates
** TODO Kung: replicate the env, to see what's the difference
* TODO JIRA: Migrate env from one machine to another
* devops podcast
http://foodfightshow.org
* #  --8<-------------------------- separator ------------------------>8--
* TODO Where to track the password of readonly user in critical env
* TODO [#A] prepared for DevOps Training: YouTube Video
* TODO [#A] Chef market cookbook problem: how to make sure latest chef upgrade work without regression issues for my requirements
* TODO Need consist support for running low disk, due to large logfile
https://totvslab.atlassian.net/browse/CLOUDPASS-6792
Atlassian Cloud
* TODO [#A] How to track the audit log
* TODO mail: Fwd: FW: Need to get DevOps candidate for identity project as soon as possible.           :noexport:
[[gnus:myself#CAB_ojTtOzuDh-yme-EL_B12KdGQz9hpPewfHsOKTFJnm3Wub7A@mail.gmail.com][Email from Denny Zhang (Sun, 25 Jan 2015 10:30:12 -0500): Fwd: FW: Need to get DevOps ca]]
#+begin_example
From: Denny Zhang <filebat.mark@gmail.com>
Subject: Fwd: FW: Need to get DevOps candidate for identity project as soon as possible.
To: Yaodong Hu <yaodonghu@gmail.com>
Cc: Jay Zheng <jayzheng07@gmail.com>
Date: Sun, 25 Jan 2015 09:30:12 -0600

Hi Don

Would you please take a look at below email?
It should be an opportunity for us to win a better bargain or make more contribution to TOTVS Labs.

Note: I'm not very sure whether Vicente's losing power or influence in their parent company.

Regards,
Denny
---------- Forwarded message ----------
From: Denny Zhang <denny.zhang@totvs.com>
Date: Sun, Jan 25, 2015 at 10:21 AM
Subject: FW: Need to get DevOps candidate for identity project as soon as possible.
To: "filebat.mark@gmail.com" <filebat.mark@gmail.com>

---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Sunday, January 25, 2015 9:21 AM
To: Vicente Goetten; Kung Wang
Subject: Need to get DevOps candidate for identity project as soon as possible.

Hi Vicente & Kung

Looks like even after we have finished transferred identity project to BR team, we may not be able
to find capable DevOps candidate in BR. 
Or the guy may not be ready to fully support my role in identity.

So in that case, I will need to support both Identity project and MDM project then. Right?

As far as I know, I'm mainly involved in identity project in below:
- [Operate] 7x24 day-to-day operate and issue escalation for all critical identity envs.
- [Upgrade/Release] Pushing latest release to all of them
- [Build/QA cycle] On-demand trouble shooting for QA cycles, and chef update for new release.

Please note:
- In the beginning of a new project, DevOps need much more effort than the later phase.
  We will need time to do research and learning, setup the infra layer according to the new
requirement.
  I understand I may have to support identity/MDM simultaneously.
  Just remind you guys, I may make slower progress unfortunately, due to resource issue.

- Need people to review my documentation for the transmission of DevOps effort in Identity
  I will surely try my best to improve the doc to enforce a smoothly transmission. It's better we
can review the doc, to better guarantee this.

Regards,
Denny

--
Thanks,
Denny

#+end_example
* TODO mail: Re: Need to get DevOps candidate for identity project as soon as possible.           :noexport:
[[gnus:p0-totvs#C7170A52-DBD5-4D4B-931B-61C38B9519C6@totvs.com][Email from Vicente Goetten (Mon, 26 Jan 2015 00:17:24 -0600): Re: Need to get DevOps candida]]
#+begin_example
From: Vicente Goetten <goetten@totvs.com>
Subject: Re: Need to get DevOps candidate for identity project as soon as possible.
To: Denny Zhang <denny.zhang@totvs.com>, Kung Wang <kung.wang@totvs.com>
Date: Mon, 26 Jan 2015 00:17:24 -0600

Denny

We understand and we have been pushing Brazil to hire a DevOps to help us with Fluig Identity. We
will keep you posted, ok?

Thanks

Vicente Goetten
+1 650 933-4902   -   goetten@totvs.com

From: Denny Zhang <denny.zhang@totvs.com>
Date: Sunday, January 25, 2015 at 7:21 AM
To: Vicente Goetten <goetten@totvs.com>, Kung Wang <kung.wang@totvs.com>
Subject: Need to get DevOps candidate for identity project as soon as possible.

Hi Vicente & Kung

Looks like even after we have finished transferring identity project to BR team, we may not be able
to find capable DevOps candidate in BR. Or the guy would not be ready to fully support my role in
identity.

So in that case, I will need to support both Identity project and MDM project then. Right?

As far as I know, I'm mainly involved in identity project in below:
- [Operate] 7x24 day-to-day operate and issue escalation for all critical identity envs.
- [Upgrade/Release] Pushing latest release to all of them
- [Build/QA cycle] On-demand trouble shooting for QA cycles, and chef update for new release.

Please note:
- In the beginning of a new project, DevOps need much more effort than the later phase.
  We will need time to do research and learning, setup the infra layer according to the new
requirement.
  I understand I may have to support identity/MDM simultaneously.
  Just remind you guys, I may make slower progress unfortunately, due to resource issue.

- Need people to review my documentation for the transmission of DevOps effort in Identity
  I will surely try my best to improve the doc to enforce a smoothly transmission. It's better we
can review the doc, to better guarantee this.

Regards,
Denny

#+end_example
* TODO mail: FW: Issue with CustomerFI           :noexport:
[[gnus:mail.misc#EF9859611DA81140B2B29B02EC8AD6EAF8F0F6@helios.mex01.local][Email from Denny Zhang (Mon, 26 Jan 2015 17:04:08 +0000): FW: Issue with CustomerFI]]
#+begin_example
From: Denny Zhang <denny.zhang@totvs.com>
Subject: FW: Issue with CustomerFI
To: "filebat.mark@gmail.com" <filebat.mark@gmail.com>
Date: Mon, 26 Jan 2015 11:04:08 -0600

---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Thursday, November 27, 2014 12:47 AM
To: John Kaplan; Suresh Sathyanarayan
Cc: Kung Wang
Subject: RE: Issue with CustomerFI

Hi John/Suresh

Please note, after each upgrade of any prod envs, I will need your help to verify the system by all
means.

It's better we can have a powerful smoke test tool, thus we can lower the effort of manual test.
Or document test procedures, so that other people can replicate the steps.

Regards,
Denny
---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Thursday, November 27, 2014 12:43 AM
To: Vicente Goetten; John Kaplan; Kung Wang; Fellipe Silva
Cc: Shivang Shah; Suresh Sathyanarayan; Denny Zhang
Subject: RE: Issue with CustomerFI

Hi all

It's now very clear: customerfi, psfluigidentity, qa1b should be treated like prod env as well.

I've discussed with Kung, John and Suresh today.
Here is what we will do for any upgrade of any prod envs.

Feel free to comment.

I will also search internet to see how we can improve.
https://totvslab.atlassian.net/wiki/display/TECH/Upgrade+Procedure+for+Prod+Env

[cid]

Regards,
Denny
---------------------------------------------------------------------------------------------------
From: Vicente Goetten
Sent: Wednesday, November 26, 2014 7:17 AM
To: John Kaplan; Denny Zhang; Kung Wang; Fellipe Silva
Subject: Issue with CustomerFI

Team,

Once again we had issues with CustomerFI today. We have advised our entire company to use this
environment for demos and training. Yesterday the team who was going to the customer run all the
testings and today it wasn’t working.

I’m running out of creative excuses to them. We must be more professional on the way we work,
honestly.

What are the actions we are taking to prevent this to happen again? I want to see a plan of action
by the end of the day today.

Thanks

Vicente Goetten
+1 650 933-4902   -   goetten@totvs.com

#+end_example
* TODO mail: FW: Can't ping or ssh any identity VM           :noexport:
[[gnus:mail.misc#EF9859611DA81140B2B29B02EC8AD6EAF8F0B5@helios.mex01.local][Email from Denny Zhang (Mon, 26 Jan 2015 17:01:34 +0000): FW: Can't ping or ssh any iden]]
#+begin_example
From: Denny Zhang <denny.zhang@totvs.com>
Subject: FW: Can't ping or ssh any identity VM
To: "filebat.mark@gmail.com" <filebat.mark@gmail.com>
Date: Mon, 26 Jan 2015 11:01:34 -0600

---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Thursday, January 15, 2015 2:43 PM
To: Paulo Roberto Nobuo Maekawa; Alexandre Picagli Gallo Lavrador; Lucas Ciriaco dos Santos;
Eduardo Elias El Assais
Cc: Kung Wang; Vicente Goetten
Subject: RE: Can't ping or ssh any identity VM

Thanks, Paulo

It's back to normal now.

Regards,
Denny
---------------------------------------------------------------------------------------------------
From: Paulo Roberto Nobuo Maekawa
Sent: Thursday, January 15, 2015 2:42 PM
To: Denny Zhang; Alexandre Picagli Gallo Lavrador; Lucas Ciriaco dos Santos; Eduardo Elias El
Assais
Cc: Kung Wang; Vicente Goetten
Subject: RES: Can't ping or ssh any identity VM

Hi Denny

There was a network issue at NIMBVS

The Network team are working in it

Can you test the comunication now

cid:image001.png@01CF160E.33FDFBB0 Paulo Roberto Nobuo Maekawa
                                   IDSI – Infraestrutura, Datacenter e Segurança da
                                   Informação

                                   paulo.maekawa@totvs.com.br

                                   Cel +55 11 99977 3614   /   +55 11 99197 9869

De: Denny Zhang
Enviada em: quinta-feira, 15 de janeiro de 2015 18:06
Para: Paulo Roberto Nobuo Maekawa; Alexandre Picagli Gallo Lavrador
Cc: Kung Wang; Vicente Goetten
Assunto: Can't ping or ssh any identity VM
Prioridade: Alta

Hi there

Anyone help to check? Our identity system are not reachable now.

Regards

Denny

#+end_example
* TODO mail: FW: Wiki for common questions about Env support           :noexport:
[[gnus:mail.misc#EF9859611DA81140B2B29B02EC8AD6EAF8F05E@helios.mex01.local][Email from Denny Zhang (Mon, 26 Jan 2015 16:59:08 +0000): FW: Wiki for common questions ]]
#+begin_example
From: Denny Zhang <denny.zhang@totvs.com>
Subject: FW: Wiki for common questions about Env support
To: "filebat.mark@gmail.com" <filebat.mark@gmail.com>
Date: Mon, 26 Jan 2015 10:59:08 -0600

---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Friday, January 23, 2015 10:39 AM
To: Fellipe da Silva - TexoIT; Marcel Roberto Dias; Marcel Horner; André Gomes de Riba; Camilla
Damiani; Reinaldo Oliveira Machado Junior
Cc: totvs.labs; Kung Wang; Vicente Goetten
Subject: Wiki for common questions about Env support

Hi guys

While doing review for the devops work in the past 6 months, I found people constantly fetch DevOps
for multiple questions/problems. Those questions are actually general TOI-style questions

Thus I came up with this wiki.
https://totvslab.atlassian.net/wiki/display/TECH/Fluig+Env+List

[cid]

@Marcel/@Fellipe, for the questions you asked early this morning, guess you can find answers there
now.
Feel free to comment or advise, if it's not good enough.

Regards,
Denny

#+end_example
* TODO mail: FW: Better integration and collaboration with Brazil           :noexport:
[[gnus:mail.misc#EF9859611DA81140B2B29B02EC8AD6EAF8EE1C@helios.mex01.local][Email from Denny Zhang (Mon, 26 Jan 2015 15:59:06 +0000): FW: Better integration and col]]
#+begin_example
From: Denny Zhang <denny.zhang@totvs.com>
Subject: FW: Better integration and collaboration with Brazil
To: "filebat.mark@gmail.com" <filebat.mark@gmail.com>
Date: Mon, 26 Jan 2015 09:59:06 -0600
X-Priority: 1

---------------------------------------------------------------------------------------------------
From: Vicente Goetten
Sent: Wednesday, January 21, 2015 5:28 PM
To: totvs.labs
Cc: Weber George Canova; Marcelo Eduardo Sant'Anna Cosentino
Subject: Better integration and collaboration with Brazil

Team,

One of the things that we have always been discussing is how to have a better and deeper
integration with our parent company, how can we (TOTVS Labs) help TOTVS to continue to innovate,
adopt open standards and new technologies as well.

In order to achieve this goal TOTVS has created a new division called Architecture Group, which is
lead by Weber Canova (cc’d here). The R&D part of TOTVS Labs is now part of this group as well. The
goal is to have an elite squad of engineers, ux designers and QA’s working together in projects
that will help TOTVS in the long term. The Master Data Management project is one of them, along
with the LOCL (Beacons) and many others that we will be exploring together.

The Business development side of TOTVS Labs will continue to work with Marcelo Cosentino, who leads
International Markets and M&A.

Weber,
Welcome to TOTVS Labs! We are excited to make a greater impact at TOTVS future.

Marcelo,
We look forward to helping TOTVS to enter in the US market.

PS: I’ll give you guys details tomorrow during our standup.

Regards

Vicente Goetten
+1 650 933-4902   -   goetten@totvs.com

#+end_example
* TODO mail: Setup monthly technologies exchange meeting           :noexport:
[[gnus:mail.misc#EF9859611DA81140B2B29B02EC8AD6EAF8EDC9@helios.mex01.local][Email from Denny Zhang (Mon, 26 Jan 2015 15:58:09 +0000): Setup monthly technologies exc]]
#+begin_example
From: Denny Zhang <denny.zhang@totvs.com>
Subject: Setup monthly technologies exchange meeting
To: "filebat.mark@gmail.com" <filebat.mark@gmail.com>
Date: Mon, 26 Jan 2015 09:58:09 -0600

________________________________________
From: Denny Zhang
Sent: Friday, January 23, 2015 5:22 PM
To: Kung Wang; totvs.labs
Subject: RE: Dev-Op team monthly reviews and new technologies exchange

Thanks, Kung.

Yes, that's is productive and practical meeting.
Looking forward to next month's sharing and discussion.

Regards,
Denny
________________________________________
From: Kung Wang
Sent: Friday, January 23, 2015 4:20 PM
To: totvs.labs
Subject: Dev-Op team monthly reviews and new technologies exchange

1. What things in the chef open source community, that we found good
and should apply? what they do that we don’t do and what we think it’s
good to have?
    a. better document for support platforms
    b. better document for dependencies
    c. modulize better and more configurable
    d. use test kitchen and have unit tests
    e. use public jenkins to compile to do continuous integration for the code contributed in open source

2. What things we see in the open source community, that we think we do better?
    a. We made our cookbook more atomic than others, and has less
dependencies and do better job in core service it means to serve

3. new technologies we see that will help us to do deployment down the road
    a. upgrade to Chef 12, as it is now only one enterprise edition,
easy to switch to non-license model with more stable codebase.
    b. use Chef-provisioning to solve cross-machine service dependencies. It's new feature just came out in Nov 2014.

#+end_example
* TODO mail: DevOps: Don't be afraid to shout aloud for bad news.           :noexport:
[[gnus:mail.misc#EF9859611DA81140B2B29B02EC8AD6EAF8EDA5@helios.mex01.local][Email from Denny Zhang (Mon, 26 Jan 2015 15:56:32 +0000): DevOps: Don't be afraid to sho]]
#+begin_example
From: Denny Zhang <denny.zhang@totvs.com>
Subject: DevOps: Don't be afraid to shout aloud for bad news.
To: "filebat.mark@gmail.com" <filebat.mark@gmail.com>
Date: Mon, 26 Jan 2015 09:56:32 -0600

---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Monday, January 26, 2015 9:21 AM
To: Vicente Goetten; Kung Wang
Subject: RE: Need to get DevOps candidate for identity project as soon as possible.

Absolutely!

One big lesson I've learned from supporting Identity system:
- Identity potential risks, before they shall happen
- Don't be afraid to shout aloud, if team is not paying enough attention.

To refresh our memory, below are some real examples:
- Backup process is not setup in the very beginning. Backup is not valid or complete, when we badly
need that.
- So many times, machine run into low disk. We know that may cause problems, but we didn't put it
as priority#1.
- Huge log files are generated in many different services, etc.

Hope you don't mind, I will be the bad guy who keep telling "bad news" from time to time.

Surely, I will try my best to not be that noisy or work with wrong priority.

Regards,
Denny
---------------------------------------------------------------------------------------------------
From: Vicente Goetten
Sent: Monday, January 26, 2015 12:17 AM
To: Denny Zhang; Kung Wang
Subject: Re: Need to get DevOps candidate for identity project as soon as possible.

Denny

We understand and we have been pushing Brazil to hire a DevOps to help us with Fluig Identity. We
will keep you posted, ok?

Thanks

Vicente Goetten
+1 650 933-4902   -   goetten@totvs.com

From: Denny Zhang <denny.zhang@totvs.com>
Date: Sunday, January 25, 2015 at 7:21 AM
To: Vicente Goetten <goetten@totvs.com>, Kung Wang <kung.wang@totvs.com>
Subject: Need to get DevOps candidate for identity project as soon as possible.

Hi Vicente & Kung

Looks like even after we have finished transferring identity project to BR team, we may not be able
to find capable DevOps candidate in BR. Or the guy would not be ready to fully support my role in
identity.

So in that case, I will need to support both Identity project and MDM project then. Right?

As far as I know, I'm mainly involved in identity project in below:
- [Operate] 7x24 day-to-day operate and issue escalation for all critical identity envs.
- [Upgrade/Release] Pushing latest release to all of them
- [Build/QA cycle] On-demand trouble shooting for QA cycles, and chef update for new release.

Please note:
- In the beginning of a new project, DevOps need much more effort than the later phase.
  We will need time to do research and learning, setup the infra layer according to the new
requirement.
  I understand I may have to support identity/MDM simultaneously.
  Just remind you guys, I may make slower progress unfortunately, due to resource issue.

- Need people to review my documentation for the transmission of DevOps effort in Identity
  I will surely try my best to improve the doc to enforce a smoothly transmission. It's better we
can review the doc, to better guarantee this.

Regards,
Denny

#+end_example
* TODO mail: FW: Network connectivity issue of identity system           :noexport:
[[gnus:mail.misc#EF9859611DA81140B2B29B02EC8AD6EAF8EB2C@helios.mex01.local][Email from Denny Zhang (Mon, 26 Jan 2015 03:32:57 +0000): FW: Network connectivity issue]]
#+begin_example
From: Denny Zhang <denny.zhang@totvs.com>
Subject: FW: Network connectivity issue of identity system
To: "filebat.mark@gmail.com" <filebat.mark@gmail.com>
Date: Sun, 25 Jan 2015 21:32:57 -0600

---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Sunday, January 25, 2015 9:30 PM
To: sp.datacenter.redes
Cc: devopslabs; Denny Zhang; Vicente Goetten
Subject: RE: Network connectivity issue of identity system

Hi there

That machine can't access totvslabs.customerfi.com:443 neither.

Regards,
Denny
---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Sunday, January 25, 2015 8:53 AM
To: sp.datacenter.redes
Cc: devopslabs; Denny Zhang
Subject: Network connectivity issue of identity system

Hi there

One of our nagios check(check_PS_LOGIN) keeps failing, which is tracked in ticket TECH-77

While debugging this, I found the root cause is:
- machine (172.20.16.13) fail to connect 443 port of totvslabs.psfluigidentity.com.

Previously, it's able to connect days ago, before our network maintenance.
Would you please help to check?

,-----------
| root@fluig-id-cdn-01:/etc/nagios/nrpe.d# ifconfig | grep 'inet addr'
| ifconfig | grep 'inet addr'
|           inet addr:172.20.16.13  Bcast:172.20.16.127  Mask:255.255.255.128
|           inet addr:127.0.0.1  Mask:255.0.0.0
|
| root@fluig-id-cdn-01:/etc/nagios/nrpe.d# telnet totvslabs.psfluigidentity.com 443
| Trying 187.94.63.123...
`-----------

Regards,
Denny

#+end_example
* #  --8<-------------------------- separator ------------------------>8--
* [#A] Make good relationship with key contributors
#+BEGIN_EXAMPLE
[1/26/15, 12:35:25 PM] Fellipe Augusto da Silva: oh I see, didn't know about that
[1/26/15, 12:35:30 PM] Fellipe Augusto da Silva: will you continue with Labs in the new project?
[1/26/15, 12:35:35 PM] denny: Yes, I will
[1/26/15, 12:35:51 PM] denny: Everyone about identity will be transferred, including my part.
[1/26/15, 12:35:52 PM] Fellipe Augusto da Silva: cool, we'll be working together again then, probably :D
[1/26/15, 12:35:59 PM] denny: That’s great.
[1/26/15, 1:16:51 PM] denny: Fellipe, please do me a favor.

If you’ve any suggestions about doc, please do let me know.
#+END_EXAMPLE
* TODO mail: Fwd: Digital ocean machines created for testing by Shivang and Mitu           :noexport:
[[gnus:mail.misc#A0660BCB-960E-4378-B64B-08F6327F1FB2@totvsinfra.mail.onmicrosoft.com][Email from Denny Zhang (Mon, 26 Jan 2015 20:43:01 +0000): Fwd: Digital ocean machines cr]]
#+begin_example
From: Denny Zhang <denny.zhang@totvs.com>
Subject: Fwd: Digital ocean machines created for testing by Shivang and Mitu
To: Denny Zhang <filebat.mark@gmail.com>
Date: Mon, 26 Jan 2015 14:43:01 -0600

Sent from my iPhone

Begin forwarded message:

    From: Kung Wang <kung.wang@totvs.com>
    Date: January 26, 2015 at 2:19:34 PM CST
    To: Shivang Shah <shivang.shah@totvs.com>, Mitu <mitu@totvs.com>
    Cc: Denny Zhang <denny.zhang@totvs.com>, Vicente Goetten <goetten@totvs.com>
    Subject: Digital ocean machines created for testing by Shivang and Mitu

    Mitu and Shivang,

    Here are two machines you requested. Please you are not using them, please let Denny to
    deprovision them.

    198.199.105.82 Active 8GB Ram 80GB SSD Disk San Francisco 1 Ubuntu 12.04.5 x64
    104.236.164.144 Active 8GB Ram 80GB SSD Disk San Francisco 1 Ubuntu 12.04.5 x64

    ssh -i ~/.ssh/id_rsa.pub root@198.199.105.82
    ssh -i ~/.ssh/id_rsa.pub root@104.236.164.144

    —Kung

#+end_example
* Set up Boundaries: Don't reply non-critical questions/messages off the working hours.
* [#A] pattern/sentence of communication                          :IMPORTANT:
** pattern of rejection
- Unfortunately, I have a lot on my plate as well.
- Instead of turning down a colleague's request for help, you can offer to take a specific piece of the task, and then request someone else take the rest.
- To boss: I know getting this project done and implementing the new software are your priorities, so which of these two tasks do you want me to tackle to help you the most?
- Instead of offering up a "No" right away, go with a "Yes, and."
- I wish I could, but as a rule of DevOps, ...
- Change the subject. "You know, your comment about the boss reminds me of something. There's an office party coming up, right? Are you bringing anyone?"
** pattern of giving negative feedback
- If you want to give negative feedback to a co-worker, you can say something like, "I really appreciate how hard you've been working on the new project. However, I think the project can be even better if you let Mary help you out a bit more."
** Consider the other person's viewpoint and acknowledge it.
http://www.wikihow.com/Be-Tactful
* [#A] Lesson: Add Major tasks/story to each sprint: get credit for the dev side of devops :Important:
* #  --8<-------------------------- separator ------------------------>8--
* TODO Communication: Why I miss the daily meeting
#+BEGIN_EXAMPLE
[1/26/15, 12:24:14 PM] denny: I’m not sure how large the scope you mean.

I will perform upgrade in this Thursday, while Lucas is watching.
[1/26/15, 12:24:32 PM] John Kaplan: i see. ok
[1/26/15, 2:11:23 PM] denny: John, please do me a favor about daily standup.
[1/26/15, 2:12:09 PM] denny: It happened multiple times that I’m online, but still miss the daily standup.

When I didn’t show up, would you please drop a Skype message to me?
[1/26/15, 2:12:13 PM] denny: Thanks
#+END_EXAMPLE
* TODO Communication: claim for resource, instead of over commit
#+BEGIN_EXAMPLE
[1/26/15, 12:40:43 PM] kungchaowang: ok, let’s start with little less scale of production, less machines to start with
[1/26/15, 12:40:57 PM] Vicente Goetten: sounds good
[1/26/15, 12:41:02 PM] Vicente Goetten: it's important to monitor this env as well
[1/26/15, 12:41:02 PM] Vicente Goetten: ok?
[1/26/15, 12:41:54 PM] denny: Sure, Vicente.

Could we use the same nagios system like prod env, or it’s better to be a separate one?
[1/26/15, 12:41:59 PM] Vicente Goetten: yes
[1/26/15, 12:42:04 PM] Vicente Goetten: i'll be back in a few minutes
#+END_EXAMPLE
* TODO Communication: How I handle this sudden request
#+BEGIN_EXAMPLE
[1/28/15, 4:00:18 PM] kungchaowang: Denny, marcel has push his code
[1/28/15, 4:00:33 PM] kungchaowang: Please build and test
[1/28/15, 4:01:09 PM] denny: Nice. Have you tried that?
[1/28/15, 4:01:35 PM] kungchaowang: No, I am outside doing baby serting
[1/28/15, 4:01:42 PM] kungchaowang: Setting
[1/28/15, 4:01:46 PM] denny: Oh, I see.
[1/28/15, 4:02:08 PM] denny: Let me check that.
[1/28/15, 4:02:16 PM] denny: denny created a group conversation
[1/28/15, 4:02:16 PM] kungchaowang: 1.4.4
#+END_EXAMPLE
* #  --8<-------------------------- separator ------------------------>8--
* Argument: routine Ops and urgent issues support at nights and weekends
* Argument: already show the strong passion, skill and responsibility
* Argument: flexiblity to the team: give constant feedback for devopers; active help to QA and Doc
* Argument: paraell support for MDM and identity
* #  --8<-------------------------- separator ------------------------>8--
* Argument: For skype message before 8AM or after 8PM, only reply urgent messages
* Argument: I don't want to be the only one, who can perform the procedure
- On-premise deployment or upgrade
- Restart service on prod env
- Upgrade customerfi/psfluigidentity
* Argument: Can't book my time fully, because need to prepared for urgency and improvement of routine process
* #  --8<-------------------------- separator ------------------------>8--
* Argument: For daily standup meeting, switch from mandatory to on-demand
- No need to be the driven lead
- Indicate people to work with documentation
#+BEGIN_EXAMPLE
[1/26/15, 12:32:07 PM] kungchaowang: np Denny
[1/26/15, 12:32:32 PM] kungchaowang: we just like to talk to you and hear your voice.
[1/26/15, 12:32:44 PM] denny: =====================
About daily standup, I propose to change my visibility from mandantory to optional.
[1/26/15, 12:32:46 PM] denny: LOL
[1/26/15, 12:33:10 PM] denny: Let’s talk about that, when we’ve time. Like this Thursay’s call.
#+END_EXAMPLE
* TODO Argument: 分配时间去改进每天的例行工作
http://www.infoq.com/cn/articles/11devops
* TODO Argument with TOTVS
- Only support 2 envs
- Argument for env support at nights and weekends
* TODO Argument: Ask developers to maintain internal test env, but follow the same develop process
测试环境的新版本发布可否由开发人员自己来做
http://www.infoq.com/cn/articles/effective-ops-part-01
线上系统程序代码可否自动打包、持续部署？ 测试环境的新版本发布可否由开发人员自己来做，甚至自己来做测试？ 这些无疑可以很大提升运维和开发效率。
* TODO issue only triggered by certain customer request or behavior, not easily to be found in QA cycle
#+BEGIN_EXAMPLE
[2/4/15, 7:48:26 AM] Fellipe Augusto da Silva: we reverted to the older version and still there are some error in there. The strange thing is that its only happening on SP01, other domains that have the same SmrtSync version are working just fine
[2/4/15, 7:49:30 AM] Lucas Schiochet: The other domains are using the same SS ? (like jv01)
[2/4/15, 7:49:52 AM] Fellipe Augusto da Silva: JV01 I don't knw, but Henrique told me that there are other domains with the same SS version, and no problems at all
[2/4/15, 7:49:57 AM] Fellipe Augusto da Silva: only on SP01
[2/4/15, 7:51:54 AM] Fellipe Augusto da Silva: Henrique is going to migrate EUA01 to the latest version and make a test to see if it goes through
[2/4/15, 7:52:01 AM] Fellipe Augusto da Silva: if it does, then there is something wrong with the SP01 domain
[2/4/15, 7:55:50 AM] Vicente Goetten: Fellipe
Do you see anything in the logs?
[2/4/15, 7:55:57 AM] Fellipe Augusto da Silva: some errors, yeah
[2/4/15, 7:56:01 AM] Fellipe Augusto da Silva: Horner is checking what's going on
[2/4/15, 7:56:03 AM] Vicente Goetten: What about the other customers?
[2/4/15, 7:56:09 AM] Vicente Goetten: Onco
[2/4/15, 7:56:14 AM] Fellipe Augusto da Silva: no complaints from them, only at SP01
[2/4/15, 7:56:23 AM] Fellipe Augusto da Silva: Tiago found an error in the latest version, he's fixing it now
[2/4/15, 7:56:42 AM] Vicente Goetten: Do you know what it is?
[2/4/15, 7:57:08 AM] Fellipe Augusto da Silva: I think that there was a logic in the smartsync to authenticate several users at the same time, but Eric asked to remove it
[2/4/15, 7:57:35 AM] Fellipe Augusto da Silva: what I think it happened is that the logic was removed from the SmartSync, but the backend was still sending the requests at the same time
[2/4/15, 7:57:44 AM] Fellipe Augusto da Silva: so SmartSync was not handling it, and returning an error
[2/4/15, 7:57:47 AM] Vicente Goetten: I see
[2/4/15, 7:57:48 AM] Fellipe Augusto da Silva: or something like that
[2/4/15, 7:57:56 AM] Vicente Goetten: My goodness
[2/4/15, 7:58:11 AM] Vicente Goetten: Denny
As soon as they fix it
[2/4/15, 7:58:18 AM] Vicente Goetten: We need to do a push
[2/4/15, 7:58:25 AM] Fellipe Augusto da Silva: he's fixing the logic in the SmartSync
[2/4/15, 7:58:28 AM] Fellipe Augusto da Silva: not sure if we will need a push
[2/4/15, 7:58:36 AM] Fellipe Augusto da Silva: don't know how the SmartSync is released though
[2/4/15, 7:58:50 AM] Vicente Goetten: Denny ca help
[2/4/15, 7:58:53 AM] Fellipe Augusto da Silva: ok
[2/4/15, 7:59:20 AM] Vicente Goetten: What about the server side? Don't we need to change to not send multiple users?
[2/4/15, 7:59:27 AM] Lucas Schiochet: Tiago already fixed and he is testing now
[2/4/15, 8:00:32 AM] Fellipe Augusto da Silva: no need Vicente, cause the fix on SmartSync would solve the issue
[2/4/15, 8:00:39 AM] Vicente Goetten: I see
[2/4/15, 8:00:40 AM] Fellipe Augusto da Silva: I'm not sure why Eric asked to remove it though
[2/4/15, 8:01:34 AM] Vicente Goetten: There might be a reason
[2/4/15, 8:01:50 AM] Vicente Goetten: And I am concerned that we are adding it again
[2/4/15, 8:02:18 AM] Vicente Goetten: We will have to monitor to see if the issue goes away
[2/4/15, 8:02:22 AM] Fellipe Augusto da Silva: ok
[2/4/15, 8:04:46 AM] denny: :)
[2/4/15, 8:06:31 AM] Vicente Goetten: Login with AD works on EUA01
[2/4/15, 8:07:58 AM] Fellipe Augusto da Silva: Henrique just updated to the latest version
[2/4/15, 8:08:18 AM] Fellipe Augusto da Silva: so it looks like an isolated case on SP01
[2/4/15, 8:10:28 AM] Vicente Goetten: Are already testing the new Ss on prod?
[2/4/15, 8:10:59 AM] Fellipe Augusto da Silva: he updated the SP01 this morning to see if that problem was going to be solved
[2/4/15, 8:12:48 AM] Fellipe Augusto da Silva: ok, I found the issuethat is happening on 1.2.5
[2/4/15, 8:13:23 AM] Fellipe Augusto da Silva: I'll need to access couchbase though, I'll ask for Reinaldo's help
[2/4/15, 8:14:12 AM] Vicente Goetten: What is it?
[2/4/15, 8:14:31 AM] Fellipe Augusto da Silva: in this last sprint the Auth Result was changed to receive an ENUM instead of a Boolean
[2/4/15, 8:14:45 AM] Fellipe Augusto da Silva: for some reason, some results were not removed from the couchbase doc
[2/4/15, 8:14:56 AM] Fellipe Augusto da Silva: so they're still in there with the true/false
[2/4/15, 8:15:11 AM] Fellipe Augusto da Silva: the Backend tries to read it, expecting a ENUM, but receives a true/false and that causes the error
[2/4/15, 8:15:17 AM] Fellipe Augusto da Silva: I'll clean the doc in there and it should solve the issue
#+END_EXAMPLE
* TODO Need credential and test data in prod env
#+BEGIN_EXAMPLE
[2/4/15, 8:46:48 AM] Fellipe Augusto da Silva: i'll clean the doc now
[2/4/15, 8:49:02 AM] Fellipe Augusto da Silva: ok, doc is cleaned
[2/4/15, 8:49:10 AM] Fellipe Augusto da Silva: so the login on SP01 should be fine now, do we have any cred to test?
#+END_EXAMPLE
* TODO mail: CP-6792: neo4j-server log file of console.log is way too big.           :noexport:
[[gnus:mail.misc#EF9859611DA81140B2B29B02EC8AD6EAF9756D@helios.mex01.local][Email from Denny Zhang (Wed, 4 Feb 2015 09:51:02 -0600): CP-6792: neo4j-server log file]]
#+begin_example
From: Denny Zhang <denny.zhang@totvs.com>
Subject: CP-6792: neo4j-server log file of console.log is way too big.
To: Kung Wang <kung.wang@totvs.com>
CC: Denny Zhang <denny.zhang@totvs.com>
Date: Wed, 04 Feb 2015 09:51:02 -0600

Hi Kung

Below check in QA1B timeout.

I found out CP-6792 reproduced in QA1B. This issue is first found in customerfi.

Anyone can help me resolve this issue?

[cid]

Regards,

Denny

#+end_example
* #  --8<-------------------------- separator ------------------------>8--
* Routine job: How to avoid Vicente asking my here to revert vm in digital ocean
* TODO Manually trigger the check of all nagios, after system is already up
* TODO [#B] monitor java program for the jstack of JVM
http://www.infoq.com/cn/articles/wide-range-devops
#+BEGIN_EXAMPLE
对于传统运维团队来说，搭建一个监控系统来展示这些指标数据是小菜一碟，而调用Statsd和Graphite的接口使用起来是非常简单的，对于开发团队来说，只需几行代码。通过这些技术的变化，开发人员现在就能全面的了解代码对系统的影响，并对运维工作有一个大致的了解。在这个阶段，开发和运维的合作已经开始了，虽然只是一个小的方面，但可以说你们已经向DevOps迈进了一步。我们选择了一个合适的切入点，那么在此基础上继续发展，未来这种合作会更加广泛。
#+END_EXAMPLE

http://www.infoq.com/cn/articles/nilson-monitoring
#+BEGIN_EXAMPLE
监控中最难实现却又必须完成的功能是主动请求。获取哪些API发起主动请求和请求的确切数目的相关信息是最具挑战性也最具价值的事之一。若是访问量很大，当某项服务开始出现问题时，完成相关任务会更耗时，从而带来主动请求数量的上升。总体看，这非常非常有趣，特别是使用Java时，线程池大小固定且每项服务独占线程，一次API调用挂起就能引起整个服务崩溃。避免单个线程带来的服务崩溃十分重要。
#+END_EXAMPLE
* TODO Give training to Dev for how prod env looks like
* TODO Strategy: Start from an existing env, thus customer can see our value better by comparasion
* #  --8<-------------------------- separator ------------------------>8--
* TODO People ask for routine task
#+BEGIN_EXAMPLE
[1/29/15, 12:43:11 PM] kungchaowang: Marcel, you can not see the TECH-62 JIRA page?
[1/29/15, 12:44:07 PM] Marcel Dias: no I can't
[1/29/15, 12:45:20 PM] kungchaowang: how about this link? https://totvslab.atlassian.net/browse/CLOUDPASS-6800
[1/29/15, 12:45:52 PM] kungchaowang: Marcel, can you see the above link?
[1/29/15, 12:45:56 PM] Marcel Dias: this one I can.
[1/29/15, 12:46:09 PM] Marcel Dias: probably I have no access to TECH project
[1/29/15, 12:46:12 PM] kungchaowang: ok, we need to give you access on that TechOp space
[1/29/15, 12:47:43 PM] kungchaowang: I have show John, and now he is giving you the access
[1/29/15, 12:47:56 PM] Marcel Dias: nice
#+END_EXAMPLE
* TODO StatsD - scalable Metric collection
* TODO Sensu  - Server monitoring built for distributed systems
* TODO Should developers have root access to production servers?
http://www.quora.com/Should-developers-have-root-access-to-production-servers

You should all focus on developing a process and toolset that means nobody needs to use root access on production servers on anything approaching a regular basis.

Giving developers root access to prod is like handing whiskey and car keys to teenage boys (plagiarized from PJ O'Rourke). They WILL make senseless, unauthorized changes.

- Applications should not require root access to install or start?
- Every action (restart some service, deploy new code, …) is done through the execution facility??
- Developers should not have root access. But they do need access to certain things to do troubleshooting and restart applications.
* #  --8<-------------------------- separator ------------------------>8--
* TODO [#B] Handle about high availability
* TODO [#B] What to watch for the changes of different release
* TODO [#A] How to detect some logfiles are generated too fast or are too big
* TODO [#A] How to provide TOTVS Labs easily all-in-one build and deployment test with acceptable cost
Enable Dev/QA to try latest build + all-in-one deployment with one click: Thus we can't offload the test effort
** TODO Shivang's communication: ask for testing
[1/29/15, 6:39:31 PM] Shivang: you there denny ?
[1/29/15, 6:45:52 PM] Shivang: ping me when you are around
[1/29/15, 6:46:58 PM] denny: Hi Shivang

I’m having supper.

What’s up?
[1/29/15, 6:51:35 PM] Shivang: sorry to disturb
[1/29/15, 6:51:37 PM] Shivang: it's very quick
[1/29/15, 6:51:41 PM] Shivang: so the log file related stuff for agents
[1/29/15, 6:51:52 PM] Shivang: I programatically handled it
[1/29/15, 6:51:54 PM] Shivang: and tested it
[1/29/15, 6:51:57 PM] Shivang: about to push it in
[1/29/15, 6:52:02 PM] Shivang: 1.4.4
[1/29/15, 6:52:06 PM] Shivang: when you get a chance, you can test it ..
[1/29/15, 6:53:39 PM] denny: Sure.

Do you know how I can verify that?

Like what action can let rmi or racagent keep logging?
[1/29/15, 6:54:22 PM] denny: I can deploy latest 1.4.4 as an all-in-one env.

Would you please login and double check tomorrow morning?
* TODO [#A] Attend sprint meeting and see what we can improve?
* TODO Communication: How to deal with questions about sharing linux skills
Help: one-way? Or mutual benefit??

- Meature the time and frequency: combine to FAQ --> 80/20 rules
- Check whether too much burden??
#+BEGIN_EXAMPLE
[1/22/15, 1:50:14 PM] Mitu Singh: oh ok Denny
[1/22/15, 1:50:40 PM] Mitu Singh: yeah grepping for anything in that huge file is taking forever
[1/22/15, 1:51:01 PM] Mitu Singh: do you know which command I can use to grep information in this file
[1/22/15, 1:51:22 PM] denny: tail -n 10000 xxx.log | grep ...
[1/22/15, 1:51:48 PM] Mitu Singh: ok…thanks Denny I will try that
#+END_EXAMPLE

#+BEGIN_EXAMPLE
[1/22/15, 2:23:17 PM] Fellipe Augusto da Silva: Denny, can you send me the command to create the tunnel to the prod couchbase?
[1/22/15, 2:45:26 PM] denny: Fellipe, something like this?
ssh -N -p 22 -f root@qa1b -L 8002:localhost:9281 -n /bin/bash
#+END_EXAMPLE
* TODO Communication: how to deal with skype message, which people only say hi
- Whether the request is my duty?
#+BEGIN_EXAMPLE
[1/23/15, 2:09:05 PM] Marcel Dias: hey Denny
[1/23/15, 2:09:13 PM] Marcel Dias: how are you?
[1/23/15, 2:26:53 PM] denny: Hi Marcel, I’m good.

What’s up?
[1/23/15, 2:27:25 PM] Marcel Dias: about the Enterprise installer
[1/23/15, 2:27:42 PM] Marcel Dias: I want to know how I need to save the email server properties
[1/23/15, 2:28:11 PM] denny: You mean how to configure it as user?

Or how it’s implemented?
[1/23/15, 2:29:02 PM] Marcel Dias: I’m implementing the backend of the installer.. I need to save the information to the chef client install correctly the FI server
[1/23/15, 2:29:45 PM] denny: Would you please talk with Shivang for this?

Chef only is only a passthrough layer for this.
[1/23/15, 2:30:16 PM] denny: Do you need me to include Shivang here?
[1/23/15, 2:30:36 PM] Marcel Dias: no, I can talk to Shivang as well ;)
[1/23/15, 2:31:29 PM] denny: That’s nice.

Once you are settled with Shivang, I will change chef to cooperate with your part.

It’s quite straightforward to me, if you guys can tell the whole process clearly
#+END_EXAMPLE
* [#A] Communication: People don't check doc, even if Kung
- whether doc is clear enough: keep the doc small and simple
- Whether doc is up-to-date
- whether doc has missed the keypoints people are asking
#+BEGIN_EXAMPLE
[1/26/15, 12:21:01 PM] kungchaowang: Denny, do we have customerFi somewhere on these pages?

https://totvslab.atlassian.net/wiki/display/TECH/Fluig+Env+List
[1/26/15, 12:22:01 PM] denny: Yes, It’s included.

You can search by “customerfi”, in the link of “Fluig Testbed Env"
[1/26/15, 12:22:42 PM] kungchaowang: it’s an AIO right?
#+END_EXAMPLE
* Start a channel with similar questions on skype/slack
* TODO [#A] Who is your ideal client for consultant work??        :IMPORTANT:
- keep in 8 hours
- 8 hours --> 6 hours
* Stick to team center
* [#B] inconsistency is a big problem: loss trust and risk control
* TODO Communication: How I can highlight my daily operates effort: deal with nagios, give permission, etc.
* TODO Communication: How much portition I shall export my work to Kung/Vicente?
* TODO Communication: What should I do, when I found a ticket like this
https://totvslab.atlassian.net/browse/CLOUDPASS-6813
CP-6813: copy local backup set to remote NFS may fail

https://totvslab.atlassian.net/browse/CLOUDPASS-6810
Patch prod env for CVE-2015-0235
* TODO Communication: 40 fixed hours + If supporting off work, bill hours as well
* TODO Communication: Avoid daily standup meeting by default
* TODO Communication: lower the effort and involvement of intergration test
- avoid being dragged into feature test like Enterprise Deployment
#+BEGIN_EXAMPLE
[2/2/15, 9:46:06 AM] kungchaowang: Denny, how is the enterprise installer? have you tested it and see what backend still missing?
[2/2/15, 9:46:47 AM] denny: I was busy with something else. I don’t heard update from Marcel yet.
[2/2/15, 9:47:08 AM] kungchaowang: what we need from them? do you have list?
[2/2/15, 9:47:20 AM] kungchaowang: we need to chase them for these, so we can release tomorrow
[2/2/15, 9:48:02 AM] kungchaowang: let’s see if we can have con call with them to quickly remove these blockers
[2/2/15, 9:51:00 AM] denny: I think Marcel may have that.

Anyway, let me update what I know so far to JIRA
[2/2/15, 9:51:52 AM] kungchaowang: ok, or, let’s have con call with them to make sure what you need is there?
[2/2/15, 9:54:38 AM] denny: What I need is mainly 3 parameters.
[2/2/15, 9:55:00 AM] denny: Last time I check, they’re there.
[2/2/15, 9:56:39 AM] kungchaowang: in this case, let me try to go through it and verify if 1.4.4 is ready
[2/2/15, 9:56:48 AM] kungchaowang: can you help me on that if I have question?
[2/2/15, 9:57:04 AM] denny: Sure
[2/2/15, 9:57:25 AM] kungchaowang: let me use this page to start with:

https://totvslab.atlassian.net/wiki/display/TECH/Deploy+Identity+Enterprise+Envs
[2/2/15, 10:01:09 AM] kungchaowang: since we are using 1.4.4, so first, how to create that zip file for download. now who and how to create that zip file?
[2/2/15, 10:06:45 AM] denny: It’s done by Chef
[2/2/15, 10:07:21 AM] denny: https://github.com/TOTVS/chef/blob/master/cookbooks/fluig-vmmanager-webapp/recipes/conf_files.rb#L73-L87
[2/2/15, 10:17:05 AM] kungchaowang: I don’t see what files been copied into deploy_vmapp_webui before it’s zipped. do you know where is the chef code that show me what files are copied into deploy_vmapp_webui folder ?
[2/2/15, 10:17:32 AM] denny: https://github.com/TOTVS/chef/blob/master/cookbooks/fluig-vmmanager-webapp/recipes/conf_files.rb#L73-L87
[2/2/15, 10:18:05 AM] kungchaowang: yes, I see it’s zipped, but what files are inside there before it’s zipped?
[2/2/15, 10:18:16 AM] denny: L73-L80
[2/2/15, 10:19:01 AM] denny: L73-L80 will sync directory for this:
https://github.com/TOTVS/chef/tree/master/cookbooks/fluig-vmmanager-webapp/files/default/deploy_vmapp_webui
[2/2/15, 10:22:18 AM] kungchaowang: so, is VMManager.jar inside deploy_vmapp_webui before it’s zipped? and do we need yam file inside deploy_vmapp_webui as well?
[2/2/15, 10:22:50 AM] denny: After the new design, we don’t need the preinstaller sh.

right?
[2/2/15, 10:23:14 AM] kungchaowang: we should not need it, we should only need the jar and yaml file
[2/2/15, 10:24:07 AM] kungchaowang: that is the goal
[2/2/15, 10:24:38 AM] kungchaowang: for proxy, the test is done by dynamically creating proxy sessions to test proxy from the jar file
[2/2/15, 10:24:48 AM] denny: Then that’s something new.

Talking about the new goal for the question you asked
“I don’t see what files been copied into deploy_vmapp_webui before it’s zipped. do you know where is the chef code that show me what files are copied into deploy_vmapp_webui folder ?”
[2/2/15, 10:25:14 AM] denny: I don’t know the answer.

Maybe we can ask Marcel/Reinaldo
[2/2/15, 10:25:18 AM] kungchaowang: maybe let’s talk, will it be easier for us to clear some questions?
[2/2/15, 10:25:43 AM] denny: Let’s do that after 10 min?
[2/2/15, 10:25:48 AM] denny: I’m finishing the doc for Lucas.
[2/2/15, 10:25:52 AM] kungchaowang: sure, ping me when you are ready
[2/2/15, 10:33:13 AM] denny: Hi Kung, I’m ready for the call now
[2/2/15, 10:33:30 AM] kungchaowang: ok, let me call you now
[2/2/15, 10:33:38 AM] kungchaowang: Call started
[2/2/15, 10:34:33 AM] kungchaowang: java -jar VMManager.jar server fivmmgr.yml
[2/2/15, 10:48:56 AM] denny: | Video              | http://vimeo.com/116214704                                                                                                 |
[2/2/15, 10:49:48 AM] denny: Call ended  16 minutes 11 seconds
#+END_EXAMPLE
* TODO Communication: How to team member's expectation to me
* TODO VM automation: how to handle no enough hardware?
* TODO Discuss with Kung: Know he is busy, but need off the work load, thus we can fully conduct the actions
* #  --8<-------------------------- separator ------------------------>8--
* TODO [#A] Talk with Vicente: Don't read skype log; No role to identity, before MDM
- Don't ask other people with tasks out of them domain. Contact your manager/boss first.
#+BEGIN_EXAMPLE
[2/4/15, 11:41:43 AM] Vicente Goetten: Hello Denny
[2/4/15, 11:41:46 AM] Vicente Goetten: can we do a quick call?
[2/4/15, 11:41:55 AM] denny: Give me 5 min?
[2/4/15, 11:42:07 AM] denny: I’m supporting SS update
[2/4/15, 11:43:03 AM] Vicente Goetten: ok
[2/4/15, 11:44:50 AM] denny: Hi Vicente
[2/4/15, 11:48:55 AM] Vicente Goetten: Denny, Fellipe mentioned to me that you asked him to deploy SS to production
[2/4/15, 11:49:03 AM] Vicente Goetten: why did you ask him to deploy?
[2/4/15, 11:49:52 AM] denny: [2/4/15, 11:11:39 AM] Suresh Sathyanarayan: Denny. you are the one who has write access to the production boxes right ?
[2/4/15, 11:13:04 AM] denny: Doing

I’m fading away from the support of identity.
[2/4/15, 11:13:18 AM] Suresh Sathyanarayan: Denny you will have to scp the latest SmartSyncSetup.exe file from the branch to this location on production: /var/www/cloudpass/assets/directory
[2/4/15, 11:14:00 AM] Suresh Sathyanarayan: Ok Denny for this time you can do it and then we can train Fellipe for the future.
[2/4/15, 11:14:28 AM] denny: I guess, Fellipe would not be the right person for this job.
[2/4/15, 11:14:48 AM] Fellipe Augusto da Silva: I think that TOTVS is trying to hire a DevOps in here for handling this kind of situation
[2/4/15, 11:15:11 AM] Suresh Sathyanarayan: Ok until they hire DevOps, Fellipe can be there for emergency
[2/4/15, 11:15:16 AM] Fellipe Augusto da Silva: right
[2/4/15, 11:17:07 AM] denny: Oh, I see.

Then Fellipe please coordinate with Lucas about this.

My sudden vacancy by next month from this project may bring in a lot of inconvenience then.
[2/4/15, 11:17:40 AM] denny: Otherwise you will be handling this kind of emergency with blind mind next month.
[2/4/15, 11:18:02 AM] Suresh Sathyanarayan: Yeah Denny is right. Denny has all the knowledge of the production system, and once he is out of the project, it will be very hard for the new person to learn everything
[2/4/15, 11:18:40 AM] Fellipe Augusto da Silva: yeah, I think then Denny, we can schedule some training so you can pass all the stuff that you do for me
[2/4/15, 11:50:09 AM] Vicente Goetten: Denny
[2/4/15, 11:50:13 AM] Vicente Goetten: sorry I will not read a Skype log
[2/4/15, 11:50:25 AM] Vicente Goetten: Felipe is not a devops
[2/4/15, 11:50:32 AM] Vicente Goetten: and hasn't been trained in devops
[2/4/15, 11:50:36 AM] Vicente Goetten: we should not ask him to do that
[2/4/15, 11:51:21 AM] denny: [2/4/15, 11:13:04 AM] denny: Doing

I’m fading away from the support of identity.

[2/4/15, 11:14:28 AM] denny: I guess, Fellipe would not be the right person for this job.

[2/4/15, 11:17:07 AM] denny: Oh, I see.

Then Fellipe please coordinate with Lucas about this.

My sudden vacancy by next month from this project may bring in a lot of inconvenience then.
[2/4/15, 11:52:11 AM] denny: Hi Vicente, shall we have a call?
#+END_EXAMPLE
** TODO how to handle the case about DevOps
[2/4/15, 11:04:55 AM] denny: Fellipe, if talking about the download link. Here is the location of server side.

root@app1:/var/www/cloudpass# ls -lth /var/www/cloudpass/assets/directory
ls -lth /var/www/cloudpass/assets/directory
total 18M
-rw-r--r-- 1 tomcat7 tomcat7 2.0M Feb  3 00:16 SmartSyncSetup.exe
-rw-r--r-- 1 tomcat7 tomcat7 2.0M Jan 29 14:46 SmartSyncSetup_129.exe
-rw-r--r-- 1 tomcat7 tomcat7 2.0M Jan 26 03:46 SmartSyncSetup_126.exe
-rw-r--r-- 1 tomcat7 tomcat7 2.0M Jan  9 10:47 SmartSyncSetup_128.exe
-rw-r--r-- 1 tomcat7 tomcat7 2.0M Oct 16 16:23 SmartSyncSetup_125.exe
-rw-r--r-- 1 tomcat7 tomcat7 2.0M Sep 19 23:25 SmartSyncSet_124.exe
-rw-r--r-- 1 root    root    1.9M Sep 19 00:23 SmartSync_123.exe
-rw-r--r-- 1 root    root    1.9M Sep 19 00:23 SmartSyncSetup_123.exe
-rw-rw-r-- 1 tomcat7 tomcat7 1.9M Jul 21  2014 SmartSyncSetup_122.exe
[2/4/15, 11:05:17 AM] Suresh Sathyanarayan: you will have to overwrite
[2/4/15, 11:05:29 AM] Suresh Sathyanarayan: the SmartSyncSetup.exe
[2/4/15, 11:05:34 AM] Suresh Sathyanarayan: and then push it to the branch
[2/4/15, 11:05:45 AM] Fellipe Augusto da Silva: ok, it's already on the branch 1.4.4
[2/4/15, 11:06:01 AM] Fellipe Augusto da Silva: there is any additional step after that?
[2/4/15, 11:06:24 AM] Suresh Sathyanarayan: Oh if it’s already on the branch, then Denny will do the next step.
[2/4/15, 11:06:32 AM] Fellipe Augusto da Silva: oh ok then
[2/4/15, 11:06:45 AM] denny: Suresh, you mean run another round of chef update?
[2/4/15, 11:06:51 AM] Suresh Sathyanarayan: Yes
[2/4/15, 11:07:06 AM] Suresh Sathyanarayan: You need to make sure that the latest SmartSyncSetup is now in prod
[2/4/15, 11:07:21 AM] denny: It will result in lots of impact.

For this change, I would simply suggest scp to the location which I mentioned above.
[2/4/15, 11:07:41 AM] Suresh Sathyanarayan: Denny
[2/4/15, 11:08:04 AM] Suresh Sathyanarayan: can you scp the latest SmartSyncSetup.exe to prod?
[2/4/15, 11:10:11 AM] Suresh Sathyanarayan: Denny are you there ?
[2/4/15, 11:10:33 AM] denny: Building latest code
[2/4/15, 11:10:52 AM] denny: Fellipe, do you know how to scp?
[2/4/15, 11:11:08 AM] Fellipe Augusto da Silva: nop, I usually don't do this kind of stuff
* How log rotate effect nagios check log
** mail: ** RECOVERY Service Alert: app.customerfi.com/check_backup_log is OK ** :noexport:
[[gnus:totvs-nagios#20150204183113.7E1EB28006F@fluig-id-cdn-01.fluigidentity.com][Email from nagios@fluig-id-cdn-01.fluigidentity.com (Wed, 4 Feb 2015 18:31:13 +0000): ** RECOVERY Service Alert: app]]
#+begin_example
From: <nagios@fluig-id-cdn-01.fluigidentity.com>
Subject: ** RECOVERY Service Alert: app.customerfi.com/check_backup_log is OK **
To: <denny.zhang@totvs.com>
Date: Wed, 04 Feb 2015 12:31:13 -0600
X-Spam-Status: No, score=3.682 tagged_above=2 required=4
        tests=[DNS_FROM_AHBL_RHSBL=2.699, RDNS_DYNAMIC=0.982,
        URIBL_BLOCKED=0.001] autolearn=no
****** Nagios *****

Notification Type: RECOVERY

Service: check_backup_log
Host: app.customerfi.com
Address: 172.20.18.23
State: OK

Date/Time: Wed Feb 4 18:31:13 GMT 2015

Additional Info:

OK - no errors or warnings

#+end_example
** DONE why backup.log is empty: file has been log rotated
  CLOSED: [2015-02-04 Wed 12:37]
#+BEGIN_EXAMPLE
root@fluig-id-cust-01:~# crontab -l
# Chef Name: cron_clean_cached_memory
0 4 * * * /usr/local/bin/clean_cached_memory.sh
# Chef Name: cron_backup_fluig
0 2 * * * bash -e /usr/local/bin/fluig_backup.sh all >> /var/log/backup.log 2>&1
# Chef Name: cron_backup_cloudpasskeystore
*/5 * * * * bash -e /usr/local/bin/fluig_backup_file.sh /cloudpass/backend/build/bin/CloudpassKeystore >> /var/log/backup_cloudpasskeystore.log 2>&1

# Chef Name: remote_copy_backupset
20 3 * * * bash -e /usr/local/bin/remote_copy_backupset.sh >> /var/log/backup.log 2>&1

# Chef Name: cron_daily_clean
0 4 * * * bash -e /usr/local/bin/fluig_daily_clean.sh
root@fluig-id-cust-01:~# ls -lth /var/log/backup.log
-rw-r--r-- 1 root root 0 Feb  4 06:35 /var/log/backup.log
root@fluig-id-cust-01:~# date
Wed Feb  4 18:28:17 GMT 2015
root@fluig-id-cust-01:~#
#+END_EXAMPLE
* TODO Consultant: 不要把自己变得不可或缺: 对于客户的风险控制，对于自己时间的把握
* TODO regression issue hard to detect before pushing to prod env
** neo4j config about cache
#+BEGIN_EXAMPLE
[2/4/15, 11:45:29 AM] denny: denny added kungchaowang, Lucas Schiochet to this conversation
[2/4/15, 11:46:18 AM] Lucas Schiochet: Lucas Schiochet added Marcel Dias to this conversation
[2/4/15, 11:47:19 AM] kungchaowang: Denny, first of all, do we have customerfi’s database backup?
[2/4/15, 11:47:57 AM] denny: Yes, we have
[2/4/15, 11:48:03 AM] denny: Let’s the issue of customerfi?
[2/4/15, 11:48:24 AM] kungchaowang: they said all their data lost
[2/4/15, 11:48:37 AM] denny: Let me check.
[2/4/15, 11:51:58 AM] denny: I’ve just login to customerfi

See lots of companies
[2/4/15, 11:52:33 AM] denny: Image
[2/4/15, 11:53:07 AM] Marcel Dias: they said that they lost RAC data under the Apps
[2/4/15, 11:54:03 AM] denny: Are we talking about RAC log file under /data/fluig*logs/?
[2/4/15, 11:54:34 AM] Marcel Dias: RAC data: user permissions,  roles, menus, quickviews
[2/4/15, 11:57:01 AM] kungchaowang: Denny, what I found is, there are two folders under this folder: /data/totvslabs/scim/neo4j/embedded/index/lucene

one is node, the other is relationship. and when you peek inside, there a lot of company ids missing in the relationship folder if compared to node folder
[2/4/15, 11:58:56 AM] denny: Kung, I don’t quite understand the data layout of neo4j.

For daily backup, it’s under /data/backup/totvslabs

Would you please check about that?
[2/4/15, 12:00:23 PM] kungchaowang: yes, let me chec
[2/4/15, 12:21:17 PM] Lucas Schiochet: any lucky?
[2/4/15, 12:22:58 PM] kungchaowang: when they found having data last time?
[2/4/15, 12:23:12 PM] Lucas Schiochet: yesterday end of the day
[2/4/15, 12:23:14 PM] kungchaowang: yesterday? or
[2/4/15, 12:23:14 PM] Lucas Schiochet: before the update
[2/4/15, 12:23:50 PM] Lucas Schiochet: since in the morning the data wasn t available
[2/4/15, 12:24:05 PM] Lucas Schiochet: yesterday before update was fine
[2/4/15, 12:25:40 PM] denny: Note: one thing I did this morning about customerfi. Not sure whether it’s related

move /data/fluigidentity-logs/racagent01.log /home/denny/
[2/4/15, 12:34:06 PM] kungchaowang: that should be fine
[2/4/15, 12:41:20 PM] Lucas Schiochet: do you have any prediction to be available again?
[2/4/15, 12:42:04 PM] Lucas Schiochet: The Directors of Totvs are asking me one prediction that will be solved.
[2/4/15, 12:43:57 PM] Lucas Schiochet: Vicente already replied. Thanks :)
[2/4/15, 12:45:01 PM] kungchaowang: they are sending huge amount of data now, I believe that’s not needed, the data should be ok
[2/4/15, 12:47:00 PM] kungchaowang: this machine is currently not that powerful enough to take this amount of input yet
[2/4/15, 12:47:03 PM] kungchaowang: since it’s AIO
[2/4/15, 12:47:29 PM] kungchaowang: so I will stop their sync and check the data again. ok?
[2/4/15, 12:51:14 PM] kungchaowang: how’s now?
[2/4/15, 12:51:21 PM] kungchaowang: can you check Lucas?
[2/4/15, 12:52:21 PM] Marcel Dias: please, Lucas send them an email
[2/4/15, 12:54:06 PM] Lucas Schiochet: ok
[2/4/15, 12:54:18 PM] Lucas Schiochet: but if we will recover the backup, we does not need this data anymore
[2/4/15, 12:55:10 PM] denny: Filed CP-6861: After updating to identity-1.4.4,  customerfi has lost RAC data

Let’s post critical info there.
[2/4/15, 12:55:39 PM] Lucas Schiochet: good one Denny, after we restore the backup, we will need to analyze the cause
[2/4/15, 12:55:57 PM] Lucas Schiochet: Did you restore the data Kung?
[2/4/15, 12:57:43 PM] Lucas Schiochet: because i am accessing the env logistica and appears to be solved
[2/4/15, 12:57:44 PM] kungchaowang: no
[2/4/15, 12:57:49 PM] kungchaowang: I did not restore anything
[2/4/15, 12:59:02 PM] Lucas Schiochet: strange, but did you find a backup from yesterday night
[2/4/15, 12:59:02 PM] Lucas Schiochet: ?
[2/4/15, 12:59:29 PM] kungchaowang: let me show you why
[2/4/15, 1:02:36 PM] kungchaowang: there was a ticket open this sprint:

https://totvslab.atlassian.net/browse/CLOUDPASS-6800

and we have trouble getting correct cache from memory when entitle role to user or entitle role to group. The data been persisted to disk without any problem, when when program reads back, database only get from memory, and because of this internal bug to database server, we got no change back even disk had changed.

so, by fixing this, I turned off the cache, by using this line in neo4j.properties:

# change internal cache type
cache_type=none

after that, it reads from disk and bug 6800 is solved.

but, now we introduce another problem, which is, the AIO machine is not strong enough to run without cache support.
[2/4/15, 1:03:44 PM] kungchaowang: Solution:
1. rollback our deployment on neo4j cookbook to turn that flag on, and we will introduce bug 6800 again.
2. find another way, for example, cache_type=all, to cache all of them in cache and may also fix that issue, but means we will need more powerful machine
#+END_EXAMPLE
** #  --8<-------------------------- separator ------------------------>8--
* #  --8<-------------------------- separator ------------------------>8--
* TODO [#A] chef update has changed a lot: for java program, whenever do a new build, the cksum will be different
* TODO [#A] Routine request only I can do, due to security issue
#+BEGIN_EXAMPLE
[2/4/15, 2:27:51 PM] Shivang: need your help real quick
[2/4/15, 2:28:03 PM] Shivang: do you mind adding a cname entry to production in amazon ?
[2/4/15, 2:28:06 PM] Shivang: rekoba.fluigidentity.com
[2/4/15, 2:28:09 PM] denny: Sure
[2/4/15, 2:28:10 PM] Shivang: pointing to production ?
[2/4/15, 2:28:25 PM] Shivang: thanks .. we mistyped it .. and now we will have to manually update both DB and the cname
[2/4/15, 2:28:36 PM] Shivang: I already updated DB .. just cname is left
[2/4/15, 2:28:38 PM] Shivang: thank you!
[2/4/15, 2:28:44 PM] denny: OK, let me do that
[2/4/15, 2:33:27 PM] denny: Changed. Need to wait for a while, until dns broadcast is done
[2/4/15, 2:34:45 PM] Shivang: no problme
[2/4/15, 2:34:48 PM] Shivang: thanks
[2/4/15, 2:35:14 PM] denny: You’re welcome.

When it’s done, I will let you know in this group chat
[2/4/15, 2:36:38 PM] Shivang: thanks
[2/4/15, 2:38:55 PM] denny: Done

macs-air:~ mac$ ping rekoba.fluigidentity.com
PING app.fluigidentity.com (187.94.62.94): 56 data bytes
64 bytes from 187.94.62.94: icmp_seq=0 ttl=47 time=276.528 ms
64 bytes from 187.94.62.94: icmp_seq=1 ttl=47 time=284.326 ms
#+END_EXAMPLE
* TODO Argument: Ask customer to hire a Junior DevOps engineer, so that we can delegate my routine task like below
** Routine request only DevOps can do, due to security issue
#+BEGIN_EXAMPLE
[2/4/15, 2:27:51 PM] Shivang: need your help real quick
[2/4/15, 2:28:03 PM] Shivang: do you mind adding a cname entry to production in amazon ?
[2/4/15, 2:28:06 PM] Shivang: rekoba.fluigidentity.com
[2/4/15, 2:28:09 PM] denny: Sure
[2/4/15, 2:28:10 PM] Shivang: pointing to production ?
[2/4/15, 2:28:25 PM] Shivang: thanks .. we mistyped it .. and now we will have to manually update both DB and the cname
[2/4/15, 2:28:36 PM] Shivang: I already updated DB .. just cname is left
[2/4/15, 2:28:38 PM] Shivang: thank you!
[2/4/15, 2:28:44 PM] denny: OK, let me do that
[2/4/15, 2:33:27 PM] denny: Changed. Need to wait for a while, until dns broadcast is done
[2/4/15, 2:34:45 PM] Shivang: no problme
[2/4/15, 2:34:48 PM] Shivang: thanks
[2/4/15, 2:35:14 PM] denny: You’re welcome.

When it’s done, I will let you know in this group chat
[2/4/15, 2:36:38 PM] Shivang: thanks
[2/4/15, 2:38:55 PM] denny: Done

macs-air:~ mac$ ping rekoba.fluigidentity.com
PING app.fluigidentity.com (187.94.62.94): 56 data bytes
64 bytes from 187.94.62.94: icmp_seq=0 ttl=47 time=276.528 ms
64 bytes from 187.94.62.94: icmp_seq=1 ttl=47 time=284.326 ms
#+END_EXAMPLE
* TODO How to gracefully clarify responsibility/fault which should not go to me
#+BEGIN_EXAMPLE
[2/4/15, 3:54:43 PM] Vicente Goetten: can you hold on customerfi?
[2/4/15, 3:54:49 PM] Vicente Goetten: we should do it later today
[2/4/15, 3:55:01 PM] denny: Any suggested time?
[2/4/15, 3:55:29 PM] Vicente Goetten: I'd say after 4pm PST for sure
[2/4/15, 3:55:42 PM] Vicente Goetten: any risk to cause disruption again on customerfi?
[2/4/15, 3:55:50 PM] Fellipe Augusto da Silva: psfluigidentity also, if we can, there is some guys from TOTVS that are testing the Fluig / Identity integration in there
[2/4/15, 3:56:33 PM] Vicente Goetten: so better to do it later Denny
[2/4/15, 3:57:04 PM] denny: Should be fine, since the main purpose of push is actually to revert the change of neo4j.
[2/4/15, 3:58:29 PM] denny: So I will upgrade all of 3 envs at 4pm PST.

Is that OK? Or we prefer to do that even later.

I’m fine to reschedule to later, if Suresh is OK as well.
#+END_EXAMPLE
* #  --8<-------------------------- separator ------------------------>8--
* TODO [#A] Whether to give devlopers root priveledge: Check package cksum; Restart service by their own?
- Balance between safe and less-communication
- Readonly OS user may not work: like restart neo4j service
* Keep critical channel monitored
#+BEGIN_EXAMPLE
[2/9/15, 12:23:46 PM] Shivang: I think we had that usecase back in the days .. @suresh can confirm
[2/9/15, 12:24:01 PM] Shivang: we should be .. don't we ? it depends on how we store
[2/9/15, 12:24:07 PM] denny: Guys, this Skype group is reserved for “Upgrade Prod env”

Would you mind starting a separate Skype group to discuss the test and fix of logo issue?
[2/9/15, 12:24:18 PM] Shivang: maybe the way we store it might be a hash of companyId and appId combined? I don't know the FE logic for it
[2/9/15, 12:24:26 PM] Shivang: you got that denny
[2/9/15, 12:24:58 PM] denny: Thanks, Shivang.

Just don’t want people start to ignore messages in this group.
#+END_EXAMPLE
* TODO Audit: any ssh login need to log client IP and username
* TODO Communication: should I post CP-6922 to Skype group "Upgrade Prod env"?
* TODO [#A] Get git commit version1 and version2 for different push
* TODO communication for resource
#+BEGIN_EXAMPLE
[2/13/15, 12:19:38 PM] denny: Lucas, thanks for your help. Appreciate it.

Let’s keep checking.
[2/13/15, 12:24:25 PM] Lucas Schiochet: Thanks Denny,
What happens is that in Totvs Brazil the Cloud and DevOps is in another department.
In this department they have another director and managers that are responsible to hire and find the right guy to the challenge
[2/13/15, 12:25:17 PM] Lucas Schiochet: We as product just act as a validation condition to see with the guy that they find is the right guy (technically skills) to help us in the FI
[2/13/15, 12:26:21 PM] Lucas Schiochet: That why i don’t have enough ‘power’ to help it more
[2/13/15, 12:26:31 PM] kungchaowang: Lucas, we will do our best to assist you, but after March, I need to use more Denny’s time on new tech stack deployment coding, so you will expect more delay on your request if any.
[2/13/15, 12:27:28 PM] Lucas Schiochet: Thanks Kung, i really appreciate that.
And of course, i understand that you have a new project an a totally new challenge. is difficultt work with two entire different projects
[2/13/15, 12:28:56 PM] kungchaowang: yes, so, try to get the DevOp as soon as you can, so you have peace of mind, like i am trying to get front-end team hiring going now, we all have different urgencies
[2/13/15, 12:29:16 PM] Lucas Schiochet: Actually, we will need FE also
[2/13/15, 12:29:24 PM] Lucas Schiochet: Because Fellipe is Totvs Labs
[2/13/15, 12:29:58 PM] kungchaowang: hehe… yes, we are competing for smart people
[2/13/15, 12:30:14 PM] kungchaowang: let’s try to get people we wanted as soon as we can
#+END_EXAMPLE
* TODO can't access mail server, but contacting data center team we usually use mail
Hi there

Looks like none of us can open mail of TOTVS. Do you know who can help us?
- Open https://webmailmx.totvs.com in web browser timeout
- telnet webmailmx.totvs.com:995 timeout
* TODO [#A] Websites and tools to evaluate website security
** Heartbleed test: openssl
https://filippo.io/Heartbleed/#app.customerfi.com
* TODO blog: common questions to check for DevOps
http://www.quora.com/DevOps/What-are-most-common-problems-which-cause-outages-of-Production-Servers
* web page: What Day to Day Activities Does a Hadoop Admin Do? - Quora
http://www.quora.com/What-day-to-day-activities-does-a-Hadoop-Admin-do
** webcontent                     :noexport:
#+begin_example
Location: http://www.quora.com/What-day-to-day-activities-does-a-Hadoop-Admin-do
This page may be out of date. Save your draft before refreshing this page.Submit any pending
changes before refreshing this page.
Hide this message.

Quora

[                    ]

Login
Sign Up

Share Question

TwitterFacebookGoogle+

Related Topics

Science, Engineering, and Technology
Technology
Electronics
Computers
System Administration

What day to day activities does a Hadoop Admin do?

What does a Hadoop Admin do? It she a Hadoop developer, or like a System Admin? What are the key
skills a Hadoop Admin possesses? What are day-to-day technical challenges?
Want Answers24

3 Answers
Quora UserQuora User, co-founder @sellsy_app - frenc... (more) co-founder @sellsy_app - french
entrepreneur
1 upvote by Quora User.
Repairing, fixing, optimizing, load balancing... that kind of stuff.
Embed Quote
Written Insert a dynamic date here.
Upvote1
Downvote
Comment Loading...
More Answers Below.
Related Questions

  *
    Apache Hadoop Aministration: Windows admin to hadoop admin?
  *
    Will 4-year universities one day provide Hadoop classes?
  *
    With SysAdmin Day celebrated yesterday, What do you think about your job of System Admin?

Gilad Moscovitch
Gilad Moscovitch
Hmme insights from my team:

 1.   First thing on morning checking the monitir console (cloudera manager) and the jobtracker ui.
 2. Developing and running a files merger so that the small files and directories our data
    suppliers create would become bigger and fewer.
 3. Keep the farm working – we build monitoring, managing resources between our users and our
    tools, tunning configurations for the farm stack, for mapreduces, spark jobs and for the
    servers of course.
 4. Analyzing too heavy or failed jobs
 5. Fixing problems (even at night).
 6. Define requirements for new hosts
 7. We are kind of applicative and infrastracture dba for the hbase cluster.
 8. Upgrading the farm from time to time
 9. Trying to test and benchmarkb new buzz projects.
10. Set a configuration managment tool for our test and prod enviroments.
11. Developing an easy infrastracture to insert data to the cluster and into hive and impqla.
12. Developing an easy tool for getting the data out of hadoop into rdbms.
13. Daily support for developers who use the hadoop stack.
14. Managing users, permissions , quotas, etc

Embed Quote
Written Insert a dynamic date here.
Upvote0
Downvote
Comment Loading...
Ananda Prakash Verma
Ananda Prakash Verma, Lost in thoughtsLost in thoughts
What are the key skills a Hadoop Admin possesses?

  * Mater of Unix commands
  * Sound knowledge Unix based File System
  * Excellent hold on shell scripting
  * Deep understanding and knowledge of Operating System, Scheduling, Process Management.
  * Command on Hadoop cluster setup Single Node, Pseudo Distributed and fully distributed Mode.
  * Knowledge of Networking.

What does a Hadoop Admin do?

  * Installation and Configuration
  * Cluster Maintenance
  * Resource Management
  * Security Management
  * Troubleshooting
  * Cluster Monitoring
  * Backup And Recovery Task

Embed Quote
Written Insert a dynamic date here.
Upvote0
Downvote
Comment Loading...
1 Answer Collapsed
More
Write an answer
Related Questions

  *
    Apache Hadoop: What are some of the research topics in the field of Hadoop Framework?
  *
    Hadoop Distcp: Copy data from newer version to older version of hdfs?
  *
    Is there any institute in Hyderabad which gives a quick crash course in Hadoop within ten days?
  *
    Where can I find great Linux System Admins with cutting edge technology skills..like Hadoop?
  *
    Are there any active Hadoop projects in Chennai TCS?
  *
    I am a Unix/Linux admin and I want to become a Hadoop/Bigdata admin, is it a good move? What is
    needed to learn?
  *
    What is the best institute to learn VMware and Hadoop admin in Chennai?
  *
    What do Hadoop users think of the NSA using it so extensively in their spying activities?
  *
    I am a final-year computer science engineering student with little knowledge of programming but
    I am a CCNA. Which IT skills are in most need ... (continue)
  *
    Does Oracle have any experience or active participation in the Hadoop community?
  *
    I want to get up to speed on "state of the art" on activities in ML, Hadoop, Spark etc. What
    are recommended blogs, conference presentations e... (continue)
  *
    Are there any active initiatives underway to consolidate existing Hadoop based genomic analysis
    into a single Apache level project similar to ... (continue)
  *
    I have installed hadoop 1.0.4 on windows using cygwin. I have tried few basic commands like
    hadoop fs, hadoop admin commands.Now I have a basi... (continue)
  *
    Given the ubiquity of Hadoop activity in managing big data, how should a product person think
    about leveraging its benefits and capabilities?
  *
    What's the best way to celebrate Sysadmin Day?
  *
    Would you use tools like Chef/Puppet from day one?
  *
    Does Quora use Hadoop?

Sign in to read all of Quora.

Continue with GoogleConnected to GoogleContinue with FacebookConnected to Facebook
By continuing you indicate that you have read and agree to the Terms of Service.
Sign Up with Email

[-6e797f99a]

Loading account...

Complete Your Profile

Full Name[                    ]
Checking...
Email[                    ]
Checking...
Password[                    ]
Checking...
By creating an account you indicate that you have read and agree to the Terms of Service.
Cancel Create Account
Best Questions in System Administration

★
What are the disadvantages of disabling memory overcommit in Linux?
★
What are some time-saving tips that every Vim user should know?
★
What are some time-saving tips that every Linux user should know?
★
What are some common approaches to error aggregation, alerting, and analysis in distributed
systems?
★
What are useful free and open source tools for devops and sysadmin folks?

Top Stories
Sitemap
#
ABCDEFGHIJKLMNOPQRSTUVWXYZ
About - Careers - Privacy - Terms

#+end_example
* [#A] DevOps Resources
** web page: dustinmm80/devops_resources · GitHub
https://github.com/dustinmm80/devops_resources
*** webcontent                                                     :noexport:
#+begin_example
Location: https://github.com/dustinmm80/devops_resources
Skip to content

Sign up Sign in
[                    ]
This repository
  * Explore
  * Features
  * Enterprise
  * Blog

  * Watch 7
  * Star 18
  * Fork 6

dustinmm80/devops_resources #

  * Code #
  * Issues #
  * Pull Requests #

  * Pulse #
  * Graphs #

HTTPS clone URL

[https://github.com/d]

Subversion checkout URL

[https://github.com/d]

You can clone with HTTPS or Subversion.

Download ZIP
A list of DevOps resources - podcasts, blogs, newsletters, etc

  * 11 commits
  * 1 branch
  * 0 releases
  * 5 contributors

branch: master
Switch branches/tags
[                    ]

  * Branches
  * Tags

master
Nothing to show
Nothing to show
devops_resources/

Merge pull request #4 from edwardsgs/master …

Update README.md with more resources

latest commit 5212a25ec9
Dustin Collins dustinmm80 authored Jan 19, 2015

  Failed to load latest commit information.
# LICENSE    Initial commit    Mar 3, 2014
# README.md  Update README.md  Jan 19, 2015

README.md

 DevOps Resources

A list of DevOps resources - podcasts, blogs, newsletters, etc

---------------------------------------------------------------------------------------------------

 Podcasts

Arrested DevOps

DevOps Cafe

DevOps Mastery

Ops All The Things!

Puppet Labs Podcast

The Cloudcast

The Food Fight Show

The Ship Show

 Aggregators/Q&A

Dzone DevOps zone

dev2ops

devops.com

DevOps on Quora

LinkedIn DevOps group

/r/devops

 Blogs (Orgs)

codeascraft (etsy)

Opscode Chef

Puppet

 Blogs (Personal)

Andrew Clay Shafer

Bryan Berry

Chad Fowler

James Betteley

Joe Hirn

John Allspaw

John E. Vincent

Len Lagestee

Mike Fiedler

Nathen Harvey

Patrick Debois

Tom Duffield

Charlie Hsu

 Videos

devopsdays on Vimeo

 Newsletters

DevOps Weekly

UsingChef

  * Status
  * API
  * Training
  * Shop
  * Blog
  * About

  * © 2015 GitHub, Inc.
  * Terms
  * Privacy
  * Security
  * Contact

[                    ]

Something went wrong with that request. Please try again.

#+end_example
* TODO Evaulate whether the requirement is valid: deploy with mixed version
#+BEGIN_EXAMPLE
[2/17/15, 1:34:26 PM] kungchaowang: Denny, in order to transfer push/pull model knowledge to Robbson today, I need your help to setup an AIO machine.
[2/17/15, 1:34:38 PM] kungchaowang: remember we have couple machines that we are not using?
[2/17/15, 1:34:43 PM] kungchaowang: can we use one of them?
[2/17/15, 1:34:53 PM] denny: Could we just do that in digital ocean?
[2/17/15, 1:35:23 PM] kungchaowang: oh, no, let’s just use digital ocean one, maybe that’s easier because we control all port access
[2/17/15, 1:35:38 PM] kungchaowang: let me talk to Shivang and mitu to see if it’s ok
[2/17/15, 1:35:45 PM] denny: np
[2/17/15, 1:37:27 PM] kungchaowang: can you setup a machine in digital ocean and give it a domain name like pull.thecloudpass.com?
[2/17/15, 1:37:46 PM] denny: np
[2/17/15, 1:37:57 PM] kungchaowang: it will be a 8CPU, 8GB RAM machine at least
[2/17/15, 1:39:18 PM] kungchaowang: thank you Denny, I will send you branch # to checkout and build for backend, for front-end, we can use master
[2/17/15, 1:39:46 PM] denny: Could we use the same branch for BE and FE?
[2/17/15, 1:40:30 PM] kungchaowang: it’s better not, otherwise, you will need to consistently merge master to that newly created FE
[2/17/15, 1:40:43 PM] denny: Or you guys can patch on your own will later?
[2/17/15, 1:41:04 PM] kungchaowang: and Mitu’s changes will have to go to specific branch as well, so it won’t break master
[2/17/15, 1:42:27 PM] kungchaowang: so, for backend, will be a specific branch, Mitu is creating it now, for front-end, we can use master
[2/17/15, 1:44:15 PM] kungchaowang: but yes, we can also branch out to the same branch name for frontend, just need to frequently merge into master
[2/17/15, 1:44:18 PM] kungchaowang: so, up to you
[2/17/15, 1:45:19 PM] denny: Our deployment code only support one branch for all components.

I guess we may need to update the env on-demand.

If we can use the same branch, the upgrade would be super easy that everyone can do that.
Otherwise, every time Mitu/Robbson may need my help.
[2/17/15, 1:45:57 PM] denny: So I would suggest use the same branch, and merge master of FE to that branch.
#+END_EXAMPLE
* #  --8<-------------------------- separator ------------------------>8--
* TODO Developer request prod env change
#+BEGIN_EXAMPLE
[2/18/15, 9:57:32 AM] Reinaldo: Hi denny
[2/18/15, 9:58:21 AM] denny: Hi Reinaldo
[2/18/15, 9:59:19 AM] Reinaldo: we need to run the script to inactivate users that where removed from AD, on TOTVS context on production
[2/18/15, 9:59:33 AM] Reinaldo: what is the best way and time to do that?
[2/18/15, 10:00:08 AM] denny: We have a dedicated Skype group, discussing “Prod env”’ maintaince.

Let’s discuss there.
[2/18/15, 10:04:18 AM] denny: ============
@Reinaldo, about the change:

Would you please comment the detail procedure in below wiki. So I can take it from there.
    https://totvslab.atlassian.net/wiki/pages/viewpage.action?pageId=48463913
[2/18/15, 10:05:39 AM] Reinaldo: detail on comments?
[2/18/15, 10:06:08 AM] denny: Image
[2/18/15, 10:06:20 AM] denny: Yes, write a comment should be good enough.
[2/18/15, 10:07:20 AM] Reinaldo: what exactly you need me to put there? the steps to run the script?
[2/18/15, 10:08:14 AM] denny: I see. Will you perform the procedure directly?
[2/18/15, 10:08:28 AM] Reinaldo: I don't have access to production
[2/18/15, 10:08:37 AM] Reinaldo: and don't know the backup procedures
[2/18/15, 10:09:07 AM] denny: Then i will do that. So I need enough info to proceed.
[2/18/15, 10:09:36 AM] Reinaldo: ok... i'll put that on the comments on that page
[2/18/15, 10:09:44 AM] denny: Nice
[2/18/15, 10:19:08 AM] Reinaldo: we're doing some more tests to this script today, so I'll talk to you until the end of the day about this
[2/18/15, 10:22:08 AM] denny: Np
[2/18/15, 10:23:46 AM] denny: About when to perform the procedure, would you please sync up with Lucas first?

Normally, we only change prod env after 4 PM PST, to lower the risk.
[2/18/15, 10:27:53 AM] denny: I noticed your comment. It looks good to me. Some replies from me.

https://totvslab.atlassian.net/wiki/pages/viewpage.action?pageId=48463913&focusedCommentId=48890002#comment-48890002
[2/18/15, 10:31:46 AM] Reinaldo: Lucas is on vacation
[2/18/15, 10:32:33 AM] denny: I see
[2/18/15, 10:34:43 AM] Reinaldo: I'm changing the script to provide a list of all the users affected by the script
[2/18/15, 10:34:54 AM] Reinaldo: so we can reactivate them if needed later
[2/18/15, 10:35:00 AM] denny: Nice
[2/18/15, 10:57:38 AM] denny: Hi Reinaldo

About your questions:
We dont have a List, we need to get the ID of TOTVS company (i don't know what it is on Production)

Do you know how we can figure out this?
[2/18/15, 11:00:25 AM] Reinaldo: ok... just a sec...
[2/18/15, 11:02:41 AM] Reinaldo: I don't have access to that...
[2/18/15, 11:03:11 AM] Reinaldo: if you login on production with the ADMIN user, you can access the company and get the ID
[2/18/15, 11:04:21 AM] denny: Do you know the exact company name?
[2/18/15, 11:04:38 AM] denny: Image
[2/18/15, 11:04:50 AM] denny: Here is what I see, after obtaining the admin credential.
[2/18/15, 11:06:08 AM] Reinaldo: TOTVS S/A
[2/18/15, 11:06:29 AM] Reinaldo: the domain should be totvs.fluigidentity.com
[2/18/15, 11:06:45 AM] denny: Image
[2/18/15, 11:07:19 AM] denny: REST API Token

REST API v2

Company ID 	zf0y84vo717g8hjx
Client ID	c9889a3c-4114-4119-ba13-c144649d4423
Download Private Key
REST API v1
[2/18/15, 11:07:33 AM] Reinaldo: yes... that's the one
[2/18/15, 11:08:06 AM] denny: Nice. Do you have the bug number related to this?
[2/18/15, 11:08:44 AM] Reinaldo: CLOUDPASS-6864
#+END_EXAMPLE
* TODO Developer purpose: setup the env
http://10.165.4.67:8088/job/fluigidentity-development-backend/configure
#+BEGIN_EXAMPLE
#!/bin/bash

version_num=$version
deployment_id="${deployment_target}.release"
if [ "$is_snapshot" == "true" ]; then
  version_num="${version}-SNAPSHOT"
  deployment_id="${deployment_target}.snapshot"
fi


echo -e "\n\n========================================\n\n"
echo -e "branch: $branch\n"
echo -e "skip_test parameter: $skip_test\n"
echo -e "version: $version\n"
echo -e "snapshot: $is_snapshot\n"
echo -e "version number: $version_num\n"
echo -e "deployment_target: $deployment_target\n"
echo -e "deployment_id: $deployment_id\n"
echo -e "restart_servers: $restart_servers\n"
echo -e "couchbase bucket name: $couchbase_bucket\n\n\n"


echo -e "git reset --hard"
git reset --hard

echo -e "git checkout $branch\n\n"
git checkout $branch
git pull
git log | head -n 50

# now replace couchbase bucket name
echo -e "current path = $(pwd), now start replace couchbase bucket name\n"
find . -name server.properties | while read f; do
  echo -e "$f\n"
  sed -i.bak 's/cloudpassBucketName=cloudpass/cloudpassBucketName=dev/' $f
done
find . -name ServerConstants.java | while read f; do
  echo -e "$f\n\n"
  sed -i.bak "s/\"cloudpass\"/\"dev\"/" $f
done

# make sure we get correct java home
echo -e "JAVA_HOME=$JAVA_HOME\n\n"
export PATH="$JAVA_HOME/bin:$PATH"
java -version

# print envs
echo -e "\n\n========== Environment Variables ==========\n\n"
env
echo -e "\n\n\n\n"


echo -e "\n\ncopy local_policy.jar and US_export_policy.jar, make sure we always has correct security file after JDK auto-upgrade\n\n"
cp /var/lib/jenkins/jars/local_policy.jar $JAVA_HOME/jre/lib/security/local_policy.jar
cp /var/lib/jenkins/jars/US_export_policy.jar $JAVA_HOME/jre/lib/security/US_export_policy.jar

# make sure we have this global option setup
echo -e "MAVEN_OPTS=-Xmx512m -XX:MaxPermSize=128m -Dmaven.test.skip=false -Dmaven.javadoc.failOnError=false -Dmaven.compiler.source=1.7 -Dmaven.compiler.target=1.7\n\n"
export MAVEN_OPTS="-Xmx512m -XX:MaxPermSize=128m -Dmaven.test.skip=false -Dmaven.javadoc.failOnError=false -Dmaven.compiler.source=1.7 -Dmaven.compiler.target=1.7"


function enable_search {
    find . -name search.yml | while read f; do
       # first enable everything, and change data folder from /tmp/.. to /data/..
       sed 's/enabled: false/enabled: true/g' $f > ${f}.1
       # the enabled flag in inputConfiguration section should be disabled
       sed -e '1,/^inputConfiguration/b' -e 's/enabled: true/enabled: false/;' ${f}.1 > ${f}.2
       # after timeLineConfiguration, enable again
       sed -e '1,/^timeLineConfiguration/b' -e 's/enabled: false/enabled: true/;' ${f}.2 > ${f}.3
       # everything after hornetQServerConfiguration should be disabled
       sed -e '1,/^hornetQServerConfiguration/b' -e 's/enabled: true/enabled: false/g' ${f}.3 > ${f}.local
       rm ${f}.1
       rm ${f}.2
       rm ${f}.3
    done
}

function hide_core_error_output {
    find . -name logback-test.xml | while read f; do
       # if there is a backup file, restore it
       if [ -e ${f}.local ]; then
           cp ${f}.local $f
       fi
       # backup the original file
       cp $f ${f}.local
       sed '/ref="CONSOLE"/d' $f > ${f}.1
       mv $f $f.local
       mv ${f}.1 $f
    done
}

function deploy_rest_client_to_snapshot {
    cd service/rest-client
    mvn deploy:deploy-file \
        -Dfile=target/rest-client-1.0.jar \
        -DpomFile=pom.xml \
        -DrepositoryId=fluigidentity.snapshot \
        -Durl=http://10.165.4.66:8580/repository/totvslabs-release/
    cd -
}

function deploy_idm_common_model_to_snapshot {
    cd idm-common-model
    mvn deploy:deploy-file \
        -Dfile=target/idm-common-model-1.0.jar \
        -DpomFile=pom.xml \
        -DrepositoryId=fluigidentity.snapshot \
        -Durl=http://10.165.4.66:8580/repository/totvslabs-release/
    cd -
}

function kill_adsync_server {
    # kill adsync
    echo "ready to kill existing ADSync server"
    ps -lef | grep -i adsync.jar | grep -v grep
    ps -lef | grep -i adsync.jar | grep -v grep | awk '{print $4}' | while read p; do kill -15 $p; done
}

function kill_rmi_server {
    # kill rmi
    echo "ready to kill existing RMI server"
    ps -lef | grep -i serverstart | grep -i java | grep -v keystore | grep -v grep
    ps -lef | grep -i serverstart | grep -i java | grep -v keystore | grep -v grep | awk '{print $4}' | while read p; do kill -9 $p; done
}

function kill_keystore_server {
    # kill keystore
    echo "ready to kill existing Keystore server"
    ps -lef | grep -i keystoreserverstart | grep -i java | grep -v grep
    ps -lef | grep -i keystoreserverstart | grep -i java | grep -v grep | awk '{print $4}' | while read p; do kill -9 $p; done
}

function kill_search_server {
    # kill search
    echo "ready to kill existing Search server"
    ps -lef | grep -i search.jar | grep -i java | grep -v grep
    ps -lef | grep -i search.jar | grep -i java | grep -v grep | awk '{print $4}' | while read p; do kill -15 $p; done
}

function kill_rest_server {
    # kill rest
    echo "ready to kill existing Rest server"
    ps -lef | grep -i rest.jar | grep -i java | grep -v grep
    ps -lef | grep -i rest.jar | grep -i java | grep -v grep | awk '{print $4}' | while read p; do kill -15 $p; done
}

# delete keystore files if any
rm -Rf core/idmKeyStore
rm -Rf service/rest/idmKeyStore


echo -e "\n\ncopy local_policy.jar and US_export_policy.jar, make sure we always has correct security file after JDK auto-upgrade"
echo $JAVA_HOME
cp /var/lib/jenkins/jars/local_policy.jar $JAVA_HOME/jre/lib/security/local_policy.jar
cp /var/lib/jenkins/jars/US_export_policy.jar $JAVA_HOME/jre/lib/security/US_export_policy.jar
echo -e "\n\n"

# make sure we have this global option setup
export MAVEN_OPTS="-Xmx512m -XX:MaxPermSize=128m -Dmaven.test.skip=false -Dmaven.javadoc.failOnError=false -Dmaven.compiler.source=1.7 -Dmaven.compiler.target=1.7"

# hide the core test console output
hide_core_error_output

# change version number
mvn versions:set -DnewVersion=$version_num
mvn versions:update-child-modules


# remove any existing keystore files (only safe to do it here)
find . -name CloudpassKeystore | xargs rm -Rf
find . -name idmKeyStore | xargs rm -Rf

echo -e "\n\nmvn install -Dmaven.test.skip=$skip_test\n\n"
mvn clean install -Dmaven.test.skip=$skip_test -Dmaven.javadoc.failOnError=false

if [ $? -eq 0 ]; then

    # if we will do test, before integration test, shutdown servers
    if [ "$skip_test" != "true" ]; then
        kill_adsync_server
        kill_rmi_server
        kill_rest_server
        kill_search_server
        kill_keystore_server
    fi

    # integration test
    cd service/rest
    #echo -e "\n\nmvn clean test -Dtest=RestApiTestSuite -DfailIfNoTests=false -Dmaven.test.skip=$skip_test\n\n"
    #mvn clean test -Dtest=RestApiTestSuite -DfailIfNoTests=false -Dmaven.test.skip=$skip_test

    if [ $? -eq 0 ]; then
        # back to top level
        cd -

        # deployment should immediately following clean install, as those jar file still have all resources inside
        # deploy rest-client to snapshot repository
        #deploy_rest_client_to_snapshot

        # deploy idm-common-model to snapshot repository
        #deploy_idm_common_model_to_snapshot

        echo -e "\n\nmvn deploy -P${deployment_id} -Dmaven.test.skip=true\n\n"
        mvn deploy -P${deployment_id} -Dmaven.test.skip=true -Dmaven.javadoc.failOnError=false


        # create report
        echo -e "\n\nmvn site -Ddependency.locations.enabled=false -Dmaven.test.skip=true\n\n"
        mvn site -Ddependency.locations.enabled=false -Dmaven.test.skip=true -Dmaven.javadoc.failOnError=false

        # restart all services if we have a successful build
        if [ $? -eq 0 ]; then

            # make sure jars are copying into correct folder
            echo -e "\n\nchange front-end jar deployment folder to fluigidentity-development-frontend/workspace\n\n"
            #sed -i 's/\.\.\/frontend\/idm-cloudpass/\.\.\/\.\.\/fluigidentity-development-frontend\/workspace\/idm-cloudpass/g' pom.xml
            find . -name pom.xml | xargs grep "frontend/idm-cloudpass" | cut -d":" -f1 | sort | uniq | while read pom; do
                echo -e "\nreplace $pom file from ../frontend/idm-cloudpass to ../../fluigidentity-development-frontend/workspace/idm-cloudpass\n"
                sed -i 's/\.\.\/frontend\/idm-cloudpass/\.\.\/\.\.\/fluigidentity-development-frontend\/workspace\/idm-cloudpass/g' $pom
            done

            echo -e "\n\nremove existing distribution jar files and libraies"
            rm -R build/dist
            rm -R build/lib

            echo -e "\n\nPacking jars"
            echo -e "mvn clean package -Dmaven.test.skip=true -Dmaven.compiler.source=1.7 -Dmaven.compiler.target=1.7 -Pall-jars\n\n"
            mvn clean package -Dmaven.test.skip=true -Dmaven.compiler.source=1.7 -Dmaven.compiler.target=1.7 -Pall-jars

            # enable services and also change property files
            echo "enable search"
            enable_search

            if [ "$restart_servers" == "true" ]; then
                # kill adsync
                kill_adsync_server
                kill_rmi_server
                kill_rest_server
                kill_search_server
                kill_keystore_server
                sleep 30

                echo "pwd = "
                pwd

                cd build/bin

                # start search
                export BUILD_ID=dontKillMe
                echo -e "\n\n\nRun search and hornetQ servers"
                chmod +x search_service_start.sh
                nohup $(pwd)/search_service_start.sh > /tmp/search_service_start.log 2>&1 &
                sleep 20
                ps -lef | grep -i search.jar | grep -i java | grep -v grep

                # start keystore
                export BUILD_ID=dontKillMe
                echo -e "\n\n\nRun keystore server"
                chmod +x keystore_server_start.sh
                nohup $(pwd)/keystore_server_start.sh > /tmp/keystore_server_start.log 2>&1 &
                sleep 20
                ps -lef | grep -i keystoreserverstart | grep -i java | grep -v grep

                # start rmi
                echo -e "\n\n\nRun rmi server"
                chmod +x rmistart_purge.sh
                nohup $(pwd)/rmistart_purge.sh > /tmp/rmistart_purge.log 2>&1 &
                sleep 30
                ps -lef | grep -i serverstart | grep -i java | grep -v keystore | grep -v grep

                # start adsync
                echo -e "\n\n\nRun adsync server"
                chmod +x adsync_service_start.sh
                nohup $(pwd)/adsync_service_start.sh > /tmp/adsync_service_start.log 2>&1 &
                sleep 5
                ps -lef | grep -i adsync | grep -v grep

                # start rest
                export BUILD_ID=dontKillMe
                echo -e "\n\n\nRun rest server"
                chmod +x rest_service_start.sh
                #nohup $(pwd)/rest_service_start.sh > /tmp/rest_service_start.log 2>&1 &
                sleep 20
                #ps -lef | grep -i rest.jar | grep -i java | grep -v grep

                # back to project root
                cd ../..
            else
                echo -e "\n\n\nrestart_servers = $restart_servers, we will not restart any server/services\n\n\n"
            fi

        else

            echo -e "\n\nall backend servers were not restarted as build was failed\n\n"

        fi
    else

        cd -
        echo -e "\n\npackaging action did not perform as build was failed\n\n"
        echo -e "\n\nall backend servers were not restarted as build was failed\n\n"
        exit 1

    fi

else

    echo -e "\n\npackaging action did not perform as build was failed\n\n"
    echo -e "\n\nall backend servers were not restarted as build was failed\n\n"
    exit 1

fi
#+END_EXAMPLE
* TODO TECH-70: Avoid restart critical services during chef update
* TODO When changing something, do the cleanup: log location is changed
#+BEGIN_EXAMPLE
[2/19/15, 5:52:41 PM] Mitu Singh: they are not showing the current logs
[2/19/15, 5:53:19 PM] denny: The racagent log files are no longer in /data/fluigidentity-logs, but under /data/fluigidentity-logs/cloudpass_logs
[2/19/15, 5:53:34 PM] Mitu Singh: I think you can remove the logs under /data/fluigidentity-logs
[2/19/15, 5:54:03 PM] Mitu Singh: so there will be only one directory cloudpass_logs
[2/19/15, 5:54:12 PM] Mitu Singh: and won’t be so confusing
[2/19/15, 5:54:31 PM] denny: Yes, that’s a good idea.
[2/19/15, 5:54:59 PM] denny: I will enforce this for all critical envs today
[2/19/15, 5:55:14 PM] Mitu Singh: thanks Denny
[2/19/15, 5:55:28 PM] denny: You’re welcome, Mitu

And thanks a lot for your patient
[2/19/15, 5:55:38 PM] denny: and improvement suggestions
[2/19/15, 5:55:52 PM] Mitu Singh: you are welcome too:)
#+END_EXAMPLE
* #  --8<-------------------------- separator ------------------------>8--
* TODO Jay Problem
** linkedin problem: 注意影响. Indeed好一些
** Linkedin keep update, to improve the influence
** #  --8<-------------------------- separator ------------------------>8--
** TODO update for current status
** TODO Problem: Remote: want on-site
** TODO Problem: Don't want corp-corp
- 希望转手: Where you are? And what do you need?
- 困难: 猎头不愿意, 手续. subcontract
- rate: 高一些
** #  --8<-------------------------- separator ------------------------>8--
** Problem: visa problem
** Problem: part time?
** Problem: what's the strength
** #  --8<-------------------------- separator ------------------------>8--
** When go to Boston? This March.
* TODO [#A] Talk with Jay: Consutlant VS Dev                      :IMPORTANT:
- If I have a night support, I should be able to take next morning off
- Argument for the night and weekends support
- Argument for feature levels' support
- Don't assume oyur manager know how much time you work? Need solid stastics and evidence
- Kung doesn't know what I do, I give my assginments myself
- Need to ask Kung/Vicente constantly for my clear major goals, instead of detail task items

- Dev: Goal goal is already set up; Need yourself to set up
- Consultant: Decision made. Like when to present, present to who, and how to present
- What's interest in Charge maker
- 活是干不完
- Watch out political conflicts
- 过了十年，谁都不记得做了什么，但是记得和你做事情的感觉
- 不要把consultant弄到少你不可？
- understand system/project expectation?
* TODO [Jay] How to answer recruiters' questions like below
** TODO mail: Re: Congrats Denny!!                                 :noexport:
[[gnus:nnfolder%2Barchive:mail.sent.mail#m2sie41ik7.fsf@gmail.com][Email from Denny Zhang (Tue, 17 Feb 2015 12:47:36 -0600): Re: Congrats Denny!!]]
#+begin_example
From: Denny Zhang <filebat.mark@gmail.com>
Subject: Re: Congrats Denny!!
To: "Heinz Bartesch" <heinz@pcninc.com>
Date: Tue, 17 Feb 2015 12:47:36 -0600
User-Agent: Gnus/5.13 (Gnus v5.13) Emacs/24.4 (darwin)

Hi Heinz

I'm fine with short-term contract or long-term employment.

If full-time employment, the salary actually varies for different
regions and companies, as you know.

I would be OK, if it compete with the average salary of senior DevOps.

Regards,
Denny
--
Denny Zhang(张巍)

A problem well stated is a problem half-solved

                              ,-----._
   .                    .  ,'        `-.__,------._
  //                  __\\\\'                        `-.
 ((    _____-'___))                           |
  `:='/     (   _/                            |
  `.=|      |='                               |
     |)   O |                                  \\
     |      |                               /\\  \\
     |     /                          .    /  \\  \\
     |    .-..__            ___   .--' \\  |\\   \\  |
    |o o  |     ``--.___.  /   `-'      \\  \\\\   \\ |
     `--''        '  .' / /             |  | |   | \\
                       |  | / /              |  | |
                  |  ||  |              | /| |
                  ( .' \\ \\              || | |
                  | |   \\ \\            // / /
                  | |    \\ \\          || |_|
                 /  |    |_/         /_|
                /__/

Tue, 17 Feb 2015 10:20:13 -0800 "Heinz Bartesch" <heinz@pcninc.com>
writes:

> Thanks!
>
> So, if I were able to find a client that would consider remote option, what would your salary
> requirements be in that condition?
>
> Heinz Bartesch
>
> Principal
>
> Professional Consulting Network
>
> San Francisco, CA
>
> Direct 415-820-6347
>
> FAX 415 869-3347
>
>  email: heinz@pcninc.com
>
> website:  www.pcninc.com
>
>  LinkedIn: http://www.linkedin.com/in/hhbartesch
>
>  https://twitter.com/HeadhunterHeinz
>
> http://www.youtube.com/watch?v=tVpQvPFHefI&feature=c4-overview&list=UUN1oQzby5kzVSjgqTcwD1MA
>
> From: Denny Zhang [mailto:filebat.mark@gmail.com]
> Sent: Tuesday, February 17, 2015 10:15 AM
> To: Heinz Bartesch
> Subject: Re: Congrats Denny!!
>
> Heinz
>
> Sure. Here we go.
>
> On Tue, Feb 17, 2015 at 12:12 PM, Heinz Bartesch <heinz@pcninc.com> wrote:
>
> Do I have your most current resume on file?
>
> Heinz Bartesch
>
> Principal
>
> Professional Consulting Network
>
> San Francisco, CA
>
> Direct 415-820-6347
>
> FAX 415 869-3347
>
>  email: heinz@pcninc.com
>
> website:  www.pcninc.com
>
>  LinkedIn: http://www.linkedin.com/in/hhbartesch
>
>  https://twitter.com/HeadhunterHeinz
>
> http://www.youtube.com/watch?v=tVpQvPFHefI&feature=c4-overview&list=UUN1oQzby5kzVSjgqTcwD1MA
>
> From: Denny Zhang [mailto:filebat.mark@gmail.com]
> Sent: Tuesday, February 17, 2015 10:12 AM
> To: Heinz Bartesch
> Subject: Re: Congrats Denny!!
>
> Heinz
>
> Yes, that's right.
>
> DevOps is on high-demand, and most of them want in-house.
>
> I will show my expertise to help us earn the remote opportunities.
>
> So if you have some suitable ones, please let me know.
>
> On Tue, Feb 17, 2015 at 12:07 PM, Heinz Bartesch <heinz@pcninc.com> wrote:
>
> Denny, for you I assume?
>
> It’s finding the ‘remote’ positions that is the challenge. As you know, most companies like to have
> their DevOps guys in house…..
>
> Heinz Bartesch
>
> Principal
>
> Professional Consulting Network
>
> San Francisco, CA
>
> Direct 415-820-6347
>
> FAX 415 869-3347
>
>  email: heinz@pcninc.com
>
> website:  www.pcninc.com
>
>  LinkedIn: http://www.linkedin.com/in/hhbartesch
>
>  https://twitter.com/HeadhunterHeinz
>
> http://www.youtube.com/watch?v=tVpQvPFHefI&feature=c4-overview&list=UUN1oQzby5kzVSjgqTcwD1MA
>
> From: Denny Zhang [mailto:filebat.mark@gmail.com]
> Sent: Tuesday, February 17, 2015 10:05 AM
> To: denny zhang
> Cc: Heinz Bartesch
> Subject: Re: Congrats Denny!!
>
> Hi Heinz
>
> You're one of the most experienced technical recruiter.
>
> If you have any available DevOps + Remote positions on hand, let me know.
>
> Regards,
>
> Denny
>
> On Tue, Feb 17, 2015 at 11:56 AM, denny zhang <denny.zhang001@gmail.com> wrote:
>
> Hi Heinz
>
> Glad to hear you again.
>
> Sure, I will keep an eye for you.
>
> On Thu, Feb 12, 2015 at 11:16 AM, Heinz Bartesch <heinz@pcninc.com> wrote:
>
> Hope the opportunity at TOTVS turns out to be everything you hope and expect, and then some!!
>
> If by the way TOTVS is doing more hiring, I’d love the intro to any hiring manager and would be
> happy to reward you for your efforts!
>
> Thanks and, good luck!! J
>
> Heinz Bartesch
>
> Principal
>
> Professional Consulting Network
>
> San Francisco, CA
>
> Direct 415-820-6347
>
> FAX 415 869-3347
>
>  email: heinz@pcninc.com
>
> website:  www.pcninc.com
>
>  LinkedIn: http://www.linkedin.com/in/hhbartesch
>
>  https://twitter.com/HeadhunterHeinz
>
> http://www.youtube.com/watch?v=tVpQvPFHefI&feature=c4-overview&list=UUN1oQzby5kzVSjgqTcwD1MA
>
> --
>
> Thanks,
> Denny
>
> --
>
> Thanks,
> Denny
>
> --
>
> Thanks,
> Denny

#+end_example
* TODO [Jay] Customer don't want to corp-corp cooperation
* #  --8<-------------------------- separator ------------------------>8--
* TODO When will DNS propogation takes for the whole world understand the CNAME change: In my test, it takes 6 min
[2/23/15, 12:04:45 PM] kungchaowang: the DNS propogation may take several hours
[2/23/15, 12:05:07 PM] kungchaowang: because DNS is in US amazon cloud, for them to be activated to new IPs, it may take time
[2/23/15, 12:05:15 PM] denny: In my test of AWS Router5, it look like only takes ~several minutes
[2/23/15, 12:05:44 PM] denny: Thanks for the remind, Kung.

So it’s ok that we do the CNAME switch 3 PM PST?
[2/23/15, 12:05:48 PM] kungchaowang: you are in US, that maybe true, that’s what I mean, just FYI, I have no clue how much time for Brazil people to see it
[2/23/15, 12:06:03 PM] denny: Oh, I see. Thanks for the remind!


#+BEGIN_EXAMPLE
[2/23/15, 4:57:14 PM] denny: changing CNAME
[2/23/15, 5:03:08 PM] denny: My test shows DNS propagation has finished: from 187.94.63.130 to 187.94.63.141

@Suresh, please help to verify the sanity of new customerfi
https://app.customerfi.com
[2/23/15, 5:03:27 PM] denny: First “ping app.customerfi.com”, make sure it points to “187.94.63.141".
[2/23/15, 5:03:31 PM] Suresh Sathyanarayan: ok i will Denny
#+END_EXAMPLE
* TODO Chef supermarket jira cookbook: postgresql syntax error
http://ourhat.com/?p=129
http://ithelpblog.com/itapplications/install-jira-on-centos/

#+BEGIN_EXAMPLE
       Recipe: postgresql::server

           - execute "bash"  "/tmp/chef-script20150218-2375-1m16qro"
       Recipe: build-essential::_rhel
        (skipped due to action :nothing)
         * package[bison] action nothing (skipped due to action :nothing)
        (skipped due to action :nothing)
         * package[gcc] action nothing (skipped due to action :nothing)
        (skipped due to action :nothing)
         * package[kernel-devel] action nothing (skipped due to action :nothing)
         * package[make] action nothing (skipped due to action :nothing)
        (skipped due to action :nothing)
         * package[patch] action nothing (skipped due to action :nothing)
       Recipe: postgresql::ruby
        (up to date)
       Recipe: jira::local_database

       ================================================================================
       Error executing action `create` on resource 'postgresql_database_user[jira]'
       ================================================================================

       PG::SyntaxError
       ---------------
       ERROR:  syntax error at or near "NOREPLICATION"
       LINE 1: ...bY1EppLZP6GI5Q0Z3U' NOCREATEDB NOCREATEROLE LOGIN NOREPLICAT...
                                                             ^

       Cookbook Trace:
       ---------------
       /tmp/kitchen/cache/cookbooks/database/libraries/provider_database_postgresql_user.rb:53:in `exec'
       /tmp/kitchen/cache/cookbooks/database/libraries/provider_database_postgresql_user.rb:53:in `action_create'

       Resource Declaration:
       ---------------------
       # In /tmp/kitchen/cache/cookbooks/jira/recipes/local_database.rb

        32: postgresql_database_user 'jira' do
        33:   connection postgresql_connection_info
        34:   password node['jira']['local_database']['password']
        35:   action :create
        36: end
        37:

       Compiled Resource:
       ------------------
       # Declared in /tmp/kitchen/cache/cookbooks/jira/recipes/local_database.rb:32:in `from_file'

       postgresql_database_user("jira") do
         provider Chef::Provider::Database::PostgresqlUser
         action [:create]
         retries 0
         retry_delay 2
         guard_interpreter :default
         username "jira"
         host "localhost"
         privileges [:all]
         login true
         cookbook_name "jira"
         recipe_name "local_database"
         connection {:host=>"localhost", :username=>"postgres", :password=>"IHP9aWAclXGuxMV3mXV8"}
         password "qdbY1EppLZP6GI5Q0Z3U"
       end

       Recipe: jira::server

           - restart service service[jira]
       Recipe: postgresql::server_redhat

           - restart service service[postgresql]

       Running handlers:
       [2015-02-18T17:09:14+00:00] ERROR: Running exception handlers
       Running handlers complete
       [2015-02-18T17:09:14+00:00] ERROR: Exception handlers complete
       [2015-02-18T17:09:14+00:00] FATAL: Stacktrace dumped to /tmp/kitchen/cache/chef-stacktrace.out
       Chef Client failed. 41 resources updated in 1112.680769212 seconds
       [2015-02-18T17:09:15+00:00] ERROR: postgresql_database_user[jira] (jira::local_database line 32) had an error: PG::SyntaxError: ERROR:  syntax error at or near "NOREPLICATION"
       LINE 1: ...bY1EppLZP6GI5Q0Z3U' NOCREATEDB NOCREATEROLE LOGIN NOREPLICAT...
                                                             ^

       [2015-02-18T17:09:15+00:00] FATAL: Chef::Exceptions::ChildConvergeError: Chef run process exited unsuccessfully (exit code 1)
>>>>>> Converge failed on instance <default-centos-65>.
>>>>>> Please see .kitchen/logs/default-centos-65.log for more details
>>>>>> ------Exception-------
>>>>>> Class: Kitchen::ActionFailed
>>>>>> Message: SSH exited (1) for command: [sh -c '
sudo -E /opt/chef/bin/chef-client --local-mode --config /tmp/kitchen/client.rb --log_level auto --force-formatter --no-color --chef-zero-port 8889 --json-attributes /tmp/kitchen/dna.json
']
>>>>>> ----------------------
#+END_EXAMPLE
* [#B] web page: Building a Devops team - Agile Sysadmin
http://www.agilesysadmin.net/building-a-devops-team
** webcontent                     :noexport:
#+begin_example
Location: http://www.agilesysadmin.net/building-a-devops-team
Agile Sysadmin

Delivering value through web operations

  * Home
  * Building a Devops team

Building a Devops team

This is a guest post by Brian Henerey, from Sony Computer Entertainment Europe.

Background

I've had 3 roles at Sony since joining in August 2008. Nearly a year ago I took over the management
of the original engineering team I joined. This was a failing team by any definition, but I was
excited about the opportunity to reshape it. I knew the remaining team was deeply unhappy and
likely to quit at any moment, so I had a few immediate goals:

  * Hire!
  * Keep people from quitting.
  * Hire!

Side story: I stumbled on one important objective I didn't list however. Keep customers happy. It
doesn't matter how awesome you think your team can be if no one wants to work with you based on
past experiences. I didn't appreciate how much a demotivated employee could jeopardise customer
relationships by virtue of not caring. It has taken me months to restore trust with one customer.
I've heard a story about a manager offering employees £500 to quit on a regular basis. I think that
probably has some practical problems, but its a tempting idea to cull the unmotivated.

I come from a long background of small/medium size enterprises. It has been a challenge adapting to
a large corporation, but I don't think there's much unique to Sony about the anti-Devops patterns
I've encountered. I know several people in small companies who says they've been practicing Devops
before there was such a word and I completely agree. The trouble of silos, bureaucracy,
organizational boundaries, politics, etc, seem pretty common in larger businesses though. I can't
speak to how to create a Devops culture across a large organisation from the top down, but I've
been working really hard to create one from the inside.

The beginning

A year ago I'd never heard of the term Devops. If you're in the same boat, it is easy to find a
great deal to read about what Devops is:

  * what is this devops thing anyway?
  * what devops means to me
  * Devops and Agile Operations

And what it is not:

  * What devops is not
  * devops is not a technology problem
  * devops not jobtitle
  * devops is not just about automation

However, I suspect some people will have trouble finding the read-worthy gems amongst all the
chatter. Here's a good place to get started: getting started with devops. The gigantic list of
Devops related bookmarks compiled by Patrick Debois shows why you may not want to try and read
everything: devops bookmarks

If you're in the know already and Devops resonates with you, and you want to build a team around
the concept, here's how I went about it.

Networking

The terms Devops didn't really take shape for me until I started to talk about it with others.
Fortunately, London has a really active Devops community so I've had ample opportunity. The
tireless Gareth Rushgrove organises many events, and The Guardian is a frequent host. I've been to
sessions discussing Continuous Integration, Deployments, Google App Engine, Load Balancers, Chef,
CloudFoundry, etc. I've found people to be incredibly open about technology, processes, culture,
difficulties and successes they've had.

While Devops is of course about more than technology and tools, I personally have found Devops to
be an excellent banner under which to have really interesting conversations. Having a forum which
brings people from diverse backgrounds together has helped me shape my own internal understanding
of what Devops should be about.

I felt a bit of an imposter going to the initial London Devops meetups because I was so keen on
recruiting. However, the quality of the discussions has been so good I eagerly anticipate each
upcoming meetup even though I'm no longer hiring. I've also discovered that half the attendees are
also hiring. It's a Devopsee's market.

Result!: I met and subsequently hired Stephen Nelson-Smith from Atalanta-Systems. (He's @Lordcope
on twitter, and the author of agilesysadmin.net

Working definition of Devops

If you're going to hire people with Devops in mind, its good to have a working definition. I like
the pillars of Devops (CAMS) put forth by John Willis: what devops means to me

  * Culture
  * Automation
  * Measurement
  * Sharing

SMAC might have been a better acronym, but I'll go with CAMS.

A Devops job spec

I don't think Devops is a role, though I've seen jobs posting for such a thing. I only mentioned
that I was looking for someone 'Devops-savvy', and later changed it to 'Devops-minded' or something
similar. The job posting expired and I'd have to dig it out, but R.I.Pinearr described in on
Twitter as the 'perfect devops job posting'. I'm pretty keen on revising a job spec until the
requirements are only things I actually require and can measure against. Saying that, how to write
a job spec is way outside the scope of this post. To summarize, I was looking for:

  * problem solving skills
  * 'can do' attitude
  * good team fit (really hard to quantify)
  * a broad set of skills (LAMP, Java, C++, Ruby, Python, Oracle, Scaling/Capacity,
    High-Availability, etc, etc)

My team works on a ton of different technology stacks, and the landscape is constantly changing.
Its a techie-dream job, but the interpersonal skills are the most important.

Recruiters

I strongly believe in giving recruiters a fair bit of my time. I've seen many people be rude to
recruiters, ignore them, etc, and then wonder why they don't get good candidates through. I'm quite
keen on engaging the recruiters, explaining the role I'm trying to fill thoroughly, and having the
occasional coffee or beer with them. Feedback is of course vital to candidates, and I try to give
it honestly and quickly, letting the recruiter worry about sugar coating things.

CV selection

This is tough. I regularly get CV blindness where everyone starts to look the same. And generally
ill-suited. I try to remember there are human beings on the other end and force myself to have
concrete reasons why I'm rejecting someone. Talking to a recruiter about this helps me be concrete.

First interview - remote technical test

This is where things get interesting! I don't know if this is unique to London, but I've had a LOT
of candidates from other countries apply to join this team. If someone has a good CV and the
recruiter vouches for their English language skills, I developed a great screening test which can
be conducted remotely. This saves a trip to London + hotel, and I can end it promptly if things
aren't going well. Here's how it works:

  * I email the candidate/recruiter a url to an ec2 instance that I spin up on the day about 20
    minutes before the interview.
  * The instance is running a web browser which contains instructions for the test. These only
    state that the candidate will need a terminal such as Putty if they're on Windows.
  * At the arranged time I phone the candidate. I explain that there will be two tests. The first
    is a sys admin task which will be time bound to 20 minutes. The second is a programming task
    which they can use the remainder of the time to complete. The call will end after 1 hour.
  * I explain the rules: They are to perform all of their work on the ec2 instance. They have a
    test account/password, and sudo root access. They can use any resources they want to solve the
    problems. Google, man pages, libraries are not only fair game, but fully expected.
  * I explain what I want from them: They need to talk to me, tell me what they are thinking, and
    walk me through the problem solving process. I'm far more interested in that dialogue than
    whether they solve either problem I give them.
  * I also add that we're using Screen, and I can see everything they type.
  * I swap the index.html with the complete instructions in place, make note of the time, and let
    them begin.

The problems

1) Its really quite simple: install Wordpress and configure it to work properly. The catch is that
we install mysql first, break it, and then watch as candidates wonder what the heck is going on.
For an experienced sysadmin this is child's play. I tended to interview people with stronger
development background and less familiar installing applications. I could tell almost immediately
how well someone knew there way around a Linux system. It was interesting to see what kinds of
assumptions people made about the system itself (I never mentioned the OS that was running. Several
just assumed Ubuntu.) Some people read instructions, some don't. I give people the mysqladmin
password, but some people search on how to reset a lost password because they didn't read what I
gave them. I had one guy spend 10 minutes trying to ssh to http://ec2....... I gave him a pass on
nerves, but he continued to suck and I ended it soon there after. He blamed language barrier
(Eastern European), and said if only I had been more clear to him. If I can't communicate with him,
I think that's a pretty big problem and it doesn't really matter who's fault it is.

2) We provide sanitized Production Tomcat logs for a real application we support and ask the
candidate to write a log parsing script in a language of their choice. We want the output of the
script to show methods calls, call counts, frequencies, average and 90% latencies. Our preference
is Ruby, but they can do it however they'd like. I had one candidate choose to implement this in
Bash and was writing some serious regex-fu that I had no idea how it worked. He got stuck however,
and I couldn't help but ask as he claimed to be a Ruby developer why he didn't do it in Ruby, which
was my stated preference. He started over in Ruby and did okay. Depending how much time was spent
on problem 1, this part of the interview is really boring for me. I stay on the phone in case they
have questions, I ask them to explain their approach before they begin coding, but then I just
start checking email/etc. After 60 minutes total is up, I explain to the candidate that they can
continue working on the coding task as long as they need and to send me an email when they've
finished. I get off the phone however, stating that we'll give them feedback as soon as we've
reviewed the code they submit and explain the next steps.

Results

I put several candidates through this process. In the beginning of creating this test, I'd have a
couple members of my team on this call as well, but we found this too time consuming and a bit
intimidating to certain candidates. Timeboxing problem 1 was a HUGE improvement, and once Stephen
Nelson-Smith was on board I had someone better than me at evaluating the Ruby code. We all felt
this test process was extremely revealing of candidates skillsets and I highly recommend it.

One of my favourite candidates conducted this interview on a laptop in the shared wifi area of a
crowded and noisy London hostel. In the background were screaming people and overbearing Christmas
music. He was able to tune out the distractions and nailed both problems with ease, and got major
bonus points for doing so.

Round 2 - Face to face interview

Round 2 actually has a few parts:

  * Coffee/lunch/dinner informal chat up to 1 hour in length. I explain what I'm looking for; they
    can talk about themselves; we can find out if we have a good match.
  * Hypothetical whiteboard problem solving exercise: You receive a call saying customer goes to
    http://yoursite.com and gets a blank page. What do you do next? We can improvise a bit here on
    what the actual problem is, but we're hoping to learn two things: How does this person approach
    problem solving? What level of architectural complexity have they been exposed to?
  * 2 hours of pair programming with a member of my team. This is usually a real bit of work that
    needs doing. It could be writing a chef cookbook, or a cucumber test, etc. We want to learn
    what its like to work closely with this person. My team pair programs often. Do we want to pair
    with this person day in / day out?

Round 3 - my boss + any member of my team who hasn't met the candidate yet.

  * This is generally very open, though my boss has her own techniques for evaluating people.

Its very important to me that everyone on my team have a voice. I was quite keen on one candidate,
but when one of my team member's voiced vague concerns about the person's team-fit, we all stopped
and took it on board. We rejected the candidate in the end because once the first doubts were out
in the open, other people's concerns started to be raised as well. I recognised that I was a bit
too keen to hire someone to fill a pressing need and am glad how things worked out..

A GREAT candidate/hire

One of my favourite hires not only does he know C, Java, and Linux, but wrote a sample Ruby
application because he knew we were looking to hire Ruby skills within the team. His app worked out
the shortest path between tube stations, though only in terms of number of stops, not time
travelled. This initiative told me a lot about him, and its been 100% the same since he joined the
team. Eager to learn and try new things. Any problem/task put in front of him is 'easy'. My only
trouble is he tends to consider problems solved when he's worked out in his head how he will solve
it. This is a bit of a joke really. I accused him the other day of declaring checkmate on a task
because he was so confident it would be completed in his next 7 seven steps.

Beyond hiring

Now what? Well, hiring the right people is HUGE. We celebrated each hire, as opposed to the typical
'leaving drinks' when people move on. How I manage the team will be a future blog post (I hope),
but I'll add one quick comment. Hiring people according to the vision I had means that I am held
accountable as well. Whenever I find myself explaining that the reason for a decision I'm making is
'politics', I know I have to change.

About the author

Image

Brian Henerey heads up Operations Engineering in the Online Technology Group at Sony Computer
Entertainment Europe. His passions include Devops, Tool-chains, Web Operations, Continuous Delivery
and Lean thinking. He's currently building automated infrastructure pipelines with Ruby, Chef, and
AWS, enabling self-service, just-in-time development and test environments for Sony's Worldwide
Studios.

Image Image

Published on 25 May 2011 in Agile, Devops, System Administration

View comments.

Articles by category

  * System Administration
  * Ruby
  * Red Hat
  * Python
  * Puppet
  * Psychology
  * Productivity
  * Monitoring
  * Linux
  * Emacs
  * Devops
  * Chef
  * CentOS
  * AWS
  * Agile

Subscribe to our feed

About Agile Sysadmin

This is the blog of Atalanta Systems, specialists in implementing systems automation and lean
practices to maximise the value of operations.

You can follow Atalanta CEO, Helena, on twitter here.

And Stephen, Principal Consultant, here.

Powered by Nesta, a Ruby CMS. Design by Stephen Nelson-Smith.

#+end_example
* #  --8<-------------------------- separator ------------------------>8--
* TODO [#A] Track skype message, understand how is contacting you every day, and identity useless contact
* TODO [#B] Tracke release changes: analysis git commit history for each new release
http://www.agileweboperations.com/code-inventory-and-tracking-releases
* web page: Deploy ALL the Things - blog dot lusis
http://blog.lusis.org/blog/2011/10/18/deploy-all-the-things/
** webcontent                     :noexport:
#+begin_example
Location: http://blog.lusis.org/blog/2011/10/18/deploy-all-the-things/
blog dot lusis

development, operations and everything in between

  * RSS

[                    ]
  * Blog
  * Archives
  * Projects
  * Noah

Deploy ALL the Things

Oct 18th, 2011 | Comments

This is part 2 in a post on deployment strategies. The previous post is located here

My previous post covered some of the annoying excuses and complaints that people like to use when
discussing deployments. The big take away should have been the following:

  * The risk associated with deploying new code is not in the deploy itself but everything you did
    up to that point.
  * The way to make deploying new code less risky is to do it more often, not less.
  * Create a culture and environment that enables and encourages small, frequent releases.
  * Everything fails. Embrace failure.
  * Make deploys trivial, automated and tolerant of failure.

I want to make one thing perfectly clear. I’ve said this several times before. You can get 90% of
the way to a fully automated environment, never go that last 10% and still be better off than you
were before. I understand that people have regulations, requirements and other things that prevent
a fully automated system. You don’t ever have to flip that switch but you should strive to get as
close as possible.

Understanding the role of operations

Operations is an interesting word. Outside of the field of IT it means something completely
different than everywhere else in the business world. According to Wikipedia:

    Business operations encompasses three fundamental management imperatives that collectively aim
    to maximize value harvested from business assets

      + Generate recurring income

      + Increase the value of the business assets

      + Secure the income and value of the business

IT operations traditionally does nothing in that regard. Instead IT operations has become about
cock blocking and being greybeareded gatekeepers who always say “No” regardless of the question. We
shunt the responsibility off to the development staff and then, in some sick game of ‘fuck you’, we
do all we can to prevent the code from going live. This is unsustainable; counter-productive; and
in a random twist of fate, self destructive.

One thing I’ve always tried to get my operations and sysadmin peers to understand is that we are
fundamentally a cost center. Unless we are in the business of managing systems for profit, we
provide no direct benefit to the company. This is one of the reasons I’m so gung-ho on automation.
John Willis really resonated with me in the first Devops Cafe podcast when he talked about the 80/
20 split. Traditionally operations staff spends 80% of its time dealing with bullshit fire-fighting
muck and 20% actually providing value to the business. The idea that we can flip that and become
contributing members of our respective companies is amazing.

Don’t worry. I’ll address development down below but I felt it was important to set my perspective
down before going any further.

Technical Debt and Risk Management

Glancing back to my list of take-aways from the last post, I make a pretty bold (to some people)
statement. When I say that deploy risk is not the deploy itself but everything up to that point,
I’m talking about technical debt.

Technical debt takes many forms and is the result of both concious, deliberate choices as well as
unintended side-effects. Some examples of that are:

  * Lack of or insufficient testing and associated
  * Overreliance on time consuming manual processes
  * Shortcuts to meet deadlines - both artifical and real
  * Violation of the 10-minute maxim
  * Technological choices
  * Cultural choices
  * Fiscal limitations

All of these things can lead to technical debt - the accumulation of dead bodies in the room as a
byproduct of how we work. At best, someone at least acknowledges they exist. At worst, we stock up
on clothespins, pinch our nostrils shut and hope no one notices the stench. Let’s address a couple
of foundational things before we get into the fun stuff.

Testing

Test coverage is one of the easiest ways to manage risk in software development. One of the first
things to go in a pinch is testing. Even that assumes that testing was actually a priority at some
point. I’m not going to harp on things like 100% code coverage. As I said previously, humans tend
to overcompensate. Test coverage is also, however, one of the easiest places to get your head above
water. If you don’t have a culture of committment to testing, it’s hard but not impossible to get
started. You don’t have to shutdown development for a week.

 1. Start by having a commitment to write tests for any new code going forth.
 2. As bugs arise in untested code, make a test case for the bug a requirement to close the bug.
 3. Find a small victory in existing code. Create test coverage for low hanging fruit.
 4. Plan for a schedule to cover any remaining code

The key here is baby steps. Small victories. Think Fezzik in ‘The Princess Bride’ - “I want you to
feel like you’re winning”.

Testing is one of the foundations you have to have to reach deploy nirvana. System administrators
have a big responsiblity here. Running tests has to be painless, unobstrusive and performant. You
should absolutely stand up something like Jenkins that actually runs your test suite on check-in.
As that test suite grows, you’ll need to be able to provide the capacity to grow with it. That’s
where the next point can be so important.

Manual processes

Just as testing is a foundation on the code side, operations has a commensurate responsibility to
reduce the number of human hands involved with creating systems. We humans, despite the amazing
potential that our brains provide, are generally stupid. We make mistakes. Repeatability is not
something we’re good at. Some sort of automated and repeatable configuration management strategy
needs to be adopted. As with testing, you can make some amazing progress in baby steps by
introducing some sort of proper configuration management going forward. I don’t recommend you
attempt to retrofit complex automation on top of existing systems beyond some basics. Otherwise
you’ll be spending too much time trying to differentiate between “legacy” and “new” servers roles.
If you are using some sort of virtualization or cloud provider like EC2, this is a no brainer. It’s
obviously a bit harder when you’re using physical hardware but still doable.

Have you ever played the little travel puzzle game where you have a grid of moving squares? The
idea is the same. You need just ONE empty system that you can work with to automate. Pick your
simplest server role such as an apache webserver. Using something like Puppet or Chef, write the
‘code’ that will create that role. Don’t get bogged down in the fancy stuff the tools provide. Keep
it simple at first. Once you think you’ve got it all worked out, blow the server away and apply
that code from bootstrap. Red, green, refactor. Once you’re comfortable that you can reprovision
that server from bare metal, move it into service. Make sure you have your own set of ‘test cases’
that ensure the provisioned state is the correct one. This will become important later on.

Take whatever server it’s replacing and do the same for the next role. When I came on board with my
company I spent many useless cycles trying to retrofit an automation process on top of existing
systems. In the end, I opted to take a few small victories (using Chef in this case):

 1. Create a base role that is non-destructive to existing configuration and systems. In my case,
    this was managing yum repos and user accounts.
 2. Pick the ‘simplest’ component in our infrastructure and start creating a role for it.
 3. Spin up a new EC2 instance and test the role over and over until it works.
 4. Terminate the instance and apply the role on top with a fresh one.
 5. Replace the old instances providing that role with the new ones and move to the next role.

Using this strategy, I was able to replace all of our legacy instances for the first and second
tiers of our stack in a couple of months time. We are now at the point where, assuming Amazon plays
nice with instance creation, we can have any role in those tiers recreated at a moment’s notice.
Again, this will directly contribute to how we mitigate risk later on.

10 minute maxim

I came up with this from first principles so I’m sure there’s a better name for it. The idea is
simply this:

    Any problem that has to be solved in five minutes can be afforded 10 minutes to think about the
    solution.

System Administrators often pride ourselves on how cleverly and quickly we can solve a problem.
It’s good for our egos. It’s not, however, good for our company. Take a little extra time and
consider the longer term impact of what solution you’re about to do. Step away from the desk and
move. Consult peers. Many times I’ve come to the conclusion that my first instinct was the right
one. However more often than not, I’ve come across another solution that would create less
technical debt for us to deal with later.

A correlary to this is the decision to ‘fix it or kick it’. That is ‘Do we spend an unpredictable
amount of time trying to solve some obscure issue or do we simply recreate the instance providing
the service from our above configuration management’. If you’ve gone through the previous step, you
have should have amazing code confidence in your infrastructure. This is very important to have
with Amazon EC2 where you can have an instance perform worse overtime thanks to the wonders of
oversubscription and noisy neighbors.

Fuck that. Provision a new instance and run your smoke tests (I/O test for instance). If the smoke
tests fail, throw it away and start a new one. It’s amazing the freedom of movement afforded by
being able to describe your infrastructure as code.

Getting back to deploys

I would say that without the above, most of the stuff from here on out is pretty pointless. While
you CAN do automated and non-offhour deploys without the above, you’re really setting yourself up
for failure. Whether it’s a system change or new code, you need to be able to ensure that that some
baseline criteria can be met. Now that we’ve got the foundation though, we can build on it and
finally adopt some distinct strategies for releases.

Building on the foundation

The next areas you need to work on are a bit harder.

Metrics and monitoring

Shooting in the dark sucks. Without some sort of baseline metric, you authoritatively say whether
or not a deploy was ‘good’. If it moves, graph it. If it moves, monitor it. You need to leverage
systems like statsd (available in non-node.js flavors as well) that can accept metrics easily from
your application and make them availabile in the amazing graphite.

The key here is that getting those metrics be as frictionless as possible. To fully understand
this, watch this presentation from Coda Hale of Yammer. Coda has also created a kick-ass metrics
library for the JVM and others have duplicated his efforts in their respective languages.

Backwards compatibility

You need to adopt a culture of backwards compatibility between releases. This is not Microsoft
levels we’re talking about. This affects interim releases. As soon as you have upgraded all the
components, you clean up the cruft and move on. This is critical to getting to zero/near-zero
downtime deploys.

Reduce interdependencies

I won’t go into the whole SOA buzzword bingo game here except to say that treating your internal
systems like a third party vendor can have some benefits. You don’t need to isolate the teams but
you need to stop with shit like RMI. Have an established and versioned interface between your
components. If component A needs to make a REST call to component B, upgrades to the B API should
be versioned. A needs version 1 of B’s api. Meanwhile new component C can use version 2 of the API.

Automation as a default

While this ties a lot into the testing and configuration management topics, the real goal here is
that you adopt a posture of automation by default. The reason for this should be clear in Eric
Ries’ “Five Whys” post:

    Five Whys will often pierce the illusion of separate departments and discover the human
    problems that lurk beneath the surface of supposedly technical problems.

One of the best ways to eliminate human problems is to take the human out of the problem. Machines
are very good at doing things repeatedly and doing them the same way every single time. Humans are
not good at this. Let the machines do it.

Deploy Strategies

Here are some of the key strategies that I (and others) have found effective for making deploys a
non issue.

Dark Launches

The idea here is that for any new code path you insert in the system, you actually exercise it
before it goes live. Let’s face it, you can never REALLY simulate production traffic. The only way
to truly test if code is performant or not is to get it out there. With a dark launch, you’re still
making new database calls but using your handy dandy metrics culture above, you now know how
performant it really is. When it gets to acceptable levels, make it visible to the user.

Feature flags

Feature flags are amazing and one of the neat tricks that people who perform frequent deploys
leverage. The idea is that you make aspects of your application into a series of toggles. In the
event that some feature is causing issues, you can simply disable it through some admin panel or
API call. Not only does this let you degrade gracefully but it also provides for a way to A/B test
new features. With a bit more thought put into the process, you can enable a new feature for a
subset of users. People love to feel special. Being a part of something like a “beta” channel is an
awesome way to build advocates of your system.

Smoke testing at startup

This is one that I really like. The idea is simply that your application has a basic set of ‘tests’
it runs through at startup. If any of those tests fail, the code is rolled back.

Now this is where someone will call me a hypocrite because I said you should and can never really
roll back. You’re partially right. In my mind, however, it’s not the same thing. I consider code
deployed once it’s taken production traffic. Up until that point, it’s just ‘pre-work’ essentially.
Let’s take a random API service in our stack. I’m assuming you have two API servers in this case.

  * Take one out of service
  * Deploy code
  * Smoke tests run
  * If smoke tests fail, stop new code and start old code
  * If smoke tests pass, start sending production traffic to server
  * If acceptable, push to other server
  * profit!

Now you might see a bit of gotcha there. I intentionally left out a step. This is a bit different
than how shops like Wealthfront do it. They actually DO roll back if production monitoring fails.
My preference is to use something similar to em-proxy to do a sort of mini-dark launch before
actually turning it over to end-users. You don’t have to actually use em-proxy. You could write
your own or use something like RabbitMQ or other messaging system. This doesn’t always work
depending on the service the component is providing but it does provide another level of ‘comfort’.

Of course this only works if you maintain backwards compatibility.

Backwards Compatibility

This is probably the hardest of all to accomplish. You may be limited by your technology stack or
even some poor decision made years ago. Backwards compatibility also applies to more than just your
software stack. This is pretty much a critical component of managing database changes with zero
downtime.

Code related

Your code needs to understand ‘versions’ of what it needs. If you leverage some internal API, you
need to maintain support for an older version of that API until all users are upgrade. Always be
deprecating and NEVER EVER redefine what something means. Don’t change a property or setting that
means “This is my database server hostname” to “This is my mail server hostname”. Instead create a
new property, start using it and remove the old on in a future release. Don’t laugh, I’ve seen this
done. As much as I have frustrations with Java, constructor overloading is a good example of
backwards compatibility.

Database related

Specifically as it relates to databases, consider some of the following approaches:

  * Never perform backwards incompatible schema changes.
  * Don’t perform ALTERs on really large tables. Create a new table that updated systems use and
    copy on read to the new table. Migrate older records in the background.
  * Consider isolating access to a given table via a service. Instead of giving all your
    applications access to the ‘users’ table, create a users service that does that.
  * Start exercising code paths to new tables early by leveraging dark launches

Some of these techniques would make Codd spin in his grave.

We’re undergoing a similar situation right now. We originally stored a large amount of ‘blob’ data
in Voldemort. This was a bit perplexing as we were already leveraging S3 for similar data. To
migrate that data (several hundred gigs) we took the following approach:

  * Deploy a minor release that writes and new data to both Voldemort and S3.
  * Start a ‘copy’ job in the background to migrate older data
  * Continue to migrate data
  * When the migration is finished, we’ll deploy a new release that uses S3 exclusively
  * Profit (because we get to terminate a few m1.large EC2 instances)

This worked really well in this scenario. These aren’t new techniques either. Essentially, we’re
doing a variation of a two-phase commit.

Now you might think that all this backwards compatibility creates cruft. It does. Again, this is
something that requires a cultural shift. When things are no longer needed, you need to clean up
the code. This prevents bloat and makes understanding it down the road so much easier.

Swinging like a boss

Here’s another real world example:

Our code base originally used a home-rolled load balancing technique to communicate with one of our
internal services. Additionally, all communication happened over RPC using Hessian. Eventually this
became untenable and we decided to move to RabbitMQ and JSON. This was a pretty major change but at
face value, we should have been able to manage with dual interfaces on the provider of the service.
That didn’t happen.

You see, to be able to use the RabbitMQ libraries, we had to upgrade our version of Spring. Again,
not a big deal. However our version of Hessian was so old that the version of Hessian we would have
to use with the new version of Spring was backwards incompatible. This is yak shaving at its
finest, folks. So basically we had to upgrade 5 different components all at once just to get to
where we wanted and NEEDED to be for the long term.

Since I had already finished coding our chef cookbooks, we went down the path of duplicating our
entire front-end stack. What made this even remotely possible was the fact that we were using
configuration management in the first place. Here’s how it went down:

  * Duplicate the various components in a new Chef environment called ‘prodB’
  * Push new code to these new components
  * Add the new components to the ELBs and internal load balancers for a very short 5-10 minute
    window. Sort of a mini-A/B test.
  * Check the logs for anything that stood out. Validated the expected behavior of the new systems.
    Thsi also gave us a chance to ‘load-test’ our rabbitmq setup. We actually did catch a few small
    bugs this way.

Once we were sure that things looked good, we swung all the traffic to the new instances and pulled
the old ones out. We never even bothered to upgrade the old instances. We just shut them down.

Obviously this technique doesn’t work for everyone. If you’re using physical hardware, it’s much
more costly and harder to pull off. Even internally, however, you can leverage virtualization to
make these kinds of things possible.

Bitrot

What should be the real story in this is that bitrot happens. Don’t slack on keeping third-party
libraries current. If a third-party library introduces a breaking change and it affects more than
one part of your stack, you probably have a bit too tight of a coupling between resources.

Wrap up/Take away

This post came out longer than I had planned. I hope it’s provided you with some information and
things to consider. Companies of all shapes, markets and sizes are doing continuous deployment,
zero downtime deploys and all sorts of things that we never considered possible. Look at companies
like Wealthfront, IMVU, Flickr and Etsy. Google around for phrases like ‘continuous deployment’ and
‘continuous delivery’.

I’m also painfully aware that even with these tricks, some folks simply cannot do them. There are
many segments of industry that might not even allow for this. That doesn’t mean that some of these
ideas can’t be implemented on a smaller scale.

Posted by John E. Vincent Oct 18th, 2011 Deploy, DevOps, Strategy, Tooling

Tweet

« Rollbacks and other deployment myths Github Trolling for Fun and Profit »

Comments

Please enable JavaScript to view the comments powered by Disqus.

About my Blogger blog

I'm currently in the process of migrating content from my blogger blog into Octopress. As such,
this all seems pretty threadbare. If you're curious, you can get to it here

Recent Posts

  * A few things
  * systemd-redux
  * Software Empathy
  * The End of Linux
  * berks

Github Repos

  * Status updating...

@lusis on Github

Latest Tweets

  * Status updating...

Follow @lusis

Copyright © 2014 - John E. Vincent - Powered by Octopress

#+end_example
* web page: On Being A Senior Engineer | Kitchen Soap
http://www.kitchensoap.com/2012/10/25/on-being-a-senior-engineer/
** webcontent                     :noexport:
#+begin_example
Location: http://www.kitchensoap.com/2012/10/25/on-being-a-senior-engineer/
[cropped-he]

Kitchen SoapThoughts on systems safety, capacity planning, and web operations.

Kitchen Soap

  * About Me
  * Talks
  * Books
  * Complex Systems
  * Human Factors
  * WebOps

[-- Menu --     ]
On Being A Senior Engineer

  * 25. Oct
  * /
  * Culture, Etsy, Human Factors, Random, WebOps
  * /
  * 124 Comments

I think that there’s a lot of institutional knowledge in our field, especially about what makes for
a productive engineer. But while there are a good deal of books in the management field about
“expert” roles and responsibilities of non-technical individual contributors, I don’t see too many
modern books or posts that might shed light directly on what makes for a good senior engineer. One
notable exception is of course Kate Matsudaira, who has been posting quite a good deal recently
about the cultural sides of engineering.

Yet at the same time, a good lot of successful engineers whom I have known all remember the mentor
who taught them what it meant to be “senior”.

I do, however, agree 100% with my friend Theo’s words about being “senior” in his chapter of the
Web Operations book by O’Reilly:

    “Generation X (and even more so generation Y) are cultures of immediate gratification. I’ve
    worked with a staggering number of engineers that expect the “career path” to take them to the
    highest ranks of the engineering group inside 5 years just because they are smart. This is
    simply impossible in the staggering numbers I’ve witnessed. Not everyone can be senior. If,
    after five years, you are senior, are you at the peak of your game? After five more years will
    you not have accrued more invaluable experience? What then? “Super engineer”? Five more years?
    “Super-duper engineer.” I blame the youth of our discipline for this affliction. The truth is
    that there are very few engineers that have been in the field of web operations for fifteen
    years. Given the dynamics of our industry many elected to move on to managerial positions or
    risk an entrepreneurial run at things.”

He’s right: this field of web operations is still quite young. So we can’t be surprised when people
who have a title of ‘senior’ exhibit unsurprisingly immature behavior, both technical and
non-technical. If you haven’t read Theo’s chapter, I suggest you do.

Having said that, what does it actually mean to be ‘senior’ in this discipline? I certainly have an
opinion of what it means, given that I’m charged with hiring, supporting, and retaining engineers
whom are deemed to be senior. This notion that there is a bar to be passed in terms of career
development is a good one, but I’d also add that these criteria exist on a spectrum, as opposed to
a simple list of check-boxes. You don’t wake up one day and you are “senior” just because your
title reflects that upon a promotion. Senior engineers don’t know everything. They’re not perfect
in their technical knowledge, and they’re OK with that.

In order not to confuse titles with expectations that are fuzzy, sometimes I’ll refer to
engineering maturity.

Meaning: I expect a “senior” engineer to be a mature engineer.

I’m going to gloss over the part where one could simply list the technical areas in which a mature
engineer should have some level of mastery or understanding (such as “Networking”, “Filesystems”,
“Algorithms”, etc.) and instead highlight the personal characteristics that in my mind give me
indication that someone can influence an organization or a business positively in the domain of
engineering.

Over on Quora, someone once asked me “What are the attributes (other than technical ability/
experience) that makes a great VP of Technical Operations?”. The list of attributes that I
mentioned in the answer came with the understanding that they are perpetual aspirations of my own.
This post is similar to that answer.

I might first argue that senior engineers in web development and operations have the same
characteristics as senior engineers in other fields of engineering (mechanical, electrical,
chemical, etc.) in which case The Unwritten Laws of Engineering are applicable. Again, if you
haven’t read this, please go do so. It was originally written in 1944, published by the American
Society of Mechanical Engineers. A good excerpt from the book is here.

While the book’s structure and prose still has a dated feel (“…refrain from using profanity in the
workplace…” or “…men should pay particular attention to shaving habits and the trimming of beards
and mustaches…”), it gives a good outline of the non-technical expectations, responsibilities, and
inner workings of an engineering organization with respect to how both managers and mature
engineers might behave.

Obligatory Pithy Characteristics of Mature Engineers

All posts that attempt to give insight to aspirational characteristics must have an over-abundance
of bullet points, and the field of engineering has a fair share of them. Therefore, I’m going to
give you some, some mine and some pulled from various sources, many from the Unwritten Laws
mentioned above.

Mature engineers seek out constructive criticism of their designs.

Every successful engineer I’ve met, upon finishing up a design or getting ready for a project, will
continually ask their peers questions along the lines of:

  * “What could I be missing?”
  * “How will this not work?”
  * “Will you please shoot as many holes as possible into my thinking on this?”
  * “Even if it’s technically sound, is it understandable enough for the rest of the organization
    to operate, troubleshoot, and extend it?”

This is because they know that nothing they make will ever only be in their hands, and that good
peer review is what makes better design decisions. As it’s been said elsewhere, they “beg for the
bad news.”

Mature engineers understand the non-technical areas of how they are perceived.

Being able to write a Bloom Filter in Erlang, or write multi-threaded C in your sleep is
insufficient. None of that matters if no one wants to work with you. Mature engineers know that no
matter how complete, elegant, or superior their designs are, it won’t matter if no one wants to
work alongside them because they are assholes. Condescension, belittling, narcissism, and
ego-boosting behavior send the message to other engineers (maybe tacitly) to stay away. Part of
being happy in engineering comes from enjoying the company of the people you work with while
designing and building things. An engineer who is quick to call someone a moron is someone destined
to stunt his or her career.

This also means that mature engineers have self-awareness when it comes to their communication.
This isn’t to say that every mature engineer communicates perfectly, only that they have some
notion about where they could be better, and continually ask for a gut-check from peers and
managers on how they’re doing. They aim to be assertive, not passive or aggressive in how they get
their ideas across.

I’ve mentioned it elsewhere, but I must emphasize the point more: the degree to which other people
want to work with you is a direct indication on how successful you’ll be in your career as an
engineer. Be the engineer that everyone wants to work with.

Now this isn’t to say that you should shy away from giving (or getting) constructive criticism on
the work produced by engineering (as opposed to the engineer personally), for fear of pissing
someone off. There’s a difference between calling someone a moron and pointing out faults in their
code or product. In a conversation with Theo, he pointed out another possible area where our field
may grow up:

    “We as an industry need to (of course) refrain from critiques of human character and condition,
    but not shy away from critiques of work product. We need to get tougher skin and be able to
    receive critique through a lens that attempts to eliminate personal focus.

    There will be assholes, they should be shunned. But the attitude that someone’s code is their
    baby should come to an end. Code doesn’t have feelings, doesn’t develop complexes and certainly
    doesn’t exhibit the most important trait (the ability to reproduce) of that which carries for
    your genetic strains.”

See also below #2 and #10 in The Ten Commandments of Egoless Programming.

I think this has a corollary from the Unwritten Laws (emphasis mine):

    Be careful about whom you mark for copies of letters, memos, etc., when the interests of other
    departments are involved.

    A lot of mischief has been caused by young people broadcasting memorandum containing damaging
    or embarrassing statements. Of course it is sometimes difficult for a novice to recognize the
    “dynamite” in such a document but, in general, it is apt to cause trouble if it steps too
    heavily upon someone’s toes or reveals a serious shortcoming on anybody’s part. If it has wide
    distribution or if it concerns manufacturing or customer difficulties, you’d better get the
    boss to approve it before it goes out unless you’re very sure of your ground.

This of course underscores the dated feel of the book, but in the modern era, I still believe the
main point to be true. Nothing indicates that you have a lack of perspective and awareness like a
poorly thought out and nonconstructive tweet that slings venomous insults. It’s a junior engineer
mistake to toss insults about a piece of complex technology in 140 characters.

I certainly (much like Christopher Brown mentioned in his keynote at Velocity London) pay attention
to those sorts of public remarks when I come across them so that I can note who I would reconsider
hiring if they ever applied to work at Etsy.

Mature engineers do not shy away from making estimates, and are always trying to get better at it.

From the Unwritten Laws:

    Promises, schedules, and estimates are necessary and important instruments in a well-ordered
    business. Many engineers fail to realize this, or habitually try to dodge the irksome
    responsibility for making commitments. You must make promises based upon your own estimates for
    the part of the job for which you are responsible, together with estimates obtained from
    contributing departments for their parts. No one should be allowed to avoid the issue by the
    old formula, “I can’t give a promise because it depends upon so many uncertain factors.”

Avoiding responsibility for estimates is another way of saying, “I’m not ready to be relied upon
for building critical pieces of infrastructure.” All businesses rely on estimates, and all
engineers working on a project are involved in Joint Activity, which means that they have a
responsibility to others to make themselves interpredictable. In general, mature engineers are
comfortable with working within some nonzero amount of uncertainty and risk.

Mature engineers have an innate sense of anticipation, even if they don’t know they do.

This code looks good, I’m proud of myself. I’ve asked other people to review it, and I’ve taken
their feedback. Now: how long will it last before it’s rewritten? Once it’s in production, how will
its execution affect resource usage? How much so I expect CPU/memory/disk/network to increase or
decrease? Will others be able to understand this code? Am I making it as easy as I can for others
to extend or introspect this work?

Mature engineers understand that not all of their projects are filled with rockstar-on-stage work.

    However menial and trivial your early assignments may appear, give them your best effort.

Getting things done means doing things you might not be interested in. No matter how sexy a project
is, there are always boring tasks. Tedious tasks. Tasks that a less mature engineer may deem
beneath their dignity or their job title. My good friend Kellan Elliot-McCrea (Etsy’s CTO) had this
to say about it:

    “Sometimes the saving grace of a tedious task is their simplicity and maturity manifests in
    finishing them quickly and moving on. Sometimes tasks are tedious because they require extreme
    discipline and malleable attention span. It’s an odd phenomena that the most tedious tasks,
    only to be carried out by the most senior engineers, can also be the most terrifying.”

Mature engineers lift the skills and expertise of those around them.

They recognize that at some point, their individual contribution and potential cannot be exercised
singularly. They recognize that there is only so much that can be produced by a single person, and
the world’s best engineering feats are executed by teams, not singularly brilliant and lone
engineers. Tom Limoncelli makes this point quite well in his post.

At Etsy we call this a “generosity of spirit.” Generosity of spirit is one of our core engineering
values, but also a primary responsibility of our Staff Engineer position, a career-level position.
These engineers spend the time to make sure that more junior or new engineers unfamiliar with the
tech or processes we have not only understand what they are doing, but also why they are doing it.
“Teaching to fish” is a mandatory skill at this level, and that requires having both patience and a
perspective of investment in the rest of the organization.

Therefore instead of: “OK, move over, lemme just do it for you”, it’s instead: “Ok, let’s work on
this together. I can show you how I’m writing/troubleshooting/etc. Then, you do it so I can be sure
you know why/how we’re doing it this way, etc.”

Related: see below about getting credit.

Mature engineers make their trade-offs explicit when making judgements and decisions.

They realize all engineering decisions, implementations, and designs exist within a spectrum; we do
not live in a binary world. They can quickly point out contexts where one successful approach or
solution could work and where it could not. They know that one cannot be both efficient and
thorough at the same time (The ETTO Principle), that most projects engineers work on exist on an
axis of optimality and brittleness, and that whether the problems they are solving are acute or
chronic.

They know that they work within a spectrum of ideal and non-ideal, and are OK with that. They are
comfortable with it because they strive to make the ideal and non-ideal in a design explicit. Later
on in the lifecycle of a design, when the original design is not scaling anymore or needs to be
replaced or rewritten, they can look back not with a perspective of how short-sighted those earlier
decisions were, but instead say “yep, we made it this far with it and knew we’d have to extend or
change it at some point. Looks like that time is now, let’s get to work!” instead of responding
with a cranky-pants, passive-aggressive Hindsight Bias-filled remark with counterfactuals (e.g..
“those idiots didn’t do it right the first time!”, “they cut corners!”, “I TOLD them this wouldn’t
work!”)

Many pithy quotes exist that shine light on this notion of trade-offs, and mature engineers know
that there are limits to any philosophy-laden quotes (including the ones I’m writing here):

  * “Premature optimization is the root of all evil.” – a very abused maxim, and I’ve written about
    it before. A corollary to that might be (taken from here) ‘Understanding what is and isn’t
    “premature” is what separates senior engineers from junior engineers.’
  * “Right tool for the job” – another abused one. The intention here is reasonable: who wants to
    use a tool that isn’t appropriate? But a rare perspective is that this can be detrimental when
    taken to the extreme. A carpenter doesn’t arm himself with every variation and size of hammer
    that is available, even thought he may encounter hammering tasks that could be ideally handled
    by each one. Why? Because lugging around (and maintaining) a gazillion hammers incurs a cost.
    As such, decisions on this axis have trade-offs.

The tl;dr on trade-offs is that everyone cuts corners, in every project. Immature engineers
discover them in hindsight, disgusted. Mature engineers spell them out at the onset of a project,
accept them and recognize them as part of good engineering.

(Related: Your Code May Be Elegant, But Mine Fucking Works)

Mature engineers don’t practice CYAE (“Cover Your Ass Engineering”)

The scenario where someone will stand on ceremony as an excuse for not attempting to understand how
his or her code (or infrastructure) could be touched by other parts of the system or business is a
losing proposition. Covering your ass sends the implicit message that you are someone willing to
throw others (on your team? in your company? in your community?) under the proverbial bus at the
mere hint that your work had any flaw. Mature engineers stand up and accept the responsibility
given to them. If they find they don’t have the requisite authority to be held accountable for
their work, they seek out ways to rectify that.

An example of CYAE is “It’s not my fault. They broke it, they used it wrong. I built it to spec, I
can’t be held responsible for their mistakes or improper specification.”

Mature engineers are empathetic.

In complex projects, there are usually a number of stakeholders. In any project, the designers,
product managers, operations engineers, developers, and business development folks all have goals
and perspectives, and mature engineers realize that those goals and views may be different. They
understand this so that they can navigate effectively in the work that they do. Being empathetic in
this sense means having the ability to view the project from another person’s perspective and to
take that into consideration into your own work.

Goal conflicts are inherent in all engineering work, and complaining about them (instead of
embracing them as requirements for success) is a sign of a less mature engineer.

They don’t make empty complaints.

Instead, they express judgements based on empirical evidence and bring with those judgements
options for solving the problem which they’ve identified. A great manager of mine said to never go
to your boss with a complaint about anything without at least one (ideally more than one)
suggestion for a solution. Even demonstrating that you’ve tried working the problem on your own and
came up empty-handed is better than an empty complaint.

Mature engineers are aware of cognitive biases

This isn’t to say that every mature engineer needs to have a degree in psychology, but cognitive
biases are what can limit the growth of an engineer’s career at a certain point. Even if they’re
not aware of the details of how they appear or how these biases can be guarded against, most mature
engineers I know have a level of self-awareness to at least recognize they (like everyone) are
susceptible to them.

Culturally, engineers work day-to-day in empirical evidence in research. Basically: show me the
data. The issue with cognitive biases is that we can be blissfully unaware of when we are
interpreting data with our own brains in ways that defy empirical data, and can have a surprising
effect on how we get work done and work on teams.

A great list of them exists on Wikipedia, but some of the ones that I’ve seen engineers (including
myself) fall prey to are:

  * Self-Serving Bias – basically: if something is good, it’s probably because of something I did
    or thought of. If it’s bad, it’s probably the doing of someone else.
  * Fundamental Attribution Error – basically: the bad results that someone else got from his work
    must have something to do with how he is, personally (stupid, clumsy, sloppy, etc.) whereas if
    I get bad results, it’s because of the context that I was in, the pressure I was under, the
    situation I was in, etc.
  * Hindsight Bias – (it is said that this is the most-studied phenomenon in the history of modern
    psychology) basically: after an untoward or negative event (a severe bug, an outage, etc.) “I
    knew it all along!”. It is the very strong tendency to view the past more simply than it was in
    reality. You can tell there is Hindsight Bias going on when descriptions involve
    counterfactuals, or “…they should have…”, or “…how did they not see that, it’s so obvious!”.
  * Outcome Bias – like above, this comes up after a surprising or negative event. If the event was
    very damaging, expensive to clean up, or severe, then the decisions or actions that contributed
    to that event are judged to be very stupid, reckless, or negligent. The judgement is
    proportional to how severe the event was.
  * Planning Fallacy – (related to the point about making estimates under uncertainty, above)
    basically: being more optimistic about forecasting the time a particular project will take.

There are plenty of others, all of which I find personally fascinating and I can get lost in
learning more about them. Highly suggested reading, if you’re at all interested in learning about
how you might be limiting your own effectiveness.

The Ten Commandments of Egoless Programming

Appropriate, even if old…I’ve seen it referenced as coming from The Psychology of Computer
Programming, written in 1971, but I don’t actually see it in the text. Regardless, here are The Ten
Commandments of Egoless Programming, found on @wyattdanger‘s blog post on receiving advice from his
dad:

 1. Understand and accept that you will make mistakes. The point is to find them early, before they
    make it into production. Fortunately, except for the few of us developing rocket guidance
    software at JPL, mistakes are rarely fatal in our industry. We can, and should, learn, laugh,
    and move on.
 2. You are not your code. Remember that the entire point of a review is to find problems, and
    problems will be found. Don’t take it personally when one is uncovered. (Allspaw note –
    related: see below, number #10, and the points Theo made above.)
 3. No matter how much “karate” you know, someone else will always know more. Such an individual
    can teach you some new moves if you ask. Seek and accept input from others, especially when you
    think it’s not needed.
 4. Don’t rewrite code without consultation. There’s a fine line between “fixing code” and
    “rewriting code.” Know the difference, and pursue stylistic changes within the framework of a
    code review, not as a lone enforcer.
 5. Treat people who know less than you with respect, deference, and patience. Non-technical people
    who deal with developers on a regular basis almost universally hold the opinion that we are
    prima donnas at best and crybabies at worst. Don’t reinforce this stereotype with anger and
    impatience.
 6. The only constant in the world is change. Be open to it and accept it with a smile. Look at
    each change to your requirements, platform, or tool as a new challenge, rather than some
    serious inconvenience to be fought.
 7. The only true authority stems from knowledge, not from position. Knowledge engenders authority,
    and authority engenders respect – so if you want respect in an egoless environment, cultivate
    knowledge.
 8. Fight for what you believe, but gracefully accept defeat. Understand that sometimes your ideas
    will be overruled. Even if you are right, don’t take revenge or say “I told you so.” Never make
    your dearly departed idea a martyr or rallying cry.
 9. Don’t be “the coder in the corner.” Don’t be the person in the dark office emerging only for
    soda. The coder in the corner is out of sight, out of touch, and out of control. This person
    has no voice in an open, collaborative environment. Get involved in conversations, and be a
    participant in your office community.
10. Critique code instead of people – be kind to the coder, not to the code. As much as possible,
    make all of your comments positive and oriented to improving the code. Relate comments to local
    standards, program specs, increased performance, etc.

Novices versus Experts

Now I generally don’t follow too much on knowledge acquisition as a research topic, but I do
believe it’s hard to get away from when talking about the evolving nature of a discipline. One bit
of interesting breakdown comes from a paper from Dreyfus and Dreyfus called “A Five Stage Model of
the Mental Activities Involved in Directed Skill Acquisition” which has laid out characteristics of
various levels of expertise:

                  * Rigid adherence to rules or plans
Novice            * Little situational perception
                  * No (or limited) discretionary judgment

                  * Guidelines for action based on attributes and aspects, which are all equal and
Advanced            separate
Beginner          * Limited situational perception

                  * Conscious deliberate planning
Competent         * Standardized and routine procedures

                  * Sees situations holistically rather than as aspects
Proficient        * Perceives deviations from normal patterns
                  * Uses maxims for guidance, whose meanings are contextual

                  * No longer relies on rules, guidelines or maxims
Expert            * Intuitive grasp of situations
                  * Analytic approach used only in novel situations

The paper goes on to state:

    Novices operate from an explicit rules and knowledge-based perspective. They are deliberate and
    analytical, and therefore slower to take action, they decide or choose.

(which means that novices are deeply subject to local rationality)

    Experts operate from a mature, holistic well-tried understanding, intuitively and without
    conscious deliberation. This is a function of experience. They do not see problems as one thing
    and solutions as another, they act.

(which means that experts are context driven)

I don’t necessarily subscribe to the notion of such dry lines being drawn between skill levels,
because I think that there is a lot more granularity and facets of expertise than just those
outlined above, but I think it’s helpful to be aware of the unfortunately over-simplified
categories.

Dirty secret: mature engineers know the importance of (sometimes irrational) feelings people have.
(gasp!)

How people feel about technologies, technical decisions, and technical directions is just as
important (if not more) than the facts about the details. Mature engineers know this, and adjust
accordingly. Again, being empathetic can help you understand how another person on your team feels
about a technical decision, even if they themselves don’t have an easy time articulating why they
feel that way.

People’s confidence in software, architectures, or patterns is heavily influenced by past
experience, and can result in positive or negative reactions to using them. Used to work at a
mod_perl shop that had a lot of mystifying outages? Then you can’t be surprised to feel reluctant
to use it in a different company, even if the supporting expertise and use cases are entirely
different. All you remember is that mod_perl = major headaches, so you’re going to be wary of using
it in any context again.

Mature engineers understand this phenomenon when making a case to use technology that carries
baggage, even if it’s irrational. Convincing a group to use tools and patterns that they aren’t
comfortable with isn’t a straightforward task. The “right tool for the job” maxim also has
(sometimes unquantifiable) comfortability as a parameter.

For an illustration of how people’s emotions drive technical decisions and opinions, read any flame
war about anything, ever.

“It is amazing what you can accomplish if you do not care who gets credit.”

This quote is commonly attributed to Harry S. Truman, but it looks like it might have first been
said by a Jesuit priest in a different form. In any case, this is another indication you’re working
with a mature engineer: they hold the success of the project much higher than the potential praise
they may get personally for working on it. The attribution of praise or credit can be the source of
such dysfunction in an engineering-driven organization, and I believe it’s because it’s largely
invisible.

The notion is liberating, and once understood and internalized, a world of progress and innovative
thinking can flourish, because the engineer isn’t overly concerned with the personal liability of
equating the work to their own career success.

Not The End

I’m at the moment blessed to work with a number of mature engineers here at Etsy, and it’s quite
humbling. We are indeed a young field, and while I think we can learn a great deal from other
fields of engineering on this topic, I also think we have an advantage. The web is inextricably
tied to the notion of publishing and sharing information, globally. We need to continue pointing
out what it means to be a “senior” and “mature” engineer if we have a hope of progressing the field
into a true discipline.

Many thanks to members of the Etsy Operations team, Mike Brittain, Kellan Elliott-McCrea, Marc
Hedlund, and Theo Schlossnagle for reviewing drafts of this post. They all make me a more mature
engineer.

Share story

  *
  *
  *
  *
  *
  *
  *
  *

A Mature Role for Automation: Part I

Availability: Nuance As A Service

[]

I like making things go! At the moment, I'm SVP of Infrastructure and Operations at Etsy, and I'm
currently pursuing a Master's degree in Human Factors and Systems Safety at Lund University.

124 Comments

 1. Pingback: You’re a senior engineer. Now what? | Associative Disarray

 2. Eduard Florinescu   •

    I think there is one aspect totally ignored here: there is an optimal ratio for senior/novice
    to be considered.

    In a project a senior contribution can be diluted both by novices and other seniors(but novice
    on that project).

 3. allspaw   •     Author

    Thanks for the comment Eduardo!

    You touched on collaboration: is it dilution of senior contribution to a project, or providing
    a mature engineer with an opportunity to lift the expertise of a novice engineer?

 4. Eduard Florinescu   •

    @allspaw
    Thinking more about it, both effective contribution and mentoring are desirable within a
    project, and a senior manager would probably recognize mentoring at least as valuable as
    effective technical work.

 5. Engineer   •

    Those are some awesome thoughts indeed. You remembered me of my boss who never forgot to tell
    me the authorities a senior engineer has.

 6. Pingback: On Being A Senior Engineer - jondavidjohn.com

 7. Pingback: A Brief History Of 'My' Time » List of Blogs/Posts/Videos/Podcasts/Other

 8. Pingback: The Internet Fishing Trawler: Food For Thought Edition | Bede Carroll

 9. Bob the Chef   •

    What you describe is at the level of junior engineer or college student. A senior engineer
    should already have a proper intuition and confidence that transcends, if you will, what you’ve
    written. You need to reevaluate your standards. A senior engineer doesn’t follow rules (nor
    should a junior engineer, but the key here is that the transgression is far worse for a
    so-called senior engineer to commit). He reasons and reasons from experience which includes
    knowing the nature of experience and what can be known from it. He should have a greater wisdom
    about things, at the very least concerning his field. The sad trend in these blogs is this rule
    posturing which is the antithesis of wisdom. There are no shortcuts to wisdom. Rules can never
    offer that. In fact, the rule mentality is potentially your worst enemy and can impede the
    natural progression towards reasoned experience. This is equally true for life in general, not
    just the small and relatively minor piece of it which in this case is your engineering trade.

10. allspaw   •     Author

    Bob: I’m wondering if you read the piece. With respect to rules, I agree with the viewpoint of
    Dreyfus and Dreyfus, which says that experts: “No longer relies on rules, guidelines or maxims”

    I do not disagree with anything that you’ve written in your comment. Would like to hear more on
    how you disagree with what I’ve written here.

11. Randy   •

    This is a great article. As a junior engineer (and transplant from the astrophysics community),
    I found this helpful as a sort of general guide for my own personal growth. There were several
    of the points where I got excited that I was already moving in that direction (with plenty of
    opportunity to continue to grow).

12. Pingback: On “The Emperor’s Old Clothes” - coopy on code

13. Pingback: Diving back in … maybe |

14. Pingback: Four short links: 21 January 2014 - O'Reilly Radar

15. Peter Hozák   •

    @Bob, @allspaw:

    Let’s look at a definition of a rule: “one of a set of explicit or understood regulations or
    principles governing conduct or procedure within a particular area of activity” (
    https://www.google.co.uk/search?q=define+rule – assuming you were not talking about British
    royalty).

    Now, that surely cannot be the definition of rules we want our senior engineer to be free of –
    surely we want them to obey the syntax of their programming and natural languages, not to
    murder their colleagues during heated meetings and flush the toilet.

    Regardless, let’s try to infer the meaning of “rules” from its utility to distinguish between
    junior and senior engineers. If you are a junior engineer and stop following “rules”, do you
    become more senior? If someone is not following “rules”, is it a good indicator of their
    seniority? Hmmm, no, I cannot come up with any useful definition.

    Is “wisdom” to decide when to break what rules the silver bullet to aspire for if you are a
    junior engineer? To look for when you are hiring? What should you look (listen, smell, …) for
    when you want to increase your wisdom? Is it just time, so 50-year-old engineer is always more
    senior than 30-year-old? Or is “wisdom” a property of the “soul” and cannot be indicated by any
    rational “rules”, so all training efforts as well as hiring “guidelines” are a-priory doomed to
    fail?

    No. I believe your (dis)agreement is incomprehensible and what is worse, impractical. The
    article illustrates various aspects of seniority in engineering very nicely and no
    transcendental comments will make the training/hiring decisions any easier.

16. Pingback: Challenge the norms of work: Dave Zwieback, VP Engineering at Next Big Sound |
    popforms

17. Pingback: Responsibility | Ben.geek.nz

18. Pingback: Kitchen Soap – Engineering’s Relationship To Science

19. Pingback: 165 RR Systems Programming Tricks with Julia Evans

20. Pingback: Professional Development – 2014 – Week 45

21. Blaine Hatab   •

    I still reference this to people when I explain to them what it really means to become a Senior
    Developer. There is so much more than code involved with leading projects and this article
    covers it so nicely. I can’t say enough about how important the human interaction is when being
    a project lead.

22. Sarah   •

    Great article! Most of your advice seems quite relevant for any “senior” position, but as I’m
    starting my EE degree in the fall, it’s nice to have some commentary specific to the work
    environment I will likely end up in. Thanks for the article!

23. Pingback: The Engineer and the Craftsman | inso

24. Pingback: Professional Development – 2015 – Week 8

 Older Comments

Leave a Reply Cancel reply

Your email address will not be published. Required fields are marked *

Name * [                              ]

Email * [                              ]

Website [                              ]

        [                                             ]
        [                                             ]
        [                                             ]
        [                                             ]
        [                                             ]
        [                                             ]
        [                                             ]
Comment [                                             ]

You may use these HTML tags and attributes: <a href="" title=""> <abbr title=""> <acronym title="">
<b> <blockquote cite=""> <cite> <code> <del datetime=""> <em> <i> <q cite=""> <strike> <strong>

 Post Comment

Recent Posts

  * Stress, Strain, and Reminders
  * The Infinite Hows (or, the Dangers Of The Five Whys)
  * Translations Between Domains: David Woods
  * Teaching Engineering As A Social Science
  * Engineering’s Relationship To Science
  * Paradigm Check Point: Prefacing Debriefings

Copyright © 2015 · Theme design by the Bluth Company · www.bluth.is

#+end_example
* #  --8<-------------------------- separator ------------------------>8--
* web page: If You Think Hiring an Expert is Expensive, Wait Until You do it Wrong!
http://blog.flux7.com/if-you-think-hiring-an-expert-is-expensive-wait-until-you-do-it-wrong
** webcontent                     :noexport:
#+begin_example
Location: http://blog.flux7.com/if-you-think-hiring-an-expert-is-expensive-wait-until-you-do-it-wrong
844-Flux700
/
Contact Us
Search this site on Google
[                    ] Search Google
  *

  *

  *

  *

  *

Flux7 Logo

  * Home
  * Company
      + About Us
      + Technology Expertise
      + Careers
      + Partners
      + News & Events
          o News
          o Press Releases
          o Events
  * Solutions
      + Assessment Packages
          o Cloud Infrastructure Assessment
          o DevOps Assessment Package
          o Dev Flow Assessment Package
          o Docker Assessment Package
      + Cloud Attune Package
      + Solutions for SMBs
          o DevOps for SMBs
          o Cloud for SMBs
          o IT Optimization
      + Solutions for Enterprises
          o DevOps for Enterprises
          o Cloud for Enterprises
          o IT Optimization
      + Docker
          o Docker Solution
          o Docker Assessment Package
          o Docker Resources
      + Products
          o Vyscale
      + Training
      + Support Packages
  * Industries
      + Flux7’s Cloud Solutions for Healthcare and Life Sciences
  * Clients
      + Clients
      + Case Studies
  * Resources
      + Blog
      + Presentations
      + White Papers
      + Webinars & Meetup Videos
  * Contact Us

Blog

DevOps & Cloud Computing Hub

  * Resources
  * Blog
  * If You Think Hiring an Expert is Expensive, Wait Until You do it Wrong!

If You Think Hiring an Expert is Expensive, Wait Until You do it Wrong!

You Can’t Afford Cheap!

Some people always try to do things on the cheap. They will always pick the least expensive way of
doing something. They consider the lowest cost as being the most important metric when it comes to
any particular job.

The problem is that a low up-front cost is not always a good guide to how much a job will cost
overall. Indeed a low upfront cost can often lead to expensive bills down the line as you try to
recover from deficiencies encountered as a result of that low-cost option.

Paying an expert to find you a solution generally ends up the cheapest option in the long run.
There is usually a solid reason why people undercut others.  More often than not, it is because
that person does not have the skills, ability or speed to match their higher charging brethren.
They literally need to charge at a lower rate so that they can get the work to learn their skills.
In many cases the reason why you are paying a cheaper rate for something is because you are
unwittingly consenting to being a guinea pig.

What Can Experts Do?

Anyone considered to be an expert, will have the qualifications and experience to prove that they
can live up to the term. They will be able to perform quicker and more efficiently than others.
Their hourly rate may be higher than their more amateur competitors but they will take less hours
to do the necessary tasks. Often the overall job will end up cheaper because of this.

They have built up a knowledge base through their experience. They know the best practices to
follow, and just as importantly they will have worked out what are the bad practices that should be
avoided. You are not going to have to pay them to experiment, change their mind, and start again on
a different track. Trial and error can be very expensive, both in terms of cost (more hours of
labour, paying for wasted resources etc) and in terms of time (the longer the job takes the further
you are away from completion, and that may have flow-on effects to your own clients).

They know from the outset what has to be done. They will not having to Google to learn the basics
of how to do the job that you are paying them for.

One example of this we have seen is in the kitchen door industry. There are relatively few firms
that manufacture kitchen doors. One firm wanted to get a batch of kitchen doors made quickly – they
had promised their clients that the kitchen would be ready to be installed in a  ridiculously quick
time. The problem is that they had also bid a very low rate for those kitchens, and expected the
kitchen door manufacturers to come to the party with cheap kitchen doors – preferably made within a
week. To their surprise the expert kitchen door manufacturers all said “no”. They would not put
their reputations on the line just because a potential customer wanted things cheap. In the end the
client had to import the doors from China, and they took twice as long to arrive as promised.
Before long the coating started to peel off - much quicker than those doors made by the expert
firms.

It is the same when you deal with your firm’s data. You need to think about what is the expert way
to handle and look after that valuable data. Don’t look at what is the cheapest method, look at
what is the most cost-effective method, of handling your data. A cheap method would, for instance,
be to save all of your files internally, possibly on $100 portable hard disks. This suddenly loses
its attraction and affordability the day that a disk becomes corrupted and you have to go begging
to a data recovery service to help you out.

Some people try and do everything themselves – that way they don’t have to pay upfront for services
rendered. Again, there are issues here. Tim Ferriss has become well known for his writings on the
Four Day Work Week. In his books he posits that people should aim is to be as effective as
possible. You will not be effective if you try and do everything yourself. You should focus on
those tasks that most need to be done. Your effectiveness will improve immeasurably if you
outsource those jobs that are not essential to be done in-house

The Right Experts Make a Difference

Of course, you need to do your homework if you go down the outsourcing track. It helps if you know
exactly what it is that you are looking for. Make certain that any firm that you approach knows its
stuff. Do they sound legitimate? Do they appear to know the language? Do they present themselves
professionally? Do they have a well-designed website with solid content on? Do they have a physical
address that can be verified? Are they well known in their industry? Do you know any satisfied
clients?

We have had one client in recent times who hired a company to help them with their data storage
issues. The firm they dealt with were experts in biotech, the industry this client is in, and
because of this they felt quite an affinity with them. The problem was though, that as much as they
could claim to be an expert in biotech, and had some experience with data storage in that area,
they had no knowledge about Amazon Web Services (AWS), which is a key part of our client’s cloud
computing storage. In the end that client came to Flux 7, because of our expertise in operating
with AWS.

The Expert Seal of Approvalapproved-29149_640

There are times having an expert “seal of approval” is very useful to your credibility.

 Outsiders can see that you are a firm that believes in taking quality advice. They can see that
you work with experts who know what they are doing and who will help improve your bottom line. This
is one of those areas that potential investors take a look at when they undertake due diligence
reports.seful to your credibility.

Why Using the Skills of AWS Experts Makes Sense

Flux7 can rightfully state we are AWS experts. We have built up a client base and built up our
expertise in the use of Amazon’s cloud computing platform.

Because we know how the system operates, and use it every day, we have a hardware knowledge that is
second-to-none. We know what works. We can easily give an independent review of your cloud
infrastructure from certified AWS consultants, and an AWS Advanced Tier partner. We know the best
practices for server uptime.

Similarly our software developers can develop CloudFormation scripts to automate your deployment
process. You will not have to think about how your data is being safely stored – it will all happen
for you.

Our experts have full architectural knowledge of the apps and systems, which can easily be adapted
to your own situation.

So what is the cheapest way to keep your data safe? Doing everything in-house, using you or your
staff’s time and relative lack of expertise? Employing the cheapest bidder to do “something” to
store your data. Or to contract an expert in data storage and cloud computing systems, who knows
precisely the best solution for your data needs, giving you a highly effective result?

February 20, 2015 / AWS

Share the Post

  * Tweet
  *
  *
  *

About the Author

Flux7 Labs

Categories

  * Apache Hadoop (3)
  * AWS (33)
  * Benchmarking (25)
  * Case Studies (1)
  * Cloud Computing (12)
  * Deployment (4)
  * DevOps (20)
  * Docker (20)
  * Events (11)
  * Flux7 Labs (4)
  * Glossary (14)
  * News & Updates (1)
  * NoSQL (4)
  * Openstack (8)
  * Press Release (7)
  * Quizzes (7)
  * Spot Instances (1)
  * Surveys (1)
  * Tutorials (1)
  * Virtual Meetups (1)

Subscribe to Email Updates

Connect With Us

Recent Posts

  * Cloud Infrastructure Best Practices for Life Sciences and Healthcare
  * If You Think Hiring an Expert is Expensive, Wait Until You do it Wrong!
  * On Papercuts And DevOps
  * Flux7 Wins 2015 Modern Impact Awards, Best AWS Consulting Partner
  * Building a Continuous Integration Environment in AWS

Company

  * About Us
  * Careers
  * Clients
  * Partners
  * Press Releases

Solutions

  * Solutions for SMBs
  * Solutions for Enterprises
  * Training
  * Products

Resources

  * Blog
  * Case Studies
  * White Papers
  * Presentations
  * Events

Connect With Us

  *

  *

  *

  *

  *

Copyright © 2014. Flux7 | Sitemap

#+end_example
* TODO mail: A very good post about expert consultant.           :noexport:
[[gnus:nnfolder%2Barchive:mail.sent.mail#m2egpcobny.fsf@gmail.com][Email from Denny Zhang (Thu, 26 Feb 2015 10:55:13 -0600): A very good post about expert ]]
#+begin_example
From: Denny Zhang <filebat.mark@gmail.com>
Subject: A very good post about expert consultant.
To: JayZheng <jayzheng07@gmail.com>, Yaodong Hu <yaodonghu@gmail.com>, Ming <ming.zhang.china@gmail.com>
Cc: Denny Zhang <filebat.mark@gmail.com>
Date: Thu, 26 Feb 2015 10:55:13 -0600
User-Agent: Gnus/5.13 (Gnus v5.13) Emacs/24.4 (darwin)

http://blog.flux7.com/if-you-think-hiring-an-expert-is-expensive-wait-until-you-do-it-wrong

It's a very good article about consultant. Also flux7 is a very good
role model for AWS consultant, or even OpenStack.

Some digest:
# [Can deliver] have the qualifications and experience to prove that they can live up to the term.
# [Faster] Their hourly rate may be higher, but they may take less hours. No need google for basics.
# [Best Practices] They know the best practices to follow. Trial and error can be very expensive.

--
Denny Zhang(张巍)
Email: filebat.mark@gmail.com
Website: http://www.dennyzhang.com/

Architecture represents the significant design decisions that shape a
system

⎝≧⏝⏝≦⎠

#+end_example
* TODO [#A] neo4j search recovery stuck
https://totvslab.atlassian.net/browse/CLOUDPASS-6986
#+BEGIN_EXAMPLE
Description
After data recovery, search service stuck in neo4j recovery.
root@id-msg:~/restore_test# tail -f /data/totvslabs/neo4j/embedded/messages.log
2015-02-24 00:41:04.458+0000 INFO o.n.k.i.t.TxManager: TM opening log: /data/totvslabs/neo4j/embedded/tm_tx_log.2
2015-02-24 00:41:04.602+0000 INFO o.n.k.i.t.x.XaLogicalLog: Non clean shutdown detected on log /data/totvslabs/neo4j/embedded/index/lucene.log.2. Recovery started ...
2015-02-24 00:41:04.616+0000 INFO o.n.k.i.t.x.XaLogicalLog: /data/totvslabs/neo4j/embedded/index/lucene.log.2 logVersion=73 with committed tx=596061
Issue Links
mentioned in
[CONFLUENCE (totvslab.atlassian.net)] Page Changeset for Upgrading/Patching prod env
Activity
All
Comments
Work Log
History
Activity

Denny Denny Zhang added a comment - 2 days ago
One special thing may need attention:
We will have to run "chown neo4j:neo4j -R /data/totvslabs", otherwise neo4j service will fail to start.
While in prod env/psfluigidentity/old customerfi, it's ok to keep /data/totvslabs with the ownership of root:root.
When we start search service, some new files will be generated under /data/totvslabs/neo4j/embedded.
Those files's ownership are root:root, instead of neo4j:neo4j.

Denny Denny Zhang added a comment - 2 days ago - edited
Tried to redo the data recovery, no luck.
CC Kung Wang

Denny Denny Zhang added a comment - Yesterday
After 6 hours, the recovery of search's neo4j is done.
Critical log message of /data/totvslabs/neo4j/embedded/messages.log:
2015-02-24 00:41:04.458+0000 INFO o.n.k.i.t.TxManager: TM opening log: /data/totvslabs/neo4j/embedded/tm_tx_log.2
2015-02-24 00:41:04.602+0000 INFO o.n.k.i.t.x.XaLogicalLog: Non clean shutdown detected on log /data/totvslabs/neo4j/embedded/index/lucene.log.2. Recovery started ...
2015-02-24 00:41:04.616+0000 INFO o.n.k.i.t.x.XaLogicalLog: /data/totvslabs/neo4j/embedded/index/lucene.log.2 logVersion=73 with committed tx=596061
2015-02-24 06:04:34.974+0000 INFO o.n.k.i.t.x.XaLogicalLog: /data/totvslabs/neo4j/embedded/index/lucene.log.2 entries found=171075 lastEntryPos=20102962
2015-02-24 06:04:34.975+0000 INFO o.n.k.i.t.x.XaLogicalLog: Opened logical log /data/totvslabs/neo4j/embedded/index/lucene.log.2 version=73, lastTxId=604657 (recovered)
2015-02-24 06:04:34.975+0000 INFO o.n.k.i.t.x.XaLogicalLog: XaResourceManagerlucene.log sorting 1 xids
2015-02-24 06:04:34.975+0000 INFO o.n.k.i.t.x.XaLogicalLog: XaResourceManagerlucene.log checkRecoveryComplete 0 xids
2015-02-24 06:04:34.975+0000 INFO o.n.k.i.t.x.XaLogicalLog: XaResourceManagerlucene.log recovery completed.

Denny Denny Zhang added a comment - 7 hours ago - edited
Looks like we need to run: "chown neo4j:neo4j -R /data/totvslabs/scim/neo4j", instead of "chown neo4j:neo4j -R /data/totvslabs"
#+END_EXAMPLE
* TODO [#B] Blog: What I need as my backup support??
- Novel: Bill
- Case: deploy LAMP in all-in-one env in Ubuntu; Support Ubuntu/CentOS, MacOSX; Support cluster deployment
        Backup and monitoring

- Case: security ssh: ssh tunnel, password authentication, no malicious request, iptables port forwarding

- Extra bounous: LFS (Build linux from scratch)
* #  --8<-------------------------- separator ------------------------>8--
* TODO [#A] Make improvement points or problems visible or measurable for the team :IMPORTANT:
* TODO [#A] Discuss: When design a system, provide a switch. If turn on, it will reject all write request, only allow readonly requests
Thus we can have a safe time window of prod env maintaince. In most case, HA may not work perfectly.
* web page: Startups: 5 Signs That You Need to Invest in DevOps
http://blog.flux7.com/startups-5-signs-that-you-need-to-invest-in-devops
** webcontent                     :noexport:
#+begin_example
Location: http://blog.flux7.com/startups-5-signs-that-you-need-to-invest-in-devops
844-Flux700
/
Contact Us
Search this site on Google
[                    ] Search Google
  *

  *

  *

  *

  *

Flux7 Logo

  * Home
  * Company
      + About Us
      + Technology Expertise
      + Careers
      + Partners
      + News & Events
          o News
          o Press Releases
          o Events
  * Solutions
      + Assessment Packages
          o Cloud Infrastructure Assessment
          o DevOps Assessment Package
          o Dev Flow Assessment Package
          o Docker Assessment Package
      + Cloud Attune Package
      + Solutions for SMBs
          o DevOps for SMBs
          o Cloud for SMBs
          o IT Optimization
      + Solutions for Enterprises
          o DevOps for Enterprises
          o Cloud for Enterprises
          o IT Optimization
      + Docker
          o Docker Solution
          o Docker Assessment Package
          o Docker Resources
      + Products
          o Vyscale
      + Training
      + Support Packages
  * Industries
      + Flux7’s Cloud Solutions for Healthcare and Life Sciences
  * Clients
      + Clients
      + Case Studies
  * Resources
      + Blog
      + Presentations
      + White Papers
      + Webinars & Meetup Videos
  * Contact Us

Blog

DevOps & Cloud Computing Hub

  * Resources
  * Blog
  * Startups: 5 Signs That You Need to Invest in DevOps

Startups: 5 Signs That You Need to Invest in DevOps

Having a DevOps approach for application or product development is like H[2]O to your organization.
It’s a basic need to live long and prosper.

Yes, DevOps is like H[2]O:

  * High-quality bug-free apps and products

  * Heights of innovation

  * One-click deployments

And a lot more to be honest!

Whether you’re a dev or ops guy, chances are you are constantly being educated about a DevOps
approach or methodology. You might even be aware of the myths and facts of DevOps and how a DevOps
infrastructure affects your customers.

The questions to ask are these:

  * How do you know you aren’t using DevOps?

  * And, isn’t it time you think of an investment in DevOps?y_u_no_use_devops

Because DevOps is a culture --a process, there’s no definite checklist that you can use to
understand your DevOps stand. The current state-of-the-art DevOps approach does not provide a
ready-to-use framework or manifesto. However, there are a lot of best practices and indicators that
can help you understand where you stand when it comes to DevOps.

We’ve put together a list of five signs, or indicators, (it’s not THE list, as there’s no specific
checklist) that, when relatable, implies you’re missing out from DevOps at the very core. In that
case, you need to call for a team meeting to start thinking DevOps.

Sign #1: Your team has the best developers, but an application deployment takes three times longer
than it’s supposed to take.

This clearly indicates that your feedback loop is at stake. Whether it’s a local feedback loop,
wherein the developer does local testing before the code is sent to QA, or a feedback that a
developer receives from QA, it’s significant to send feedback to the developer as quickly as
possible. Why? Context switching.

If it takes a long time for the feedback to reach the developer, it’s very likely that your
developer has moved on to coding the next feature. Therefore, the context of the previous feature
is not as fresh as it would have been if the feedback was sent quicker.

Sign #2: You are terrified at the thought of hiring new developers.

Irrespective of the size of your organization, you constantly face the issue of a lack of
documentation. You let go of one of your current employees or he quits your firm for another job.
What if the same employee was responsible for major developments and has failed to document his
work appropriately?

It’s going to be a disaster for the new employee hired to replace him.

Sign #3: You have ideas booming among the team; but, the practicality of the idea de-motivates you.

Your team and you are bursting with creative and innovative ideas. You have the needed skills. But
what about factors like cost, time and resource allocation that bring you down every time you think
of a new idea?

As much as an idea can end up being life-changing to you, not having a DevOps approach in place is
prepping you to see the light of your organization’s doomsday.

Sign #4: You end up doing a string of tedious manual steps.

A lack of automated scripts that take care of your repeatable tasks calls for tedious manual steps
that are way more faulty given the involvement of the human element. This deprives you of sleep.
And the last time you had a good night’s sleep was … well, you can’t remember, can you?

Your doctor advises that you must sleep seven to eight hours a night to help stay in good health.
Research and studies are constant reminders of the health hazards of bad sleeping habits. But, here
you are, running around the clock, fixing an issue, only to get ready to face another.

Sign #5: You feel your devs and ops spend more time finger-pointing than actually working.

And then comes the cherry on top. There’s a whole lot of finger-pointing and blame-game playing
going on within your teams. No one wants to take responsibility. You are not really sure who caused
the issue in the first place.

In short, you feel you are in a mess.

You keep missing your business goals only to procrastinate and push them into the next month, then
the next, and, yes, the next. You end up being satisfied with the results you see while they are no
where close to what they must be.

If you recognize at least one of these signs taking hold at your organization, then it’s quite
possible that it’s not too long before you also see the rest of them.

There is no time for second thoughts when it comes to emphasizing the need for a DevOps approach
and putting it in place. It’s a basic need and a necessary investment.

Put it into practice! Find out how, and when, one startup got the DevOps framework they needed.

I want a DevOps case study now

August 24, 2014 / DevOps

Share the Post

  * Tweet
  *
  *
  *

About the Author

Flux7 Labs

Categories

  * Apache Hadoop (3)
  * AWS (33)
  * Benchmarking (25)
  * Case Studies (1)
  * Cloud Computing (11)
  * Deployment (4)
  * DevOps (20)
  * Docker (20)
  * Events (11)
  * Flux7 Labs (4)
  * Glossary (14)
  * News & Updates (1)
  * NoSQL (4)
  * Openstack (8)
  * Press Release (7)
  * Quizzes (7)
  * Spot Instances (1)
  * Surveys (1)
  * Tutorials (1)
  * Virtual Meetups (1)

Subscribe to Email Updates

Connect With Us

Recent Posts

  * If You Think Hiring an Expert is Expensive, Wait Until You do it Wrong!
  * On Papercuts And DevOps
  * Flux7 Wins 2015 Modern Impact Awards, Best AWS Consulting Partner
  * Building a Continuous Integration Environment in AWS
  * re:Invent 2014: What AWS Users Must Know to Plan for Agile Infrastructure

Company

  * About Us
  * Careers
  * Clients
  * Partners
  * Press Releases

Solutions

  * Solutions for SMBs
  * Solutions for Enterprises
  * Training
  * Products

Resources

  * Blog
  * Case Studies
  * White Papers
  * Presentations
  * Events

Connect With Us

  *

  *

  *

  *

  *

Copyright © 2014. Flux7 | Sitemap

#+end_example
* [#A] web page: Checklist for Validating A DevOps Architecture | Part 2
http://blog.flux7.com/blogs/devops/checklist-validating-devops-architecture-part-2
** webcontent                     :noexport:
#+begin_example
Location: http://blog.flux7.com/blogs/devops/checklist-validating-devops-architecture-part-2
844-Flux700
/
Contact Us
Search this site on Google
[                    ] Search Google
  *

  *

  *

  *

  *

Flux7 Logo

  * Home
  * Company
      + About Us
      + Technology Expertise
      + Careers
      + Partners
      + News & Events
          o News
          o Press Releases
          o Events
  * Solutions
      + Assessment Packages
          o Cloud Infrastructure Assessment
          o DevOps Assessment Package
          o Dev Flow Assessment Package
          o Docker Assessment Package
      + Cloud Attune Package
      + Solutions for SMBs
          o DevOps for SMBs
          o Cloud for SMBs
          o IT Optimization
      + Solutions for Enterprises
          o DevOps for Enterprises
          o Cloud for Enterprises
          o IT Optimization
      + Docker
          o Docker Solution
          o Docker Assessment Package
          o Docker Resources
      + Products
          o Vyscale
      + Training
      + Support Packages
  * Industries
      + Flux7’s Cloud Solutions for Healthcare and Life Sciences
  * Clients
      + Clients
      + Case Studies
  * Resources
      + Blog
      + Presentations
      + White Papers
      + Webinars & Meetup Videos
  * Contact Us

Blog

DevOps & Cloud Computing Hub

  * Resources
  * Blog
  * Checklist for Validating A DevOps Architecture | Part 2

Checklist for Validating A DevOps Architecture | Part 2

Last week we explored how business goals should inform every good DevOps strategy. This week we’ll
discuss how to use those goals to validate your DevOps architecture. From our experience at Flux7,
the best way to do this is to define the workflows of key users.

To ensure that an architecture will meet a client’s business goals, we ask ourselves the following
questions:

 1. What is the developer workflow and how will we enable it?

 2. How will we handle mirroring environments for disasters?

 3. How will we handle scaling up and down?

 4. How will we update the environment?

 5. How will we update the code?

 6. How will we keep the code and environment aligned?

 7. How will we make changes to the infrastructure?

To illustrate how these questions inform our work, we’ll walk you through them using our setup from
the previous post, “The Best Way To Deploy Ruby On Rails in AWS”, which was as follows:

  * Chef used to deploy and bake the environment.

  * Capistrano used to handle code deployments.

  * Git repository on GitHub used to store code.

We used CloudFormation templates for infrastructure deployment.

Now let’s examine how this setup addressed the seven questions above.

What was the developer workflow and how did we enable it?

Using CloudFormation templates to orchestrate infrastructure deployment, the developers selected a
pre-baked AMI with the correct environment setup. Even though we deployed the code with Capistrano,
we also created a Chef recipe for deployment.

[aJjGFGo3y8y4f-imPWIvjDpcmmIX6h22hKpriF_4xSwilXlxuMdKIy_5tsYI9iqiaMeRvkvTrOD]

How did we handle mirroring environments for disasters?

Our Ruby on the Rails deployment was a real-time experience for a startup client. They could afford
a cold DR provided the right alerts were set up for monitoring the website. It’s a good idea to
make regular production-AMI backups to S3 and to make a copy to the DR region. In case of disaster,
the environment can be retrieved by using the CloudFormation template with the latest AMI in the
new region and then updating the route 53 to point to the new region.

[PJGu5Zjd7JpfHIDmPb5CPhLjFgdGZ9BBZryJ2kLGpi-yrV8WtzxVz74Nf_xEyyzmTtWR7ByjckX]

How did we handle scaling up and down?

We implemented autoscaling. It’s important to know that an app server is “hot” when online without
having to intervene manually. This may require scripting because the same AMI needs to work in
several different environments.

How did we update the environment?

We edited the Chef recipe, checked for proper functioning and then baked the AMI. To improve Chef
recipe debug loops, we experimented with recipes inside a Docker container. This approach ensured
rapid revert to a previous state in case of failure.

[XIhjSK2eq8WqeV4rUb6YXKzZ9wIVeYSUHBYHQaX8G-bCqREn0iC94fte1Pj4onn-rpeCadjqkP6]

How did we update the code?

We pushed the code from the dev branch to the master branch and ran the Capistrano recipe.
Capistrano connected to the GitHub account and checked the latest copy of the required code
revision. Since the code was pulled at deployment, rather than being baked into the AMI, baking a
new AMI for each code update wasn’t needed. This approach is particularly suitable for hotfixes.

[Bo5vAlw1c4NJ2MwvQt9IbTBTs62zuyDY28uXjaabGWnuRd2tpt7CW99iZOOqiwcesjoi4tsFjZV]

How did we keep the code and environment aligned?

Manual overhead made sure that deployed code worked in its respective environment. Docker may come
in handy in such cases since it versions both code and environment, but we haven’t yet tried this
approach.

How did we make changes to the infrastructure?

We updated the CloudFormation template, deployed the environment and code, checked for complete
proper functioning, and qualified template changes. We assessed the outage caused by the template
update and, depending on the outage, updated the previous stack or created a new stack, and
transitioned to S3 when completed.

[EwgBv1jzVnT11wNUXkuEPdOO7rYFJic2hZeJU4Or-BjNwS58cpzrbr4QPFqpE1uqtEvgMLJGmP-]

Given the wide variety of needs for various organizations, there’s no right or wrong approach to
developing your DevOps architecture. But it’s always best to make small iterative-but-real
improvements because a huge project that tries to accomplish everything is far more likely to fail.
The key to success is not to prevent failure, but rather to maintain a low failure cost.

March 03, 2014 / DevOps

Share the Post

  * Tweet
  *
  *
  *

About the Author

Ali Hussain

Categories

  * Apache Hadoop (3)
  * AWS (33)
  * Benchmarking (25)
  * Case Studies (1)
  * Cloud Computing (11)
  * Deployment (4)
  * DevOps (20)
  * Docker (20)
  * Events (11)
  * Flux7 Labs (4)
  * Glossary (14)
  * News & Updates (1)
  * NoSQL (4)
  * Openstack (8)
  * Press Release (7)
  * Quizzes (7)
  * Spot Instances (1)
  * Surveys (1)
  * Tutorials (1)
  * Virtual Meetups (1)

Subscribe to Email Updates

Connect With Us

Recent Posts

  * If You Think Hiring an Expert is Expensive, Wait Until You do it Wrong!
  * On Papercuts And DevOps
  * Flux7 Wins 2015 Modern Impact Awards, Best AWS Consulting Partner
  * Building a Continuous Integration Environment in AWS
  * re:Invent 2014: What AWS Users Must Know to Plan for Agile Infrastructure

Company

  * About Us
  * Careers
  * Clients
  * Partners
  * Press Releases

Solutions

  * Solutions for SMBs
  * Solutions for Enterprises
  * Training
  * Products

Resources

  * Blog
  * Case Studies
  * White Papers
  * Presentations
  * Events

Connect With Us

  *

  *

  *

  *

  *

Copyright © 2014. Flux7 | Sitemap

#+end_example
* TODO setup mirror system and only support readonly request, just in case emergency
* web page: Logging for Success | the agile admin
http://theagileadmin.com/2010/08/20/logging-for-success/
** webcontent                                                      :noexport:
#+begin_example
Location: http://theagileadmin.com/2010/08/20/logging-for-success/
the agile admin
Skip to content

  * Home
  * About
  * What Is DevOps?

[cropped-chaos]
← Oracle Declares War On Open Source
Austin Cloud Computing Users Group Meeting Tomorrow →
by ernestm | August 20, 2010 · 3:19 pm
↓ Jump to Comments

Logging for Success

I’ve been working on a logging standards document for our team to use.  We are having a lot of
desktop-software developers contributing software to the Web now, and it is making me take a step
back and re-explain some things I consider basics.  I did some Googling for inspiration and I have
to say, there’s not a lot of coherent bodies of information on what makes logging “good” especially
from an operations point of view.  So I’m going to share some chunks of my thoughts here, and would
love to hear feedback.

You get a lot of opinions around logging, including very negative ones that some developers
believe.  “Never log!  Just attach a debugger!  It has a performance hit!  It will fill up disks!” 
But to an operations person, logs are the lifeblood of figuring out what is going on with a complex
system.  So without further ado, for your review…

Why Log?

Logging is often an afterthought in code.  But what you log and when and how you log it is critical
to later support of the product.  You will find that good logging not only helps operations and
support staff resolve issues quickly, but helps you root-cause problems when they are found in
development (or when you are pulled in to figure out a production problem!).  “Attach a debugger”
is often not possible if it’s a customer site or production server, and even in an internal
development environment as systems grow larger and more complex, logs can help diagnose
intermittent problems and issues with external dependencies very effectively.  Here are some
logging best practices devised over years of supporting production applications.

Logging Frameworks

Consider using a logging framework to help you with implementing these.  Log4j is a full-featured
and popular logging package that has been ported to .NET (Log4net) and about a billion other
languages and it gives you a lot of this functionality for free.  If you use a framework, then
logging correctly is quick and easy.  You don’t have to use a framework, but if you try to
implement a nontrivial set of the below best practices, you’ll probably be sorry you didn’t.

The Log File

  * Give the log a meaningful name, ideally containing the name of the product and/or component
    that’s logging to it and its intent.  “nifarm_error.log” for example is obviously the error log
    for NIFarm.  “my.log” is… Who knows.
  * For the filename, to ensure compatibility cross-Windows and UNIX, use all lower case, no
    spaces, etc. in the log filenames.
  * Logs should use a .log suffix to distinguish themselves from everything else on the system (not
    .txt, .xml, etc.).  They can then be found easily and mapped to something appropriate for their
    often-large size.  (Note that the .log needs to come after other stuff, like the datetime stamp
    recommended below)
  * Logs targeted at a systems environment should never delete or overwrite themselves.  They
    should always append and never lose information.  Let operations worry about log file deletion
    and disk space – do tell them about the log files so they know to handle it though.  All
    systems-centric software, from Apache on up, logs append-only by default.
  * Logs targeted at a desktop environment should log by default, but use size-restricted logging
    so that the log size does not grow without bound.
  * Logs should roll so they don’t grow without bound.  A good best practice is to roll daily and
    add a .YYYYMMDD(.log) suffix to the log name so that a directory full of logs is easily
    navigable.  The DailyRollingFileAppender in the log4 packages does this automatically.
  * Logs should always have a configurable location.  Applications that write into their own
    program directory are a security risk.  Systems people prefer to make logs (and temp files and
    other stuff like that) write to a specific disk/disk location away from the installed product
    to the point where they could even set the program’s directory/disk to be read only.
  * Put all your logs together.  Don’t scatter them throughout an installation where they’re hard
    to find and manage (if you make their locations configurable per above, you get this for free,
    but the default locations shouldn’t be scattered).

Much more after the jump![trans]

How Many Logs?

One or multiple logs for a given product are both OK.  What you want to do is have a clear purpose
for each separate log.  Common log file divisions are separate usage logs vs error logs, or
separate logs per major component.  If you combine usage with errors, each line needs to have
something indicating which it is.  Keep in mind that if you separate component logs too much it’ll
be hard to trace problem timelines across all those files.

It’s best to optimize log files for their use rather than worrying about them being theoretically
separate.  Apache logs are a good example – there’s an access log and an error log.  Errors still
appear in the access logs as accesses with an error code on them, but the detail information is in
the error log.  This is because if you have a log of accesses, you expect it to contain ALL
accesses.  But you want it to be concise and completely machine parsable, which an error log isn’t
necessarily.

You will always have at least one “main” log – call it the execution log, or the error log, or
whatnot, it’s the main log all your messages go into and is used for troubleshooting.  You want to
flush this log to disk every time you write to it so crashes don’t destroy information.  I’ll refer
to this as the “error” log below – even though it can have informational messages and whatnot its
main point is to highlight errors.

Other logs for specific other purposes are fine – in fact if you have another major use case, like
“A report the PMMs use to determine what kinds of compiles are coming into the app,” that should
probably be a separate log file made appropriate for that use.

Log Format and Content

  * Log in plaintext so logs can be viewed in Notepad etc.
  * Log a single event to a single line.  Stack trace kinds of things can be multiline, but it’s
    best to keep it single.  Remember a multithreaded application could intersperse a bunch of
    stuff between those lines you think are “adjacent”.
  * Log with a delimiter between fields so logs can be easily parsed.  Pipes, commas, or spaces are
    OK but make sure you escape inserted strings that include that delimiter!  Do not use fixed
    widths.  If you have an empty field, put something in there (like Apache uses “-“)
  * The more formatted and machine readable a log file is, the more it can be automatically
    consumed and acted upon.
  * Every log line should start with a date/time stamp, ideally in YYYYMMDDHHMMSS order (e.g.
    2010-05-07 19:51:57).  Use 24 hour time format (no AM/PM).  This makes logs easily searchable
    and sortable.  UTC preferred.
  * Every error log line should have a standard severity.
  * You should always log any diagnostic ID that indicates what process, thread, session, or other
    instance of any multi-instance resource generated the event.
  * You should log information about the user’s identity – both network info (e.g. IP address) and
    any authentication info (e.g. username).
  * You should be very specific about where the event came from, at the class/method level.
  * Do NOT log sensitive data.  Passwords should never go into a log (whether the authorization
    event was a pass or fail).  Notify operations of any personally identifiable information you
    log (email addresses, etc.) due to legal requirements surrounding such data (we have to scrub
    it before sending it outside NI for example).
  * Log a unique ID for each error that can also be presented to the user by your code, so that an
    end user reporting an error can be traced back to the actual error information in the system. 
    “Hey, it says ‘Error 420804′ when I try to upload a file.”  Remember error reports, if and when
    they come, can be days later and have gone through multiple people – “some guy had an upload
    problem at some point in the last couple days” isn’t real helpful when there’s 250 MB of log
    files from that period.
  * Store data in your exceptions to make them easier to read – the more context you have, the
    better you’ll be able to log it.  Say what you expected and what you got.  “Tried to run a job
    requiring 10 service credits for user foo@bar.com but they have only 5 remaining” is much
    better than “Job failed.”
  * You should use your application log and not standard out/system logs/tomcat logs/Windows logs. 
    Those should be for unforeseen untrapped exceptions and you should expect that anything ending
    up in those would generate a request to you to handle that exception in the code in the future.
  * Don’t log and rethrow an exception.  Log it only once, as high in the stack as possible.
  * Keep context in mind.  If you’re logging all successful logins, but not unsuccessful ones, how
    obvious is that to someone six months later looking at the log because there’s problems?

Now, none of this is to say that you should go out and execute other code and do lookups to
populate your error.  But if the code throwing the error already has access to context information,
user information, etc. – you should include it and not just keep it from the poor person reading
the log.

Logging Levels

Don’t fret over “whether” to log something or not.  The answer, if you have to ask the question, is
yes.  The question should simply be what level to log it at.

You should use the semi-standard set of log levels – [FATAL|ERROR|WARN|INFO|DEBUG|TRACE].  Here’s
what they should mean.

In production, logging is usually set to WARN level. More detailed levels are only turned on if
there’s a known problem or the developer wants to capture more detail for a limited time.

  * FATAL: Level FATAL is for things that cause the software to not start or crash.  “Can’t load
    that DLL” or “Out of memory, going down” qualify.  If your app tries to start or crashes,
    someone should be able to go to the log and find a FATAL line that says when and why.
  * ERROR: At level ERROR, the only things that should go into the log are problems that need to be
    actionable by someone.  There is no such thing as a “routine error.”  Those should be put at
    level WARN.  ERRORs are things that aren’t end user error but that indicate something
    technical’s not right with the system/application.  “Can’t connect to (database, ldap, file
    server)”, “trying to save this file but am getting an error saying I can’t,” etc.  ERROR log
    lines should be rare enough that they page operations staff or trigger automated routines.
  * WARN: At level WARN, put anything that is a temporary problem.  An example is if an app
    couldn’t connect to the authorization service the first time, but will try three more times
    before giving up.  That should generate WARNs until it’s done trying and fails, which would be
    an ERROR.  Also at WARN is any activity that is not totally routine.  A failed login due to a
    bad password is a WARN level.  Bad user inputs are WARN level.  Finding a virus in an uploaded
    file and disposing of it successfully is a WARN level.  WARN messages would appear on
    operations consoles and might be monitored for volume.
  * INFO: At level INFO and above, you should log every single call to an external dependency.  If
    you are talking over a network port, that means you. Talking to a Web service, a database, an
    authentication server, a file server, or anything like that should be logged and ideally a
    timing taken of how long it took.  One of the most common errors in a complex system is that
    one of the many elements it depends on gets slow or goes down.  If logging is at INFO level,
    you should be able to see major activity – every user coming in, every job submitted, etc. – a
    high level map of “what is going on” with the application.
  * DEBUG: At level DEBUG, you should log every time you go into or out of parts of your code.  If
    you’re using a logging framework, it’s as easy to use this as it is to put in print
    statements.  Don’t put in print statements, ever, use debug level logging.
  * TRACE: TRACE level is what you’d use if you wanted to log loads of input/output or similar –
    like a Web app that logs every line of HTML it outputs to the user for some reason.

Changing Log Levels In Production

You should be able to configure your application’s log severity level to log only events of
severity X and above in an easily changed configuration file.  Let the operations staff know where
this setting is.  As a bonus, let this level be changed without having to restart your application/
app server.

If your application/log framework is set to read in its configuration repeatedly as it runs, then
log levels can be changed on the fly.  This can incur a performance penalty, though some log
frameworks do this multithreaded or once every time increment rather than every time it logs to
minimize the impact.  If your app requires a restart to set its log level, then changing levels
will probably have to wait until maintenance windows.

Examples

Here’s some examples of “happy” logs.

1.  This is an application called “portal” that calls a Web service called “ills” that in turn
creates or authenticates users against a LDAP repository.  Notice the time and date stamps, the
pipe delimitation, and location (module and line number) this was thrown from the code.  There are
WARNs for minor issues (auth failed, user already existed , INFOs for major steps, DEBUG for
details, and TRACE for input/output.  There are no ERRORs because nothing happened that is bad
enough to provoke intervention.  This is from Log4j; there is no “standard” format as it’s
configurable but this is what they tend to look like.
portal.20100819.log:
2010-08-19 10:20:17,214|INFO|MyfacesConfig.java|185|Starting up Tomahawk on the
MyFaces-JSF-Implementation
2010-08-19 10:20:31,229|INFO|TomcatAnnotationLifecycleProvider.java|47|Creating instance of
com.ni.apps.lvdotcom.portal.controller.MyMainController
2010-08-19 10:20:31,230|DEBUG|MyMainController.java|23|MyMainController commences
2010-08-19 10:20:31,230|DEBUG|MyMainController.java|29|Hidden flavor: uib
2010-08-19 10:20:31,231|DEBUG|MyMainController.java|33|Setting the flavor to hidden param: uib
2010-08-19 10:20:31,231|DEBUG|MyMainController.java|69|MyMainController completes
2010-08-19 10:20:31,232|INFO|TomcatAnnotationLifecycleProvider.java|47|Creating instance of
com.ni.apps.lvdotcom.portal.controller.MyUserController
2010-08-19 10:20:31,233|INFO|TomcatAnnotationLifecycleProvider.java|47|Creating instance of
com.ni.apps.lvdotcom.portal.controller.MyMessagingController
2010-08-19 10:20:31,233|DEBUG|MyMessagingController.java|15|MyMessagingController- Initializing.
2010-08-19 10:20:31,250|INFO|TomcatAnnotationLifecycleProvider.java|47|Creating instance of
com.ni.apps.lvdotcom.portal.controller.MyLoginController
2010-08-19 10:20:31,252|DEBUG|MyLoginController.java|62|login- The app flavor is: uib
2010-08-19 10:20:31,693|WARN|ILLSClient.java|238|ILLS could not authenticate. Returned Status: 401
2010-08-19 10:20:31,694|WARN|MyLoginController.java|96|Invalid Login: karthik.gaekwad@ni.com
2010-08-19 10:20:31,695|TRACE|ILLSClient.java|241|<html><head><title>Apache Tomcat/6.0.26 - Error
report</title><style><!--H1 {font-family:Tahoma,Arial,sans-serif;color:white;background-color:#
525D76;font-size:22px;} H2 {font-family:Tahoma,Arial,sans-serif;color:white;background-color:#
525D76;font-size:16px;} H3
{font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;font-size:14px;} BODY
{font-family:Tahoma,Arial,sans-serif;color:black;background-color:white;} B
{font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;} P
{font-family:Tahoma,Arial,sans-serif;background:white;color:blac
k;font-size:12px;}A {color : black;}A.name {color : black;}HR {color : #525D76;}--></style> </head>
<body><h1>HTTP Status 401 - java.lang.Exception: Failed to authenticate: karthik.gaekwad@ni.com
at com.ni.apps.lvdotcom.user.web.core.AccountFacade.login(AccountFacade.java:141)
<stack trace>
…
2010-08-19 10:21:38,660|TRACE|MyAccountController.java|160|Typed FirstName: Karthik
2010-08-19 10:21:38,660|TRACE|MyAccountController.java|162|Typed LastName: Gaek
2010-08-19 10:21:38,706|WARN|MyAccountController.java|178|Account creation Error: could not create
account for karthik.gaek@ni.com
com.ni.apps.lvdotcom.portal.exception.ApplicationException: error_user_in_ldap
at com.ni.apps.lvdotcom.portal.web.core.AccountManagementFacade.createAccountStep1
(AccountManagementFacade.java:75)<stack trace>
...
2.  Apache logs, for those not familiar with them.  They conform to an actual W3C standard format. 
The access log is space delimited, and wraps fields with spaces in quotes.  It puts a “-“ in for
fields that would otherwise be empty.  The access log is a completely regular log, more complex
errors are put in the error log so that the access log is concise and parsable.  They’re very
configurable, this is our default configuration.  If you are using/writing a Web server you should
be logging similar information.

access.20100819.log:
2010-08-19 10:48:42 10.209.121.205 - 10.240.95.149 130.164.78.45 users.niwsc.com GET /portal/app/
page/account.xhtml  HTTP/1.1 200 16222 12020 12097 2944351088 "Mozilla/5.0 (Windows; U; Windows NT
5.1; en-US; rv:1.9.2.8) Gecko/20100722 Firefox/3.6.8 ( .NET CLR 3.5.30729)" "-" "JSESSIONID=
0173772CBB28982130AA198BD86539B9" "http://users.niwsc.com/portal/app/page/account.xhtml"
2010-08-19 10:49:38 10.209.121.205 - 10.240.95.149 130.164.78.45 users.niwsc.com GET /portal/app/
page/account.xhtml ?p=confirm&u=kgaekwad%40ni.com&token=210E5823DB09016C HTTP/1.1 200 6891 11235
12097 2912881520 "Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.2.8) Gecko/20100722
Firefox/3.6.8 ( .NET CLR 3.5.30729)" "-" "JSESSIONID=0173772CBB28982130AA198BD86539B9" "
http://users.niwsc.com/portal/app/page/account.xhtml?p=confirm&u=kgaekwad%40ni.com&token=210E5823DB09016C
"2010-08-19 10:49:46 10.209.121.205 - 10.240.95.149 130.164.78.45 users.niwsc.com GET /portal/app/
page/account.xhtml  HTTP/1.1 200 16222 14889 12097 2933861232 "Mozilla/5.0 (Windows; U; Windows NT
5.1; en-US; rv:1.9.2.8) Gecko/20100722 Firefox/3.6.8 ( .NET CLR 3.5.30729)" "-" "JSESSIONID=
0173772CBB28982130AA198BD86539B9" "http://users.niwsc.com/portal/app/page/account.xhtml"2010-08-19
10:51:36 10.209.121.205 - 10.240.95.149 130.164.78.45 users.niwsc.com GET /portal/app/page/
account.xhtml ?p=confirm&u=kgaekwad%40ni.com&token=210E5823DB09016C HTTP/1.1 200 6891 90415 12095
3049249648 "Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.2.8) Gecko/20100722 Firefox/
3.6.8 ( .NET CLR 3.5.30729)" "-" "JSESSIONID=0173772CBB28982130AA198BD86539B9" "
http://users.niwsc.com/portal/app/page/account.xhtml?p=confirm&u=kgaekwad%40ni.com&token=210E5823DB09016C
"

errors.20100819.log:
[Thu Aug 19 05:07:33 2010] [error] [client 83.242.145.34] client sent HTTP/1.1 request without
hostname (see RFC2616 section 14.23): /w00tw00t.at.ISC.SANS.DFind:)

Conclusion

Remember that log files get very large on busy system, and that there are lots of different logs –
app logs, system logs, etc. – that have to be rooted through, often by someone who doesn’t know how
your code was written and what it does when.  Operations will be more successful if they can figure
out what your code was trying to do and what exactly about that failed.  Support will be more
successful if when a customer sends them log files, they can figure out the same thing.  And if
these folks can help customers quickly, then everyone’s happy.  Next best is that they have to come
to you (assuming you still work at that company/on that product) and ask you “what this means.”  Of
course, it’s possible to log so badly that you don’t know what it means either.  If you can’t look
at your own application’s log after a crash and understand what was going on at the time, no one
else will be able to either.  Debuggers are fine for development but are not a production problem
finding tool.

References

  * http://en.wikipedia.org/wiki/Log4j
  * http://logging.apache.org/log4j/
  * http://stackoverflow.com/questions/696321/best-logging-framework-for-native-c
  * http://today.java.net/pub/a/today/2006/04/06/exception-handling-antipatterns.html
  * http://codemonkeyism.com/7-good-rules-to-log-exceptions/

About these ads

Share this:

  * Twitter
  * LinkedIn
  * More
  *

  * Google
  * Facebook
  *
  * Tumblr
  * StumbleUpon
  *
  * Reddit
  * Pinterest
  *
  * Print
  * Email
  *
  *

Related

7 Comments

Filed under DevOps

Tagged as best practices, Log Management, logging

← Oracle Declares War On Open Source
Austin Cloud Computing Users Group Meeting Tomorrow →

7 responses to “Logging for Success”

 1. [8635] Randy W
    August 20, 2010 at 11:37 pm

    Nice article, thanks for pulling it together.
    One point that you didn’t mention amd might consider for your standards is that some logging
    frameworks (like log4j) provide boolean checks to determine whether you are at a given log
    level.
    So, I can call isDebugEnabled() or isInfoEnabled() methods before executing a log message.
    This is important for Debug and Info level messages (also Trace if you use them) because of the
    volume of those messages in the normal execution path.
    Because programming languages generally process nested code from the inside-out (eg, arguments
    are processed before being passed into a function) a debug log message can generate some
    processing even if debugging is not enabled.
    For example, the following log4j statement will always incur a String concatenation, regardless
    of the log level because the arguments are processed before the call to the logging framework:

    Logger.debug(“Error #” + errorNum + ” occurred.”);

    To avoid this, use the frameworks checks so that you incur a lightweight boolean check instead
    of a more expensive string concatenation.

    if (Logger.isDebugEnabled){Logger.debug(“Error #” + errorNum + ” occurred.”);}

    This will significantly reduce the impact of the many trace, debug, and info messages in the
    code.

    Reply
 2. [4e46] Adam Fletcher
    August 23, 2010 at 9:25 am

    Great article!

    I prefer LogBack to log4j (http://logback.qos.ch/) as LogBack extends log4j in useful ways,
    such as allowing rotation based on time and size (so you can say “rotate this log daily or when
    the log is bigger than 100MB”). I like this because dealing with large log files is very
    painful. Also, log4j compresses logs synchronously, so that it pauses application execution
    during compression which is a high-impact bug when your logs are big. LogBack fixes this bug as
    well.

    -Adam

    Reply
 3. [daeb] ernestm
    August 25, 2010 at 11:51 am

    Hey guys, sorry you got caught in the overzealous WordPress spam filter, but I let ya out. Both
    good points. Log4j isn’t the only game in town. On the Windows side for C#/C++ types pantheois
    and a variety of log4j-like stuff that isn’t the “official from the log4j site” port (log4cxx)
    like log4cplus and log4net.

    Reply
 4. [6e8e] Karthik Gaekwad
    September 5, 2010 at 1:33 pm

    Hey! A google search of my name found this blog. Fancy that!

    That being said, I had something to add.

    I noticed you had added 6 levels of logging from TRACE to FATAL. At the time of implementation,
    I’ve realized that most frameworks hadn’t started with 6 levels, but 5 instead (DEBUG through
    FATAL). TRACE is a little newer, and while most frameworks (aka log4j) support it now, they
    haven’t always supported it.

    That being said, I don’t use TRACE as much in my logs but generally start with DEBUG.

    Reply
      + [daeb] ernestm
        September 9, 2010 at 9:37 am

        Yeah, I think it’s OK to combine the two if you don’t have a trace level – but if you log
        full streams of input and/or output, then you risk not being able to turn debug logs on in
        production for troubleshooting because of sheer volume.

        Reply
 5. [daeb] ernestm
    January 20, 2013 at 8:57 am

    See also: http://www.masterzen.fr/2013/01/13/the-10-commandments-of-logging/

    Reply
 6. [2814] Matthew Skelton (@matthewpskelton)
    January 22, 2013 at 12:24 pm

    Hi Ernest, hot from the comments thread on masterzen’s blog, here’s the link to a recent
    article of mine (in SDPJ) covering a technique for tuning logging levels in Production which
    avoids the need to decide on logging levels at compile time:

    http://blog.matthewskelton.net/2012/12/05/tune-logging-levels-in-production-without-recompiling-code/

    Cheers

    Matthew

    Reply

Leave a Reply Cancel reply

Enter your comment here...
[                    ]

Fill in your details below or click an icon to log in:

  *
  *
  *
  *
  *

Gravatar
Email (required) (Address never made public)
Name (required)
[                    ]
Website
[                    ]
WordPress.com Logo

You are commenting using your WordPress.com account. ( Log Out / Change )

Twitter picture

You are commenting using your Twitter account. ( Log Out / Change )

Facebook photo

You are commenting using your Facebook account. ( Log Out / Change )

Google+ photo

You are commenting using your Google+ account. ( Log Out / Change )

Cancel

Connecting to % s

[ ] Notify me of new comments via email.

[ ] Notify me of new posts via email.

 Post Comment

  * Search for: [                    ]  Search
  * Subscribe

    Enter your email address to subscribe to the Agile Admin and receive notifications of new posts
    by email.

    Join 1,395 other followers

    [                    ]

     Sign me up!

  * Recent Comments

      + Siva on Why Does Cloud Load Balancing Suck?
      + DevOps Teams - Establishing a DevOps Team - Musing Mashup on A DevOps Manifesto
      + Ravan Asteris on A DevOps Manifesto
      + April on AWS re:Invent Keynote Day 1 Takeaways
      + Top 10 links for the week of Nov 10 - HighOps on AWS re:Invent Keynote Day 1 Takeaways
      + ernestm on AWS re:Invent Keynote Day 1 Takeaways
      + DevOps Collections #4 | …snapshots of relevance… on Scrum for Operations: Just Add DevOps
      + twadeus on Scrum for Operations: Just Add DevOps
      + Thrawn on Why Does Cloud Load Balancing Suck?
      + Scrum for Operations: Just Add DevOps | the agile admin on Scrum for Operations: How We
        Got Started
  * Recent Posts

      + AWS re:Invent Keynote Day 2 Takeaways
      + AWS re:Invent Keynote Day 1 Takeaways
      + Scrum for Operations: Just Add DevOps
      + The Cloud Procurement Pecking Order
      + AWS Dying! Rackspace Pulls Out Of Cloud! News At 11!
      + Friday is System Administrator Appreciation Day
      + Velocity 2014 After Action Report
      + Know your options for infrastructure monitoring
      + DevOpsDays Silicon Valley 2014 Day Two Notes
      + DevOpsDays Silicon Valley 2014 Day One Notes
  * Austinites

      + Agile Austin
      + Agile Austin DevOps SIG
      + Austin DevOps
      + Austin OWASP Chapter
      + bazaarvoice: engineering blog
      + CloudAustin (Austin Cloud User Group)
      + Coté Industries (Michael Coté)
      + Crossing Silos (Dan Zentgraf)
      + Gauntlt
      + Splunk Ninja (Michael Wilde)
      + The Agile Executive (Israel Gat)
  * Cloud

      + Adrian Cockcroft's Blog
      + All Things Distributed
      + Amazon Web Services Blog
      + Cloud Computing, Software and System Performance
      + OWASP Home
      + ReadWriteCloud
      + Steve Souders
      + Technometria
  * DevOps

      + Agile Operations Blog
      + Agile Sysadmin
      + Agile Testing
      + Agile Web Operations
      + Beyond DevOps: Reflections on User-Centered IT
      + Constructolution
      + Cuddletech (Ben Rockwood)
      + Cutter Consortium
      + dev2ops (The DTO Crew)
      + DevOps Cafe Podcast
      + DevOps.com
      + Etsy's Code as Craft
      + Geeks Gone Mad
      + High Scalability
      + Kitchen Soap (John Allspaw)
      + Lusis (John Vincent)
      + obfuscurity (Jason Dixon)
      + Planet DevOps
      + Rugged DevOps
      + Sanjeev Sharma
      + Server Fault
      + The Ship Show
  * @wickett

      + “Applying Security Discernment for IoT and in Life” w/ @m1a1vet on Feb 6 in Austin >
        hackformers.org/2015/01/29/mic… 3 days ago
      + #AppSecCali was awesome, thanks to all the organizers and volunteers for all your hard work
        4 days ago
      + reward the good security behavior instead of trying to penalize the problems #appseccali @
        zanelackey 4 days ago
      + define empathy as a core value of your team culture @zanelackey #AppSecCali 4 days ago
      + instead of blocking, the focus becomes on incentivizing teams to reach out to security @
        zanelackey #AppSecCali 4 days ago
  * @ernestmueller

      + Interested in #docker and containers? Come out to Container Days Austin, an unconference,
        this March 27-28! containerdaysaustin.com/2015/ #cdatx 3 days ago
      + RT @femfreq: Sorry fellas but insisting “rape and death threats are a normal part of the
        gaming community” is not a legitimate criticism of… 5 days ago
      + This Tuesday at #CloudAustin, Michael Cote and Dave Nielsen will deliver the Cloud State of
        the Union address! Signup meetup.com/CloudAustin/ev… 2 weeks ago
      + Bonus speaker this month at @CloudAustin - we have both @cote and @davenielsen presenting!
        meetu.ps/2DTfkl 2 weeks ago
      + RT @keen_io: An open source repo for responsive dashboard templates keen.github.io/
        dashboards/ http://t.co/9RfeVGVhfO 3 weeks ago
  * @iteration1

      + How incredibly picky you are shell script. 2 days ago
      + .@Runscope is the best tool to use if you're trying to test whether your networking and
        orchestration work as expected in odd scenarios. 2 days ago
      + RT @thereaIbanksy: Simple... http://t.co/eiD76lQEcP 3 days ago
      + RT @cote: @botchagalupe @iteration1 your talk title "If a container runs without
        networking, does it exist? P.S. Networking considered hard… 4 days ago
      + RT @chrylarson: Programmer in need of loving home. @smartthings #nodejs #angularjs #
        javascript #startup #php #api #arduino http://t.co/eZGh… 4 days ago
  *

    2013 agile amazon APM application security appsec austin Automation aws azure big data bug chef
    Cloud cloudcamp Cloud Computing conference Conferences configuration management deploy DevOps
    devopsdays ec2 facebook failure google IaaS InfoSec infrastructure interactive labview lascon
    logging Management metrics microsoft monitoring netflix ni Operations ops oracle owasp paas
    performance provisioning puppet Q&A reinvent release SaaS scalability scrum scrum4ops Security
    service splunk suppliers sxsw sxswi system administration systems testing tools unconference
    velocity velocity08 velocityconf velocityconf08 velocityconf09 velocityconf10 velocityconf13
    velocityconf14 web webops
  * Archives

      + November 2014
      + September 2014
      + August 2014
      + July 2014
      + June 2014
      + May 2014
      + April 2014
      + March 2014
      + February 2014
      + January 2014
      + December 2013
      + November 2013
      + October 2013
      + September 2013
      + August 2013
      + July 2013
      + June 2013
      + April 2013
      + March 2013
      + January 2013
      + October 2012
      + July 2012
      + May 2012
      + April 2012
      + March 2012
      + February 2012
      + January 2012
      + December 2011
      + November 2011
      + September 2011
      + August 2011
      + July 2011
      + June 2011
      + May 2011
      + April 2011
      + March 2011
      + February 2011
      + January 2011
      + December 2010
      + November 2010
      + October 2010
      + September 2010
      + August 2010
      + July 2010
      + June 2010
      + April 2010
      + March 2010
      + February 2010
      + January 2010
      + September 2009
      + July 2009
      + June 2009
      + March 2009
      + February 2009
      + January 2009
      + December 2008
      + October 2008
      + September 2008
      + August 2008
      + July 2008
      + June 2008

the agile admin · thoughts on agile web operations and devops by @ernestmueller, @wickett,
@iteration1 and @bproverb
Blog at WordPress.com. · The Pilcrow Theme.
Follow

Follow “the agile admin”

Get every new post delivered to your Inbox.

Join 1,395 other followers

 Sign me up

Build a website with WordPress.com
Send to Email Address Your Name [                    ] Your Email Address
loading  Send Email  Cancel
Post was not sent - check your email addresses!
Email check failed, please try again
Sorry, your blog cannot share posts by email.
[b]

#+end_example
* #  --8<-------------------------- separator ------------------------>8--
* TODO Discussion: Reduce cost in DigitalOcean: avoid long-run QA env
* TODO Discussion: Maintaince window: provide switch to only handle readonly request
* web page: Successful AWS Cloud Projects We’ve Done at Flux7
http://blog.flux7.com/blogs/aws/successful-aws-cloud-projects-weve-done-at-flux7
** webcontent                     :noexport:
#+begin_example
Location: http://blog.flux7.com/blogs/aws/successful-aws-cloud-projects-weve-done-at-flux7
844-Flux700
/
Contact Us
Search this site on Google
[                    ] Search Google
  *

  *

  *

  *

  *

Flux7 Logo

  * Home
  * Company
      + About Us
      + Technology Expertise
      + Careers
      + Partners
      + News & Events
          o News
          o Press Releases
          o Events
  * Solutions
      + Assessment Packages
          o Cloud Infrastructure Assessment
          o DevOps Assessment Package
          o Dev Flow Assessment Package
          o Docker Assessment Package
      + Cloud Attune Package
      + Solutions for SMBs
          o DevOps for SMBs
          o Cloud for SMBs
          o IT Optimization
      + Solutions for Enterprises
          o DevOps for Enterprises
          o Cloud for Enterprises
          o IT Optimization
      + Docker
          o Docker Solution
          o Docker Assessment Package
          o Docker Resources
      + Products
          o Vyscale
      + Training
      + Support Packages
  * Industries
      + Flux7’s Cloud Solutions for Healthcare and Life Sciences
  * Clients
      + Clients
      + Case Studies
  * Resources
      + Blog
      + Presentations
      + White Papers
      + Webinars & Meetup Videos
  * Contact Us

Blog

DevOps & Cloud Computing Hub

  * Resources
  * Blog
  * Successful AWS Cloud Projects We’ve Done at Flux7

Successful AWS Cloud Projects We’ve Done at Flux7

AWS PROJECT

The current trends in technology indicate that more than 60% of the businesses use cloud computing
for their IT operations. Among the various cloud service providers, Amazon Web Services [AWS] is a
pioneer and continues to be a leader in the cloud market.

If your firm hasn’t yet moved to the cloud, here are six reasons why you should consider a
migration now.

At Flux7, we have had several magnificent encounters with clients whose needs have revolved around
and within the cloud. Specifically, AWS. This post is about three such scenarios we’ve had during
the last few months.

They are:

 1. Reducing AWS spending by $5,000 per month

 2. Moving two renewable energy giants to the cloud

 3. Achieving high performance and low costs using AWS

Reducing AWS Spending by $5,000 per Month

Amazon Web Services delivers a rich feature set and provides services on a pay-as-you-go basis.
Although this means that a customer or user pays only for the service that he/she actually used, it
is quite possible to overpay and end up with a heavy monthly AWS bill.

Consider the following scenarios which depict how AWS bills could be unknowingly high, possibly due
to lack of best practices.

1. Running Dev and Test instances even while not in use, say, at night, when the instances could be
turned off.

2. Unused EBS volumes, private AMIs and snapshots, that consume a lot of a space, and, in turn, a
lot of money.

3. Lack of autoscaling policies in place that lead to over allocation of resources, even during
times of lull for your website or application.

4. Use of instance sizes that don’t fit or meet the actual requirements. Using instances larger
than is needed increases cost, and using instances smaller than is needed reflects in the
performance.

A similar situation was faced by our client who was overpaying by $5,000 per month. A thorough AWS
audit was performed by Flux7. We concluded that with a comprehensive list of recommendations, we
could reduce the client’s AWS bills up to $5,000 each month, and even more. Read the case study
here to better understand more about the AWS audit and our findings .

Moving Two Renewable energy Giants to the Cloud

As mentioned before, the cloud is becoming the necessity of the day, and it’s a typical exercise of
enterprises moving, or planning to move, to the cloud. Several business requirements call for cloud
migration, including scalability, agility, high availability, and the list goes on. One such
interesting call for migrating to the cloud was from solar panel manufacturers with applications
that could be put to full use if moved to the Cloud.

Consider the following:

Solar Panel Monitoring Systems -- provide real-time data on the power consumed by a customer at any
given time.

Customer Portal, Billing & Accounting System -- a comprehensive dashboard to enable customers to
better understand their usage, track bills paid, and defuncts in payment.

A few other applications include billing enforcement system and firmware upgrade manager, as well
as contract and quotation management software.

What benefits did we gain from the cloud-based solutions? Here are some of them:

  * Ability to produce higher quality software

  * Reduce conflicts between Devs and Ops

  * Create production-like Dev environments in less than five minutes

  * No shortage of IT staff and shorter new hire ramp-up

  * Improve customer engagement and satisfaction

Read the case study now to better understand how Flux7 got it done.

Achieving High Performance at Low Cost Using AWS

The third use case describes cloud usage for an online media company, Yactraq. It provided a
speech2Topics API. Its service focuses on extracting data from videos for use in advertising,
search and discovery. The API returns a list of topics discussed in the video at specific times.
The API is also used for sentiment analysis. The API works in real-time, and customers expect the
topics within minutes of submitting a video.

Yactraq’s real issues peak in times of increased demands.

Yactraq has partnered with Flux7 to handle the scaling and price optimization. At Flux7, we
developed VyScale, which is a spot-strategy-as-a-service SaaS product. VyScale uses proprietary
machine-learning algorithms and historical data to dynamically choose the best spot strategy.

Using AWS spot instances in our strategy led to:

  * 60-million seconds of video successfully processed

  * 60%-80% reduction in costs

  * Effective autoscaling and disaster recovery solutions

  * Automated solution requiring no human intervention

Our motivation to use spot instance gets credited to Yactraq’s pricing model, which is based on the
number of minutes processed, and that the cost of compute directly impacts the bottom line.

As a result, we proudly earned an honorable mention at the 2013 AWS re:Invent event for our product
VyScale and its use at Yactraq. Click here to learn how Flux7 was able to make such an impression .

Then read the case study about Yactraq to better understand how Flux7 improved its process.

To learn even more about what we can do at Flux7 with AWS cloud services, email us now at
info@flux7.com, or visit our website for solutions at www.flux7.com

April 25, 2014 / AWS

Share the Post

  * Tweet
  *
  *
  *

About the Author

Flux7 Labs

Categories

  * Apache Hadoop (3)
  * AWS (33)
  * Benchmarking (25)
  * Case Studies (1)
  * Cloud Computing (12)
  * Deployment (4)
  * DevOps (20)
  * Docker (20)
  * Events (11)
  * Flux7 Labs (4)
  * Glossary (14)
  * News & Updates (1)
  * NoSQL (4)
  * Openstack (8)
  * Press Release (7)
  * Quizzes (7)
  * Spot Instances (1)
  * Surveys (1)
  * Tutorials (1)
  * Virtual Meetups (1)

Subscribe to Email Updates

Connect With Us

Recent Posts

  * Cloud Computing in Healthcare: Best Practices for Life Sciences and Healthcare
  * If You Think Hiring an Expert is Expensive, Wait Until You do it Wrong!
  * On Papercuts And DevOps
  * Flux7 Wins 2015 Modern Impact Awards, Best AWS Consulting Partner
  * Building a Continuous Integration Environment in AWS

Company

  * About Us
  * Careers
  * Clients
  * Partners
  * Press Releases

Solutions

  * Solutions for SMBs
  * Solutions for Enterprises
  * Training
  * Products

Resources

  * Blog
  * Case Studies
  * White Papers
  * Presentations
  * Events

Connect With Us

  *

  *

  *

  *

  *

Copyright © 2014. Flux7 | Sitemap

#+end_example
* TODO When restarting service, do we have to check logfile?
* TODO Lower the risk about configuration template change
#+BEGIN_EXAMPLE
[3/4/15, 10:34:36 AM] denny: denny added Andre Uhlrich, kungchaowang, Lucas Schiochet to this conversation
[3/4/15, 10:34:51 AM] denny: Hi Lucas, would you please see this comment of CP-7006?

https://totvslab.atlassian.net/browse/CLOUDPASS-7006?focusedCommentId=22707&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-22707
[3/4/15, 10:41:23 AM] Andre Uhlrich: How long this problem is happening?
[3/4/15, 10:42:21 AM] denny: 1. We should make developers on the same page with DevOps: whenever configuration template is changed, notify DevOps to update configuration template.

2. The recent change of rest.yml and search.yml may need some discussion with related developers. Would you please add them into the loop?

For example:
1. In search.yml, we changed “jms.topic.lucene” by adding more roles. Any special action needed for upgrading existing system?
2. In rest.yml, we have removed “socketServerConfiguration”. That’s the direct root cause of CP-7006. Is that on purpose?
[3/4/15, 10:42:56 AM] denny: Andre, the problem happens ever since the configuration file is changed in backend repo.
[3/4/15, 10:43:35 AM] Lucas Schiochet: who change this files?
[3/4/15, 10:43:46 AM] denny: Let me see
[3/4/15, 10:47:30 AM] denny: I see, both change to search.yml and rest.yml come from Kung.

https://github.com/TOTVS/backend/commits/master/service/rest/rest.yml
https://github.com/TOTVS/backend/commits/master/service/search/search.yml
[3/4/15, 10:48:37 AM] denny: Let me sync up more with Kung.

@Lucas, please sync up with developer team:
- Whenever change the configuration file, notify DevOps to update configuration template.
[3/4/15, 10:48:55 AM] denny: I’ve updated that to below wiki
https://totvslab.atlassian.net/wiki/display/TECH/Procedure+To+Make+A+New+Release
“Confirm with developers, if there're any configuration file changed. If yes, change chef code respectively. And upload related cookbook to spchef.fluigidentity.com”

#+END_EXAMPLE
* TODO contact with Chef expert
# svanzoest
https://github.com/svanzoest-cookbooks/apache2/issues/325#issuecomment-77504961
* #  --8<-------------------------- separator ------------------------>8--
* TODO nagios check: selenium login may fail from time to time
#+BEGIN_EXAMPLE
[2/4/15, 3:30:38 PM] denny: Update some of my solid observation:

1. nagios has the similar selenium login test like Suresh posted. It will be done every 5 min.
2. Before our update of 1.4.4, the test always succeed. And it fails in a very small chance. But it do happen. When that happens, I checked that manually, it looks fine.
3. After our update of 1.4.4 and before our fix of doc this morning.
    The selenium login fail from time to time.
     I thought the flipping result might be some intermediate situation. Or just false alarm.
[2/4/15, 3:32:00 PM] denny: ==========================
So do we have any test which may fail in a big chance before?
So that we can confirm prod env is fine now.  Otherwise above test doesn’t justify the healthy of the system, IMO.
#+END_EXAMPLE
* TODO [#B] Perform critical action with cautious
#+BEGIN_EXAMPLE
[3/6/15, 3:45:35 PM] Jay Zheng: hi denny, FSENET said the app/update has already been released, can you do a check and let me know if it's true?
[3/6/15, 3:49:18 PM] denny: Oh, yes. My fault.
[3/6/15, 3:49:54 PM] denny: I was on another concall minutes ago.  I planned to release my stub app while having the concall, maybe click that with wrong app developer account.
[3/6/15, 3:51:34 PM] denny: Sorry about that, Jay.
[3/6/15, 3:51:44 PM] Jay Zheng: Is there anyway to take this back?
[3/6/15, 3:51:55 PM] denny: Just tried to upgrade it. It looks good.
[3/6/15, 3:52:17 PM] Jay Zheng: client is a little bit upset -- it's related to their marketing event
[3/6/15, 3:52:21 PM] Jay Zheng: and news release
#+END_EXAMPLE

#+BEGIN_EXAMPLE
[2/13/15, 2:45:38 PM] denny: I see, 362552579@qq.com is a testflight account I used in Tony device.
[2/13/15, 2:45:47 PM] Jay Zheng: yes
[2/13/15, 2:45:51 PM] denny: The problem is we have already gave the UDID permission.
[2/13/15, 2:46:00 PM] denny: But testflight doesn’t show up that UDID
[2/13/15, 2:46:54 PM] Jay Zheng: a couple of things we can do: 1. Set up ubertester this weekend, and so we can all test on ubertester
[2/13/15, 2:47:17 PM] Jay Zheng: 2. Or, make tony’s UDID work on testflightapp
[2/13/15, 2:48:08 PM] denny: Like I said in the email. The problem goes to testflight.

All other devices we’re trying the exact same process in testflight.
But that one just don’t work.
[2/13/15, 2:49:06 PM] Jay Zheng: do you remember that account’s password?
[2/13/15, 2:49:26 PM] Jay Zheng: can you login and delete the device from that account?
[2/13/15, 2:53:37 PM] denny: http://testflightapp.com/install/bd15824a7f4e83e740336e1d14a24ad6-MTUzMTY4ODI/
[2/13/15, 2:53:50 PM] denny: Would you please ask Tony to try this link?

It will work.
[2/13/15, 2:54:28 PM] denny: I just login to 362552579@qq.com, and accept the invitation.

Now testflight show up the UDID of 2ac3d9d2503da254501876825d60c1ff1bcaa0f0
[2/13/15, 2:54:38 PM] denny: Wired trick
[2/20/15, 8:32:37 AM] denny: Jay, we need customer’s apple developer account, to submit the app.

Do you have that?
[2/20/15, 8:36:39 AM] Jay Zheng: I think we have that long time ago…
[2/20/15, 8:36:49 AM] denny: Well, where I can find that?
[2/20/15, 8:37:14 AM] Jay Zheng: I don’t know, let’s both check and I will ask client for it too
[2/20/15, 8:45:05 AM] denny: I checked my local knowledge base and wiki. No luck
[2/20/15, 8:47:29 AM] Jay Zheng: it’s in one of the emails, I’ve already emailed client, will get back to you today
[2/20/15, 8:49:59 AM] Jay Zheng: by the way, good on getting yourself out, let’s have a discussion on that in a week and see how’s that going. We have other ways to use your chef experties, can you track who downloaded you cookbook? (or do you have a way to let them register before you download?)
[2/20/15, 8:50:34 AM] Jay Zheng: I meant Good Job on putting yourself out there
[2/20/15, 8:51:18 AM] denny: sure, let’s have a talk. Today I’m a bit busy. How about tomorrow?
[2/20/15, 8:52:09 AM] Jay Zheng: ok, tomorrow is good, how about tomorrow night 9:00pm?
[2/20/15, 8:52:38 AM] denny: Fine for me
[2/20/15, 8:54:14 AM] Jay Zheng: ok, talk to you then
[2/20/15, 8:54:25 AM] denny: np, thanks, jay
[2/20/15, 11:19:28 AM] denny: Hi Jay

The credential (mcbridefse@gmail.com/Labatt05) doesn’t work.

https://developer.apple.com
Click “Member Center” on the top menu.

Does it work for you?
[2/20/15, 11:51:23 AM] denny: While we are contacting customers for the right apple developer account, I will try to submit the app with a fake name by our own apple developer account
[2/20/15, 12:59:16 PM] Jay Zheng: ok
[2/20/15, 1:02:13 PM] Jay Zheng: try Labatt06 instead of Labatt05 for PW
[2/20/15, 1:02:54 PM] denny: Yes, this one works
[2/20/15, 1:24:02 PM] denny: Note, I tried to submit with our own apple developer.

Appstore complains “Invalid Binary”. I’m checking why.

Once it works, I will try to use customer’s apple account
[2/20/15, 1:24:12 PM] denny: Image
[2/20/15, 1:33:37 PM] Jay Zheng: ok, you can directly try customer’s account if you want — we need to try that anyway
[2/20/15, 1:57:46 PM] denny: We’d better testing in “staging env” first.
1. Submit by our app account, and release the fake app
2. Submit by customer app account, and wait customer’s signal to release the app
3. Verify the fake app in all devices.

When customer signal us in step#2, we can only proceed if step#3 looks good.
[2/20/15, 1:57:54 PM] denny: Otherwise, we will be in trouble.
[2/20/15, 3:02:17 PM] denny: Image
[2/20/15, 3:02:54 PM] denny: Finish step1, and waiting for App Store to approve.

Moving to step2
[2/20/15, 4:05:21 PM] denny: Image
[2/20/15, 4:05:24 PM] denny: Step2 is done
[2/21/15, 10:55:57 PM] denny: Hi Jay, looks like tonight is a bit late.

Maybe we can talk tomorrow or some later time
[2/22/15, 7:21:35 AM] Jay Zheng: sorry, I forgot. Let’s talk tonight, 9 pm eastern time?
[2/22/15, 7:49:19 AM] denny: sure, np
[2/22/15, 7:56:15 PM] Jay Zheng: hi denny
[2/22/15, 7:57:07 PM] denny: hi Jay
[2/22/15, 7:57:38 PM] Jay Zheng: you ready for a quick call?
[2/22/15, 7:57:45 PM] denny: Yes
[2/22/15, 8:21:27 PM] denny: Call  23 minutes 4 seconds
[2/22/15, 11:09:01 PM] denny: About big data, tableau is a rising star.

http://www.tableau.com
[3/6/15, 3:52:36 PM] denny: call?
[3/6/15, 3:52:54 PM] Jay Zheng: can't call right now, I will a different client
[3/6/15, 3:53:15 PM] Jay Zheng: I am with a different client
[3/6/15, 3:53:22 PM] denny: The only way to revert is uploading another version.

And it takes 10 days~
[3/6/15, 3:54:40 PM] Jay Zheng: will it stop this release?
[3/6/15, 3:55:11 PM] denny: From the GUI, it doesn’t seem.
[3/6/15, 3:55:21 PM] denny: Let me google a little bit
[3/6/15, 4:06:49 PM] denny: hmm, there don’t seem to be a way to stop the release.

I know, customer may not feel uncomfortable with below comments/explanation.
1. Last weeks’ downloads is 6, which means the impact would be very small.
2. It’s Friday afternoon, which may different very little with Sunday release.
3. We try to release earlier, thus we can buy some time to test it ourselves, in order to better serve customer.

4. If customer do want to rollback, we will have to upload a new version, which will take ~10 days to take effect.
[3/6/15, 4:11:49 PM] denny: 5. We can wrote a message to apple, asking them to rollback. Mostly like apple won’t answer
[3/6/15, 4:13:48 PM] Jay Zheng: it's not about rollback, it's "stop releasing", rollback requires two updates -- customer will see another udpates, even more confusing if someone just happen to download between now and the "rolllback".
[3/6/15, 4:14:23 PM] Jay Zheng: Let me talk to Fsenet, hopefully, it's not a disaster
[3/6/15, 4:14:27 PM] denny: Correction:
[3/6/15, 4:14:35 PM] denny: For the last week, no download at all
[3/6/15, 4:14:56 PM] denny: For the last month, 3 downloads
[3/6/15, 4:15:14 PM] Jay Zheng: OK, but all the people who have their App's installed will see the update sign right now, right?'
[3/6/15, 4:15:38 PM] denny: Not necessarily
[3/6/15, 4:16:31 PM] denny: They won’t see that, unless they manually check
[3/6/15, 4:17:01 PM] denny: I mean, only if they go to “App Store” —> “Updates”.
[3/6/15, 4:19:05 PM] Jay Zheng: a lot of people have the updates automatically turned on -- anyway, not much we can do at this point. I will talk to FSENET, we should learn a lesson -- next time, maybe we let client do it themselves...
[3/6/15, 4:19:31 PM] denny: yes, agree
[3/6/15, 4:19:38 PM] denny: sorry about that.
[3/6/15, 4:20:24 PM] denny: Hope it helps:
1. We try to release earlier, thus we can buy some time to test it ourselves, in order to better serve customer.
2. Last month’ downloads is 3, which means the impact would be very small.
3. It’s Friday afternoon, which may different very little with Sunday release.
4. If customer do want to rollback, we will have to upload a new version, which will take ~10 days to take effect.
[3/6/15, 4:21:50 PM] denny: F.Y.I: let’s say we upload a new version with multiple critical bugs, we actually still have little to do.

Unless submit another version, and wait 10 days.
#+END_EXAMPLE
* TODO [#A] What Need To Know, when operate a new Component, Say Elasticsearch, Hbase :IMPORTANT:
** [Usage] Learn how to use it, as a normal end user
- If you can't understand, it would be super hard to debug/trouble shooting it
** [Monitoring] What problems we may run into?
** [Deploy/Upgrade] How to deploy and try?
** [Backup] How is the data stored and updated?
* TODO Monitoring: watch network latency
- Without internet ICMP, how I can know how fast the WAN traffic is?
#+BEGIN_EXAMPLE
[3/9/15, 12:56:17 PM] Lucas Schiochet: Hi Denny
[3/9/15, 12:56:48 PM] Lucas Schiochet: Oncoclonicas reported that to login to fluig via identity is taking to much time
[3/9/15, 12:57:05 PM] Lucas Schiochet: Can you inform with the use of resources in production is fine ?
[3/9/15, 12:58:04 PM] denny: Sure
[3/9/15, 1:02:42 PM] Lucas Schiochet: It is normal?
[3/9/15, 1:03:46 PM] denny: Just checked nagios and log files, they are clean
[3/9/15, 1:04:08 PM] denny: I tried to login by https://app.fluigidentity.com

Yes, it’s a bit slow.
[3/9/15, 1:09:38 PM] denny: Lucas, they looks good to me, though apache reported some error with tomcat.

The errors are seen before, and they should be fine.
[3/9/15, 1:10:47 PM] Lucas Schiochet: The main issue is when try to redirect to fluig app
[3/9/15, 1:10:55 PM] Lucas Schiochet: Appears that is a network issue
[3/9/15, 1:11:16 PM] denny: Could we reproduce the issue?
[3/9/15, 1:11:37 PM] denny: =================
BTW, there’re two service use a bit more memory than normal.

Usually the trouble shooting of these problem goes to backend lead, which is Kung.

Are there any resource from your team can do that?
[3/9/15, 1:12:19 PM] denny: The problem should not be related with current load performance issue.

Let me posted in the Skype group. OK?
[3/9/15, 1:12:23 PM] Lucas Schiochet: Today is holiday
[3/9/15, 1:12:37 PM] Lucas Schiochet: Is joinville
[3/9/15, 1:12:43 PM] denny: Maybe we should just post as early as possible.
[3/9/15, 1:12:48 PM] Lucas Schiochet: I am going home to get my notebook
[3/9/15, 1:12:51 PM] Lucas Schiochet: And verify
[3/9/15, 1:13:02 PM] denny: When people came back from holiday, they can check. What do you think?
[3/9/15, 1:13:39 PM] Lucas Schiochet: In half of hour I will be avail ale
[3/9/15, 1:13:50 PM] Lucas Schiochet: Is holiday just in joinville
[3/9/15, 1:13:54 PM] denny: No rush to fix and deep dive today.
[3/9/15, 1:14:02 PM] Lucas Schiochet: The other cities are using and complain about it :/
[3/9/15, 1:14:47 PM] denny: So should I post the two issues now, or wait for tomorrow?
[3/9/15, 1:15:45 PM] Lucas Schiochet: I recommend now
[3/9/15, 1:15:49 PM] denny: Issues of prod env happens at holiday and weekends. That’s what I frequently observe before. So I’d suggest post as soon as possible.
[3/9/15, 1:16:06 PM] denny: Nice.

No urgent for the two issues, I will post.
[3/9/15, 1:18:07 PM] denny: ==================
It should be network issue. Here is what I found
[3/9/15, 1:18:34 PM] denny: 1. I’ve ping the machine of prod env, it takes 300 ms.
2. I’ve ping one VM in totvslabs, it takes 80 ms.
#+END_EXAMPLE
* TODO Get rid of being dragged to issues you don't need to handle
#+BEGIN_EXAMPLE
[3/9/15, 1:32:14 PM] denny: Add Meken into the loop.

Hi Meken
Here is the Skype Group, we use to discussing issues of identity prod env.
[3/9/15, 1:35:13 PM] Lucas Schiochet: Perfect, thanks Dennt
[3/9/15, 1:35:16 PM] Lucas Schiochet: i just arrive home
[3/9/15, 1:35:29 PM] Lucas Schiochet: Meek, can you provide us the test user that you are using to simulate?
[3/9/15, 1:35:43 PM] Vicente Goetten: guys
[3/9/15, 1:35:46 PM] Vicente Goetten: I'll be leaving this group
[3/9/15, 1:35:49 PM] Vicente Goetten: if you guys need my help
[3/9/15, 1:35:52 PM] Vicente Goetten: please let me know, ok?
#+END_EXAMPLE
* TODO [#A] [Jay] How to handle the case of people asking to turn to a permanent role :IMPORTANT:
* TODO For design, keep things simple and stupid
- MDM sandbox test: no need for docker
#+BEGIN_EXAMPLE
[3/5/15, 9:29:31 AM] kungchaowang: this is the file I see, but yes, seems no kitchen:

https://github.com/TOTVS/mdmdevops/blob/master/image_template/Vagrantfile
[3/5/15, 9:29:45 AM] denny: That’s right
[3/5/15, 9:30:10 AM] kungchaowang: so, it has chefDK and docker
[3/5/15, 9:30:31 AM] denny: curl -L https://getchef.com/chef/install.sh | bash

This don’t install chefDK, but only chef utility.
[3/5/15, 9:30:51 AM] denny: From that command, what we need is chef-solo.
[3/5/15, 9:35:49 AM] kungchaowang: ok, from what I read, that install.sh installed chefDK, but anyway, let’s say it only chef-solo and some chef stuff and docker
[3/5/15, 9:36:10 AM] kungchaowang: now, for jenkins, you will be starting docker in that VM’s docker container right?
[3/5/15, 9:36:19 AM] denny: Yes
[3/5/15, 9:37:27 AM] denny: Maybe we can have a quick call to sync up and discuss
[3/5/15, 9:37:53 AM] kungchaowang: are you ok to talk?
[3/5/15, 9:37:57 AM] denny: yes
[3/5/15, 9:38:17 AM] kungchaowang: nice, let me call you
[3/5/15, 9:38:22 AM] denny: cool
[3/5/15, 9:38:32 AM] kungchaowang: Call started
[3/5/15, 9:41:01 AM] denny: Entrance point of everything related:
https://totvslab.atlassian.net/wiki/display/MDMP/How+To+Setup+Sandbox
[3/5/15, 9:43:16 AM] denny: https://github.com/TOTVS/mdmdevops/blob/master/misc/Vagrantfile
[3/5/15, 9:44:12 AM] denny: Jenkins
http://192.168.50.10:8081
[3/5/15, 9:45:08 AM] denny: docker run -t -p 18000:80 -p 18080:8080 -d denny/totvslabs:latest /bin/bash
[3/5/15, 9:46:51 AM] kungchaowang: user laptop 192.168.50.10:8080 —> VM’s 8080 -> 80801 -> docker jenkins container’s 8080
[3/5/15, 9:47:27 AM] denny: 192.168.50.10
[3/5/15, 9:48:22 AM] denny: user laptop —> VM’s 192.168.50.10:8080 - -> docker jenkins container’s 8080
[3/5/15, 10:33:36 AM] denny: https://github.com/TOTVS/mdmdevops/tree/master/cookbooks
[3/5/15, 10:44:11 AM] denny: Hi Denny,

I'm fine and you ?.

Excuse my absence on Skype. But as we talked earlier, i have much work to do in Fluig.

The TOVS are hiring someone to take my activities. And therefore  I still have to wait and don't have a date. But anyway tomorrow I'll talk to Lucas to know more about the activities
[3/5/15, 10:47:44 AM] denny: Call ended  1 hour 9 minutes 12 seconds
[3/5/15, 11:06:43 AM] kungchaowang: do you use packer or Terraform to do data upload to atlas? or you just use Atlas’s UI?
[3/5/15, 11:06:53 AM] denny: Atlas’s UI
[3/5/15, 11:07:00 AM] denny: It’s really really slow!!
[3/5/15, 11:08:04 AM] denny: Like early this morning, I’ve triggered an upload.

Now here is the progress
[3/5/15, 11:08:11 AM] denny: Image
[3/5/15, 11:08:20 AM] denny: Total size is 700 MB
[3/5/15, 11:28:38 AM] denny: Kung, I’ve forwarded an email about ChefConf to you, just in case you’re interested.
[3/5/15, 11:29:13 AM] kungchaowang: I saw that 3 months ago, because since you have got the immediate training, I think all these you can skip
[3/5/15, 11:29:34 AM] denny: https://www.chef.io/chefconf/schedule/
[3/5/15, 11:29:55 AM] denny: Here are the topics. Anything interested or new?
[3/5/15, 11:32:39 AM] kungchaowang: the only thing that I may be interested is the security
[3/6/15, 11:28:50 PM] denny: After several nights’ struggle, I finally succeeded in Kitchen + OpenStack cluster.
https://github.com/DennyZhang/denny-chef-devops/blob/master/cookbooks/devops-test/.kitchen.openstack.yml
[3/6/15, 11:29:34 PM] denny: The main suffer rise in the trouble shooting of OpenStack Neutron. Really confusing and complex.
[3/8/15, 12:29:24 AM] kungchaowang: that is good news Denny, this is good for your self-learning, but for Totvs now, the most important this is just what we had discussed and try to create the same Jenkins on digital ocean. If that works, we can start giving to developer to use it.
[3/8/15, 12:30:06 AM] denny: Sure.
[3/9/15, 9:20:07 AM] denny: Kung, I’ve made a lot of progress for sandbox test last weekend.

I should be able to deliver the first version/POC for the whole stuff by the end of this week.

Maybe we can sync up like this Thursday.
[3/9/15, 9:21:00 AM] denny: If I can mainly work on identity project, it would be faster. Well, pity the fact is the opposite.
[3/9/15, 4:52:47 PM] kungchaowang: sorry was in meeting whole morning.

this is great progress, yes, let’s sync up when you are ready
[3/9/15, 4:53:02 PM] denny: Sure. The code skeleton is almost ready.
[3/9/15, 4:53:55 PM] denny: Let’s talk this Thursday?

Lucas just setup daily meeting for me with Meken and Alexdanre.. It will take 4 hours every day.
[3/9/15, 4:59:17 PM] kungchaowang: yes, please help them as priority, we can talk whenever you are free
[3/10/15, 10:34:48 AM] kungchaowang: how’s the training? do you think they can handle it?
[3/10/15, 10:35:52 AM] denny: not started yet.

It starts 11:00-15:00 PST everyday
[3/10/15, 10:37:15 AM] denny: denny created a group conversation
[3/10/15, 10:40:09 AM] denny: Kung, the summary status is updated into the group chat with Lucas
[3/10/15, 11:06:20 AM] kungchaowang: thank you Denny
[3/10/15, 11:07:49 AM] denny: Drafted wiki about MDM sandbox
 https://totvslab.atlassian.net/wiki/display/MDMP/How+To+Setup+Sandbox
[3/10/15, 11:08:51 AM] denny: It’s far from done yet, but the wiki already describes the workflow I understand.

Looking forward to your feedback
[3/10/15, 11:11:20 AM] kungchaowang: one question related to Chef, for example, if I created a cookbook, say mdm-elasticsearch, and it depends on elastic search cookbook, in that cookbook, I have depends in metadata.rb, and also have the Berksfile read the metadata.rb, test with test kitchen all good. but now, when I try to use Chef solo to test this cookbook, it tells me “elastic search” cookbook not found.
[3/10/15, 11:11:38 AM] kungchaowang: do you know what I should I do for the solo.rb?
[3/10/15, 11:11:38 AM] denny: That’s right
[3/10/15, 11:12:22 AM] denny: That’s the behavior it’s supposed to be.

Usually we have two approaches for this
[3/10/15, 11:13:36 AM] denny: 1. in mdm-elasticsearch, run berkshelf command.
    It will automatically download cookbooks based on Berksfile
[3/10/15, 11:14:02 AM] denny: 2. Predownload all depended cookbooks, and add the directory to solo.rb
[3/10/15, 11:14:17 AM] kungchaowang: you mean run berkshelf? or berks ?
[3/10/15, 11:14:31 AM] denny: berks
[3/10/15, 11:15:05 AM] denny: Method #1 looks promising, but we’d better use method #2 in our case.

That’s my judgement, we can talk more about this.
[3/10/15, 11:16:14 AM] kungchaowang: the reason you suggestion #2 is because sometimes berks does not resolve dependencies correctly?
[3/10/15, 11:16:24 AM] denny: Two reasons.
[3/10/15, 11:16:36 AM] kungchaowang: also, what command you run berks to download cookbook?
[3/10/15, 11:17:59 AM] kungchaowang: also, it will be hard to download all dependencies because you will need to recursively looking each cookbook for it, and berks is designed to do that, I would say we should use berks to do this job right?
[3/10/15, 11:18:56 AM] denny: The command  is “berks install”
[3/10/15, 11:19:22 AM] denny: If we’re using kitchen, I don’t need to run it mnaually.
[3/10/15, 11:20:00 AM] denny: The reason I prefer method #2 is
1. Everything we do the test, we will keep polling depended cookbooks from internet.
[3/10/15, 11:20:07 AM] denny: It’s time consuming for our test.
[3/10/15, 11:21:24 AM] denny: 2. There will be a lot of cookbooks depended. Most cookbooks won’t specify the version of their depended cookbooks.

So it will probably poll the latest version. But latest version will introduce problems all the time.
[3/10/15, 11:21:37 AM] denny: This means our test will fail from time to time, due to that.
[3/10/15, 11:23:06 AM] denny: BTW, if we run “berks install” in our laptop, the cookbooks will be downloaded to “~/.berkshelf/cookbooks”
[3/10/15, 11:24:16 AM] kungchaowang: if we put depends = to match exact version, it should be fine right?
[3/10/15, 11:24:29 AM] denny: Unfortunately, it won’t solve the problem
[3/10/15, 11:24:42 AM] denny: Let me give you an example.
[3/10/15, 11:24:51 AM] denny: Say we have mdm-elasticsearch cookbook
[3/10/15, 11:25:17 AM] denny: It depends on elasticsearch cookbook.


Yes, we can specify the version of elasticsearch
[3/10/15, 11:26:28 AM] denny: Keep going

Let’s say elasticsearch depends on apache2.
And metadata.rb of elasticsearch looks like “apache2 >= 2.1.0”, which is the normal case.
[3/10/15, 11:27:19 AM] kungchaowang: yes, if you do apache2 = 2.1.0, will that solve the problem of downloading latest version?
[3/10/15, 11:27:23 AM] denny: So elasticsearch cookbook will always pull latest version of apache2, even we have specify the version of elasticsearch.

Right?
[3/10/15, 11:27:39 AM] denny: metadata.rb of elasticsearch is not controlled by us.
[3/10/15, 11:28:15 AM] denny: Or do you may we specify “apache2 = 2.1.0” in metadata.rb of mdm-elasticsearch?
[3/10/15, 11:28:47 AM] denny: may -> mean
[3/10/15, 11:28:58 AM] kungchaowang: yes
[3/10/15, 11:29:10 AM] kungchaowang: so we download only that version of dependencies
[3/10/15, 11:29:51 AM] kungchaowang: also, we can use “berks install --path chef/cookbooks” to download to same folder of cookbooks, so we have:

mdm-elasticsearch
elasticsearch
…
[3/10/15, 11:30:07 AM] denny: Yes, this might work.

So we need manually figure out all cookbooks depended by mdm-elasticsearch, and specify their specific versions.
[3/10/15, 11:31:46 AM] denny: ==========
Another thing need to decide: whether run berk on fly or pre downloaded cookbooks, when we run sandbox test.

The difference would be network traffic.
[3/10/15, 11:31:47 AM] kungchaowang: no, we only need to figure out the exact version of the version of our “mdm-elasticsearch” depends, as long as elastic search of that version passed the test, we can safely depends on that
[3/10/15, 11:33:05 AM] kungchaowang: or, you think that because elastic search may just grab any new version of dependencies it depends and that breaks the version?
[3/10/15, 11:33:59 AM] denny: I think elasticsearch won’t try newer version, as long as we have already pre download them.
[3/10/15, 11:34:58 AM] kungchaowang: yes, you can do that too, I am just thinking to prevent figuring out the dependencies ourselves. as that’s what berks was design for
[3/10/15, 11:36:12 AM] denny: The main problem of berk way are:
1. cookbooks depenency
2. internet traffic.

We have resolved by manually specify all cookbooks and specific version in our metadata.rb. Right?
[3/10/15, 11:36:19 AM] denny: For point 1
[3/10/15, 11:37:21 AM] kungchaowang: so you also agree just specify the exact version in metadata.rb? if yes, then we resolve #1
[3/10/15, 11:37:31 AM] denny: Yes, I agree
[3/10/15, 11:37:58 AM] denny: For point #2, I’ve an idea
[3/10/15, 11:38:22 AM] kungchaowang: for #2, we use berks —install —path = xxxx to download the cookbook, so our test kitchen won’t download them again and again?
[3/10/15, 11:38:42 AM] denny: When we build image of vagrant or docker, we pre-run chef update once.

Thus all cookbooks will be already downloaded, if we try from the images.
[3/10/15, 11:39:32 AM] denny: I’ve tried digital ocean, it can support us boot VM from backup.

So the same approach apply to digitalocean/AWS like vagrant.
[3/10/15, 11:43:42 AM] kungchaowang: I am thinking why we need docker, for example, if I run jenkins on my guest at port 8080, run the repo server with ngnix at port 8081 in vagrant, and have jenkins machine in digital ocean and AWS also run repo server in the same jenkins box as well. Why we have to have docker?
[3/10/15, 11:44:25 AM] denny: If we don’t have docker, we will have to deploy jenkins and repo server in the same machine of all-in-one VM.
[3/10/15, 11:45:11 AM] kungchaowang: yes, if you have docker, you will do the same, but run it as docker container, it is just different form of using the memory in that machine, am I right on this?
[3/10/15, 11:45:39 AM] denny: It will effect files in the same OS.
[3/10/15, 11:46:07 AM] denny: configuration files and packages
[3/10/15, 11:46:44 AM] kungchaowang: but from my point of view, you need those files anyway while deployment, so it’s just either in that container or in the VM, but anyway, they are same “physical” machine
[3/10/15, 11:47:32 AM] denny: I’m a bit confused.

Are you indicating deploy jenkins and repo server in the same VM directly?
[3/10/15, 11:48:15 AM] kungchaowang: yes, I am thinking that will be very straight forward, because we know the app, we know what port won’t be used, so just start jenkins and repo server in those ports.
[3/10/15, 11:49:10 AM] kungchaowang: and since we don’t give user privilege to login that VM, so we can download the code and also have predefined keys in that VM, no one will be able to see them. so it’s still safe
[3/10/15, 11:49:10 AM] denny: Yes, that’s straightforward. However, I don’t quite agree.
[3/10/15, 11:49:38 AM] denny: Here is my reasoning.
[3/10/15, 11:51:08 AM] denny: 1. Let’s say jenkins need to download JDK and lots of build kit. They may change system state.

So for this all-in-one deployment, it will be not the same like what we have for prod env.
[3/10/15, 11:51:51 AM] denny: 2. Say all-in-one have some problem, developer will change the code and rebuild it.

Instead of destroying everything each time, we can retrigger build and deploy from Jenkins.
[3/10/15, 11:52:51 AM] denny: For a full integration test, yes, they can also destroy everything and try again.

But this would be the things to do, after the verification is done in previous test.
[3/10/15, 11:53:14 AM] denny: The difference would be like “make test” VS “make clean && make test"
[3/10/15, 11:55:01 AM] denny: How do you think, Kung?
[3/10/15, 12:00:03 PM] kungchaowang: if I look at jenkins supermarket cookbook, you see this:
https://supermarket.chef.io/cookbooks/jenkins
“However, the war installation method will require you to install a valid Java runtime”

so, usually I use chef-solo to install mdm-java first, then I install mdm-jenkins, so that solve the inconsistent java issue, as now they are using same java version.

for your #1, in prod env, we will have our jenkins machine as another machine pre-created, so it will always different from sandbox steps, only thing is that users does not know

for your #2, locally, developer goes to VM:8080 to rebuild they code, push to local repo and trigger chef-solo to deploy, so they does not need to restart the whole VM.
[3/10/15, 12:01:51 PM] denny: So we start 2 VM?
[3/10/15, 12:02:02 PM] kungchaowang: no, just the same VM
[3/10/15, 12:02:47 PM] kungchaowang: the this VM runs, jenkins and repo, then we ask user to go to that jenkins to run build, and it builds jar, push to local repo, and we trigger chef-solo to install on that VM
[3/10/15, 12:03:38 PM] denny: Jenkins and Repo server will certainly change the env.

Are we 100% sure the change won’t effect the test of all-in-one env?
[3/10/15, 12:05:41 PM] kungchaowang: for the all-in-one in production, you will have your own chef server, repo server and jenkins, so production should be fine. for local sandbox, since our repo only stores mdm building jar code, so we can run ngnix in different port, and it won’t conflict with our mdm app after install. we do the same for jenkins as well
[3/10/15, 12:07:50 PM] kungchaowang: I think the difference between you and me is down to if the repo server and jenkins conflict with our app right?
[3/10/15, 12:08:05 PM] denny: Right.
[3/10/15, 12:08:16 PM] denny: So, if we can make the assumption, I’m definitely fine.
- The change of Repo server and Jenkins won’t effect test of all-in-one env.
[3/10/15, 12:09:01 PM] denny: It will simplify a lot
[3/10/15, 12:10:06 PM] kungchaowang: I think it should not. after looking into repo server, it is very easy to setup for person repo,  yes, that’s extra you won’t install to VM, but the apt install seems not a lot of things install. for jenkins, it installed as WAR file, a single self-contain file, as long as we run the same java cookbook, then we are good for our app as well
[3/10/15, 12:10:12 PM] denny: The port conflict is definitely fine. e.g. We can start repo server at port 18000, Jenkins at 18080.

I’m not sure about the packages and configuration files.
[3/10/15, 12:11:37 PM] kungchaowang: there should be no packages at first in our personal repo, and jenkins configuration files can specify location, so we are ok for not mixing them
[3/10/15, 12:12:21 PM] denny: That’s great. Then let’s make this assumption now, and resolve issues if we may have later
[3/10/15, 12:12:37 PM] kungchaowang: but, that’s what I think, if you still like to use docker, you can use it, I just think it’s a little overkill for the local sandbox
[3/10/15, 12:13:53 PM] denny: Sure, I’m not that technical addicted for docker. Let’s keep it simple. And it would be good for people who use it.

BTW, I already know enough for how to use it.
[3/10/15, 12:15:21 PM] kungchaowang: actually, I have difficulty to see how to efficiently use docker
[3/10/15, 12:15:54 PM] denny: What’s the difficulty? Do you have some specific problems?
#+END_EXAMPLE
* #  --8<-------------------------- separator ------------------------>8--
* TODO [#A] How to minimize the need of restart the whole service stack, if issues(especially network issues) happens
* TODO DevOps Role model and company
http://www.stratalux.com
http://www.5ops.com
* TODO [#B] How to test whether the entire world can't access the system or just someone?
https://blog.serverdensity.com/do-you-trust-your-critical-infrastructure/
* TODO [Jay] How to avoid pepole from old consulting projects keep ping me in Skype
[5/6/15, 9:28:18 AM] Meken Goncalves: So better keep the current plan and update it for the same version
[5/6/15, 9:29:12 AM] Meken Goncalves: I created new environments and am trying again
[5/6/15, 9:29:14 AM] Meken Goncalves:  :)
[5/6/15, 9:30:04 AM] Meken Goncalves: another question. sprepo is a chef-workstation . Right?
[5/6/15, 9:30:16 AM] denny: no
[5/6/15, 9:30:40 AM] Meken Goncalves: who is chef-workstation?
[5/6/15, 9:31:08 AM] denny: Usually people setup chef workstation in his local workstation.
[5/6/15, 9:31:20 AM] denny: local laptop
* TODO [Jay] 被过往项目追杀
** TODO mail: Re: FSE Mobile app                                   :noexport:
[[gnus:mail.misc#CAJ1AhVVtdG0u_-4dxCUug1LKC%3D9wUWbemAi_yYcanfBb9Pbu%2BQ@mail.gmail.com][Email from Jay Zheng (Fri, 8 May 2015 10:42:57 -0400): Re: FSE Mobile app]]
#+begin_example
From: Jay Zheng <jayzheng07@gmail.com>
Subject: Re: FSE Mobile app
To: shawn@fsenet.com
Cc: Denny Zhang <filebat.mark@gmail.com>
Date: Fri, 08 May 2015 09:42:57 -0500

Hi Shawn,

I am available for call this afternoon between 3:00pm and 5:00pm EST time. I'm in a meeting now and
I will call you as soon as the meeting ends. 

Tomorrow (Saturday), I am usually not available, but if this is super urgent, I can make time for
you in the afternoon, please let me know what time you plan for a meeting/call.

Regards,

-Jay

On Fri, May 8, 2015 at 10:27 AM, <shawn@fsenet.com> wrote:

    Hi Jay and Denny.  I hope you and the team are well.  Please give me a call
    as asap re a number of bugs we have noticed in the mobile application that
    we urgently need resolved.  Are you available for a call tomorrow?
    Thanks.

    S

    Shawn Cady
    Sr. Director Solution Design and Planning
    FSEnet+ GDSN Data Pool
    Office (617) 600-4200
    Cell (727) 688-6186
    Fax (617) 762-0531
    http://www.fsenet.com

--
Jay J. Zheng

#+end_example
* TODO [#A] How to track issue and generate measurable stastic easily
* TODO [#A] graphite: generate one graph: system availability + different components availability :IMPORTANT:
* TODO [#B] log file of tomcat is truncated
** TODO CP-7026: hornetq.log is truncated when hornetq service is restarted.
*** TODO mail: RE: Message server issue                            :noexport:
[[gnus:myself#EF9859611DA81140B2B29B02EC8AD6EAFC17B3@helios.mex01.local][Email from Denny Zhang (Sat, 28 Mar 2015 20:34:53 -0600): RE: Message server issue]]
#+begin_example
From: Denny Zhang <denny.zhang@totvs.com>
Subject: RE: Message server issue
To: Lucas Vinicius Schiochet <lucas.schiochet@fluig.com>, Kung Wang <kung.wang@totvs.com>
CC: Meken Santos Goncalves <meken.goncalves@totvs.com.br>,
        Alexandre Guimarães Malucelli
        <alexandre.malucelli@fluig.com>, Denny Zhang <denny.zhang@totvs.com>
Date: Sat, 28 Mar 2015 22:34:53 -0400

Lucas

About rmi log, check these
- /data/fluigidentity-logs/cloudpass_logs/server.log
- /data/fluigidentity-logs/cloudpass_logs/server_logs_archieve

About hornetq log:
- When I checked it last night, here is the tail of message
  https://totvslab.atlassian.net/browse/CLOUDPASS-7022
  root@fluig-id-messaging-01:~# tail -f /opt/hornetq/logs/hornetq.log
  tail -f /opt/hornetq/logs/hornetq.log
  Exception in thread "Naming Bootstrap#152" java.lang.OutOfMemoryError: Java heap space
  Exception in thread "Naming Bootstrap#153" java.lang.OutOfMemoryError: Java heap space
  Exception in thread "Naming Bootstrap#154" java.lang.OutOfMemoryError: Java heap space
  Exception in thread "Naming Bootstrap#155" java.lang.OutOfMemoryError: Java heap space
  Exception in thread "Naming Bootstrap#156" java.lang.OutOfMemoryError: Java heap space
  Exception in thread "Naming Bootstrap#157" java.lang.OutOfMemoryError:
  Java heap space

- Yes, it looks like restart hornetq will truncate hornetq log
  DevOps will need to improve this. I will do that, if Meken/Alex are
  not available for this.

________________________________________
From: Lucas Vinicius Schiochet
Sent: Saturday, March 28, 2015 2:24 PM
To: Kung Wang
Cc: Denny Zhang
Subject: Re: Message server issue

Hi Kung,

I already did a pre analysis about this issue and made some points in the
ticket.

Unfortunately I wasn¹t able to access the hornerq Log before the Crash
what made a little hard to get the full diagnostic.
Same thing happened with the RMI server, the log from day 03/28 start
after 6 AM, and the period between midnight and 6 AM stay unknown.

In this week we will do a better analysis about this.

Regards,
Lucas Schiochet

On 3/28/15, 3:28 AM, "Kung Wang" <kung.wang@totvs.com> wrote:

>Lucas,
>
>Per Denny¹s input on Friday night 9:25PST:
>
>[3/27/15, 9:25:52 PM] denny: Hi Kung, you there?
>[3/27/15, 9:26:33 PM] denny: In identity prod env, hornetq run out of
>memory
>
>I try to start it, but the process is started. However ³service hornetq
>status² doesn¹t show it.
>[3/27/15, 9:26:46 PM] denny: Looks like no BR guys are on line for this.
>
>Can you check with Fluigidentity DevOp to see if they can help?
>
>Thank you,
>
>‹Kung
>
>

#+end_example
* web page: The Wide Range of DevOps
http://www.infoq.com/articles/wide-range-devops
** webcontent                                                      :noexport:
#+begin_example
Location: http://www.infoq.com/articles/wide-range-devops
BT

  * Contribute
  * About Us
  * About You
  * Purpose Index

  * Exclusive updates on:
  * [twitter]
  * [facebook]
  * [linkedin]
  * [gplus-16]
  * [rss]

Facilitating the spread of knowledge and innovation in professional software development
[Search              ]  submit
Login
[logo_bigge]

  * En |
  * 中文 |
  * 日本 |
  * Fr |
  * Br

1,023,962 Dec unique visitors

  * Development
      + Java
      + .Net
      + Cloud
      + Mobile
      + HTML5
      + JavaScript
      + Ruby
      + DSLs
      + Python
      + PHP
      + API

    Featured in

    []

    All in Development
  * Architecture
    & Design
      + Architecture
      + Modeling
      + Scalability/Performance
      + DDD
      + BDD
      + AOP
      + Patterns
      + Security
      + Cloud
      + SOA

    Featured in

    []

    All in Architecture & Design
  * Process & Practices
      + Agile
      + Leadership
      + Collaboration
      + Agile Techniques
      + Methodologies
      + Continuous Integration
      + Lean/Kanban

    Featured in

    []

    All in Process & Practices
  * Operations & Infrastructure
      + Hadoop
      + Performance
      + Big Data
      + DevOps
      + Cloud
      + APM
      + Virtualization
      + NoSQL

    Featured in

    []

    All in Operations & Infrastructure
  * Enterprise Architecture
      + Enterprise Architecture
      + BPM
      + Business/IT Alignment
      + Architecture Documentation
      + IT Governance
      + SOA

    Featured in

    []

    All in Enterprise Architecture

London 2015
Mar 2 - Mar 6

New York 2015
Jun 08 - Jun 12

  * Mobile
  * HTML5
  * JavaScript
  * APM
  * Big Data
  * Cloud
  * API Design
  * PHP

All topics
You are here: InfoQ Homepage Articles The Wide Range of DevOps

The Wide Range of DevOps [article-lo]

Posted by Mitchell Hashimoto on Sep 13, 2012 |

  * Share
  * Share
  * |
  *
  *
  *
  *
  *
  *
  *
  * `Read later'
  * `My Reading List'

This article is based on a talk I gave at DevOpsDays in Sweden titled “DevOps is not an absolute.
It’s a range.” The video of the talk may be viewed online, but is not necessary to view prior to
reading this article.

For the past few years, DevOps is a term we’ve seen or heard practically non-stop in articles,
presentations, keynotes, and general conversation. DevOps claims to create a faster feedback loop
and lower the cost of product iteration all while improving the overall stability of your systems.
Like anything making impressive claims, it was easy to ignore or dismiss the movement due to
immaturity or lack of evidence. But time has passed, companies have continued to show real-world
gains, and various processes for adopting DevOps in organizations have emerged. Therefore, the time
has never been better to investigate and bring this movement into your own work environment.

For the uninitiated, it’s easy to view DevOps as a single change, much like a single switch
controls the power to a light. Looking at it this way, adopting such a change can seem like a
daunting -- perhaps impossible -- task. And just like general engineering, trying to build
something complex as a single unit of change typically results in failure. Luckily, DevOps isn’t a
single switch, and it can be broken down into a series of changes. The deployment and timing of
these changes can be tightly controlled and fine-tuned based on what is right for your
organization.

Related Vendor Content

5 Unsung Tools of DevOps

Geek Guide: Slow Down to Speed Up - Continuous QA in DevOps

Gartner Magic Quadrant for Application Performance Monitoring

The Seven Habits Of Highly Effective DevOps

Solving the database deployment problem with Database Lifecycle Management (DLM)

Related Sponsor

[VCR_Box_Lo]

White Paper: 5 Reasons Why New Relic's a Developer’s Best Friend

Conveniently, the changes necessary for DevOps can be plotted on a timeline-style graph, where the
extreme left represents traditional ops culture and practices, and the right represents a newer
DevOps-style. In this view of the world, the question is not “Is your company practicing DevOps?”
but instead is the more accurate “How strong of a DevOps culture has your company adopted?”

As a quick disclaimer, the ideas and examples put forth in this article are shaped to a certain
organizational structure. These assumptions are based on my own personal experience of working in
companies with in-house dev and ops teams, having ops in charge of development environments,
working with a limited number of projects, and so on. The downside of this is that if your
organization doesn’t fit these assumptions, the ideas presented may not be right for you. However,
the upside is that these ideas are based on real world experience in multiple work environments
that matched similar situations.

The Range of DevOps

Looking at this range, it’s important to firmly establish what exactly the far left and far right
represent, so that we can better understand what it means as this range is traversed.

The far left side represents traditional ops culture and practices.

A generalized description of this extreme can be “black-box ops.” In this culture, the ops team is
siloed away from the dev team, and interaction is either avoided or reluctantly forced. The
defining trait of this side of the range is that dev and ops inherently have opposing goals. The
dev team is tasked with and praised for shipping new features and moving the product forward. The
goal of the ops team is to maintain stability above all else. Without proper communication, these
exist in conflict with each other, since it is in the best interest of ops to not ship new
features, and it is in the best interest of dev to ship new features as quickly as possible.
Because introducing any kind of change into a stable system can potentially introduce unexpected
instabilities, ops avoids this if at all possible.

A concrete example: an application developer introduces a bug in the code which causes an infinite
loop in a certain edge case not caught by QA or tests. If such a change were deployed by ops,
suddenly certain servers would spin to 100% CPU, causing instability. If ops simply avoided
deploying this change, there would've been no issue, or at least no new issues. This is the point
of view of this side of the range.

The far right side represents a fully embraced DevOps culture where dev and ops are one and the
same. Here, devs do ops, ops do dev, and both teams have a mutual goal of shipping features
together while maintaining a certain level of reliability.

[3fig1]

By knowing these two extremes -- and stressing that both sides are indeed extreme -- getting from
one side to the other may seem intimidating. And it is intimidating, as long as you view it as a
single step. By breaking the timeline down into a series of manageable chunks, the task becomes
approachable, the benefits are easily clear, and results suddenly seem within reach.

Cultural vs. Technical Changes in DevOps

DevOps requires both cultural and technical change in an organization. Culturally, barriers needs
to be broken down so that ops teams and development teams communicate more openly and share common
goals. Technically, developers need to better understand how ops teams work and have a good
knowledge of system architectures. Ops engineers need to know how the development process works and
have a better understanding of the code itself.

When DevOps is broken down into chunks, I’ve found it easier to introduce this by alternating
between cultural and technical change. You’ll notice in the coming sections that each section
follows this pattern. This is done for good reason: change is hard, radical change is near
impossible. By alternating what is changing, each change is more gradually introduced. Instead of
one big change, there is one small cultural change followed by one small technical change followed
by another small cultural change and so on. From this style, teams never wake up feeling as though
everything has changed from beneath them. Instead, it feels like change occurred organically and at
a more natural pace, increasing the likelihood that such change sticks within an organization.

Metrics, Metrics Everywhere

The first chunk in moving from the left to the right is to enable metric aggregation across your
organization at both an infrastructure and application level. Or, as I prefer to call it: metrics,
metrics everywhere. There are many great talks on this subject, but it ultimately comes down to
answering a single crucial question: What does my code do?

Development will happily answer this question by showing you the code. Unfortunately, code only
describes what code should do but not what it actually does. Code is like a cooking recipe: it
describes the steps to reach a certain tasty outcome, but doesn’t have any effect on the actual
real-world result. We’ve all at some point in our lives attempted a recipe with less-than-edible
results. Likewise, code may describe a process to achieve some desirable effect, but the actual
consequence of the code on a real-world system is unpredictable from the code itself. Below is a
code example where the developer may have changed a cache timeout from 3600 to 1800 seconds.
Looking at the code itself you can see this change, but it is hard to predict the overall system
effect of this change.

[7fig2small]

Ops will answer this question by logging into a machine and getting some data out of the running
system such as memory or CPU utilization. This is the right answer! This shows the effect of code
in the real world. Ops has access to a lot more data, too. This data provides answers to important
questions such as “What is the system-wide effect of this change?” or “Why did service Y slow down
after service X was deployed?” Historically, developers could only answer these questions by
speculating about how the code will run. While this sometimes works, having access to actual data
is undoubtedly more powerful. The image below shows an example of what ops can see: data for a
running production system.

[3fig3small]

It is important to remember where we are on our range of DevOps at this point. We’re just to the
right of the far left, so we’re still very much in a traditional ops environment. Because of this,
giving developers access to production systems is not going to work. Most developers are not
comfortable in this environment and when people get uncomfortable, it is natural to retract back to
a comfortable environment. Attempting any sort of change in an organization without maintaining a
certain level of comfort along the way will result in the change not being well supported,
ultimately resulting in reverting back to old ways.

To surface this data in a developer-friendly way is quite simple: graphs. Graphing technology has
been around for years, but has been particularly popular in recent years with the emergence of
tools such as Graphite and Statsd. By hooking system metrics into Graphite and exposing the API to
developers, the best of both worlds is achieved: ops can expose system metrics and developers can
expose application metrics. Suddenly, developers have access to memory, CPU usage, etc. in addition
to statistics about application events such as log ins, log outs, and so on.

For a developer, implementing a metric is a single line of code:

[5fig4small]

Which results in a graph that looks like the following in Graphite:

[2fig5small]

Setting up these new graphing systems is normal work for a traditional ops team, and the interface
to Statsd and Graphite is so simple that developers can start graphing with only a few lines of
code. With these low-friction technical changes, developers now have insight into performance,
system-wide effects of code, and ops in general. And now, even at this point, you can say that your
organization is doing some amount of DevOps, because dev and ops are now interacting in at least a
small way. Moving forward, the interactions will become greater, but this is a comfortable starting
position.

Infrastructure Documentation

With a general insight into the performance and health of production systems, it is natural for
developers to become curious about what comprises the underlying system. To many developers, a
large scale production system is a black box: a request goes in and a response comes out, but the
various systems it touches in between is unknown.

To address this, infrastructure should be documented. This can begin with very basic high level
diagrams of a request flow and what software is hit at what point. As this matures, documentation
should address what certain pieces of the architecture do and why it was chosen versus other
potentially competing solutions. In addition to specific software packages, the documentation can
hit on points such as how new servers come online, potential failure cases and resolutions, intros
to unix tools, and so on. The point of this documentation is for developers to have a resource to
become more comfortable with the architecture of a production system from a high-level.

Once these resources are made available, developers can freely learn more about the system
architecture if they are interested. And interest in the infrastructure comes from the graphing
system we implemented earlier, since that gives developers a simple way to look at a running
system. With metrics and documentation, the black box behind ops is beginning to disappear. There
is still not a lot of collaboration between the two teams, but the barriers to this becoming a
reality are quickly disappearing.

Production-Mirror Development Environments

Up to this point, developers have interacted with ops mainly through systems instrumentation and
written documentation. Equipped with this basic knowledge, it would be great if developers could
actually experiment with and interact with the internals of the underlying ops. Doing this to a
production environment at this point is not only unrealistic, but poses a threat to the stability
of your systems. Instead, it is preferable to give developers a sandbox to play in.

Made specifically for this purpose, Vagrant is a tool for packaging and distributing development
environments in the form of VirtualBox virtual machines. These virtual machines are built up using
standard configuration management such as Chef, Puppet, or even just basic shell scripts. Because
of this, ops can use the same production setup scripts to setup portable development environments.
Developers are expected to do all work in these environments, because they match production as
closely as possible. Additionally, developers no longer need to worry about manually setting up
their machines, because ops handles this via properly configured Vagrant machines.

These development environments, built on top of production ops scripts, give developers a sandbox
to play with real systems. If any damage is done, the virtual machine can always be destroyed and
re-created. On top of simply being a sandbox, the actual setup of the virtual machines gives
developers an insight into how servers are provisioned, how ops changes are rolled out to machines,
and a real world look into the architecture of their systems.

DevOps Office Hours

Developers now have a sandbox to tinker with a real system, documentation to learn more about the
system, and metrics as a way to gather data from production. Despite all of this, ops is still new
and intimidating. Luckily, we are friendly people, and it is time to begin having true interaction
between the two teams. This interaction can come from forums, a help desk, or even walking over to
the other person and having a real conversation.

I’ve found the best solution for introducing this new practice to be office hours. Office hours are
a fixed amount of regularly scheduled time that an ops or dev engineer dedicates to answering any
sort of questions. These questions can range from extremely basic such as “how do I search for
files on the machine?” to relatively advanced: “can you explain the reasoning behind this HAProxy
configuration parameter?” The most important quality of these office hours is that no judgment is
passed, no matter what question is asked. These office hours are a time when engineers can feel
safe asking anything relevant.

With this in place, an important milestone is reached: communication! Both dev and ops have an
understanding of what each other does, they’re both able to see and interact with each other’s
work, and they’re both talking.

Mitigating the Risk of Devs Doing Ops

Before continuing, I’d like to point out that at this point your organization has a DevOps culture
healthier than most organizations. And it has been introduced in a slow, methodical, low-risk
manner. Continuing forward, we begin entering the extreme right of our aforementioned timeline of
DevOps. This area is still radical compared to the previous steps and is not as well defined.
However, organizations have successfully integrated this and are seeing benefits from such changes.

Developers now have all the tools to begin making real ops change and taking responsibility for it.
Just as everything prior, this can be introduced in smaller chunks in order to mitigate risk and
make everyone more comfortable.

The first is to use a standard open source model for ops change: pull requests and code review.
When a developer wants to introduce something new, he or she can make the changes and issue a pull
request. They can test this change in Vagrant managed machines that were setup earlier. The pull
request gives an actual ops team member the chance to review and sanity check the change. If
anything is amiss, comments can be given and the developer then doesn’t make those mistakes again
in the future. In the end, the pull request is merged, with developers feeling confident and proud
they made a change while ops feels safe knowing that the change was vetted by them.

Second, and more experimental even at the time of this article, is to use some level of continuous
integration with ops. At a very basic level, this would be a CI server such as Jenkins verifying
ops scripts run without error on every commit within a sandboxed environment, possibly managed by
Vagrant. Basic smoke tests such as verifying that an HTTP request can be made to the resulting
infrastructure can be done as well.

With one or both of these in place, developers are now safe to make ops changes. Ops feels safe
because they are still vetting the changes. This is the first time that dev and ops are truly
working together and share some level of responsibility with each other. There are still distinct
dev and ops teams but the distinction is quickly dissipating.

Devs: Go Crazy!

Now, on to the true extreme right on the DevOps timeline: developers do all ops. By implementing
all the previously mentioned pieces, the technical and cultural change is in place that this
becomes a real possibility. In practice, this generally works by continuing to maintain two
separate teams that work together much more closely. The ops team can be smaller and more
developers can be brought on. Developers do actually do ops with some supervision by the few ops
people. Developers can and should be on call, with ops being the second line of defense in the case
of an outage.

To reiterate, this only works because of the foundation which we’ve built piece by piece. Metrics
give insight into system-wide effect of a developer’s code. Documentation allows developers to
learn more about the production architecture so that they can better understand the effect of
different changes. Virtual machines and a workflow built on top of automated configuration scripts
save time for ops by letting them using production tools to create development machines while
allowing developers to have a sandbox to actually tinker with the system architecture. Office hours
or forums are an outlet for any sort of questions that developers or ops may have about each other,
and provide a safe learning environment. Automated infrastructure tests and code review give both
ops and dev a security blanket so that the risk of ops change is mitigated. The end result of all
this is that each team communicates much more freely, each team trusts each other more, and in the
end the distinction between these teams is much more blurred.

DevOps

The benefits of DevOps are numerous. First and foremost, there is more collaboration and trust
within an organization. The rate that features are delivered is improved because there are more
people to do ops and ops doesn’t need to just say “no” since developers are also held responsible
for any changes. Believe it or not, DevOps also improves the overall stability of your system,
because there are more capable eyes on the effect of various changes. Because features can be more
quickly delivered, there are less large upgrades that require downtime. Instead, changes are
delivered in smaller, more manageable pieces that may not require downtime at all.

Where are you on the timeline? Where do you want to be? As long as you’re not on the extreme left,
your organization is already practicing DevOps. This breakdown gives you the steps necessary to
confidently move forward without risking too much, and if you feel that the change isn’t working
properly, it is small enough that it can be reverted and tried again at a later date.

About the Author

[Mitchell]Mitchell Hashimoto is the creator of Vagrant and is an operations engineer for Kiip. He
is passionate about all things ops and open source, and enjoys spending hours of his free time each
day contributing to the community. In addition to simply contributing to open source, Mitchell
enjoys speaking at conferences and user groups about Vagrant. Mitchell can be found on GitHub and
Twitter as @mitchellh.

  * Sections
  * Operations & Infrastructure
  * Topics
  * Operations
  * Infrastructure
  * Devops
  * Cloud Computing
  * IT Service Management

Related Editorial

Hello stranger!

You need to Register an InfoQ account or Login or login to post comments. But there's so much more
behind being registered.

Get the most out of the InfoQ experience.

Tell us what you think

[                    ] [                    ]

Allowed html: a,b,br,blockquote,i,li,pre,u,ul,p

[ ] Email me replies to any of my messages in this thread
Post Message
Community comments
Close

by

on

  * View
  * Reply
  * Back to top

Close
Subject [                    ] Your Reply Quote original message [                    ]

Allowed html: a,b,br,blockquote,i,li,pre,u,ul,p

[ ] Email me replies to any of my messages in this thread
Post Message    Cancel
Close
Subject [                    ] Your Reply [                    ]

Allowed html: a,b,br,blockquote,i,li,pre,u,ul,p

[ ] Email me replies to any of my messages in this thread

    Cancel
Close

 OK
Discuss

  * Popular
  * 10 days
  * 40 days
  * 6 months

Educational Content

  * All
  * Articles
  * Presentations
  * Interviews
  * Books
  * Research

Spring 4 and Java 8

Adib Saikali Jan 28, 2015

[logo-java]

Mike Long on Modern C++ and the C++ Memory Model

Mike Long Jan 28, 2015

[Mike-Long-]

Explore Your Data: The Fundamentals of Network Analysis

Amy Heineike Jan 27, 2015

[Amy]

Evolution of the PayPal API Platform: Enabling the Future of Money

Deepak Nadig Jan 27, 2015

[Dee]

Metrics-Driven Prioritization

Sam McAfee Jan 27, 2015

[Sam]

The Impact of Lean and Agile Quantified: 2014

Larry Maccherone Jan 26, 2015

[Larry]

  * Older

Sponsored Links

InfoQ Weekly Newsletter

Subscribe to our Weekly email newsletter to follow all new content on InfoQ

[click2view]
[Your email here     ]  Subscribe
  * Home
  * All topics
  * QCon Conferences
  * About us
  * About You
  * Contribute
  * Purpose Index
  * Create account
  * Login

  * QCons Worldwide
  * London
    Mar 2-6, 2015
  * São Paulo
    Mar 23-27, 2015
  * Beijing
    Apr 23-25, 2015
  * Tokyo,
    April 21, 2015
  * New York
    Jun 8-12, 2015
  * Rio de Janeiro
    Aug 24-25, 2015
  * Shanghai,
    Oct 15-17, 2015
  * San Francisco
    Nov 16-20, 2015

InfoQ Weekly Newsletter

Subscribe to our Weekly email newsletter to follow all new content on InfoQ

[click2view]
[Your email here     ]  Subscribe
  * Your personalized RSS
  * For daily content and announcements
  * For major community updates
  * For weekly community updates

Personalize Your Main Interests

    [*] Development
    [*] Architecture & Design
    [*] Process & Practices
    [*] Operations & Infrastructure
    [*] Enterprise Architecture

This affects what content you see on the homepage & your RSS feed. Click preferences to access more
fine-grained personalization.

                                                                    InfoQ.com and all content
                                                                    copyright © 2006-2015 C4Media
General Feedback   Bugs           Advertising     Editorial         Inc. InfoQ.com hosted at
feedback@infoq.com bugs@infoq.com sales@infoq.com editors@infoq.com Contegix, the best ISP we've
                                                                    ever worked with.
                                                                    Privacy policy
BT
Close
Email [                    ] Password [                    ]  submit
Login with Google
Login with Twitter
Login with Facebook
Login with Microsoft

Forgot password ?

InfoQ Account Email [                    ] Send Email

Back to login

Resend Activation [                    ] Resend

Back to login

Don't have a username ?

REGISTER HERE

#+end_example
* TODO Try Cucumber: 用Selenium、Cucumber等工具自动化生产环境的冒烟测试和回归测试
http://www.infoq.com/cn/articles/thoughtworks-anthology-xj-devops-business-agile
* TODO [#A] Contact people are doing consultanting in Bay area
* TODO DevOps: Track what has been typed in terminal commands
#+BEGIN_EXAMPLE
[3/3/15, 2:38:05 PM] denny: For the next project, I’m proposing:
-  automatically log any command anyone running in the prod env.
[3/3/15, 2:38:09 PM] denny: What do you guys think?
[3/3/15, 2:38:40 PM] denny: Thus we know what commands have been executed before by terminal login.
[3/3/15, 2:51:20 PM] Shivang: sure .. definitely
[3/3/15, 2:51:53 PM] Shivang: matter of fact, if create specific users on each box with specific rights .. even better .. so that no 2 people use the same login
[3/3/15, 3:18:15 PM] denny: Yes, that’s a good idea.

I will enforce this by chef.
[3/3/15, 3:18:21 PM] denny: Thanks, Shivang.
#+END_EXAMPLE
* TODO mail: RE: Network connectivity issue of identity system     :noexport:
[[gnus:mail.misc#EF9859611DA81140B2B29B02EC8AD6EAF8EB0C@helios.mex01.local][Email from Denny Zhang (Sun, 25 Jan 2015 21:30:20 -0600): RE: Network connectivity issue]]
#+begin_example
From: Denny Zhang <denny.zhang@totvs.com>
Subject: RE: Network connectivity issue of identity system
To: sp.datacenter.redes <sp.datacenter.redes@totvs.com.br>
CC: devopslabs <devopslabs@totvs.com.br>, Denny Zhang <denny.zhang@totvs.com>, Vicente Goetten <goetten@totvs.com>
Date: Sun, 25 Jan 2015 21:30:20 -0600

Hi there

That machine can't access totvslabs.customerfi.com:443 neither.

Regards,
Denny
---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Sunday, January 25, 2015 8:53 AM
To: sp.datacenter.redes
Cc: devopslabs; Denny Zhang
Subject: Network connectivity issue of identity system

Hi there

One of our nagios check(check_PS_LOGIN) keeps failing, which is tracked in ticket TECH-77

While debugging this, I found the root cause is:
- machine (172.20.16.13) fail to connect 443 port of totvslabs.psfluigidentity.com.

Previously, it's able to connect days ago, before our network maintenance.
Would you please help to check?

,-----------
| root@fluig-id-cdn-01:/etc/nagios/nrpe.d# ifconfig | grep 'inet addr'
| ifconfig | grep 'inet addr'
|           inet addr:172.20.16.13  Bcast:172.20.16.127  Mask:255.255.255.128
|           inet addr:127.0.0.1  Mask:255.0.0.0
|
| root@fluig-id-cdn-01:/etc/nagios/nrpe.d# telnet totvslabs.psfluigidentity.com 443
| Trying 187.94.63.123...
`-----------

Regards,
Denny

#+end_example
* TODO [#A] Never run your processes as root or Administrator login unless absolutely necessary
* DONE mail: AWS Certified Solutions Architect – Associate (ENGLISH) Completed :noexport:
  CLOSED: [2015-05-06 Wed 15:58]
[[gnus:mail.misc#1924440115.14138.1430943595110.JavaMail.certs@PRODTC01][Email from donotreply@kryteriononline.com (Wed, 6 May 2015 13:19:55 -0700 (MST)): AWS Certified Solutions Archit]]
#+begin_example
From: donotreply@kryteriononline.com
Subject: AWS Certified Solutions Architect – Associate (ENGLISH) Completed
To: denny.zhang001@gmail.com
Date: Wed, 06 May 2015 15:19:55 -0500

Hello Denny,

Congratulations! You have successfully completed the AWS Certified Solutions Architect – Associate
exam and you are now AWS Certified. You can now use the AWS Certified Solutions Architect –
Associate credential to gain recognition and visibility for your proven experience with AWS
services.

Attached to your test completion email, you will find your certificate, logo file and certification
guidelines.

Please note that use of the logos are subject to the AWS Certification Program Agreement.

Gain visibility for your achievements: Add AWS Certification to your LinkedIn profile
Click here to add AWS Certified Solutions Architect – Associate to the Certification section of
your LinkedIn Profile. LinkedIn research shows that members with certifications on their profiles
receive 6x more profile views.

Join AWS Certified Global Community on LinkedIn
Click here to become part of our growing community of AWS Certified Individuals. Membership is open
only to AWS Certified Individuals so you can engage with peers, make new connections, and learn
more from others who have validated their technical expertise in working with AWS.

Congratulations again on your achievement.

Overall Score: 70%

Topic Level Scoring:

1.0 Designing highly available, cost efficient, fault tolerant, scalable systems : 66%

2.0 Implementation/Deployment: 75%

3.0 Security: 62%

4.0 Troubleshooting: 100%

Do not reply to this email. If you have any questions about the AWS Certification program, please 
contact us for assistance.

Thank you.

[2. application/x-any; AWS_certification_logo_guidelines_SAA_English.pdf]...

[3. application/x-any; AWS Certified Solutions Architect-Associate_English.zip]...

[4. application/x-any; awsSolutionsArchitect_AE.pdf]...

#+end_example
* TODO [#A] DevOps candidate can't describe issues clearly, or do some local trouble shooting
[5/6/15, 9:33:36 AM] Meken Goncalves: yes
[5/6/15, 9:33:53 AM] denny: Official Repo server for Chef in SP
[5/6/15, 9:36:00 AM] Meken Goncalves: i understand now, sprepo is that
https://docs.chef.io/chef_repo.html
[5/6/15, 9:39:29 AM] denny: It’s a apache web server, serving packages.
http://sprepo.fluigidentity.com
[5/6/15, 12:13:29 PM] Meken Goncalves: Hi Denny,
We Have a problem. I Acces the sprepo and see what disk size are full
[5/6/15, 12:13:38 PM] Meken Goncalves: root@ip-10-253-160-9:~# df -ha
Filesystem      Size  Used Avail Use% Mounted on
/dev/xvda1       30G   30G     0 100% /
proc               0     0     0    - /proc
sysfs              0     0     0    - /sys
none            4.0K     0  4.0K   0% /sys/fs/cgroup
none               0     0     0    - /sys/fs/fuse/connections
none               0     0     0    - /sys/kernel/debug
none               0     0     0    - /sys/kernel/security
udev            7.4G  8.0K  7.4G   1% /dev
devpts             0     0     0    - /dev/pts
tmpfs           1.5G   73M  1.4G   5% /run
none            5.0M     0  5.0M   0% /run/lock
none            7.4G     0  7.4G   0% /run/shm
none            100M     0  100M   0% /run/user
none               0     0     0    - /sys/fs/pstore
systemd            0     0     0    - /sys/fs/cgroup/systemd
root@ip-10-253-160-9:~#
[5/6/15, 12:16:07 PM] denny: Do you know what data/directories use so many disk capacity?
[5/6/15, 12:18:30 PM] denny: ?
[5/6/15, 12:18:46 PM] Meken Goncalves: not yet, but I will look
[5/6/15, 12:19:37 PM] denny: I’ve removed some log files and garbage data.

Let me know what you found.
[5/6/15, 12:19:51 PM] Meken Goncalves: df -ha
[5/6/15, 12:22:48 PM] denny: Meken, after May 8th, you will be on your own.

To better help you, please do some more investigation, when raise issues to me. OK?
[5/6/15, 12:23:37 PM] Meken Goncalves: Ok Denny, Np
[5/6/15, 12:25:52 PM] denny: Meken

The good thing is if identity still need me after May 8th, you guys can book me several hours per day.

Please sync up with Lucas, if we need that. Because it takes longer, it will be charged by hour.
[5/6/15, 12:26:59 PM] Meken Goncalves: Nice. i will
[5/6/15, 12:29:00 PM] denny: If the issue is because of missing info, I will definitely help with no charge.

If other issues, it will charge at normal rate.
[5/6/15, 12:29:32 PM] denny: BTW, looks like /var/ is the problem for sprepo

root@ip-10-253-160-9:/data/fluigidentity-logs# du -h -d 1 /var/
du -h -d 1 /var/
244M	/var/cache
4.0K	/var/opt
108K	/var/mail
856K	/var/spool
4.0K	/var/tmp
1004K	/var/backups
17G	/var/lib
6.2M	/var/log
75M	/var/chef
5.1G	/var/www
4.0K	/var/local
4.0K	/var/crash
22G	/var/
[5/6/15, 12:30:09 PM] Meken Goncalves: 26.8 GB .
21.7 GB ./var
2.8 GB ./data
936.8 MB ./usr
694.5 MB ./opt
307.6 MB ./cloudpass
269.2 MB ./home
72.4 MB ./run
61.8 MB ./lib
24.0 MB ./boot
9.5 MB ./bin
9.4 MB ./sbin
7.7 MB ./etc
2.2 MB ./tmp
56.0 KB ./root
20.0 KB ./conf
16.0 KB ./lost+found
8.0 KB ./dev
4.0 KB ./srv
4.0 KB ./mnt
4.0 KB ./media
4.0 KB ./lib64
0.0 KB ./sys
0.0 KB ./proc
[5/6/15, 12:30:15 PM] Meken Goncalves: yes i see
[5/6/15, 12:30:32 PM] denny: /var/lib/ looks like the one hold the most capacity
[5/6/15, 12:31:45 PM] denny: hmm, I should configure nagios to monitor not only prod envs  but also envs like these
[5/6/15, 12:36:36 PM] denny: I’ve removed old branches under /var/lib/jenkins/code/BuildFluigRepo

It should be fine now.
[5/6/15, 12:37:00 PM] denny: root@ip-10-253-160-9:/var/lib/jenkins/code/BuildFluigRepo# du -h -d 1
du -h -d 1
2.1G	./master
2.0G	./identity-1.4.5.1
2.1G	./identity-1.4.5
1.9G	./identity-1.4.3
2.0G	./identity-1.4.4
9.9G	.
root@ip-10-253-160-9:/var/lib/jenkins/code/BuildFluigRepo#
[5/6/15, 12:37:43 PM] Meken Goncalves: Nice Denny
[5/6/15, 12:38:16 PM] denny: Each code branch takes 2GB. We have around 10 branches before, thus it takes 20GB
[5/6/15, 12:38:48 PM] denny: One lesson learned for me: setup monitoring for supporting servers as well.
[5/6/15, 12:39:11 PM] denny: BTW, thanks for finding this issue, Meken.
[5/6/15, 12:47:46 PM] Meken Goncalves: I found this case because I was checking out the apache settings within that server. and I have a question.

why the new server have to change the vhost port to 80 and in the current server this set to 8282?
[5/6/15, 12:48:12 PM] denny: All customers are using http://sprepo.fluigidentity.com
[5/6/15, 12:49:53 PM] Meken Goncalves: right
[5/6/15, 1:53:31 PM] Meken Goncalves: I've Performed some of the steps you prepared, the the Link Below. but I would like some help with the steps of the Backup. and restore.
it's possible?


sprepo.fluigidentity.com: It's a identity repo server.
Prepare a VM of Ubuntu 12.04, with more than 4GB memory ............. Done
Deploy fluig Jenkins 					............. Done
How To Setup Jenkins For Fluig Identity			............. Done
Change vhost port from 8282 to 80			............. Done
vim  /etc/apache2/sites-enabled/repo_vhost		............. Done
service apache2 reload					............. Done
Trigger all build for all active branches, thus the packages are generated in the repo server.	............. Done
See step4 in Procedure To Make A New Release		............. Done
Change Route53 CNAME of sprepo.fluigidentity.com to this VM					............. Done


spchef.fluigidentity.com: It's a chef 11 server		............. Done
Prepare a VM of Ubuntu 12.04, with more than 4GB memory	............. Done
Add "127.0.0.1 spchef.fluigidentity.com" to /etc/hosts, and configure spchef.fluigidentity.com as FQDN hostname	............. Done
Deploy Chef 11 server for Ubuntu 12.04 64 bits.		............. Done
https://www.digitalocean.com/community/tutorials/how-to-install-a-chef-server-workstation-and-client-on-ubuntu-vps-instances ............. Done
Most version of Chef server 11 should work. Here we use Chef 11.1.3.							     ............. Done
Setup workstation and ~/.chef/knife.rb correctly	
Do chef server migration by knife-backup, like this	
http://www.ameir.net/blog/archives/326-migrating-from-one-chef-server-to-another.html
knife backup export -D ~/chef-backup/ -c ~/.chef/knife-orig.rb
knife backup restore -D ~/chef-backup -c ~/.chef/knife-new.rb
Change Route53 CNAME of spchef.fluigidentity.com to this VM
[5/6/15, 1:55:55 PM] Meken Goncalves: where I have to perform these steps? which Server?

Setup workstation and ~/.chef/knife.rb correctly	
Do chef server migration by knife-backup, like this	
http://www.ameir.net/blog/archives/326-migrating-from-one-chef-server-to-another.html
knife backup export -D ~/chef-backup/ -c ~/.chef/knife-orig.rb
knife backup restore -D ~/chef-backup -c ~/.chef/knife-new.rb
Change Route53 CNAME of spchef.fluigidentity.com to this VM
[5/6/15, 2:12:58 PM] denny: Meken, have tried to deploy a new chef 11 server, then migrate it to a new vm?
[5/6/15, 2:44:04 PM] Meken Goncalves: I already have the server server installed and the repo created

http://54.207.64.117:8180/view/All/job/BuildFluigRepo/2/console
[5/6/15, 2:44:56 PM] Meken Goncalves: ******** sprepo ********
Jenkins http://54.207.64.117:8180/view/All/job/BuildFluigRepo/2/console
sprepo http://54.207.64.117
******** Chef Server ******** 
https://54.207.88.186/users/admin
[5/6/15, 3:50:31 PM] denny: That’s good.

So you can try to migrate for the chef server of 88.186. See how things going.
[5/7/15, 8:54:15 AM] Meken Goncalves: Morning Denny,

which is admin password with spchef.fluigidentity.com ?
[5/7/15, 8:56:35 AM] denny: Morning Meken

mekenadmin/password1
[5/7/15, 8:56:46 AM] denny: private key for mekenadmin

-----BEGIN RSA PRIVATE KEY-----
MIIEpAIBAAKCAQEAvhAU+QVqgrMT8uVqFsroT6Hp1LS6jIEwYJPBfKGlPzHlpoBh
GdE5p3wRAMXb3qzOukBkqfdKBJAhpRlmw5zVW7UVp7jzxqRkKMPM3k6sHhYCQleg
NVzaM4FxDl4FZl7yOoNifqESl+3xzz0MTt2Zf9q1DhFqyDZ1KuiZJLvNqHG2oZH+
FUdNtmXEM2Ma/KNqiY71ar5ogsz+uniu/V/VhuKa2Et27ktzr7JuUsErSApL1omg
yF46gUDdmtf66ZQHMxmN4jgBklTFBYKdT+ArLrF63qRYHiSdH0M4SFssP+5E7TAo
iR8UK7nNJgNGoqVeqzdeo6zs5Ubebb7EtDo3YQIDAQABAoIBAQCsNzg5t+2dxhQC
WFu7kVnUphqRcL1ECN9D8z4z5ugrjdPP/a1+TjWWi/WAJMgoSZ775tMPqxG3dr31
skGKZ7Zv5XJcylqhGF3lDh25JcIRdNHROULid2MDnntJkGoGK2wDFv+NS/fkEGe1
51QatfKbhhneSGvgRHAAVEhHn6AmymoqMcCNM5Q5qPabuJaw9VMfNlmTXeUfapX0
1zV/JM6szi1PVHRdD5WqlWCqFW3aynv3EBvaZqHAP2EtgEzk8HkWX2Xkn04KDuAb
ED0+ww9aTj+VTp4htH89pWtDaIzYODhJUflImnJlnelINqNXc3WlUbfw7GqMnwk5
yIAXrrDNAoGBAOsbrmQgD3B7cIguw8uIVJIU6J4FWhCS89Zpr5ZIVltJCv7FZKK3
bjeCIeQ7NN8sbrkUC8Zk6cDes4tumn5Hb49YoZxrbjmPpz0TzuLFEYXjC7MyfxZ6
JJVD/Or5wDmb7/ID6WlH2q+dyfLQcDhJjbyLN9cWuBE1gwwolfSCsxMrAoGBAM7z
seI9lzehgu+QWXqinvgqQLpPDxiA5+8ZITzbkUHqbeqa5/N+ISkLiIzRoKdyxTOK
VPjlLfAcPyOi16ESvWV7B5E5pzD5G5lGTc1rickeSfpNfyf0TXyTga+17GctLpvz
POpYXvc9fPGTBy7uHrzGyx2Bg3fenCpHq2t3WYmjAoGBAJRfKMQ5U2UKEa9vy9KT
m8OA/HhVKkyRYN6sXco6pnz/cLftvJ/PoPfY4SiWkLxS3yFf3Dp9DuPP54ET8N3G
mUnehkcfqTUcSk+KQ6Lq+S8EZSrWsEtwE8w7Vs63hK8WkOuruk7dsM3phzv8fQWY
raESPtA3nzwFCEnRBymCnh53AoGAOIsYxQmy8T4tuiqkZ/9ak89nk//ZzgYaWJdz
H1+WVn4ovfrI+RwzDzXZfzAfRuDyxFw9Tyu+22W8Uo5Bf/7QxJNSw/kOlzDYu44b
385L/SlLaRoXbeEv8qOSwWFhT+dmXrGcqSKv/7lLE+3p/oaM22MtR8iFFRE7dcnT
Ki+XxSUCgYAIKbnfOTrEla7FF27GrT8iUMo1rCuWKU5tWWr2dYDZ/8RyWUGRX0Nb
zYs/hBvMYl/X4MaLYfGUk6rQbMcxOGq+jhKBNEZxbxe6J2DOBj6PJyVRAIc5VDMF
BwPNhdmU2IsKe0waKkqRPtnXv9wBztlx+yRf9JxUv3tfGM1z/o+Wng==
-----END RSA PRIVATE KEY-----
[5/7/15, 8:57:09 AM] denny: When you login, you can also regenerate the key or reset password, if you like.
[5/7/15, 8:57:17 AM] Meken Goncalves: Thanks Denny
[5/7/15, 8:57:19 AM] Meken Goncalves: :)
[5/8/15, 8:42:56 AM] Meken Goncalves: Morning Denny,

I managed to migrate the chef server to the new environment, but when trying to configure postfix, I am unable to read the configuration file on the current server. he's really bad
[5/8/15, 9:43:01 AM] denny: Meken

I don’t quite understand. What problem do you mean?
[5/8/15, 9:48:57 AM] Meken Goncalves: the server mail.fluigidentity.com this very bad. I can't read nor copy the postfix configuration file
[5/8/15, 9:52:14 AM] denny: Can you ssh to the server as root?

ssh root@mail.fluigidentity.com
[5/8/15, 9:52:21 AM] Meken Goncalves: yes
[5/8/15, 9:52:39 AM] Meken Goncalves: i can access, but the server are very slow
[5/8/15, 9:53:54 AM] denny: Command of free and top looks good. And I can login and run commands with no big latency.
[5/8/15, 9:55:25 AM] Meken Goncalves: for me, it crashes immediately after connection, I can't run any command
[5/8/15, 9:56:07 AM] denny: I’ve just tried. It’s fine at my side.
[5/8/15, 9:58:00 AM] Meken Goncalves: I'll show you
[5/8/15, 9:58:22 AM] denny: Call – busy
[5/8/15, 9:59:06 AM] denny: I’m on a concall.

Maybe you can try some other machines or linux box.
[5/8/15, 9:59:32 AM] Meken Goncalves: Sorry
[5/8/15, 9:59:42 AM] Meken Goncalves: i can try
[5/8/15, 10:00:37 AM] denny: BTW, I’ve just tried this.

1. Login to one linux box in Nimbvs.
2. ssh from the linux box to mail.fluigidentity.com

It looks fine.
[5/8/15, 10:01:13 AM] denny: For your convenient, I’ve reset the root password for mai.fluigidentity.com to TOTVSPassword1
* #  --8<-------------------------- separator ------------------------>8--
* TODO mail: Code build fail, due to git conflict           :noexport:
[[gnus:myself#EF9859611DA81140B2B29B02EC8AD6EA27DEC145@helios.mex01.local][Email from Denny Zhang (Fri, 8 May 2015 09:31:12 -0500): Code build fail, due to git co]]
#+begin_example
From: Denny Zhang <denny.zhang@totvs.com>
Subject: Code build fail, due to git conflict
To: Kung Wang <kung.wang@totvs.com>
CC: Denny Zhang <denny.zhang@totvs.com>
Date: Fri, 08 May 2015 09:31:12 -0500

Hi Kung

The code build fails.

Looks like the build process will change some files which are in github.
And it eventually lead to git conflict. Thus build fails.

http://10.165.4.67:48080/job/BuildMDMRepo/374/console

Here is the console output.

+ git checkout master
Already on 'master'
M       app/web-apps/fluigdata-admin/index.html
M       app/web-apps/fluigdata-docs/dist/js/main.js
M       app/web-apps/mdm-ui/index.html
Your branch is behind 'origin/master' by 1 commit, and can be fast-forwarded.
  (use "git pull" to update your local branch)
+ git pull
error: Your local changes to the following files would be overwritten by merge:
        app/web-apps/fluigdata-admin/index.html
        app/web-apps/fluigdata-docs/dist/js/main.js
        app/web-apps/mdm-ui/index.html
Please, commit your changes or stash them before you can merge.
Aborting
Updating 66d9f38..0bfd61c
Build step 'Execute shell' marked build as failure
Finished: FAILURE

Regards,

Denny

#+end_example
* TODO mail: RE: Service fail to start with CouchbaseException           :noexport:
[[gnus:myself#EF9859611DA81140B2B29B02EC8AD6EA27DEC12B@helios.mex01.local][Email from Denny Zhang (Fri, 8 May 2015 09:29:15 -0500): RE: Service fail to start with]]
#+begin_example
From: Denny Zhang <denny.zhang@totvs.com>
Subject: RE: Service fail to start with CouchbaseException
To: Shivang Shah <shivang.shah@totvs.com>, Kung Wang <kung.wang@totvs.com>
CC: Denny Zhang <denny.zhang@totvs.com>
Date: Fri, 08 May 2015 09:29:15 -0500

Hi Kung

As you said in Skype, I understand the issue is related to a couchbase issue.
https://issues.couchbase.com/browse/MB-6232

Since dev team can keep working, I guess there is some procedure or workaround to bypass this.

Do you know how I can do that? So that I can move further for all-in-one deployment by Chef.

Thus we can find more issues and resolve them earlier during the integration tests.

Regards,
Denny

---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Thursday, May 07, 2015 10:47 AM
To: Shivang Shah; Kung Wang
Cc: Denny Zhang
Subject: RE: Service fail to start with CouchbaseException

Hi Kung

I tried the latest build with a fresh install.

When I try to start app-1.0.jar, the same output.

If you'd like to ssh to the server, please check previous email in the same loop.

Regards,
Denny
---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Wednesday, May 06, 2015 8:10 PM
To: Shivang Shah; Kung Wang
Subject: RE: Service fail to start with CouchbaseException

Hi Shivang

ssh -p 5022 root@10.165.4.67 (password: TOTVSFoobar1!)

Our ssh key are all there.

Couchbase credential: (Need ssh tunnel)

Administrator/password1234

Here is how I start the service.

cd /opt/mdm

java -jar app-1.0.jar server /opt/mdm/config/mdm.yml

Regards,

Denny

---------------------------------------------------------------------------------------------------
From: Shivang Shah
Sent: Wednesday, May 06, 2015 8:04 PM
To: Denny Zhang; Kung Wang
Subject: Re: Service fail to start with CouchbaseException

Do we have access to this server?

Shivang

From: Denny Zhang <denny.zhang@totvs.com>
Date: Wednesday, May 6, 2015 at 6:03 PM
To: Shivang Shah <shivang.shah@totvs.com>, Kung Wang <kung.wang@totvs.com>
Subject: RE: Service fail to start with CouchbaseException

Thanks, Shivang

It failed with the same output.

I tried this:
1. master: 640 MB
2. session: 100 MB
3. staging: 512 MB

Regards,
Denny

---------------------------------------------------------------------------------------------------
From: Shivang Shah
Sent: Wednesday, May 06, 2015 7:55 PM
To: Denny Zhang; Kung Wang
Subject: Re: Service fail to start with CouchbaseException

Master will eventually need a lot more. 

Mater is normally >= staging

Shivang

From: Denny Zhang <denny.zhang@totvs.com>
Date: Wednesday, May 6, 2015 at 5:53 PM
To: Kung Wang <kung.wang@totvs.com>
Cc: Shivang Shah <shivang.shah@totvs.com>
Subject: RE: Service fail to start with CouchbaseException

Please note:

I initialized the couchbase with 2GB memory like below
1. session bucket: 100MB
2. staging bucket: 512 MB
3. master bucket 100MB.

Regards,
Denny
---------------------------------------------------------------------------------------------------
From: Denny Zhang
Sent: Wednesday, May 06, 2015 7:45 PM
To: Kung Wang
Cc: Denny Zhang
Subject: Service fail to start with CouchbaseException

Hi Kung

I tried to start the process, but it failed like below.

,----------- java -jar app-1.0.jar server /opt/mdm/config/mdm.yml
| [07 May 2015;00:42:15.021] - [WARN ] [AwsRoute53ServiceImpl:340] -
{"errorCode":500,"errorMessage":"com.amazonaws.services.route53.model.InvalidChangeBatchException:
Tried to create resource record set [name\u003d\u0027www.fluigdata.com.\u0027, type\u003d\
u0027CNAME\u0027] but it already exists (Service: AmazonRoute53; Status Code: 400; Error Code:
InvalidChangeBatch; Request ID: d6bd83b5-f451-11e4-9973-d325a33d26ad)","responsibleField":""} 
| 
| 
| 
| 
| Exception in thread "main" com.couchbase.client.core.CouchbaseException: Flush failed because of:
Got error: {error,{flush_wait_failed,['ns_1@127.0.0.1'],[]}}
| at com.couchbase.client.java.bucket.BucketFlusher$6.call(BucketFlusher.java:153)
| at com.couchbase.client.java.bucket.BucketFlusher$6.call(BucketFlusher.java:146)
| at rx.internal.operators.OperatorMap$1.onNext(OperatorMap.java:55)
| at rx.subjects.SubjectSubscriptionManager$SubjectObserver.onNext
(SubjectSubscriptionManager.java:224)
| at rx.subjects.AsyncSubject.onCompleted(AsyncSubject.java:101)
| at com.couchbase.client.core.endpoint.AbstractGenericHandler$1.call
(AbstractGenericHandler.java:198)
| at rx.internal.schedulers.ScheduledAction.run(ScheduledAction.java:47)
| at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
| at java.util.concurrent.FutureTask.run(FutureTask.java:266)
| at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201
(ScheduledThreadPoolExecutor.java:180)
| at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run
(ScheduledThreadPoolExecutor.java:293)
| at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
| at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
| at java.lang.Thread.run(Thread.java:745)
| Caused by: rx.exceptions.OnErrorThrowable$OnNextValue: OnError while emitting onNext value:
com.couchbase.client.core.message.config.FlushResponse.class
| at rx.exceptions.OnErrorThrowable.addValueAsLastCause(OnErrorThrowable.java:98)
| at rx.internal.operators.OperatorMap$1.onNext(OperatorMap.java:58)
| ... 11 more
`-----------

The couchbase looks like been initialized correctly.

[cid]

Regards,
Denny

#+end_example
* TODO mail: Re: referral from Jay Zheng           :noexport:
[[gnus:nnfolder%2Barchive:mail.sent.mail#m27fsb15ys.fsf@gmail.com][Email from Denny Zhang (Thu, 14 May 2015 11:25:47 -0500): Re: referral from Jay Zheng]]
#+begin_example
From: Denny Zhang <filebat.mark@gmail.com>
Subject: Re: referral from Jay Zheng
To: David Callahan <david@colaberry.com>
Date: Thu, 14 May 2015 11:25:47 -0500
User-Agent: Gnus/5.13 (Gnus v5.13) Emacs/24.4 (darwin)

Hi David

The position looks very attracting to me!

I'm quite interested.

-- 
Denny Zhang(张巍)

It feels good when you've something and you share.

 ※、ヽ、ヽ｀、｀＊、※、ヽ｀ヽ｀、｀＊、※、ヽ＊、ヽ｀、※、ヽ、
 ｀、｀＊、ヽ｀＊、｀＊、ヽ｀※ヽ｀、※、ヽ、｀、※、ヽ、 ヽ｀、
 ＊、※、ヽ｀＊、ヽ｀、｀＊、※、ヽ、ヽ｀、｀＊、※、ヽ｀ヽ｀、｀
 ＊※、ヽ、ヽ｀、＊、※、ヽ｀＊、ヽ｀、｀＊、※、ヽ、ヽ｀、｀＊、

Thu, 14 May 2015 12:09:14 -0400 David Callahan <david@colaberry.com>
writes:

> Hi Denny, 
>
> A friend of yours Jay, mentioned you are looking for new Dev Ops opportunities and have just
> received a AWS architect certification.
>
> My name is David Callahan, the Delivery Manager at Colaberry.
>
> Colaberry is an start-up focused on data Science, analytics and intelligence training. 
> Our mission is to close the skills gap for opportunity youth and veterans by providing pathways
> into technology careers through training, mentoring, and job placement. To do this we developed a
> learning gamified learning platform. In addition to the entry level courses we provide advanced
> certifications and are a Tableau, QlikView, and Cloudera certified vendor and implementation
> partner. We support the learning platform and scholarships with strategic consulting and placement
> to keep costs affordable. 
>
> Currently a handful of my clients are looking DevOps / AWS consultants. 
>
> Here is one description to give you and idea. 
>
> Title: Devops Architect 
> Duration: 8-12+ Months 
> Location: Boston, MA, 
>
> This role is extremely critical and will have a significant impact on the direction of an award
> winning, fast growing company. We are in need of a DevOps Architect to help with scalability
> challenges on different DBMS engines which handle terabytes of data every day and store petabytes
> of data.
>
>  
>
> RESPONSIBILITIES:
>
> ·         Make it easy to deploy new code and difficult to make mistakes in production
>
> ·         Monitor, measure and optimize our systems and processes
>
> ·         Automate everything
>
> ·         Build or implement resource sharing frameworks like Mesos
>
>  
>
> DESIRED SKILLS:
>
> ·         A track record managing large AWS deployments, including deep knowledge of AWS security
> and networking best practices
>
> ·         The ability to script AWS operations using Ruby or Python
>
> ·         Knowledge of Docker, experience managing Docker-based deployments a plus
>
> ·         Experience with infrastructure automation tools such as Chef, Puppet, or Ansible
>
> ·         Strong background in Unix and networking
>
> ·         Knowledge of Apache Mesos and Marathon a plus
>
> ·         Experience with SQL, Hadoop a plus
>
> --
>
> David Callahan  
>
> Delivery Manager | Colaberry
>
> p: 617-520-4936 
>
> www.colaberry.com    I   LinkedIn  
>
> [colaberryl]

#+end_example
* #  --8<-------------------------- separator ------------------------>8--
* TODO mail: Ask input for MDM Trouble Shooting Wiki           :noexport:
[[gnus:myself#EF9859611DA81140B2B29B02EC8AD6EA27E15E20@helios.mex01.local][Email from Denny Zhang (Sun, 17 May 2015 12:21:58 -0500): Ask input for MDM Trouble Shoo]]
#+begin_example
From: Denny Zhang <denny.zhang@totvs.com>
Subject: Ask input for MDM Trouble Shooting Wiki
To: Vicente Goetten <goetten@totvs.com>, Kung Wang <kung.wang@totvs.com>,
        Chinwei Wong <chinwei.wong@totvs.com>, Robson Thanael Poffo
        <robson.poffo@totvs.com.br>, Mitu <mitu@totvs.com>, Lezhong Li
        <lezhong.li@totvs.com.br>, John Kaplan <john.kaplan@totvs.com>, Shivang Shah
        <shivang.shah@totvs.com>, Denny Zhang <denny.zhang@totvs.com>, Danny
 Schreiber <danny.schreiber@totvs.com>
CC: Denny Zhang <denny.zhang@totvs.com>
Date: Sun, 17 May 2015 12:21:58 -0500

Hi Guys

I've drafted the trouble shooting wiki for MDM project.
https://totvslab.atlassian.net/wiki/display/MDMP/Basic+Trouble+Shooting+Skills

Please add your comments in the wiki, for
- Things or questions you may need to maintain the system, but they are missing from the wiki.
- Tips you have which might help others but are missing.

Regards,
Denny

#+end_example
* TODO mail: DevOps questions for MDM service           :noexport:
[[gnus:myself#EF9859611DA81140B2B29B02EC8AD6EA27E15E48@helios.mex01.local][Email from Denny Zhang (Sun, 17 May 2015 12:41:00 -0500): DevOps questions for MDM servi]]
#+begin_example
From: Denny Zhang <denny.zhang@totvs.com>
Subject: DevOps questions for MDM service
To: Kung Wang <kung.wang@totvs.com>
CC: Shivang Shah <shivang.shah@totvs.com>, Denny Zhang <denny.zhang@totvs.com>
Date: Sun, 17 May 2015 12:41:00 -0500

Hi Kung

Some questions about mdm.

Everything can verify in the your box, which is "ssh -p 6022 root@10.165.4.67".

1. Where is the log file of MDM? 
We shall need to dump messages to log file, instead of stdout only. Also enable log rotate
mechanism.

2. swagger URI of runs into 404 error
https://localhost:8443/mdm/swagger-ui/

However mdm-ui, fluigdata-admin and fluigdata-docs returns 200.

3. mdm service can start, however the start process takes too long.
It costs almost 140 seconds, during my multiple tests.

Regards,
Denny

#+end_example
* TODO nrpe-runner: Run all nagios nrpe commands
http://www.unixdaemon.net/tools/commandline/introducing-nrpe-runner.html
* TODO mail: AWS Certified SysOps Administrator– Associate (ENGLISH) Completed           :noexport:
[[gnus:mail.misc#2133491883.25459.1431359986111.JavaMail.certs@PRODTC01][Email from donotreply@kryteriononline.com (Mon, 11 May 2015 08:59:46 -0700 (MST)): AWS Certified SysOps Administr]]
#+begin_example
From: donotreply@kryteriononline.com
Subject: AWS Certified SysOps Administrator– Associate (ENGLISH) Completed
To: denny.zhang001@gmail.com
Date: Mon, 11 May 2015 10:59:46 -0500

Hello Denny,

Thank you for taking the AWS SysOps Administrator - Associate exam. Unfortunately, you were
unsuccessful in this attempt.

If you wish to re-take this exam, you will need to wait 30 days before re-registering. You must pay
the full exam fee each time you retake the exam.

Overall Score: 60%

Topic Level Scoring:

1.0 Monitoring and Metrics: 62%

2.0 High Availability: 50%

3.0 Analysis: 88%

4.0 Deployment and Provisioning: 75%

5.0 Data Management: 42%

6.0 Security: 50%

7.0 Networking: 42%

Do not reply to this email. If you have any questions about the AWS Certification program, please
contact us for assistance.

Thank you.

#+end_example
* TODO mail: Re: referral from Jay Zheng           :noexport:
[[gnus:mail.misc#CALi%3DC9q1-%3D3YMNGnzcAhvRP9F-2ZfzQeu%2BqEq4qR5uwLbVaaDQ@mail.gmail.com][Email from David Callahan (Wed, 20 May 2015 11:40:53 -0400): Re: referral from Jay Zheng]]
#+begin_example
From: David Callahan <david@colaberry.com>
Subject: Re: referral from Jay Zheng
To: Denny Zhang <filebat.mark@gmail.com>
Date: Wed, 20 May 2015 11:40:53 -0400

Hi Denny,

I will let you know ASAP after I confirm tech phone screen time 

Title: System Operations Engineer (DevOps)

Location: Woburn - (onsite first month or so than remote)

Duration: 6 Months 

Behind SilverRail's global expansion is a cloud infrastructure built and maintained by the Systems
Infrastructure team. This team provides site reliability services across all technical operations
including our core production applications, engineering & UAT systems, virtualization and storage
systems, and our public and private networks.

Those who join us will have a significant impact on the design and implementation of our multi-data
center cloud environment built on Open Compute Project hardware, the OpenStack cloud computing
environment, and a combination of enterprise-class networking gear. You'll receive hands-on
experience building the second generation of an infrastructure that serves travelers around the
world.

In addition, working with existing network infrastructure during this transition is vitally
important. There are multiple, challenging problems to be solved moving all of our systems to a new
data center environment while incurring near-zero downtime.

To help us through this next phase of growth, we're looking for smart, forward-thinking, and
motivated System Operations Engineers that are capable of reliably operating and maintaining our
systems and supporting networks.

Responsibilities

  * Support a lively and fast-paced engineering and DevOps team with monthly agile releases
  * Manage all operational aspects of our rapidly growing and changing Development and Production
    environments
  * Gain an understanding of the SilverRail application to better assess, troubleshoot, mitigate,
    and prevent issues
  * Contribute to the overall operations and strategy moving from virtualization to private cloud
    platform
  * Document system diagrams, run books, and procedures to build and become part of 24/7 SOC

Required Qualifications

  * Bachelors degree or equivalent experience
  * Demonstrable, strong Linux/UNIX experience
  * Knowledge of Apache, Tomcat
  * Experience configuring and managing virtualized environments (i.e. KVM, Xen)
  * Demonstrable experience configuring or maintaining cloud platforms (i.e. Openstack, Cloudstack,
    AWS)
  * Strong scripting skills in Bash, Python or similar
  * Experience running day-to-day data-center system operations and guestOS
  * Hands-on experience implementing and managing enterprise monitoring and logging solutions
  * Ability to work in a fast-paced environment, keeping track of and completing multiple tasks/
    issues
  * Strong oral and written communication skills and attention to detail

Desired Qualifications

  * Experience with Agile and Continuous Delivery development methodology
  * Experience with Atlassian products (Jira, Confluence, Crowd)
  * Extensive web hosting configuration, tuning and troubleshooting experience
  * Experience with automation tools a plus (i.e. Ansible, Chef, Puppet)
  * Java application server deployment and troubleshooting
  * Familiarity with Mysql administration
  * Hands-on experience with firewalls and load balancer functions and configurations (Fortigate,
    Cisco, Netscaler, F5)
  * Networking (e.g., TCP/IP, load balancing, clustering)
  * 

On Fri, May 15, 2015 at 9:43 AM, Denny Zhang <filebat.mark@gmail.com> wrote:

    Hi David
   
    I shall be available to have the call for the whole Monday morning.
   
    Regards,
    Denny
    --
    Denny Zhang(张巍)
   
    A smile is the shortest distance between two people.
   
     ●█〓██▄▄▄▄▄▄ ●●●●●●----
     ▄▅██████▅▄▃▂
     ██████████████
     ◥⊙▲⊙▲⊙▲⊙▲⊙▲⊙▲◤
   
    Fri, 15 May 2015 09:04:42 -0400 David Callahan <david@colaberry.com>
    writes:
   
    > Perfect,
    >
    > Whats your availability Monday?
    >
    > On Thu, May 14, 2015 at 4:35 PM, Denny Zhang <filebat.mark@gmail.com> wrote:
    >
    >     Hi David
    >
    >     How about some time next week?
    >
    >     My phone is +1-832-312-4346.
    >
    >     --
    >     Denny Zhang(张巍)
    >
    >     Surround yourself with inspiration.
    >
    >     (・ω・)
    >
    >     Thu, 14 May 2015 16:20:53 -0400 David Callahan <david@colaberry.com>
    >     writes:
    >
    >     > Excellent, 
    >     >
    >     > Have some time tomorrow to talk about the role?
    >     >
    >     > Whats the best number to reach you?
    >     >
    >     > On Thu, May 14, 2015 at 12:25 PM, Denny Zhang <filebat.mark@gmail.com> wrote:
    >     >
    >     >     Hi David
    >     >
    >     >     The position looks very attracting to me!
    >     >
    >     >     I'm quite interested.
    >     >
    >     >     --
    >     >     Denny Zhang(张巍)
    >     >
    >     >     It feels good when you've something and you share.
    >     >
    >     >      ※、ヽ、ヽ｀、｀＊、※、ヽ｀ヽ｀、｀＊、※、ヽ＊、ヽ｀、※、ヽ、
    >     >      ｀、｀＊、ヽ｀＊、｀＊、ヽ｀※ヽ｀、※、ヽ、｀、※、ヽ、ヽ｀、
    >     >      ＊、※、ヽ｀＊、ヽ｀、｀＊、※、ヽ、ヽ｀、｀＊、※、ヽ｀ヽ｀、｀
    >     >      ＊※、ヽ、ヽ｀、＊、※、ヽ｀＊、ヽ｀、｀＊、※、ヽ、ヽ｀、｀＊、
    >     >
    >     >     Thu, 14 May 2015 12:09:14 -0400 David Callahan <david@colaberry.com>
    >     >     writes:
    >     >
    >     >     > Hi Denny, 
    >     >     >
    >     >     > A friend of yours Jay, mentioned you are looking for new Dev Ops opportunities
    and have
    >     just
    >     >     > received a AWS architect certification.
    >     >     >
    >     >     > My name is David Callahan, the Delivery Manager at Colaberry.
    >     >     >
    >     >     > Colaberry is an start-up focused on data Science, analytics and intelligence
    training. 
    >     >     > Our mission is to close the skills gap for opportunity youth and veterans by
    providing
    >     >     pathways
    >     >     > into technology careers through training, mentoring, and job placement. To do
    this we
    >     >     developed a
    >     >     > learning gamified learning platform. In addition to the entry level courses we
    provide
    >     >     advanced
    >     >     > certifications and are a Tableau, QlikView, and Cloudera certified vendor and
    >     implementation
    >     >     > partner. We support the learning platform and scholarships with strategic
    consulting
    >     and
    >     >     placement
    >     >     > to keep costs affordable. 
    >     >     >
    >     >     > Currently a handful of my clients are looking DevOps / AWS consultants. 
    >     >     >
    >     >     > Here is one description to give you and idea. 
    >     >     >
    >     >     > Title: Devops Architect 
    >     >     > Duration: 8-12+ Months 
    >     >     > Location: Boston, MA, 
    >     >     >
    >     >     > This role is extremely critical and will have a significant impact on the
    direction of
    >     an
    >     >     award
    >     >     > winning, fast growing company. We are in need of a DevOps Architect to help with
    >     scalability
    >     >     > challenges on different DBMS engines which handle terabytes of data every day and
    store
    >     >     petabytes
    >     >     > of data.
    >     >     >
    >     >     >  
    >     >     >
    >     >     > RESPONSIBILITIES:
    >     >     >
    >     >     > ·         Make it easy to deploy new code and difficult to make mistakes in
    production
    >     >     >
    >     >     > ·         Monitor, measure and optimize our systems and processes
    >     >     >
    >     >     > ·         Automate everything
    >     >     >
    >     >     > ·         Build or implement resource sharing frameworks like Mesos
    >     >     >
    >     >     >  
    >     >     >
    >     >     > DESIRED SKILLS:
    >     >     >
    >     >     > ·         A track record managing large AWS deployments, including deep knowledge
    of
    >     AWS
    >     >     security
    >     >     > and networking best practices
    >     >     >
    >     >     > ·         The ability to script AWS operations using Ruby or Python
    >     >     >
    >     >     > ·         Knowledge of Docker, experience managing Docker-based deployments a
    plus
    >     >     >
    >     >     > ·         Experience with infrastructure automation tools such as Chef, Puppet,
    or
    >     Ansible
    >     >     >
    >     >     > ·         Strong background in Unix and networking
    >     >     >
    >     >     > ·         Knowledge of Apache Mesos and Marathon a plus
    >     >     >
    >     >     > ·         Experience with SQL, Hadoop a plus
    >     >     >
    >     >     > --
    >     >     >
    >     >     > David Callahan  
    >     >     >
    >     >     > Delivery Manager | Colaberry
    >     >     >
    >     >     > p: 617-520-4936 
    >     >     >
    >     >     > www.colaberry.com    I   LinkedIn  
    >     >     >
    >     >     > [colaberryl]
    >     >
    >     > --
    >     >
    >     > David Callahan  
    >     >
    >     > Delivery Manager | Colaberry
    >     >
    >     > p: 617-520-4936 
    >     >
    >     > www.colaberry.com    I   LinkedIn  
    >     >
    >     > [colaberryl]
    >
    > --
    >
    > David Callahan  
    >
    > Delivery Manager | Colaberry
    >
    > p: 617-520-4936 
    >
    > www.colaberry.com    I   LinkedIn  
    >
    > [colaberryl]

--

David Callahan  

Delivery Manager | Colaberry

p: 617-520-4936 

www.colaberry.com    I   LinkedIn  

[colaberryl]

#+end_example
* TODO mail: Phone Screen Confirmation           :noexport:
[[gnus:mail.misc#CALi%3DC9pD4m3VT%3Dn%2Bbbwwwwjgt-p%2BhUgmYb9duK3Dz4PxM6k%2BnQ@mail.gmail.com][Email from David Callahan (Wed, 20 May 2015 14:13:50 -0400): Phone Screen Confirmation]]
#+begin_example
From: David Callahan <david@colaberry.com>
Subject: Phone Screen Confirmation
To: denny zhang <denny.zhang001@gmail.com>
Date: Wed, 20 May 2015 14:13:50 -0400

Hi Denny, 

Please Confirm...

Date: Thursday the 21st at 2:30 PM 
Interviewer: Max Indelicato (I haven't been able to find him on LinkedIn)
They will call you at: 832-312-4346.

Please print out the job description and your resume so you have it available during the phone
screen. 

Title: System Operations Engineer (DevOps)

Location: Woburn - (onsite first month or so than remote)

Duration: 6 Months 

Behind SilverRail's global expansion is a cloud infrastructure built and maintained by the Systems
Infrastructure team. This team provides site reliability services across all technical operations
including our core production applications, engineering & UAT systems, virtualization and storage
systems, and our public and private networks.

Those who join us will have a significant impact on the design and implementation of our multi-data
center cloud environment built on Open Compute Project hardware, the OpenStack cloud computing
environment, and a combination of enterprise-class networking gear. You'll receive hands-on
experience building the second generation of an infrastructure that serves travelers around the
world.

In addition, working with existing network infrastructure during this transition is vitally
important. There are multiple, challenging problems to be solved moving all of our systems to a new
data center environment while incurring near-zero downtime.

To help us through this next phase of growth, we're looking for smart, forward-thinking, and
motivated System Operations Engineers that are capable of reliably operating and maintaining our
systems and supporting networks.

Responsibilities

  * Support a lively and fast-paced engineering and DevOps team with monthly agile releases
  * Manage all operational aspects of our rapidly growing and changing Development and Production
    environments
  * Gain an understanding of the SilverRail application to better assess, troubleshoot, mitigate,
    and prevent issues
  * Contribute to the overall operations and strategy moving from virtualization to private cloud
    platform
  * Document system diagrams, run books, and procedures to build and become part of 24/7 SOC

Required Qualifications

  * Bachelors degree or equivalent experience
  * Demonstrable, strong Linux/UNIX experience
  * Knowledge of Apache, Tomcat
  * Experience configuring and managing virtualized environments (i.e. KVM, Xen)
  * Demonstrable experience configuring or maintaining cloud platforms (i.e. Openstack, Cloudstack,
    AWS)
  * Strong scripting skills in Bash, Python or similar
  * Experience running day-to-day data-center system operations and guestOS
  * Hands-on experience implementing and managing enterprise monitoring and logging solutions
  * Ability to work in a fast-paced environment, keeping track of and completing multiple tasks/
    issues
  * Strong oral and written communication skills and attention to detail

Desired Qualifications

  * Experience with Agile and Continuous Delivery development methodology
  * Experience with Atlassian products (Jira, Confluence, Crowd)
  * Extensive web hosting configuration, tuning and troubleshooting experience
  * Experience with automation tools a plus (i.e. Ansible, Chef, Puppet)
  * Java application server deployment and troubleshooting
  * Familiarity with Mysql administration
  * Hands-on experience with firewalls and load balancer functions and configurations (Fortigate,
    Cisco, Netscaler, F5)
  * Networking (e.g., TCP/IP, load balancing, clustering)

--

David Callahan  

Delivery Manager | Colaberry

p: 617-520-4936 

www.colaberry.com    I   LinkedIn  

[colaberryl]

#+end_example
* linkedin: devops consultants
https://www.linkedin.com/title/devops-consultant?trk=pprofile_title
* #  --8<-------------------------- separator ------------------------>8--
* DONE English contractor 1099 or W2 employee
  CLOSED: [2015-05-28 Thu 14:40]
W2是雇员的报税单

1099是自雇雇员的报税单
1099对打工的来说，会少交一些税，公司也会少交很多，其他的没有什么大的影响

http://www.sinovision.net/portal.php?mod=view&aid=21226

收1099相当于你是contractor,即你是自雇身份.意思是公司不会帮你报任何工资
税. 到年底,你需要报双倍的税额 (你自己的工资税+自雇税). W-2 是公司负责
雇主工资税部分.同时扣起你的工资税报向政府. 一般来说,付你1099的薪金应比
给你W-2的雇用行式要多.

填写W2的属于全职员工，是需要准时上班下班的上班族，公司会在每次发放工资
的时候扣税，如每个员工都需要扣减工资总额7.65%的社会安全金，同时，公司
老板还要为你付另外的7.65%社会安全金。填写1099表的员工不属于全职员工，
通常不需要受公司上班时间限制，如以佣金作为主要收入的销售员，其收入不需
要每月扣税，但年度报税的时候，自己需要交纳收入总额15.3%的全额社会安全
金。W2的优点是，老板为你支付了一半的社安金，自己只需要付一半。

1099的好处是，与工作直接相关的费用可以抵税。比如用于工作的交通费用、宣
传品、办公用品，甚至宴请客户的餐费，也可以抵税。填写1099表一定要注意抵
税的部分要与收入相符，而且开支一定要与工作直接相关。用于抵税的费用，一
定要保存收据，尽管会计师并不要求报税者出示收据，但一旦国税局查帐，需要
报税者提交收据之类的证明，这些收据需要保留三年。

Hey Denny

As  a contractor you would be a 1099 or W2 employee of my agency and work at TrinteX. I can support corp to corp depending on the situation.

Do you have couple minutes to talk on the phone about this?
I do not have your number.
* TODO [#A] Jay: How to negotiate with Vicente: reasable mutual expectation with less communication :IMPORTANT:
Customers may doubt whether I'm paying more than what I should get
* TODO [#A] Question list what I need to ask for consultant projects
* TODO [#A] Question: how to assign tasks to Contract; how the assignment is given
* TODO DevOps consultant role models
http://ronaldbradford.com
http://www.ahtik.com
* DONE [#A] Less communication: Start a VM, however it's not ssh accessible :IMPORTANT:
  CLOSED: [2015-06-01 Mon 21:30]
ssh root@54.152.234.115

put "PasswordAuthentication yes" in /etc/ssh/sshd_config.

#+BEGIN_EXAMPLE
[6/1/15, 8:52:12 PM] Zhiyong Xu: hehe
[6/1/15, 9:04:11 PM] Zhiyong Xu: cannot log in
[6/1/15, 9:04:18 PM] Zhiyong Xu: errors are here:
[6/1/15, 9:04:55 PM] Zhiyong Xu: Image
[6/1/15, 9:08:12 PM] denny: Could you try again?
[6/1/15, 9:08:19 PM] Zhiyong Xu: ok
[6/1/15, 9:08:55 PM] Zhiyong Xu: the same
[6/1/15, 9:11:05 PM] denny: It should be fine.

Could you test that in Ubuntu as you did above?
[6/1/15, 9:13:25 PM] Zhiyong Xu: wait
[6/1/15, 9:15:03 PM] Zhiyong Xu: same
[6/1/15, 9:15:08 PM] Zhiyong Xu: Image
[6/1/15, 9:15:26 PM] Zhiyong Xu: Image
[6/1/15, 9:18:14 PM] denny: Yes, I see the same issue like you by checking from another computer.
[6/1/15, 9:18:26 PM] denny: Sorry about that. Let me check more about it.
[6/1/15, 9:18:36 PM] Zhiyong Xu: it's ok, thanks a lot
#+END_EXAMPLE
* DONE regulation questions for securitygroup or firewalls
  CLOSED: [2015-06-01 Mon 21:45]
[6/1/15, 9:25:16 PM] Zhiyong Xu: ok
[6/1/15, 9:25:57 PM] Zhiyong Xu: yes, it is ok now
[6/1/15, 9:25:58 PM] Zhiyong Xu: thanks
[6/1/15, 9:42:56 PM] Zhiyong Xu: I have installed tomcat and started it, but can not access it using 54.152.234.115:8080. Why?
[6/1/15, 9:43:23 PM] denny: security group only opens port 80 and 443.
[6/1/15, 9:43:42 PM] Zhiyong Xu: can you open 8080? or can I control it?
[6/1/15, 9:44:05 PM] Zhiyong Xu: because 8080 is used for administration
[6/1/15, 9:44:15 PM] Zhiyong Xu: and will use 80 for project
[6/1/15, 9:44:31 PM] denny: 8080 is open now.
* DONE Survive for network turbulence: add retry for remote_file
  CLOSED: [2015-06-01 Mon 23:55]
#+BEGIN_EXAMPLE
%w(check_proc_mem check_proc_cpu check_proc_fd).each do |proc_nagios_plugin|
  remote_file "#{node['nagios']['plugins_dir']}/#{proc_nagios_plugin}.sh" do
    source "https://raw.githubusercontent.com/DennyZhang/#{proc_nagios_plugin}/master/#{proc_nagios_plugin}.sh"
    owner 'nagios'
    group 'nagios'
    mode '0755'
    retries 3
  end
end
#+END_EXAMPLE
* DONE [#A] Fault Tolerant: Rely on public repo server, which is not stable
  CLOSED: [2015-06-02 Tue 00:20]

node.default['nodejs']['source']['url'] = \
"#{node['os_basic']['nodejs_url']}"

#+BEGIN_EXAMPLE
    Recipe: os-basic::devkit
         * apt_package[maven] action install
       - install version 3.0.5-1 of package maven
         * ark[nodejs-source] action install
       
       
           * remote_file[/tmp/kitchen/cache/nodejs-source-0.12.1.tar.gz] action create[2015-06-02T03:43:11+00:00] ERROR: Connection refused connecting to http://nodejs.org/dist/v0.12.1/node-v0.12.1-linux-x64.tar.gz, retry 1/5
       [2015-06-02T03:43:16+00:00] ERROR: Connection refused connecting to http://nodejs.org/dist/v0.12.1/node-v0.12.1-linux-x64.tar.gz, retry 2/5
       [2015-06-02T03:43:21+00:00] ERROR: Connection refused connecting to http://nodejs.org/dist/v0.12.1/node-v0.12.1-linux-x64.tar.gz, retry 3/5
       [2015-06-02T03:43:27+00:00] ERROR: Connection refused connecting to http://nodejs.org/dist/v0.12.1/node-v0.12.1-linux-x64.tar.gz, retry 4/5
       [2015-06-02T03:43:33+00:00] ERROR: Connection refused connecting to http://nodejs.org/dist/v0.12.1/node-v0.12.1-linux-x64.tar.gz, retry 5/5
       [2015-06-02T03:43:39+00:00] WARN: remote_file[/tmp/kitchen/cache/nodejs-source-0.12.1.tar.gz] cannot be downloaded from http://nodejs.org/dist/v0.12.1/node-v0.12.1-linux-x64.tar.gz: Connection refused - Connection refused connecting to http://nodejs.org/dist/v0.12.1/node-v0.12.1-linux-x64.tar.gz, giving up
       
             
             ================================================================================
       Error executing action `create` on resource 'remote_file[/tmp/kitchen/cache/nodejs-source-0.12.1.tar.gz]'
             ================================================================================
             
             Errno::ECONNREFUSED
             -------------------
             Connection refused - Connection refused connecting to http://nodejs.org/dist/v0.12.1/node-v0.12.1-linux-x64.tar.gz, giving up
             
             Resource Declaration:
             ---------------------
       # In /tmp/kitchen/cache/cookbooks/ark/providers/default.rb
             
       45:   remote_file new_resource.release_file do
       46:     Chef::Log.debug('DEBUG: new_resource.release_file')
       47:     source new_resource.url
       48:     checksum new_resource.checksum if new_resource.checksum
        49:     action :create
        50:     notifies :run, "execute[unpack #{new_resource.release_file}]"
        51:   end
       52: 
             
             Compiled Resource:
             ------------------
             # Declared in /tmp/kitchen/cache/cookbooks/ark/providers/default.rb:45:in `block in class_from_file'
             
             remote_file("/tmp/kitchen/cache/nodejs-source-0.12.1.tar.gz") do
         provider Chef::Provider::RemoteFile
         action [:create]
         retries 0
        retry_delay 2
        default_guard_interpreter :default
         path "/tmp/kitchen/cache/nodejs-source-0.12.1.tar.gz"
         backup 5
        atomic_update true
        source ["http://nodejs.org/dist/v0.12.1/node-v0.12.1-linux-x64.tar.gz"]
        use_etag true
        use_last_modified true
         declared_type :remote_file
         cookbook_name "os-basic"
#+END_EXAMPLE
* #  --8<-------------------------- separator ------------------------>8--
* TODO Contract with silverail
** Pros
- Obtain OpenStack first-hand experience of prod env
- Generate more revenue for company
- Exercise skills of doing consultant work and managing multple projects
- Shapen my DevOps skills
** Cons
- Can't manage the job 2 months later
- Harm the reputation to silverail for OSC and me
- May not have enough resource bandwith to support OSC seed project and big data project
** Actions
- Or convince silverail to take 20 hours contract after 2 months
- Get a capable US colleagues to deal the onsite requirement of silverRail, while I'm supporting from CN
* TODO mail: Sr. Dev Ops Engineer with lead, Infrastructure, AWS, Linux/Unix job opening - Denny           :noexport:
[[gnus:mail.misc#0VvyPFrVYKipVl0alK5sx1qRv9Rn2RvOGlOLtH0zwMg.1433793408217.RezContact.tomcat@sjc-rezweb2][Email from Manju via Indeed (Mon, 8 Jun 2015 13:56:48 -0600 (GMT-06:00)): Sr. Dev Ops Engineer with lead]]
#+begin_example
From: Manju via Indeed <r+0i6xl0bkPQRrNfjcW0MtcQb-yl4a-Tq1i8Kpqk4odGA@indeedemail.com>
Subject: Sr. Dev Ops Engineer with lead, Infrastructure, AWS, Linux/Unix job opening - Denny
To: Denny Zhang <filebat.mark@gmail.com>
Date: Mon, 08 Jun 2015 15:56:48 -0400
Reply-To: Manju <r+0i6xl0bkPQRrNfjcW0MtcQb-yl4a-Tq1i8Kpqk4odGA@indeedemail.com>

                             Message from Manju at HireIT People Inc.                              
  Interested? Reply to this email to contact Manju. Your contact details will be shared when you   
                                              reply.                                               
                Not interested? Decline - Your contact details will not be shared.                 
                                             Hi Denny,                                             
                                                                                                   
 I found your resume on Indeed. Please reply to this email if you are interested in discussing the 
                                      following job opening.                                       
                                                                                                   
                                            JOB DETAILS                                            
            Job Title: Sr. Dev Ops Engineer with lead, Infrastructure, AWS, Linux/Unix             
                                    Company: HireIT People Inc                                     
                                                                                                   
                                       Location: Boston, MA                                        
                               Interview Process: Telephone + Skype                                
                                         Responsibilities:                                         
                                                                                                   
            This is a hands-on position, which will require the following capabilities:            
 • Lead and contribute in the DevOps team to maintain and build out our infrastructure and servers 
                                    currently operating on AWS.                                    
  • Evolve infrastructure, server, deployment strategies and testing to support our goal of 100%   
           up-time and quick turnaround of deployments for the engineering organization.           
• Continuously improve our infrastructure to be easy to deploy, scalable, secure and fault-tolerant
                  - we are providing financial applications for the Fortune 500.                   
 • Work closely with our Architects, Engineers, Product Managers and other clients and partners of 
the DevOps team to meet the needs of the organization to stay competitive - from the infrastructure
                             up to the highest level of applications.                              
• Take on the same responsibilities of a DevOps engineer such as being on-call, writing deployment 
              scripts, debugging applications, evaluating new technologies and more.               
  • Help build a pipeline of qualified DevOps candidates for future openings and lead the DevOps   
                                            engineers.                                             
           • Drive the process in which our DevOps team operates and iterates/releases.            
                                                                                                   
                                 Requirements and Qualifications:                                  
   • You are smart with an intellectual curiosity that motivates you to keep on top of technical   
                 trends - but you also have deep knowledge in the tools of choice.                 
• You have supported Linux/Unix deployments for a company with a high traffic site in the cloud(we 
                                        don’t do Windows).                                         
 • You have designed, monitored and managed scalable and fault-tolerant deployments and supported  
                                   them in real-world scenarios.                                   
   • You have lead an Ops/DevOps team before (5 reports or more) for 2+ years - preferably at a    
                                             startup.                                              
    • You have experience with continuous integration, log collection and analysis, builds and     
                       performance monitoring/tuning of your infrastructure.                       
   • You are service-oriented, and enjoy working with engineers to make the software development   
                                 process as painless as possible.                                  
     • You are comfortable writing scripts in ruby/bash/groovy/python (at least two of those).     
• You are extremely reliable and we can count on you in times of need and are used to being on-call
                                           /pager duty.                                            
 • You have demonstrable experience with our stack - Cloud/AWS, Tomcat, MySQL, Cassandra, Apache,  
                                      HAProxy, ActiveMQ etc.                                       
                                                                                                   
                                           Nice To Have:                                           
 • Previous experience working with distributed teams - directly interacting with the development  
                                              teams.                                               
                             • Experience with Puppet, Chef or Docker.                             
                           • Experience with network and server security                           
                                                                                                   
[spacer]

#+end_example
* TODO DevOps slogan: When code is completed, you're done
* TODO mail: Fwd: AWS optimaztion           :noexport:
[[gnus:p0-colleague#CAEJMcnZm%2BRxHvPcPFHyiCTd1e9J6RNUkXvxt8icHM-a2-s7tOg@mail.gmail.com][Email from John Xu (Mon, 15 Jun 2015 09:29:16 -0400): Fwd: AWS optimaztion]]
#+begin_example
From: John Xu <jianjohnxu@gmail.com>
Subject: Fwd: AWS optimaztion
To: Denny Zhang <filebat.mark@gmail.com>, Brandon Chen <bchen.osc@gmail.com>, 
        Yaodong Hu <yaodonghu@gmail.com>, Jay Zheng <jayzheng07@gmail.com>
Date: Mon, 15 Jun 2015 09:29:16 -0400

FYI - We didn't hear anything from Pankaj as following unfortunately reason.

I just chat with Danny and Brandon so that they know this if Pankaj calls him.

---------- Forwarded message ----------
From: Pankaj Shroff <shroffg@gmail.com>
Date: Sun, Jun 14, 2015 at 9:42 PM
Subject: Re: AWS optimaztion
To: John Xu <jianjohnxu@gmail.com>

HI John - I am sorry I haven't replied back earlier. I had to rush to India to my family because of
a very tragic death of my younger brother due to Cancer. I have been busy with the family helping
them and helping myself cope with the loss we have experienced. I will get back to you very soon. I
am going to discuss the people you are referring to us with my COO. Maybe next time we meet, we
should meet together with my co-founder and COO.

Pankaj

On Wed, May 27, 2015 at 9:33 PM, John Xu <jianjohnxu@gmail.com> wrote:

    Hey Pankaj,
   
    Did you reach out to Denny yet?
    Also, I knew another good developer who has experience that you are looking for.
    I can ask him to contact with you.
   
    Do you have time to have a lunch so that we can catchup sometime this or next week?
   
    Thanks,
    John
     
   
    On Thu, May 21, 2015 at 6:10 PM, John Xu <jianjohnxu@gmail.com> wrote:
   
        Pankaj,
       
        As far as Mongo DB and Java developers, I definitely have very good connections. I will
        follow up soon.
       
        Thanks,
        John

        On Thu, May 21, 2015 at 5:56 PM, Pankaj Shroff <shroffg@gmail.com> wrote:
       
            Thanks John I will reach out to him directly. Also do you know any good tech leads who
            are expert or well experienced in Mongo DB and also good Java developers? Hadoop or Map
            reduce experience would be a plus.
           
            Pankaj

            On May 21, 2015, at 10:08 AM, John Xu <jianjohnxu@gmail.com> wrote:

                Attached his resume. 
                Let me know your thoughts...
               
                Thx!

                On Thu, May 21, 2015 at 1:01 PM, Pankaj Shroff <shroffg@gmail.com> wrote:
               
                    Yes we are looking can you make the intro
                    thx
                    Pankaj

                    On May 21, 2015, at 8:48 AM, John Xu <jianjohnxu@gmail.com> wrote:

                        Hi Pankaj,
                       
                        It looks like you are very busy after NAB? How thing going?
                        I know an engineer/architecture who is really excellent in AWS cloud
                        optimization, container computing (such as Docker), and MongoDB, etc. He is
                        certified AWS solution architect and Chef developer too. 
                       
                        If you are still looking for someone to optimize AWS cost, please let me
                        know.
                       
                        Thanks,
                        John

                <denny_devops.pdf>

--
Pankaj Shroff
shroffG@Gmail.com

#+end_example
* #  --8<-------------------------- separator ------------------------>8--
* TODO [Brandon & Jay] How to deal with this email?
** TODO mail: Re: Denny's billing hours                            :noexport:
[[gnus:p0-colleague#14e3f8c6518.101bfd5c9324213.6513977729521818541@oscgc.com][Email from david chen (Mon, 29 Jun 2015 06:40:42 -0700): Re: Denny's billing hours]]
#+begin_example
From: "david.chen" <david.chen@oscgc.com>
Subject: Re: Denny's billing hours
To: Denny Zhang <filebat.mark@gmail.com>
Date: Mon, 29 Jun 2015 08:40:42 -0500
User-Agent: Zoho Mail
X-Mailer: Zoho Mail
X-Priority: Medium

Denny,
It was January time sheet.

David
Controller      
OSC Technologies LLC
888 Washington St, Ste 301, Dedham, MA 02026

---- On Mon, 29 Jun 2015 06:38:36 -0700 Denny Zhang<filebat.mark@gmail.com> wrote ----

    Hey David
   
    Enclosed is my billing hours for this June.
   
    Another thing: have you got my last month paycheck approved and mailed? Thanks.
   
    --
    Denny Zhang(张巍)
    Email: filebat.mark@gmail.com
    Website: http://www.dennyzhang.com/
   
    Live your life to the fullest
   
    /\ /\
    ( )
    .( o ).

#+end_example
* TODO communication
** TODO mail: RE: Denny have to skip daily standup from Jul 6th    :noexport:
[[gnus:myself#EF9859611DA81140B2B29B02EC8AD6EA28F1D6FB@helios.mex01.local][Email from Denny Zhang (Mon, 29 Jun 2015 11:42:22 -0500): RE: Denny have to skip daily s]]
#+begin_example
From: Denny Zhang <denny.zhang@totvs.com>
Subject: RE: Denny have to skip daily standup from Jul 6th
To: Kung Wang <kung.wang@totvs.com>
CC: Vicente Goetten <goetten@totvs.com>, John Kaplan <john.kaplan@totvs.com>,
        Don Hu <don.hu@totvs.com>, Denny Zhang <denny.zhang@totvs.com>
Date: Mon, 29 Jun 2015 11:42:22 -0500

Kung

Sounds great! Thanks for offering this plan to help.
It will be the best for me to perform this routine meeting after 6 PM PDT.

In case of emergencies such as service outage or blocking issues,
I'm happy to hold extra meetings at 4 PM PDT, even though it will be
very early morning on my side.

So how about?
1. Every Tuesday 6 PM - 6:15 PM PDT
2. Every Thursday 6 PM - 6:15 PM PDT
3. On-demand after 4 PM

Regards,
Denny
-- 
Denny Zhang(张巍)

The questions you ask determine the quality of your life.

╮(╯_╰)╭

---------------------------------------------------------------------------------------------------
From: Kung Wang
Sent: Monday, June 29, 2015 11:22 AM
To: Denny Zhang
Cc: Vicente Goetten; John Kaplan; Don Hu
Subject: Re: Denny have to skip daily standup from Jul 6th

Denny,

This is ok, but usually what I did before is having a one-on-one stand-up on another time with you,
and I will be reporting your status on behave of you on our stand-up meeting. And, it’s better for
us to do this 2-3 times a week to keep you update on our status here as well. Will you be ok for
this? If ok, please send me best time for you as well, so we can start this next week.

—Kung

    On Jun 28, 2015, at 4:25 PM, Denny Zhang <denny.zhang@totvs.com> wrote:
   
    CC John about Denny's change of daily standup.
   
    Regards,
    Denny
    -----------------------------------------------------------------------------------------------
    From: Denny Zhang
    Sent: Thursday, June 25, 2015 10:42 AM
    To: Vicente Goetten; Kung Wang
    Cc: Don Hu; Denny Zhang
    Subject: Denny have to skip daily standup from Jul 6th
   
    Morning Vicente & Kung
   
    Due to some personal reasons, I will have to stay mostly in China during the incoming year.
    So I'll have to miss our team's daily standup since Jul 6th, because of the timing.
   
    On the bright side:
    1. When I were in China, we can have concall after 4 pm PDT, if you're interested.
    2. We can support prod env better even off US office operation hours.
    3. I will keep updating my status to wiki daily since then.
        https://totvslab.atlassian.net/wiki/display/~Denny/Denny%27s+Status+Update
   
    What do you think?
   
    Thanks,
    Denny

#+end_example
* TODO Low Communication with passionte developer
#+BEGIN_EXAMPLE
[6/30/15, 9:00:12 AM] denny: Can you update the wiki?
[6/30/15, 9:00:19 AM] denny: Then I can start from there.
[6/30/15, 9:02:35 AM] denny: About the Makefile, there are 2 suggestions.
[6/30/15, 9:03:20 AM] chenxue: 稍等，在和john讨论问题
[6/30/15, 9:03:28 AM] denny: ok
[6/30/15, 10:09:51 AM] chenxue: On 6/30/15, at 9:00 AM, denny wrote:
> https://authright.atlassian.net/wiki/display/DEV/FIDO
updated
[6/30/15, 10:10:52 AM] denny: nice.

“make install” is actually confusing, compared to “make compile” or “make
[6/30/15, 10:11:43 AM] chenxue: 调用的命名就是mvn install，make install有什么问题？
[6/30/15, 10:11:50 AM] chenxue: 要不叫make mvnInstall
[6/30/15, 10:12:26 AM] chenxue: 或者 make build
[6/30/15, 10:12:26 AM] denny: 我们是做代码编译。 在所有GNUS软件中，都是用”make”或”make compile”。
[6/30/15, 10:12:39 AM] chenxue: 问题是我这个不只是代码编译
[6/30/15, 10:12:54 AM] denny: 哦？
[6/30/15, 10:13:08 AM] chenxue: 如果只是编译那我调用的mvn命令应该是mvn compile
[6/30/15, 10:13:38 AM] chenxue: 我这个是install到mvn repo，后面的rp server才能启动
[6/30/15, 10:13:39 AM] denny: 我们现在需要一个命令：从源代码生成war或jar文件。
[6/30/15, 10:14:06 AM] chenxue: 明白了
[6/30/15, 10:14:10 AM] chenxue: 我重新写一份
[6/30/15, 10:14:15 AM] denny: 编译的机器和程序运行的机器，在我们这里不是同一台机器。
[6/30/15, 10:14:43 AM] denny: Another point:

When we run “make install”, it will enforce “git pull”.
People may want to test against a specific revision, instead of HEAD, which may have regression issue.
[6/30/15, 10:16:18 AM] chenxue: https://authright.atlassian.net/wiki/display/DEV/FIDO

updated
[6/30/15, 10:16:19 AM] denny: Furthermore people may want to test against different branch, instead of current branch.

So I’d suggest provide a makefile instructive which doesn’t enforce “git pull” by default.
[6/30/15, 10:17:22 AM] denny: Image
[6/30/15, 10:17:22 AM] denny: Like this?
[6/30/15, 10:17:44 AM] chenxue: On 6/30/15, at 10:16 AM, dz wrote:
> https://authright.atlassian.net/wiki/display/DEV/FIDO

updated

[6/30/15, 10:18:05 AM] denny: That’s what I see in above page.
[6/30/15, 10:19:16 AM] denny: Why don’t we wrap that in makefile?

Thus we don’t need to communicate about this again, like change build commands, switch mvn to gradle etc.
#+END_EXAMPLE
* #  --8<-------------------------- separator ------------------------>8--
* TODO [#A] Chef deployment failure                               :IMPORTANT:
** TODO Jenkins-auth: install gradle fail
#+BEGIN_EXAMPLE
       Processing triggers for initramfs-tools (0.103ubuntu4.2) ...
       STDERR: Extracting templates from packages: 8%
Extracting templates from packages: 16%
Extracting templates from packages: 25%
Extracting templates from packages: 33%
Extracting templates from packages: 41%
Extracting templates from packages: 50%
Extracting templates from packages: 58%
Extracting templates from packages: 66%
Extracting templates from packages: 75%
Extracting templates from packages: 83%
Extracting templates from packages: 91%
Extracting templates from packages: 100%
       ---- End output of apt-get -q -y install gradle=1.4-2ubuntu1 ----
       Ran apt-get -q -y install gradle=1.4-2ubuntu1 returned 
       [2015-06-30T21:46:15+00:00] FATAL: Chef::Exceptions::ChildConvergeError: Chef run process exited unsuccessfully (exit code 1)
>>>>>> Converge failed on instance <default-ubuntu-1404>.
>>>>>> Please see .kitchen/logs/default-ubuntu-1404.log for more details
>>>>>> ------Exception-------
>>>>>> Class: Kitchen::ActionFailed
>>>>>> Message: SSH exited (1) for command: [sh -c '

sudo -E /opt/chef/bin/chef-client --local-mode --config /tmp/kitchen/client.rb --log_level auto --force-formatter --no-color --json-attributes /tmp/kitchen/dna.json --chef-zero-port 8889
']
>>>>>> ----------------------
+ failed_cookbooks=' jenkins-auth'
+ '[' ' jenkins-auth' '!=' '' ']'
+ echo -ne '\n\n=========== Failed cookbooks:  jenkins-auth ============='
#+END_EXAMPLE
** TODO totvs sandbox update failure
[7/1/15, 10:33:42 AM] kungchaowang: got this error when doing sanboxupdate:

[2015-07-01T15:16:15+00:00] ERROR: remote_file[/usr/lib/nagios/plugins/check_proc_mem.sh] (nagios3::nagios_client line 127) had an error: OpenSSL::SSL::SSLError: hostname "raw.githubusercontent.com" does not match the server certificate
[2015-07-01T15:16:15+00:00] FATAL: Chef::Exceptions::ChildConvergeError: Chef run process exited unsuccessfully (exit code 1)
Build step 'Execute shell' marked build as failure
Finished: FAILURE
[7/1/15, 10:34:08 AM] kungchaowang: I have to drop off the net now, ttyl
[7/1/15, 10:34:20 AM] denny: np, safe drive
** TODO fido-auth: nagios error
http://50.198.76.249:443/view/All/job/KitchenDockerTestAllCookbooks/101/console
#+BEGIN_EXAMPLE
      
       Preparing to unpack .../samba-common_2%3a4.1.6+dfsg-1ubuntu2.14.04.7_all.deb ...
       Unpacking samba-common (2:4.1.6+dfsg-1ubuntu2.14.04.7) ...
       Selecting previously unselected package samba-libs:amd64.
       
       
       Selecting previously unselected package libsmbclient:amd64.
       Preparing to unpack .../libsmbclient_2%3a4.1.6+dfsg-1ubuntu2.14.04.7_amd64.deb ...
       Unpacking libsmbclient:amd64 (2:4.1.6+dfsg-1ubuntu2.14.04.7) ...
       
       Preparing to unpack .../smbclient_2%3a4.1.6+dfsg-1ubuntu2.14.04.7_amd64.deb ...
       Unpacking smbclient (2:4.1.6+dfsg-1ubuntu2.14.04.7) ...
       Selecting previously unselected package libtirpc1:amd64.
       Preparing to unpack .../libtirpc1_0.2.2-5ubuntu2_amd64.deb ...
       
       Selecting previously unselected package nagios-plugins-common.
       Preparing to unpack .../nagios-plugins-common_1.5-3ubuntu1_amd64.deb ...
       Unpacking nagios-plugins-common (1.5-3ubuntu1) ...
       
       Selecting previously unselected package nagios-plugins-basic.
       (Reading database ... 43873 files and directories currently installed.)
       Preparing to unpack .../nagios-plugins-basic_1.5-3ubuntu1_amd64.deb ...
       Unpacking nagios-plugins-basic (1.5-3ubuntu1) ...
       Selecting previously unselected package libisc95.
       Preparing to unpack .../libisc95_1%3a9.9.5.dfsg-3ubuntu0.2_amd64.deb ...
       Unpacking libisc95 (1:9.9.5.dfsg-3ubuntu0.2) ...
       STDERR: Extracting templates from packages: 40%
Extracting templates from packages: 80%
Extracting templates from packages: 100%
       ---- End output of apt-get -q -y install nagios3=3.5.1-1ubuntu1 ----
       Ran apt-get -q -y install nagios3=3.5.1-1ubuntu1 returned 
       [2015-07-01T20:34:54+00:00] FATAL: Chef::Exceptions::ChildConvergeError: Chef run process exited unsuccessfully (exit code 1)
>>>>>> Converge failed on instance <default-ubuntu-1404>.
>>>>>> Please see .kitchen/logs/default-ubuntu-1404.log for more details
>>>>>> ------Exception-------
>>>>>> Class: Kitchen::ActionFailed
>>>>>> Message: SSH exited (1) for command: [env http_proxy=http://172.17.42.1:3128 https_proxy=https://172.17.42.1:3128 sh -c '
http_proxy="http://172.17.42.1:3128"; export http_proxy
HTTP_PROXY="http://172.17.42.1:3128"; export HTTP_PROXY
https_proxy="https://172.17.42.1:3128"; export https_proxy
HTTPS_PROXY="https://172.17.42.1:3128"; export HTTPS_PROXY
sudo -E /opt/chef/bin/chef-client --local-mode --config /tmp/kitchen/client.rb --log_level auto --force-formatter --no-color --json-attributes /tmp/kitchen/dna.json --chef-zero-port 8889
']
>>>>>> ----------------------
+ failed_cookbooks=' fido-auth'
+ '[' ' fido-auth' '!=' '' ']'
+ echo -ne '\n\n=========== Failed cookbooks:  fido-auth ============='


=========== Failed cookbooks:  fido-auth =============+ exit 1
Build step 'Execute shell' marked build as failure
Sending e-mails to: denny.zhang001@gmail.com
Finished: FAILURE
#+END_EXAMPLE
** TODO jenkins-auth cookbook error: http proxy doesn't recognize no_proxy
#+BEGIN_EXAMPLE

       - suppressed sensitive resource

           * remote_file[/tmp/kitchen/cache/scm-api-0.2.plugin] action create
       - create new file /tmp/kitchen/cache/scm-api-0.2.plugin
       - update content in file /tmp/kitchen/cache/scm-api-0.2.plugin from none to cc856d

           * remote_file[/tmp/kitchen/cache/jenkins-cli.jar] action create[2015-06-19T19:36:41+00:00] WARN: remote_file[/tmp/kitchen/cache/jenkins-cli.jar] cannot be downloaded from http://localhost:18080/jnlpJars/jenkins-cli.jar: 503 "Service Unavailable"


       ================================================================================
             Error executing action `create` on resource 'remote_file[/tmp/kitchen/cache/jenkins-cli.jar]'
             ================================================================================

             Net::HTTPFatalError
             -------------------
             503 "Service Unavailable"

             Cookbook Trace:
             ---------------
             /tmp/kitchen/cache/cookbooks/jenkins/libraries/_helper.rb:375:in `ensure_cli_present!'
             /tmp/kitchen/cache/cookbooks/jenkins/libraries/_helper.rb:62:in `executor'
             /tmp/kitchen/cache/cookbooks/jenkins/libraries/plugin.rb:309:in `install_plugin_from_url'
             /tmp/kitchen/cache/cookbooks/jenkins/libraries/plugin.rb:281:in `install_plugin_from_update_center'
             /tmp/kitchen/cache/cookbooks/jenkins/libraries/plugin.rb:272:in `block in install_plugin_from_update_center'
             /tmp/kitchen/cache/cookbooks/jenkins/libraries/plugin.rb:265:in `each'
             /tmp/kitchen/cache/cookbooks/jenkins/libraries/plugin.rb:265:in `install_plugin_from_update_center'
             /tmp/kitchen/cache/cookbooks/jenkins/libraries/plugin.rb:123:in `block (2 levels) in <class:JenkinsPlugin>'
             /tmp/kitchen/cache/cookbooks/jenkins/libraries/plugin.rb:155:in `block in <class:JenkinsPlugin>'

             Compiled Resource:
             ------------------
             # Declared in

             remote_file("/tmp/kitchen/cache/jenkins-cli.jar") do
        provider Chef::Provider::RemoteFile
        action "create"
        retries 0
        retry_delay 2
        default_guard_interpreter :default
        path "/tmp/kitchen/cache/jenkins-cli.jar"
        atomic_update true
        source ["http://localhost:18080/jnlpJars/jenkins-cli.jar"]
        use_etag true
        use_last_modified true
        mode "0755"
             end


           ================================================================================
           Error executing action `install` on resource 'jenkins_plugin[git]'
           ================================================================================

           Net::HTTPFatalError
           -------------------
           remote_file[/tmp/kitchen/cache/jenkins-cli.jar] (dynamically defined) had an error: Net::HTTPFatalError: 503 "Service Unavailable"

           Cookbook Trace:
           ---------------
           /tmp/kitchen/cache/cookbooks/jenkins/libraries/_helper.rb:375:in `ensure_cli_present!'
           /tmp/kitchen/cache/cookbooks/jenkins/libraries/_helper.rb:62:in `executor'
           /tmp/kitchen/cache/cookbooks/jenkins/libraries/plugin.rb:309:in `install_plugin_from_url'
           /tmp/kitchen/cache/cookbooks/jenkins/libraries/plugin.rb:281:in `install_plugin_from_update_center'
           /tmp/kitchen/cache/cookbooks/jenkins/libraries/plugin.rb:272:in `block in install_plugin_from_update_center'
           /tmp/kitchen/cache/cookbooks/jenkins/libraries/plugin.rb:265:in `each'
           /tmp/kitchen/cache/cookbooks/jenkins/libraries/plugin.rb:265:in `install_plugin_from_update_center'
           /tmp/kitchen/cache/cookbooks/jenkins/libraries/plugin.rb:123:in `block (2 levels) in <class:JenkinsPlugin>'
           /tmp/kitchen/cache/cookbooks/jenkins/libraries/plugin.rb:155:in `block in <class:JenkinsPlugin>'

           Resource Declaration:
           ---------------------
           # In /tmp/kitchen/cache/cookbooks/jenkins-auth/recipes/conf_jenkins.rb

            66: jenkins_plugin 'git' do
            67:   version '2.3.5'
            68: end
            69:

           Compiled Resource:
           ------------------
           # Declared in /tmp/kitchen/cache/cookbooks/jenkins-auth/recipes/conf_jenkins.rb:66:in `from_file'

           jenkins_plugin("git") do
             action :install
             retries 0
             retry_delay 2
             default_guard_interpreter :default
             declared_type :jenkins_plugin
             cookbook_name "jenkins-auth"
             recipe_name "conf_jenkins"
             version "2.3.5"
         install_deps true
           end


       Running handlers:
       [2015-06-19T19:36:41+00:00] ERROR: Running exception handlers
       Running handlers complete
       [2015-06-19T19:36:41+00:00] ERROR: Exception handlers complete
       [2015-06-19T19:36:41+00:00] FATAL: Stacktrace dumped to /tmp/kitchen/cache/chef-stacktrace.out
       Chef Client failed. 90 resources updated in 757.178075384 seconds
       [2015-06-19T19:36:41+00:00] ERROR: jenkins_plugin[git] (jenkins-auth::conf_jenkins line 66) had an error: Net::HTTPFatalError: remote_file[/tmp/kitchen/cache/jenkins-cli.jar] (dynamically defined) had an error: Net::HTTPFatalError: 503 "Service Unavailable"
       [2015-06-19T19:36:41+00:00] FATAL: Chef::Exceptions::ChildConvergeError: Chef run process exited unsuccessfully (exit code 1)
>>>>>> Converge failed on instance <default-ubuntu-1404>.
>>>>>> Please see .kitchen/logs/default-ubuntu-1404.log for more details
>>>>>> ------Exception-------
>>>>>> Class: Kitchen::ActionFailed
>>>>>> Message: SSH exited (1) for command: [env http_proxy=http://10.165.4.67:3128 https_proxy=https://10.165.4.67:3128 sh -c '
http_proxy="http://10.165.4.67:3128"; export http_proxy
HTTP_PROXY="http://10.165.4.67:3128"; export HTTP_PROXY
https_proxy="https://10.165.4.67:3128"; export https_proxy
HTTPS_PROXY="https://10.165.4.67:3128"; export HTTPS_PROXY
sudo -E /opt/chef/bin/chef-client --local-mode --config /tmp/kitchen/client.rb --log_level auto --force-formatter --no-color --json-attributes /tmp/kitchen/dna.json --chef-zero-port 8889
']
>>>>>> ----------------------
MacPro:jenkins-auth mac$
#+END_EXAMPLE
** TODO mail: Build failed in Jenkins: KitchenDockerTestAllCookbooks #291 :noexport:
[[gnus:myself#1832087569.2.1435379676249.JavaMail.jenkins@4840a264a7f8][Email from denny zhang (Sat, 27 Jun 2015 04:34:36 +0000 (UTC)): Build failed in Jenkins: Kitch]]
#+begin_example
From: denny.zhang@totvs.com
Subject: Build failed in Jenkins: KitchenDockerTestAllCookbooks #291
To: denny.zhang001@gmail.com
Date: Fri, 26 Jun 2015 23:34:36 -0500
Reply-To: support@fluigdata.com

See <http://10.165.4.67:48080/job/KitchenDockerTestAllCookbooks/291/>

------------------------------------------
[...truncated 19383 lines...]
+ ssh root@172.17.42.1 mkdir -p /data/docker/nagios-mdm_jenkins/couchbase
+ ssh root@172.17.42.1 chmod 777 /data/docker/nagios-mdm_jenkins/couchbase
+ kitchen_yml=.kitchen.docker_jenkins.yml
+ instance_name=nagios-mdm-jenkins
+ cp .kitchen.docker.yml .kitchen.docker_jenkins.yml
+ sed -i 's/instance_name: .*/instance_name: nagios-mdm-jenkins/g' .kitchen.docker_jenkins.yml
+ command='KITCHEN_YAML=.kitchen.docker_jenkins.yml kitchen create'
+ echo KITCHEN_YAML=.kitchen.docker_jenkins.yml kitchen create
KITCHEN_YAML=.kitchen.docker_jenkins.yml kitchen create
+ eval KITCHEN_YAML=.kitchen.docker_jenkins.yml kitchen create
++ KITCHEN_YAML=.kitchen.docker_jenkins.yml
++ kitchen create
-----> Starting Kitchen (v1.4.1)
-----> Creating <default-ubuntu-1404>...
       Sending build context to Docker daemon  2.56 kB
       Sending build context to Docker daemon
       Step 0 : FROM totvslabs/kitchendocker:v2
        ---> a27b6c2ba01f
       Step 1 : RUN dpkg-divert --local --rename --add /sbin/initctl
        ---> Using cache
        ---> c683dfb31d7a
       Step 2 : RUN ln -sf /bin/true /sbin/initctl
        ---> Using cache
        ---> 19da578c3706
       Step 3 : ENV DEBIAN_FRONTEND noninteractive
        ---> Using cache
        ---> 30779012db8f
       Step 4 : RUN apt-get update
        ---> Using cache
        ---> b294a1182a65
       Step 5 : RUN apt-get install -y sudo openssh-server curl lsb-release
        ---> Using cache
        ---> 74befa4ad4f0
       Step 6 : RUN if ! getent passwd kitchen; then useradd -d /home/kitchen -m -s /bin/bash kitchen; fi
        ---> Using cache
        ---> b2a3746d56aa
       Step 7 : RUN echo kitchen:kitchen | chpasswd
        ---> Using cache
        ---> ab82e92a5f86
       Step 8 : RUN echo 'kitchen ALL=(ALL) NOPASSWD:ALL' >> /etc/sudoers
        ---> Using cache
        ---> a6521327369f
       Step 9 : RUN mkdir -p /etc/sudoers.d
        ---> Using cache
        ---> 93b4346e73b9
       Step 10 : RUN echo 'kitchen ALL=(ALL) NOPASSWD:ALL' >> /etc/sudoers.d/kitchen
        ---> Using cache
        ---> 8983ea84f0b2
       Step 11 : RUN chmod 0440 /etc/sudoers.d/kitchen
        ---> Using cache
        ---> 60cc3fdd024d
       Step 12 : RUN curl -L https://raw.githubusercontent.com/DennyZhang/data/master/denny_chef_provision.sh | bash -e
        ---> Using cache
        ---> 9cbcd9de3788
       Successfully built 9cbcd9de3788
       d2b84b3fcb909467ae4ca195a9f19d8e64af4e1808eade02eac93639a2244328
       0.0.0.0:32801
       bash: warning: setlocale: LC_ALL: cannot change locale (en_US.utf8)
       [SSH] Established
       Finished creating <default-ubuntu-1404> (0m1.08s).
-----> Kitchen is finished. (0m1.69s)
+ command='KITCHEN_YAML=.kitchen.docker_jenkins.yml kitchen converge'
+ echo KITCHEN_YAML=.kitchen.docker_jenkins.yml kitchen converge
KITCHEN_YAML=.kitchen.docker_jenkins.yml kitchen converge
+ eval KITCHEN_YAML=.kitchen.docker_jenkins.yml kitchen converge
++ KITCHEN_YAML=.kitchen.docker_jenkins.yml
++ kitchen converge
-----> Starting Kitchen (v1.4.1)
-----> Converging <default-ubuntu-1404>...
$$$$$$ Running legacy converge for 'Docker' Driver
       Preparing files for transfer
       Preparing dna.json
       Resolving cookbook dependencies with Berkshelf 3.2.4...
       Removing non-cookbook files before transfer
       Preparing validation.pem
       Preparing client.rb
       bash: warning: setlocale: LC_ALL: cannot change locale (en_US.utf8)
-----> Chef Omnibus installation detected (install only if missing)
       bash: warning: setlocale: LC_ALL: cannot change locale (en_US.utf8)
       Transferring files to <default-ubuntu-1404>
>>>>>> ------Exception-------
>>>>>> Class: Kitchen::ActionFailed
>>>>>> Message: Failed to complete #converge action: [scp:
>>>>>> /tmp/kitchen/cookbooks/linux-basic/recipes/system.rb: No such
>>>>>> file or directory
]
>>>>>> ----------------------
>>>>>> Please see .kitchen/logs/kitchen.log for more details
>>>>>> Also try running `kitchen diagnose --all` for configuration
+ echo all-in-one jenkins-mdm
+ grep nagios-mdm
+ failed_cookbooks=' all-in-one jenkins-mdm nagios-mdm'
+ command='KITCHEN_YAML=.kitchen.docker_jenkins.yml kitchen verify'
+ echo KITCHEN_YAML=.kitchen.docker_jenkins.yml kitchen verify
KITCHEN_YAML=.kitchen.docker_jenkins.yml kitchen verify
+ eval KITCHEN_YAML=.kitchen.docker_jenkins.yml kitchen verify
++ KITCHEN_YAML=.kitchen.docker_jenkins.yml
++ kitchen verify
-----> Starting Kitchen (v1.4.1)
-----> Converging <default-ubuntu-1404>...
$$$$$$ Running legacy converge for 'Docker' Driver
       Preparing files for transfer
       Preparing dna.json
       Resolving cookbook dependencies with Berkshelf 3.2.4...
       Removing non-cookbook files before transfer
       Preparing validation.pem
       Preparing client.rb
       bash: warning: setlocale: LC_ALL: cannot change locale (en_US.utf8)
-----> Chef Omnibus installation detected (install only if missing)
       bash: warning: setlocale: LC_ALL: cannot change locale (en_US.utf8)
       Transferring files to <default-ubuntu-1404>
>>>>>> ------Exception-------
>>>>>> Class: Kitchen::ActionFailed
>>>>>> Message: Failed to complete #converge action: [scp:
>>>>>> /tmp/kitchen/cookbooks/nagios-mdm/recipes/server_checks.rb: No
>>>>>> such file or directory
]
>>>>>> ----------------------
>>>>>> Please see .kitchen/logs/kitchen.log for more details
>>>>>> Also try running `kitchen diagnose --all` for configuration
+ echo all-in-one jenkins-mdm nagios-mdm
+ grep nagios-mdm
all-in-one jenkins-mdm nagios-mdm
+ command='KITCHEN_YAML=.kitchen.docker_jenkins.yml kitchen destroy || KITCHEN_YAML=.kitchen.docker_jenkins.yml kitchen destroy'
+ echo KITCHEN_YAML=.kitchen.docker_jenkins.yml kitchen destroy '||' KITCHEN_YAML=.kitchen.docker_jenkins.yml kitchen destroy
KITCHEN_YAML=.kitchen.docker_jenkins.yml kitchen destroy || KITCHEN_YAML=.kitchen.docker_jenkins.yml kitchen destroy
+ eval KITCHEN_YAML=.kitchen.docker_jenkins.yml kitchen destroy '||' KITCHEN_YAML=.kitchen.docker_jenkins.yml kitchen destroy
++ KITCHEN_YAML=.kitchen.docker_jenkins.yml
++ kitchen destroy
-----> Starting Kitchen (v1.4.1)
-----> Destroying <default-ubuntu-1404>...
       UID                 PID                 PPID                C                   STIME               TTY                 TIME                CMD
       root                8155                14113               0                   21:34               ?                   00:00:00            /usr/sbin/sshd -D -o UseDNS=no -o UsePAM=no -o PasswordAuthentication=yes -o UsePrivilegeSeparation=no -o PidFile=/tmp/sshd.pid
       root                8534                8155                2                   21:34               ?                   00:00:00            sshd: kitchen@notty
                   00:00:00            scp -t -r /tmp/kitchen
       d2b84b3fcb909467ae4ca195a9f19d8e64af4e1808eade02eac93639a2244328
       d2b84b3fcb909467ae4ca195a9f19d8e64af4e1808eade02eac93639a2244328
       Finished destroying <default-ubuntu-1404> (0m0.82s).
-----> Kitchen is finished. (0m1.41s)
+ for cookbook in '$cookbooks'
+ '[' os-basic = couchbase ']'
+ cd /var/lib/jenkins/code/docker/denny/mdmdevops/cookbooks/os-basic
+ echo -ne '\n\n=========== TEST os-basic ============='

=========== TEST os-basic =============+ rm -rf Berksfile.lock
+ command='bundle install'
+ echo bundle install
bundle install
+ bundle install
Using rake 10.4.2
Using addressable 2.3.8
Using ast 2.0.0
Using parser 2.2.2.5
Using astrolabe 1.3.0
Using multipart-post 2.0.0
Using faraday 0.9.1
Using berkshelf-api-client 1.2.1
Using buff-extensions 1.0.0
Using hashie 2.1.2
Using varia_model 0.4.0
Using buff-config 1.0.1
Using buff-ruby_engine 0.1.0
Using buff-shell_out 0.2.0
Using hitimes 1.2.2
Using timers 4.0.1
Using celluloid 0.16.0
Using nio4r 1.1.0
Using celluloid-io 0.16.2
Using cleanroom 1.0.0
Using minitar 0.5.4
Using sawyer 0.6.0
Using octokit 3.8.0
Using retryable 2.0.1
Using buff-ignore 1.1.1
Using erubis 2.7.0
Using json 1.8.3
Using mixlib-log 1.6.0
Using mixlib-authentication 1.3.0
Using net-http-persistent 2.9.4
Using semverse 1.2.1
Using ridley 4.2.0
Using dep-selector-libgecode 1.0.2
Using ffi 1.9.8
Using dep_selector 1.0.3
Using solve 1.2.1
Using thor 0.19.0
Using berkshelf 3.2.4
Using builder 3.2.2
Using busser 0.7.1
Using libyajl2 1.2.0
Using ffi-yajl 2.2.0
Using rack 1.6.1
Using uuidtools 2.1.5
Using chef-zero 4.2.2
Using diff-lcs 1.2.5
Using highline 1.7.2
Using mixlib-cli 1.5.0
Using mixlib-config 2.2.1
Using mixlib-shellout 2.1.0
Using net-ssh 2.9.2
Using net-ssh-gateway 1.2.0
Using net-ssh-multi 1.2.1
Using ipaddress 0.8.0
Using mime-types 2.6.1
Using systemu 2.6.5
Using wmi-lite 1.0.0
Using ohai 8.4.0
Using plist 3.1.0
Using coderay 1.1.0
Using method_source 0.8.2
Using slop 3.6.0
Using pry 0.10.1
Using rspec-support 3.3.0
Using rspec-core 3.3.0
Using rspec-expectations 3.3.0
Using rspec-mocks 3.3.0
Using rspec_junit_formatter 0.2.3
Using multi_json 1.11.1
Using rspec 3.3.0
Using rspec-its 1.2.0
Using net-scp 1.2.1
Using specinfra 2.35.1
Using serverspec 2.18.0
Using chef 12.3.0
Using fauxhai 2.3.0
Using chefspec 4.1.1
Using docker 0.0.1
Using gherkin 2.12.2
Using mini_portile 0.6.2
Using nokogiri 1.6.6.2
Using rufus-lru 1.0.5
Using polyglot 0.3.5
Using treetop 1.6.2
Using yajl-ruby 1.2.1
Using foodcritic 4.0.0
Using safe_yaml 1.0.4
Using test-kitchen 1.4.0
Using kitchen-docker 2.1.0
Using powerpack 0.0.9
Using rainbow 2.0.0
Using ruby-progressbar 1.7.5
Using rubocop 0.28.0
Using bundler 1.9.8
Bundle complete! 9 Gemfile dependencies, 94 gems now installed.
Use `bundle show [gemname]` to see where a bundled gem is installed.
+ export DOCKER_VOLUME=/data/docker/os-basic_jenkins/couchbase
+ DOCKER_VOLUME=/data/docker/os-basic_jenkins/couchbase
+ ssh root@172.17.42.1 rm -rf /data/docker/os-basic_jenkins/couchbase
+ ssh root@172.17.42.1 mkdir -p /data/docker/os-basic_jenkins/couchbase
+ ssh root@172.17.42.1 chmod 777 /data/docker/os-basic_jenkins/couchbase
chmod: cannot access `/data/docker/os-basic_jenkins/couchbase': No such file or directory
Build step 'Execute shell' marked build as failure
#+end_example
** TODO elasticsearch-auth fail: download jce fail
http://50.198.76.249:443/job/KitchenDockerTestAllCookbooks/59/consoleFull
#+BEGIN_EXAMPLE

           - Add alternative for xjc
       Recipe: java::default_java_symlink
         * link[/usr/lib/jvm/default-java] action create
           - create symlink at /usr/lib/jvm/default-java to /usr/lib/jvm/java-8-oracle-amd64
       Recipe: java::oracle_jce
         * apt_package[unzip] action install
       - install version 6.0-9ubuntu1.3 of package unzip
         * apt_package[curl] action install (up to date)
         * directory[/opt/java_jce/8] action create


         * execute[download jce] action run

           ================================================================================
           Error executing action `run` on resource 'execute[download jce]'
       ================================================================================

           Mixlib::ShellOut::ShellCommandFailed
       ------------------------------------
           Expected process to exit with [0], but received '1'
       ---- Begin output of     rm -rf /tmp/kitchen/cache/java_jce
        mkdir -p /tmp/kitchen/cache/java_jce
        cd /tmp/kitchen/cache/java_jce

           curl -L --cookie 'oraclelicense=accept-securebackup-cookie;gpw_e24=http://edelivery.oracle.com' -o jce.zip http://download.oracle.com/otn-pub/java/jce/8/jce_policy-8.zip
        # fail the resource if the checksum does not match
        # this should only happen if oracle download terms are not accepted and downloading directly from oracle
        echo "f3020a3922efd6626c2fff45695d527f34a8020e938a49292561f18ad1320b59  jce.zip" | sha256sum -c >/dev/null

           STDOUT:
           STDERR: % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                     Dload  Upload   Total   Spent    Left  Speed

  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0

  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0

100  4569  100  4569    0     0   5905      0 --:--:-- --:--:-- --:--:--  5905
           sha256sum: WARNING: 1 computed checksum did NOT match
           ---- End output of     rm -rf /tmp/kitchen/cache/java_jce
        mkdir -p /tmp/kitchen/cache/java_jce
        cd /tmp/kitchen/cache/java_jce

        curl -L --cookie 'oraclelicense=accept-securebackup-cookie;gpw_e24=http://edelivery.oracle.com' -o jce.zip http://download.oracle.com/otn-pub/java/jce/8/jce_policy-8.zip
        # fail the resource if the checksum does not match
        # this should only happen if oracle download terms are not accepted and downloading directly from oracle
        echo "f3020a3922efd6626c2fff45695d527f34a8020e938a49292561f18ad1320b59  jce.zip" | sha256sum -c >/dev/null
            ----
           Ran     rm -rf /tmp/kitchen/cache/java_jce
           mkdir -p /tmp/kitchen/cache/java_jce
        cd /tmp/kitchen/cache/java_jce

        curl -L --cookie 'oraclelicense=accept-securebackup-cookie;gpw_e24=http://edelivery.oracle.com' -o jce.zip http://download.oracle.com/otn-pub/java/jce/8/jce_policy-8.zip
        # fail the resource if the checksum does not match
        # this should only happen if oracle download terms are not accepted and downloading directly from oracle
        echo "f3020a3922efd6626c2fff45695d527f34a8020e938a49292561f18ad1320b59  jce.zip" | sha256sum -c >/dev/null


           Resource Declaration:
           ---------------------
           # In /tmp/kitchen/cache/cookbooks/java/recipes/oracle_jce.rb

            41: execute 'download jce' do
        42:   command <<-EOF
            43:     rm -rf #{Chef::Config[:file_cache_path]}/java_jce
            44:     mkdir -p #{Chef::Config[:file_cache_path]}/java_jce
        45:     cd #{Chef::Config[:file_cache_path]}/java_jce
            46:
            47:     curl -L --cookie '#{jce_cookie}' -o jce.zip #{jce_url}

            49:     # this should only happen if oracle download terms are not accepted and downloading directly from oracle
            50:     echo "#{jce_checksum}  jce.zip" | #{checksum_bin} -c >/dev/null
        51:   EOF
            52:   # if jar is already in the right location then don't need to download the JCE again
        53:   not_if { ::File.exist?( ::File.join(node['java']['oracle']['jce']['home'], jdk_version,'US_export_policy.jar') ) }
            54: end
            55:
            56: execute 'extract jce' do
            57:   command <<-EOF
            58:     unzip -o jce.zip
            59:     find -name '*.jar' | xargs -I JCE_JAR mv JCE_JAR #{node['java']['oracle']['jce']['home']}/#{jdk_version}/
            60:   EOF
            61:   cwd "#{Chef::Config[:file_cache_path]}/java_jce"
            62:   creates ::File.join(node['java']['oracle']['jce']['home'], jdk_version,'US_export_policy.jar')
        63: end
            64:
        65: %w(local_policy.jar US_export_policy.jar).each do |jar|
            66:   jar_path = ::File.join(node['java']['java_home'], 'jre', 'lib', 'security', jar)
            67:   # remove the jars already in the directory
            68:   file jar_path do
            69:     action :delete
        70:     not_if {::File.symlink? jar_path}
            71:   end
            72:   link jar_path do

            74:   end
            75: end


           ------------------
           # Declared in /tmp/kitchen/cache/cookbooks/java/recipes/oracle_jce.rb:41:in `from_file'

           execute("download jce") do
             action "run"
         retries 0
             retry_delay 2
             default_guard_interpreter :execute

             backup 5
             returns 0
         declared_type :execute
             cookbook_name "java"
             recipe_name "oracle_jce"
             not_if { #code block }
           end


       Running handlers:
       [2015-06-27T02:36:29+00:00] ERROR: Running exception handlers
       Running handlers complete
       [2015-06-27T02:36:29+00:00] ERROR: Exception handlers complete
       [2015-06-27T02:36:29+00:00] FATAL: Stacktrace dumped to /tmp/kitchen/cache/chef-stacktrace.out
       Chef Client failed. 14 resources updated in 145.840837066 seconds
       [2015-06-27T02:36:29+00:00] ERROR: execute[download jce] (java::oracle_jce line 41) had an error: Mixlib::ShellOut::ShellCommandFailed: Expected process to exit with [0], but received '1'
       ---- Begin output of     rm -rf /tmp/kitchen/cache/java_jce
           mkdir -p /tmp/kitchen/cache/java_jce
           cd /tmp/kitchen/cache/java_jce

           curl -L --cookie 'oraclelicense=accept-securebackup-cookie;gpw_e24=http://edelivery.oracle.com' -o jce.zip http://download.oracle.com/otn-pub/java/jce/8/jce_policy-8.zip
           # fail the resource if the checksum does not match
           # this should only happen if oracle download terms are not accepted and downloading directly from oracle
           echo "f3020a3922efd6626c2fff45695d527f34a8020e938a49292561f18ad1320b59  jce.zip" | sha256sum -c >/dev/null
        ----
       STDOUT:
       STDERR: % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed

  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0

  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0

100  4569  100  4569    0     0   5905      0 --:--:-- --:--:-- --:--:--  5905
       sha256sum: WARNING: 1 computed checksum did NOT match
       ---- End output of     rm -rf /tmp/kitchen/cache/java_jce
           mkdir -p /tmp/kitchen/cache/java_jce
           cd /tmp/kitchen/cache/java_jce

           curl -L --cookie 'oraclelicense=accept-securebackup-cookie;gpw_e24=http://edelivery.oracle.com' -o jce.zip http://download.oracle.com/otn-pub/java/jce/8/jce_policy-8.zip
           # fail the resource if the checksum does not match
           # this should only happen if oracle download terms are not accepted and downloading directly from oracle
           echo "f3020a3922efd6626c2fff45695d527f34a8020e938a49292561f18ad1320b59  jce.zip" | sha256sum -c >/dev/null
        ----
       Ran     rm -rf /tmp/kitchen/cache/java_jce
       -p /tmp/kitchen/cache/java_jce
           cd /tmp/kitchen/cache/java_jce

           curl -L --cookie 'oraclelicense=accept-securebackup-cookie;gpw_e24=http://edelivery.oracle.com' -o jce.zip http://download.oracle.com/otn-pub/java/jce/8/jce_policy-8.zip
           # fail the resource if the checksum does not match
           # this should only happen if oracle download terms are not accepted and downloading directly from oracle
           echo "f3020a3922efd6626c2fff45695d527f34a8020e938a49292561f18ad1320b59  jce.zip" | sha256sum -c >/dev/null
        returned 1
       [2015-06-27T02:36:30+00:00] FATAL: Chef::Exceptions::ChildConvergeError: Chef run process exited unsuccessfully (exit code 1)
>>>>>> Converge failed on instance <default-ubuntu-1404>.
>>>>>> Please see .kitchen/logs/default-ubuntu-1404.log for more details
>>>>>> ------Exception-------
>>>>>> Class: Kitchen::ActionFailed
>>>>>> Message: SSH exited (1) for command: [sh -c '

sudo -E /opt/chef/bin/chef-client --local-mode --config /tmp/kitchen/client.rb --log_level auto --force-formatter --no-color --json-attributes /tmp/kitchen/dna.json --chef-zero-port 8889
']
>>>>>> ----------------------
+ failed_cookbooks=' elasticsearch-auth'
#+END_EXAMPLE
** TODO BinLiang: tomcat error
#+BEGIN_EXAMPLE
Failed to start tomcat. Tried twice, same error.
[2015-06-23T05:13:15+00:00] INFO: Retrying execution of service[tomcat7], 3 attempt(s) left
[2015-06-23T05:13:50+00:00] INFO: Retrying execution of service[tomcat7], 2 attempt(s) left
[2015-06-23T05:14:25+00:00] INFO: Retrying execution of service[tomcat7], 1 attempt(s) left
[2015-06-23T05:15:00+00:00] INFO: Retrying execution of service[tomcat7], 0 attempt(s) left
[0m
================================================================================[0m
[31mError executing action `restart` on resource 'service[tomcat7]'[0m
================================================================================[0m

[0mMixlib::ShellOut::ShellCommandFailed[0m
------------------------------------[0m
Expected process to exit with [0], but received '1'
[0m---- Begin output of /etc/init.d/tomcat7 restart ----
[0mSTDOUT: * Starting Tomcat servlet engine tomcat7
[0m   ...fail!
[0mSTDERR:
[0m---- End output of /etc/init.d/tomcat7 restart ----
[0mRan /etc/init.d/tomcat7 restart returned 1[0m

[0mResource Declaration:[0m
---------------------[0m
# In /root/test/master/iamdevops/cookbooks/tomcat/providers/instance.rb
[0m
[0m259:   service "#{instance}" do
[0m260:     case node['platform_family']
[0m261:     when 'rhel', 'fedora'
[0m262:       service_name "#{instance}"
[0m263:       supports :restart => true, :status => true
[0m264:     when 'debian'
[0m265:       service_name "#{instance}"
[0m266:       supports :restart => true, :reload => false, :status => true
[0m267:     when 'smartos'
[0m268:       # SmartOS doesn't support multiple instances
[0m269:       service_name 'tomcat'
[0m270:       supports :restart => false, :reload => false, :status => true
[0m271:     else
[0m272:       service_name "#{instance}"
[0m273:     end
[0m274:     action [:start, :enable]
[0m275:     notifies :run, "execute[wait for #{instance}]", :immediately
[0m276:     retries 4
[0m277:     retry_delay 30
[0m278:   end
[0m279:
[0m
[0mCompiled Resource:[0m
------------------[0m
# Declared in /root/test/master/iamdevops/cookbooks/tomcat/providers/instance.rb:259:in `block in class_from_file'
[0m
[0mservice("tomcat7") do
[0m  action [:start, :enable]
[0m  updated true
[0m  supports {:restart=>true, :reload=>false, :status=>true}
[0m  retries 4
[0m  retry_delay 30
[0m  default_guard_interpreter :default
[0m  service_name "tomcat7"
[0m  enabled true
[0m  running true
[0m  pattern "tomcat7"
[0m  declared_type :service
[0m  cookbook_name :tomcat
[0mend
[0m
[0m[2015-06-23T05:15:35+00:00] INFO: execute[Deploy gateway war] sending restart action to service[tomcat7] (delayed)
[2015-06-23T05:15:35+00:00] INFO: Processing service[tomcat7] action restart (os-basic-auth::tomcat line 69)
[0m
================================================================================[0m
[31mError executing action `restart` on resource 'service[tomcat7]'[0m
================================================================================[0m

[0mMixlib::ShellOut::ShellCommandFailed[0m
------------------------------------[0m
Expected process to exit with [0], but received '1'
[0m---- Begin output of /etc/init.d/tomcat7 start ----
[0mSTDOUT: * Starting Tomcat servlet engine tomcat7
[0m   ...fail!
[0mSTDERR:
[0m---- End output of /etc/init.d/tomcat7 start ----
[0mRan /etc/init.d/tomcat7 start returned 1[0m

[0mResource Declaration:[0m
---------------------[0m
# In /root/test/master/iamdevops/cookbooks/os-basic-auth/recipes/tomcat.rb
[0m
[0m 69: service 'tomcat7' do
[0m 70:   supports status: true
[0m 71:
[0m 72:   # init_command "/etc/init.d/tomcat7" # Need for redhat OS
[0m 73:   action [:enable]
[0m 74: end
[0m
[0mCompiled Resource:[0m
------------------[0m
# Declared in /root/test/master/iamdevops/cookbooks/os-basic-auth/recipes/tomcat.rb:69:in `from_file'
[0m
[0mservice("tomcat7") do
[0m  action [:enable]
[0m  supports {:status=>true}
[0m  retries 0
[0m  retry_delay 2
[0m  default_guard_interpreter :default
[0m  service_name "tomcat7"
[0m  enabled true
[0m  pattern "tomcat7"
[0m  declared_type :service
[0m  cookbook_name :"os-basic-auth"
[0m  recipe_name "tomcat"
[0mend
[0m
[0m[2015-06-23T05:15:41+00:00] ERROR: Running exception handlers
[2015-06-23T05:15:41+00:00] ERROR: Exception handlers complete
[2015-06-23T05:15:41+00:00] FATAL: Stacktrace dumped to /var/chef/cache/chef-stacktrace.out
[2015-06-23T05:15:41+00:00] ERROR: Chef::Exceptions::MultipleFailures
[2015-06-23T05:15:41+00:00] FATAL: Chef::Exceptions::ChildConvergeError: Chef run process exited unsuccessfully (exit code 1)
Build step 'Execute shell' marked build as failure
Finished: FAILURE
#+END_EXAMPLE
** TODO docker-registry2 error: nginx
http://50.198.76.249:443/view/DeployCookbook/job/DockerDeployBasicCookbooks/38/console

https://gist.github.com/jnevelson/10211026
https://tickets.opscode.com/browse/COOK-4533

#+BEGIN_EXAMPLE
         * apt_package[nginx] action install
           - install version 1.4.6-1ubuntu3.2 of package nginx
       Recipe: nginx::ohai_plugin
         * ohai[reload_nginx] action reload/opt/chef/embedded/lib/ruby/gems/2.1.0/gems/ohai-8.5.0/lib/ohai/plugins/solaris2/network.rb:57: warning: already initialized constant ETHERNET_ENCAPS
       /opt/chef/embedded/lib/ruby/gems/2.1.0/gems/ohai-8.5.0/lib/ohai/plugins/solaris2/network.rb:57: warning: previous definition of ETHERNET_ENCAPS was here
       [2015-07-17T09:42:00+00:00] ERROR: Encountered error while running plugins: #<Ohai::Exceptions::AttributeNotFound: No such attribute: 'nginx'>
       
           
           ================================================================================
           Error executing action `reload` on resource 'ohai[reload_nginx]'
           ================================================================================
           
           Ohai::Exceptions::AttributeNotFound
           -----------------------------------
           No such attribute: 'nginx'
           
           Resource Declaration:
           ---------------------
           # In /tmp/kitchen/cache/cookbooks/nginx/recipes/ohai_plugin.rb
       
        22: ohai 'reload_nginx' do
        23:   plugin 'nginx'
        24:   action :nothing
            25: end
            26: 
           
           Compiled Resource:
           ------------------
           # Declared in /tmp/kitchen/cache/cookbooks/nginx/recipes/ohai_plugin.rb:22:in `from_file'
           
           ohai("reload_nginx") do
             action :nothing
             retries 0
             retry_delay 2
             default_guard_interpreter :default
             plugin "nginx"
             declared_type :ohai
             cookbook_name "nginx"
             recipe_name "ohai_plugin"
           end
           
       Recipe: docker-registry2::client_certificates
         * execute[update-ca-certificates] action run
       - execute update-ca-certificates
       
       
       [2015-07-17T09:42:03+00:00] ERROR: Running exception handlers
       Running handlers complete
       [2015-07-17T09:42:03+00:00] ERROR: Exception handlers complete
       Chef Client failed. 32 resources updated in 157.419289738 seconds
       [2015-07-17T09:42:03+00:00] FATAL: Stacktrace dumped to /tmp/kitchen/cache/chef-stacktrace.out
       [2015-07-17T09:42:03+00:00] ERROR: ohai[reload_nginx] (nginx::ohai_plugin line 22) had an error: Ohai::Exceptions::AttributeNotFound: No such attribute: 'nginx'
       [2015-07-17T09:42:03+00:00] FATAL: Chef::Exceptions::ChildConvergeError: Chef run process exited unsuccessfully (exit code 1)
>>>>>> Converge failed on instance <default-ubuntu-1404>.
>>>>>> Please see .kitchen/logs/default-ubuntu-1404.log for more details
>>>>>> ------Exception-------
>>>>>> Class: Kitchen::ActionFailed
>>>>>> Message: SSH exited (1) for command: [env http_proxy=http://172.17.42.1:3128 https_proxy=http://172.17.42.1:3128 sh -c '
http_proxy="http://172.17.42.1:3128"; export http_proxy
HTTP_PROXY="http://172.17.42.1:3128"; export HTTP_PROXY
https_proxy="http://172.17.42.1:3128"; export https_proxy
HTTPS_PROXY="http://172.17.42.1:3128"; export HTTPS_PROXY
sudo -E /opt/chef/bin/chef-client --local-mode --config /tmp/kitchen/client.rb --log_level auto --force-formatter --no-color --json-attributes /tmp/kitchen/dna.json --chef-zero-port 8889
']
>>>>>> ----------------------
#+END_EXAMPLE
* DONE [#B] totvs all-in-one deployment: install couchbase fail, out of hardware resource
  CLOSED: [2015-06-30 Tue 18:12]
http://10.165.4.67:48080/view/MustPass/job/KitchenDockerTestAllCookbooks/303/console
#+BEGIN_EXAMPLE
 Recipe: couchbase::server
         * remote_file[/tmp/kitchen/cache/couchbase-server-community_3.0.0-ubuntu12.04_amd64.deb] action create_if_missing (up to date)
         * apt_package[libssl1.0.0] action install (up to date)
         * dpkg_package[/tmp/kitchen/cache/couchbase-server-community_3.0.0-ubuntu12.04_amd64.deb] action install
           
       ================================================================================
           Error executing action `install` on resource 'dpkg_package[/tmp/kitchen/cache/couchbase-server-community_3.0.0-ubuntu12.04_amd64.deb]'
           ================================================================================
           
           Mixlib::ShellOut::ShellCommandFailed
           ------------------------------------
           Expected process to exit with [0], but received '1'
           ---- Begin output of dpkg -i /tmp/kitchen/cache/couchbase-server-community_3.0.0-ubuntu12.04_amd64.deb ----
           STDOUT: (Reading database ... 48355 files and directories currently installed.)
           Preparing to unpack .../couchbase-server-community_3.0.0-ubuntu12.04_amd64.deb ...
       libssl1* is installed. Continue installing
       Warning: Transparent hugepages looks to be active and should not be.
           Please look at http://bit.ly/1hTySfg as for how to PERMANENTLY alter this setting.
       Warning: Swappiness is not set to 0.
       
       
           System RAM configured : 15.63 GB
           
       Minimum number of processors required : 4 cores
           Number of processors on the system    : 8 cores
           Unpacking couchbase-server (3.0.3) ...
       Processing triggers for ureadahead (0.100.0-16) ...
       STDERR: dpkg: error processing archive /tmp/kitchen/cache/couchbase-server-community_3.0.0-ubuntu12.04_amd64.deb (--install):
        error creating directory `./opt/couchbase/doc': No such file or directory
           dpkg-deb: error: subprocess paste was killed by signal (Broken pipe)
           Errors were encountered while processing:
            /tmp/kitchen/cache/couchbase-server-community_3.0.0-ubuntu12.04_amd64.deb
           ---- End output of dpkg -i /tmp/kitchen/cache/couchbase-server-community_3.0.0-ubuntu12.04_amd64.deb ----
       
           
           Resource Declaration:
           ---------------------
           # In /tmp/kitchen/cache/cookbooks/couchbase/recipes/server.rb
           
            55:   dpkg_package File.join(Chef::Config[:file_cache_path], node['couchbase']['server']['package_file'])
        56: when "redhat", "centos", "scientific", "amazon", "fedora"
           
           Compiled Resource:
           ------------------
           # Declared in /tmp/kitchen/cache/cookbooks/couchbase/recipes/server.rb:55:in `from_file'
           
           dpkg_package("/tmp/kitchen/cache/couchbase-server-community_3.0.0-ubuntu12.04_amd64.deb") do
             action :install
             retries 0
         retry_delay 2
         default_guard_interpreter :default
             package_name "/tmp/kitchen/cache/couchbase-server-community_3.0.0-ubuntu12.04_amd64.deb"
         source "/tmp/kitchen/cache/couchbase-server-community_3.0.0-ubuntu12.04_amd64.deb"
         version "3.0.3"
         timeout 900
         declared_type :dpkg_package
             cookbook_name "couchbase"
             recipe_name "server"
           end
           
       
       Running handlers:
       [2015-06-30T21:29:27+00:00] ERROR: Running exception handlers
       Running handlers complete
       [2015-06-30T21:29:27+00:00] ERROR: Exception handlers complete
       [2015-06-30T21:29:27+00:00] FATAL: Stacktrace dumped to /tmp/kitchen/cache/chef-stacktrace.out
       Chef Client failed. 4 resources updated in 47.705962354 seconds
       [2015-06-30T21:29:27+00:00] ERROR: dpkg_package[/tmp/kitchen/cache/couchbase-server-community_3.0.0-ubuntu12.04_amd64.deb] (couchbase::server line 55) had an error: Mixlib::ShellOut::ShellCommandFailed: Expected process to exit with [0], but received '1'
       ---- Begin output of dpkg -i /tmp/kitchen/cache/couchbase-server-community_3.0.0-ubuntu12.04_amd64.deb ----
       STDOUT: (Reading database ... 48355 files and directories currently installed.)
       Preparing to unpack .../couchbase-server-community_3.0.0-ubuntu12.04_amd64.deb ...
       
       Warning: Transparent hugepages looks to be active and should not be.
       Please look at http://bit.ly/1hTySfg as for how to PERMANENTLY alter this setting.
       Warning: Swappiness is not set to 0.
       Please look at http://bit.ly/1hTySfg as for how to PERMANENTLY alter this setting.
       Minimum RAM required  : 4 GB
       System RAM configured : 15.63 GB
       
       Minimum number of processors required : 4 cores
       Number of processors on the system    : 8 cores
       Unpacking couchbase-server (3.0.3) ...
       Processing triggers for ureadahead (0.100.0-16) ...
       STDERR: dpkg: error processing archive /tmp/kitchen/cache/couchbase-server-community_3.0.0-ubuntu12.04_amd64.deb (--install):
        error creating directory `./opt/couchbase/doc': No such file or directory
       dpkg-deb: error: subprocess paste was killed by signal (Broken pipe)
       Errors were encountered while processing:
       
       ---- End output of dpkg -i /tmp/kitchen/cache/couchbase-server-community_3.0.0-ubuntu12.04_amd64.deb ----
       Ran dpkg -i /tmp/kitchen/cache/couchbase-server-community_3.0.0-ubuntu12.04_amd64.deb returned 1
       [2015-06-30T21:29:27+00:00] FATAL: Chef::Exceptions::ChildConvergeError: Chef run process exited unsuccessfully (exit code 1)
>>>>>> Converge failed on instance <default-ubuntu-1404>.
>>>>>> Please see .kitchen/logs/default-ubuntu-1404.log for more details
>>>>>> ------Exception-------
>>>>>> Class: Kitchen::ActionFailed
>>>>>> Message: SSH exited (1) for command: [env http_proxy=http://172.17.42.1:3128 https_proxy=http://172.17.42.1:3128 sh -c '
http_proxy="http://172.17.42.1:3128"; export http_proxy
HTTP_PROXY="http://172.17.42.1:3128"; export HTTP_PROXY
https_proxy="http://172.17.42.1:3128"; export https_proxy
HTTPS_PROXY="http://172.17.42.1:3128"; export HTTPS_PROXY
sudo -E /opt/chef/bin/chef-client --local-mode --config /tmp/kitchen/client.rb --log_level auto --force-formatter --no-color --json-attributes /tmp/kitchen/dna.json --chef-zero-port 8889
#+END_EXAMPLE
* web page: Jenkins Best Practices - Jenkins - Jenkins Wiki          
https://wiki.jenkins-ci.org/display/JENKINS/Jenkins+Best+Practices
** webcontent                     :noexport:
#+begin_example
Location: https://wiki.jenkins-ci.org/display/JENKINS/Jenkins+Best+Practices                                                  
  * Skip to content
  * Skip to breadcrumbs
  * Skip to header menu
  * Skip to action menu
  * Skip to quick search

Quick Search [                         ]  Search 
  * Browse
      + Pages
      + Blog
      + Labels
      + Attachments
      + Mail
      + Advanced
      + People Directory
      + Keyboard Shortcuts
      + Confluence Gadgets
  * Kohsuke Kawaguchi
      + Recently Viewed
      + Profile
      + Network
      + Labels
      + Watches
      + Drafts
      + Settings
      + Log Out

 1. Dashboard
 2. Jenkins
 3. Home
 4. Jenkins Best Practices

  * Edit
  * Add
      + Page
      + Gliffy Diagram Gliffy Diagram
      + Comment
      + Attachment
  * Tools
      + Attachments (0)
      + Page History
      + Restrictions
      + Edit in Word Edit in Word
      + Favourite
      + Watch
      + Stop Watching
      + Info
      + Link to this Page…
      + View in Hierarchy
      + View Wiki Markup
      + Export to PDF
      + Export to Word
      + Import Word Document
      + Copy
      + Move

[JENKINS] Jenkins Best Practices

Skip to end of metadata

  * Page restrictions apply
  * Added by haiphan -, last edited by Kohsuke Kawaguchi on Nov 07, 2014  (view change)

Comment:
Go to start of metadata

Jenkins        Introduction                                                                        
                                                                                                   
  * Home       Continuous Integration (CI) with automated test execution and trends has changed the
  * Mailing    way companies look at Build Management, Release Management, Deployment Automation,  
    lists      and Test Orchestration. This section describes Jenkins best practices in order to   
  * Source     provide executives, business managers, software developers and architects a better  
    code       sense of what Jenkins can contribute throughout the project lifecycle.              
  * Bugtracker                                                                                     
  * Security   Jenkins Best Practices                                                              
    Advisories                                                                                     
  * Events     # Always secure Jenkins.                                                            
  * Donation                                                                                       
  * Commercial This best practice is around authenticating users and enforcing access control on a 
    Support    Jenkins instance                                                                    
  * Wiki Site  In the default configuration, Jenkins does not perform any security checks. This    
    Map        means any person accessing the website can configure Jenkins and jobs, and perform  
               builds. While this configuration is normally acceptable for intranet use and quick  
Documents      setup, it introduces high security risks, like someone accidentally deleting your   
               build jobs, reconfiguring your job to run every minute, kicking off too many builds 
  * Meet       at the same time, reconfiguring your build instance, etc.                           
    Jenkins                                                                                        
  * Use        # Backup Jenkins Home regularly.                                                    
    Jenkins                                                                                        
  * Extend     'Nuff said.                                                                         
    Jenkins                                                                                        
  * Plugins    # Use "file fingerprinting" to manage dependencies.                                 
  * Servlet                                                                                        
    Container  When you have interdependent projects on Jenkins, it often becomes hard to keep     
    Notes      track of which version of this is used by which version of that. Jenkins supports   
               "file fingerprinting" to simplify this, so make best use of it.                     
                                                                                                   
               # The most reliable builds will be clean builds, which are built fully from Source  
                 Code Control.                                                                     
                                                                                                   
               To ensure a build can be reproducible, the build must be a clean build, which is    
               built fully from Source Code Control. This practice also implies that all code      
               including third-party jars, build scripts, release notes, etc. must be checked into 
               Source Code Control.                                                                
                                                                                                   
               # Integrate tightly with your issue tracking system, like JIRA or bugzilla, to      
                 reduce the need for maintaining a Change Log                                      
                                                                                                   
               The integration helps to track changes as they are made, including build status,    
               what build has been performed for this requirement or defects, and the link to the  
               actual build results and artifacts.                                                 
                                                                                                   
               # Integrate tightly with a repository browsing tool like FishEye if you are using   
                 Subversion as source code management tool                                         
                                                                                                   
               Repository browsing provides a quick update on what happens on a Subversion         
               repository. It also provides a graphical diff on what changes have been made from   
               the previous build.                                                                 
                                                                                                   
               # Always configure your job to generate trend reports and automated testing when    
                 running a Java build                                                              
                                                                                                   
               Trends helps project managers and developers quickly visualize current project      
               progress status. Moreover, unit testing is often not enough to provide confidence   
               that the delivered software complies to the desired quality. The more you test the  
               software, the better the delivered software complies to the desired quality.        
                                                                                                   
               # Set up Jenkins on the partition that has the most free disk-space                 
                                                                                                   
               Jenkins needs some disk space to perform builds and keep archives. All the settings,
               build logs, artifact archives are stored under the JENKINS_HOME directory. Simply   
               archive this directory to make a back up. Similarly, restoring the data is just     
               replacing the contents of the JENKINS_HOME directory from a back up.                
                                                                                                   
               # Archive unused jobs before removing them.                                         
                                                                                                   
               All unused jobs should be archived so they can be resurrected if the need arises.   
               See Administering Jenkins for ways to do this.                                      
                                                                                                   
               # Setup a different job/project for each maintenance or development branch you      
                 create                                                                            
                                                                                                   
               One of advantages of using CI tools is to detect problems early in the development  
               lifecycle. Setting up a different job/project for each branch you create will help  
               to maximize the benefit of detecting problems early as part of supporting parallel  
               development efforts and reducing risk.                                              
                                                                                                   
               # Allocate a different port for parallel project builds and avoid scheduling all    
                 jobs to start at the same time                                                    
                                                                                                   
               Multiple jobs running at the same time often cause collisions. Try to avoid         
               scheduling all jobs to start at the same time. Allocate a different port for        
               parallel project builds to avoid build collisions.                                  
                                                                                                   
               # Set up email notifications mapping to ALL developers in the project, so that      
                 everyone on the team has his pulse on the project's current status.               
                                                                                                   
               Configure each person on the people list with his or her correct email address and  
               what role he or she is currently playing.                                           
                                                                                                   
               # Take steps to ensure failures are reported as soon as possible.                   
                                                                                                   
               For example, it may be appropriate to run a limited set of "sniff tests" before the 
               full suite.                                                                         
                                                                                                   
               # Write jobs for your maintenance tasks, such as cleanup operations to avoid full   
                 disk problems.                                                                    
                                                                                                   
               # Tag, label, or baseline the codebase after the successful build.                  
                                                                                                   
               # Configure Jenkins bootstrapper to update your working copy prior to running the   
                 build goal/target                                                                 
                                                                                                   
               # In larger systems, don't build on the master.                                     
                                                                                                   
               You can do this by setting the executor count to zero. Instead, make sure all jobs  
               run on slaves. This ensures that the jenkins master can scale to support many more  
               jobs, and it also protects builds from modifying potentially sensitive data on      
               $JENKINS_HOME accidentally/maliciously.                                             

Labels parameters 

Labels

Add Labels Done
Enter labels to add to this page:
[                                        ]  Add   Done 
Please wait 
Looking for a label? Just start typing.
Comments (7)

  * Hide Comments Show Comments
  * Collapse All Collapsing… Expanding… Expand All
  * Add Comment

 1. User icon: yoavshapira
   
    Aug 21, 2008
   
    Yoav Shapira says:
   
    Where is HUDSON_HOME defined?  If I just downloaded hudson.war and put it i...
   
    Where is HUDSON_HOME defined?  If I just downloaded hudson.war and put it into an existing
    Tomcat webapps directory, where is HUDSON_HOME?  I'd like to back up my Hudson configuration
    using the above best practice, but I don't know which directory to zip up and backup.
   
      + Permalink
      + Reply
     1. User icon: yoavshapira
       
        Aug 21, 2008
       
        Yoav Shapira says:
       
        I think I might have an answer to my own questions.  Please tell me if this...
       
        I think I might have an answer to my own questions.  Please tell me if this is right.
       
        When I go to the "Manage Hudson" screen, at the very top there is a "Home directory"
        read-only line, which has a directory in it.  That directory indeed seems to contain a
        bunch of config files and fingerprints.  I bet that's what I need to zip up and copy to a
        remote secure location for backup.  Right?
       
          o Permalink
          o Reply
 2. User icon: k96
   
    Mar 08, 2011
   
    Kuh 96 says:
   
    What do you mean by "Jenkins bootstrapper" in the last practice ?
   
    What do you mean by "Jenkins bootstrapper" in the last practice ?
   
      + Permalink
      + Reply
 3. User icon: tartley
   
    Nov 03, 2011
   
    Jonathan Hartley says:
   
    Hey. Some of the above best practices are very opaque to me. > Backup Jenkin...
   
    Hey. Some of the above best practices are very opaque to me.
   
    > Backup Jenkins Home regularly.
   
    I'm not sure why. Is it just to preserve the config of Jenkins? But this only really took an
    hour or so to set up. Everything else is the output of applying our build process to files from
    source code control, so I don't think I need to back that up. Build results are too transient
    for me to care about. Am I forgetting something?
   
    > Allocate a different port for parallel project builds and avoid scheduling all jobs to start
    at the same time
   
    Port for what? Different instances of Jenkins to run on? Does that mean having several distinct
    installations of Jenkins, each under a different JENKINS_HOME? Presumably I'm misunderstanding
    this completely.
   
    > Configure Jenkins bootstrapper to update your working copy prior to running the build goal/
    target
   
    I don't understand this. If Jenkins builds are triggered by polling SCM for changes, then
    doesn't this already pull the changes? (or am I mistaken about that?) If it does, why do we
    have to update our working copy again?
   
    Thanks if anyone can help me get up to speed.
   
      + Permalink
      + Reply
 4. User icon: gfonk
   
    Jun 20, 2014
   
    Gerald Fontejon says:
   
    Could you guys leave a best practice for naming conventions?  What's your t...
   
    Could you guys leave a best practice for naming conventions?  What's your thought on placing
    spaces on job names?  I'm against it.
   
      + Permalink
      + Reply
 5. User icon: gdameron
   
    Aug 20, 2014
   
    G Dameron says:
   
    Shouldn't the use of LTS releases be considered a best practice?
   
    Shouldn't the use of LTS releases be considered a best practice?
   
      + Permalink
      + Reply
 6. User icon: martin_rust
   
    Oct 12, 2014
   
    Martin Rust says:
   
    @Jonathan: > Port for what? Guess "port" means "TCP port", am I right?...
   
    @Jonathan:
   
    > Port for what?
   
    Guess "port" means "TCP port", am I right? We should be aware that not every software allocates
    a fixed TCP server port, or maybe doesn't even use any TCP port at all, but maybe uses other
    non-shared system resources. I suggest changing "Allocate a different port ..." to "Allocate
    different system resources, like TCP ports ..." - or am I getting the meaning of this advice
    completely wrong? If so, please object, otherwise I'll clarify the page as I suggested.
   
      + Permalink
      + Reply

Add Comment

Powered by a free Atlassian Confluence Open Source Project License granted to Jenkins. Evaluate
Confluence today.

  * Powered by Atlassian Confluence 3.4.7, the Enterprise Wiki
  * Printed by Atlassian Confluence 3.4.7, the Enterprise Wiki.
  *   |  Report a bug
  *  |  Atlassian News

#+end_example
* DONE code build fail: Could not resolve dependencies for project com.totvslabs.mdm:app:jar:1.0
#+BEGIN_EXAMPLE
[6/30/15, 6:14:00 PM] kungchaowang: yes, if we build again, it should pass
[6/30/15, 6:14:11 PM] denny: Let me try
[6/30/15, 6:14:14 PM] kungchaowang: one dependencies was missing from remote
[6/30/15, 6:29:32 PM] denny: Kung, it fails again
http://10.165.4.67:48080/view/All/job/BuildMDMRepo/670/console
[6/30/15, 6:29:40 PM] kungchaowang: let me try
[6/30/15, 6:29:44 PM] kungchaowang: on my VM
[6/30/15, 6:29:48 PM] denny: thanks.
[6/30/15, 6:31:07 PM] denny: I tried in another env, it succeed.
http://104.236.159.226:18080/job/BuildMDMRepo/970/console
[6/30/15, 6:31:45 PM] denny: Let me give a retry in the failed jenkins.
#+END_EXAMPLE
** mail: Re: Build failed in Jenkins: BuildMDMRepo #969       :noexport:
[[gnus:nnfolder%2Barchive:mail.sent.mail#m26164bxvr.fsf@totvs.com][Email from Denny Zhang (Tue, 30 Jun 2015 18:05:28 -0500): Re: Build failed in Jenkins: B]]
#+begin_example
From: Denny Zhang <denny.zhang@totvs.com>
Subject: Re: Build failed in Jenkins: BuildMDMRepo #969
To: goetten@totvs.com, danny.schreiber@totvs.com, kung.wang@totvs.com, chinwei.wong@totvs.com, robson.poffo@totvs.com.br, lezhong.li@totvs.com, john.kaplan@totvs.com, shivang.shah@totvs.com, denny.zhang@totvs.com
Date: Tue, 30 Jun 2015 18:05:28 -0500
User-Agent: Gnus/5.13 (Gnus v5.13) Emacs/24.4 (darwin)

Hi all

Code build fails with below error message. Anyone can help to check?
Before today, it's fine.

If you'd like to reproduce locally, just setup local sandbox and trigger
code build with clean_start.

http://104.236.159.226:18080/job/BuildMDMRepo/969/
,----------- 
| > [INFO] generic-dao ....................................... SUCCESS [0.725s]
| > [INFO] app ............................................... FAILURE [5.432s]
| > [INFO] ------------------------------------------------------------------------
| > [INFO] BUILD FAILURE
| > [INFO] ------------------------------------------------------------------------
| > [INFO] Total time: 18.141s
| > [INFO] Finished at: Tue Jun 30 22:54:35 UTC 2015
| > [INFO] Final Memory: 43M/377M
| > [INFO] ------------------------------------------------------------------------
| > [ERROR] Failed to execute goal on project app: Could not resolve
| > dependencies for project com.totvslabs.mdm:app:jar:1.0: Could not find
| > artifact org.nlpcn:elasticsearch-sql:jar:1.3.4 in couchbase
| > (http://files.couchbase.com/maven2) -> [Help 1]
| > [ERROR] 
| > [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
| > [ERROR] Re-run Maven using the -X switch to enable full debug logging.
| > [ERROR] 
| > [ERROR] For more information about the errors and possible solutions, please read the following articles:
| > [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/DependencyResolutionException
| > [ERROR] 
| > [ERROR] After correcting the problems, you can resume the build with the command
| > [ERROR]   mvn <goals> -rf :app
`-----------

-- 
Denny Zhang(张巍)

Watch out for useless worries, like the past, the future, the nothing
you cannot change.

  /\ /\
   ( )
 .( o ).

Tue, 30 Jun 2015 22:54:35 +0000 (UTC) denny.zhang@totvs.com writes:

> See <http://104.236.159.226:18080/job/BuildMDMRepo/969/>
>
> ------------------------------------------
> [...truncated 77386 lines...]
> 13204/13700 KB   
> 13208/13700 KB   
> 13212/13700 KB   
> 13216/13700 KB   
> 13220/13700 KB   
> 13224/13700 KB   
> 13228/13700 KB   
> 13232/13700 KB   
> 13236/13700 KB   
> 13240/13700 KB   
> 13244/13700 KB   
> 13248/13700 KB   
> 13252/13700 KB   
> 13256/13700 KB   
> 13260/13700 KB   
> 13264/13700 KB   
> 13268/13700 KB   
> 13272/13700 KB   
> 13276/13700 KB   
> 13280/13700 KB   
> 13284/13700 KB   
> 13288/13700 KB   
> 13292/13700 KB   
> 13296/13700 KB   
> 13300/13700 KB   
> 13304/13700 KB   
> 13308/13700 KB   
> 13312/13700 KB   
> 13316/13700 KB   
> 13320/13700 KB   
> 13324/13700 KB   
> 13328/13700 KB   
> 13332/13700 KB   
> 13336/13700 KB   
> 13340/13700 KB   
> 13344/13700 KB   
> 13348/13700 KB   
> 13352/13700 KB   
> 13356/13700 KB   
> 13360/13700 KB   
> 13364/13700 KB   
> 13368/13700 KB   
> 13372/13700 KB   
> 13376/13700 KB   
> 13380/13700 KB   
> 13384/13700 KB   
> 13388/13700 KB   
> 13392/13700 KB   
> 13396/13700 KB   
> 13400/13700 KB   
> 13404/13700 KB   
> 13408/13700 KB   
> 13412/13700 KB   
> 13416/13700 KB   
> 13420/13700 KB   
> 13424/13700 KB   
> 13428/13700 KB   
> 13432/13700 KB   
> 13436/13700 KB   
> 13440/13700 KB   
> 13444/13700 KB   
> 13448/13700 KB   
> 13452/13700 KB   
> 13456/13700 KB   
> 13460/13700 KB   
> 13464/13700 KB   
> 13468/13700 KB   
> 13472/13700 KB   
> 13476/13700 KB   
> 13480/13700 KB   
> 13484/13700 KB   
> 13488/13700 KB   
> 13492/13700 KB   
> 13496/13700 KB   
> 13500/13700 KB   
> 13504/13700 KB   
> 13508/13700 KB   
> 13512/13700 KB   
> 13516/13700 KB   
> 13520/13700 KB   
> 13524/13700 KB   
> 13528/13700 KB   
> 13532/13700 KB   
> 13536/13700 KB   
> 13540/13700 KB   
> 13544/13700 KB   
> 13548/13700 KB   
> 13552/13700 KB   
> 13556/13700 KB   
> 13560/13700 KB   
> 13564/13700 KB   
> 13568/13700 KB   
> 13572/13700 KB   
> 13576/13700 KB   
> 13580/13700 KB   
> 13584/13700 KB   
> 13588/13700 KB   
> 13592/13700 KB   
> 13596/13700 KB   
> 13600/13700 KB   
> 13604/13700 KB   
> 13608/13700 KB   
> 13612/13700 KB   
> 13616/13700 KB   
> 13620/13700 KB   
> 13624/13700 KB   
> 13628/13700 KB   
> 13632/13700 KB   
> 13636/13700 KB   
> 13640/13700 KB   
> 13644/13700 KB   
> 13648/13700 KB   
> 13652/13700 KB   
> 13656/13700 KB   
> 13660/13700 KB   
> 13664/13700 KB   
> 13668/13700 KB   
> 13672/13700 KB   
> 13676/13700 KB   
> 13680/13700 KB   
> 13684/13700 KB   
> 13688/13700 KB   
> 13692/13700 KB   
> 13696/13700 KB   
> 13700/13700 KB   
>                  
> Downloaded:
> http://repo.maven.apache.org/maven2/org/elasticsearch/elasticsearch/1.6.0/elasticsearch-1.6.0.jar
> (13700 KB at 21206.0 KB/sec)
> [INFO] 
> [INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ elasticsearch-core ---
> [INFO] Deleting /var/lib/jenkins/code/master/mdm/elasticsearch-core/target
> [INFO] 
> [INFO] --- jacoco-maven-plugin:0.7.4.201502262128:prepare-agent (default) @ elasticsearch-core ---
> [INFO] argLine set to
> -javaagent:/var/lib/jenkins/.m2/repository/org/jacoco/org.jacoco.agent/0.7.4.201502262128/org.jacoco.agent-0.7.4.201502262128-runtime.jar=destfile=/var/lib/jenkins/code/master/mdm/elasticsearch-core/target/jacoco.exec,excludes=com/totvslabs/mdm/elasticsearch/dao/entities/*.class:com/totvslabs/mdm/elasticsearch/entities/*.class:com/totvslabs/mdm/elasticsearch/config/*.class:com/totvslabs/mdm/elasticsearch/enums/*.class
> "-javaagent:\"${settings.localRepository}\"/org/jmockit/jmockit/1.14/jmockit-1.14.jar"
> [INFO] 
> [INFO] --- maven-resources-plugin:2.3:resources (default-resources) @ elasticsearch-core ---
> [INFO] Using 'UTF-8' encoding to copy filtered resources.
> [INFO] skip non existing resourceDirectory /var/lib/jenkins/code/master/mdm/elasticsearch-core/src/main/resources
> [INFO] 
> [INFO] --- maven-compiler-plugin:2.4:compile (default-compile) @ elasticsearch-core ---
> [INFO] Compiling 19 source files to /var/lib/jenkins/code/master/mdm/elasticsearch-core/target/classes
> [INFO] 
> [INFO] --- maven-resources-plugin:2.3:testResources (default-testResources) @ elasticsearch-core ---
> [INFO] Using 'UTF-8' encoding to copy filtered resources.
> [INFO] Copying 1 resource
> [INFO] 
> [INFO] --- maven-compiler-plugin:2.4:testCompile (default-testCompile) @ elasticsearch-core ---
> [INFO] Not compiling test sources
> [INFO] 
> [INFO] --- maven-surefire-plugin:2.18.1:test (default-test) @ elasticsearch-core ---
> [INFO] Tests are skipped.
> [INFO] 
> [INFO] --- jacoco-maven-plugin:0.7.4.201502262128:report (report) @ elasticsearch-core ---
> [INFO] Skipping JaCoCo execution due to missing execution data
> file:/var/lib/jenkins/code/master/mdm/elasticsearch-core/target/jacoco.exec
> [INFO] 
> [INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ elasticsearch-core ---
> [INFO] Building jar: /var/lib/jenkins/code/master/mdm/elasticsearch-core/target/elasticsearch-core-1.0.jar
> [INFO] 
> [INFO] --- maven-install-plugin:2.3:install (default-install) @ elasticsearch-core ---
> [INFO] Installing
> /var/lib/jenkins/code/master/mdm/elasticsearch-core/target/elasticsearch-core-1.0.jar
> to
> /var/lib/jenkins/.m2/repository/com/totvslabs/mdm/elasticsearch-core/1.0/elasticsearch-core-1.0.jar
> [INFO] Installing
> /var/lib/jenkins/code/master/mdm/elasticsearch-core/pom.xml to
> /var/lib/jenkins/.m2/repository/com/totvslabs/mdm/elasticsearch-core/1.0/elasticsearch-core-1.0.pom
> [INFO]                                                                         
> [INFO] ------------------------------------------------------------------------
> [INFO] Building generic-dao 1.0
> [INFO] ------------------------------------------------------------------------
> [INFO] 
> [INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ generic-dao ---
> [INFO] Deleting /var/lib/jenkins/code/master/mdm/generic-dao/target
> [INFO] 
> [INFO] --- jacoco-maven-plugin:0.7.4.201502262128:prepare-agent (default) @ generic-dao ---
> [INFO] argLine set to
> -javaagent:/var/lib/jenkins/.m2/repository/org/jacoco/org.jacoco.agent/0.7.4.201502262128/org.jacoco.agent-0.7.4.201502262128-runtime.jar=destfile=/var/lib/jenkins/code/master/mdm/generic-dao/target/jacoco.exec,excludes=com/totvslabs/mdm/dao/*.class:com/totvslabs/mdm/dao/constants/*.class:com/totvslabs/mdm/dao/entity/*.class:com/totvslabs/mdm/dao/impl/*.class
> "-javaagent:\"${settings.localRepository}\"/org/jmockit/jmockit/1.14/jmockit-1.14.jar"
> [INFO] 
> [INFO] --- maven-resources-plugin:2.3:resources (default-resources) @ generic-dao ---
> [INFO] Using 'UTF-8' encoding to copy filtered resources.
> [INFO] skip non existing resourceDirectory /var/lib/jenkins/code/master/mdm/generic-dao/src/main/resources
> [INFO] 
> [INFO] --- maven-compiler-plugin:2.4:compile (default-compile) @ generic-dao ---
> [INFO] Compiling 9 source files to /var/lib/jenkins/code/master/mdm/generic-dao/target/classes
> [INFO] 
> [INFO] --- maven-resources-plugin:2.3:testResources (default-testResources) @ generic-dao ---
> [INFO] Using 'UTF-8' encoding to copy filtered resources.
> [INFO] skip non existing resourceDirectory /var/lib/jenkins/code/master/mdm/generic-dao/src/test/resources
> [INFO] 
> [INFO] --- maven-compiler-plugin:2.4:testCompile (default-testCompile) @ generic-dao ---
> [INFO] Not compiling test sources
> [INFO] 
> [INFO] --- maven-surefire-plugin:2.18.1:test (default-test) @ generic-dao ---
> [INFO] Tests are skipped.
> [INFO] 
> [INFO] --- jacoco-maven-plugin:0.7.4.201502262128:report (report) @ generic-dao ---
> [INFO] Skipping JaCoCo execution due to missing execution data
> file:/var/lib/jenkins/code/master/mdm/generic-dao/target/jacoco.exec
> [INFO] 
> [INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ generic-dao ---
> [INFO] Building jar: /var/lib/jenkins/code/master/mdm/generic-dao/target/generic-dao-1.0.jar
> [INFO] 
> [INFO] --- maven-install-plugin:2.3:install (default-install) @ generic-dao ---
> [INFO] Installing
> /var/lib/jenkins/code/master/mdm/generic-dao/target/generic-dao-1.0.jar
> to
> /var/lib/jenkins/.m2/repository/com/totvslabs/mdm/generic-dao/1.0/generic-dao-1.0.jar
> [INFO] Installing /var/lib/jenkins/code/master/mdm/generic-dao/pom.xml
> to
> /var/lib/jenkins/.m2/repository/com/totvslabs/mdm/generic-dao/1.0/generic-dao-1.0.pom
> [INFO]                                                                         
> [INFO] ------------------------------------------------------------------------
> [INFO] Building app 1.0
> [INFO] ------------------------------------------------------------------------
> Downloading: http://files.couchbase.com/maven2/org/nlpcn/elasticsearch-sql/1.3.4/elasticsearch-sql-1.3.4.pom
>                  
> Downloading:
> https://oss.sonatype.org/content/repositories/snapshots/org/nlpcn/elasticsearch-sql/1.3.4/elasticsearch-sql-1.3.4.pom
>                  
> Downloading:
> http://nexus.fluigdata.com:8081/nexus/content/groups/public/org/nlpcn/elasticsearch-sql/1.3.4/elasticsearch-sql-1.3.4.pom
>                  
> Downloading: http://repo.maven.apache.org/maven2/org/nlpcn/elasticsearch-sql/1.3.4/elasticsearch-sql-1.3.4.pom
>                  
> [WARNING] The POM for org.nlpcn:elasticsearch-sql:jar:1.3.4 is missing, no dependency information available
> Downloading: http://files.couchbase.com/maven2/org/nlpcn/elasticsearch-sql/1.3.4/elasticsearch-sql-1.3.4.jar
>                  
> Downloading:
> https://oss.sonatype.org/content/repositories/snapshots/org/nlpcn/elasticsearch-sql/1.3.4/elasticsearch-sql-1.3.4.jar
>                  
> Downloading:
> http://nexus.fluigdata.com:8081/nexus/content/groups/public/org/nlpcn/elasticsearch-sql/1.3.4/elasticsearch-sql-1.3.4.jar
>                  
> Downloading: http://repo.maven.apache.org/maven2/org/nlpcn/elasticsearch-sql/1.3.4/elasticsearch-sql-1.3.4.jar
>                  
> [INFO] ------------------------------------------------------------------------
> [INFO] Reactor Summary:
> [INFO] 
> [INFO] mdm ............................................... SUCCESS [1.185s]
> [INFO] mdm-core-common ................................... SUCCESS [2.443s]
> [INFO] couchbase-core .................................... SUCCESS [4.385s]
> [INFO] elasticsearch-core ................................ SUCCESS [3.633s]
> [INFO] generic-dao ....................................... SUCCESS [0.725s]
> [INFO] app ............................................... FAILURE [5.432s]
> [INFO] ------------------------------------------------------------------------
> [INFO] BUILD FAILURE
> [INFO] ------------------------------------------------------------------------
> [INFO] Total time: 18.141s
> [INFO] Finished at: Tue Jun 30 22:54:35 UTC 2015
> [INFO] Final Memory: 43M/377M
> [INFO] ------------------------------------------------------------------------
> [ERROR] Failed to execute goal on project app: Could not resolve
> dependencies for project com.totvslabs.mdm:app:jar:1.0: Could not find
> artifact org.nlpcn:elasticsearch-sql:jar:1.3.4 in couchbase
> (http://files.couchbase.com/maven2) -> [Help 1]
> [ERROR] 
> [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
> [ERROR] Re-run Maven using the -X switch to enable full debug logging.
> [ERROR] 
> [ERROR] For more information about the errors and possible solutions, please read the following articles:
> [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/DependencyResolutionException
> [ERROR] 
> [ERROR] After correcting the problems, you can resume the build with the command
> [ERROR]   mvn <goals> -rf :app
> + shell_exit
> + '[' 1 -eq 0 ']'
> + echo ERROR
> + exit 1
> Build step 'Execute shell' marked build as failure

#+end_example
* TODO Jay: how to avoid contact from old projects
#+BEGIN_EXAMPLE
[7/1/15, 11:17:02 AM] Meken Goncalves: Denny, can you help me please. Do you know this error?
[7/1/15, 11:17:03 AM] Meken Goncalves: Running handlers:
[2015-07-01T16:15:09+00:00] ERROR: Running exception handlers
Running handlers complete
[2015-07-01T16:15:09+00:00] ERROR: Exception handlers complete
[2015-07-01T16:15:09+00:00] FATAL: Stacktrace dumped to /var/chef/cache/chef-stacktrace.out
Chef Client failed. 23 resources updated in 31.501122332 seconds
[2015-07-01T16:15:10+00:00] ERROR: execute[Initialize couchbase] (fluig-initialize::initialize_couchbase line 18) had an error: Mixlib::ShellOut::ShellCommandFailed: Expected process to exit with [0], but received '1'
---- Begin output of fluig_initialize_couchbase.sh password 2048 /data/fluig_state/couchbase_already_initialized 5120 >> /var/log/chef/fluig_initialize_couchbase.log 2>&1 ----
STDOUT: 
STDERR: 
---- End output of fluig_initialize_couchbase.sh password 2048 /data/fluig_state/couchbase_already_initialized 5120 >> /var/log/chef/fluig_initialize_couchbase.log 2>&1 ----
Ran fluig_initialize_couchbase.sh password 2048 /data/fluig_state/couchbase_already_initialized 5120 >> /var/log/chef/fluig_initialize_couchbase.log 2>&1 returned 1
[2015-07-01T16:15:10+00:00] FATAL: Chef::Exceptions::ChildConvergeError: Chef run process exited unsuccessfully (exit code 1)
[7/1/15, 11:18:01 AM] denny: Morning Meken

For identity project, could you send me emails and cc Kung?
[7/1/15, 11:18:06 AM] denny: Then I can help you from there.
[7/1/15, 11:18:20 AM] Meken Goncalves: Thanks Denny
[7/1/15, 11:18:25 AM] denny: np
[7/1/15, 11:31:55 AM] Meken Goncalves: Denny
[7/1/15, 11:31:56 AM] Meken Goncalves: [1:27:47 PM] kungchaowang: yes, couchbase should be running, I don’t know why it was complianting
[1:27:55 PM] kungchaowang: can you ping Denny for it?
[7/1/15, 11:34:44 AM] denny: Meken, like I said, could you contact me by email for Identity project?
#+END_EXAMPLE
* web page: Google Testing Blog: Just Say No to More End-to-End Tests          
http://googletesting.blogspot.com/2015/04/just-say-no-to-more-end-to-end-tests.html
** webcontent                     :noexport:
#+begin_example
Location: http://googletesting.blogspot.com/2015/04/just-say-no-to-more-end-to-end-tests.html                                 
Google Testing Blog

Wednesday, April 22, 2015

Just Say No to More End-to-End Tests

by Mike Wacker

At some point in your life, you can probably recall a movie that you and your friends all wanted to
see, and that you and your friends all regretted watching afterwards. Or maybe you remember that
time your team thought they’d found the next "killer feature" for their product, only to see that
feature bomb after it was released.

Good ideas often fail in practice, and in the world of testing, one pervasive good idea that often
fails in practice is a testing strategy built around end-to-end tests.

Testers can invest their time in writing many types of automated tests, including unit tests,
integration tests, and end-to-end tests, but this strategy invests mostly in end-to-end tests that
verify the product or service as a whole. Typically, these tests simulate real user scenarios.

End-to-End Tests in Theory 

While relying primarily on end-to-end tests is a bad idea, one could certainly convince a
reasonable person that the idea makes sense in theory.

To start, number one on Google's list of ten things we know to be true is: "Focus on the user and
all else will follow." Thus, end-to-end tests that focus on real user scenarios sound like a great
idea. Additionally, this strategy broadly appeals to many constituencies:

  * Developers like it because it offloads most, if not all, of the testing to others. 
  * Managers and decision-makers like it because tests that simulate real user scenarios can help
    them easily determine how a failing test would impact the user. 
  * Testers like it because they often worry about missing a bug or writing a test that does not
    verify real-world behavior; writing tests from the user's perspective often avoids both
    problems and gives the tester a greater sense of accomplishment. 

End-to-End Tests in Practice 

So if this testing strategy sounds so good in theory, then where does it go wrong in practice? To
demonstrate, I present the following composite sketch based on a collection of real experiences
familiar to both myself and other testers. In this sketch, a team is building a service for editing
documents online (e.g., Google Docs).

Let's assume the team already has some fantastic test infrastructure in place. Every night:

 1. The latest version of the service is built. 
 2. This version is then deployed to the team's testing environment. 
 3. All end-to-end tests then run against this testing environment. 
 4. An email report summarizing the test results is sent to the team.

The deadline is approaching fast as our team codes new features for their next release. To maintain
a high bar for product quality, they also require that at least 90% of their end-to-end tests pass
before features are considered complete. Currently, that deadline is one day away:

Days  Pass % Notes                                                                                 
Left                                                                                               
1     5%     Everything is broken! Signing in to the service is broken. Almost all tests sign in a 
             user, so almost all tests failed.                                                     
0     4%     A partner team we rely on deployed a bad build to their testing environment yesterday.
             A dev broke the save scenario yesterday (or the day before?). Half the tests save a   
-1    54%    document at some point in time. Devs spent most of the day determining if it's a      
             frontend bug or a backend bug.                                                        
-2    54%    It's a frontend bug, devs spent half of today figuring out where.                     
-3    54%    A bad fix was checked in yesterday. The mistake was pretty easy to spot, though, and a
             correct fix was checked in today.                                                     
-4    1%     Hardware failures occurred in the lab for our testing environment.                    
-5    84%    Many small bugs hiding behind the big bugs (e.g., sign-in broken, save broken). Still 
             working on the small bugs.                                                            
-6    87%    We should be above 90%, but are not for some reason.                                  
-7    89.54% (Rounds up to 90%, close enough.) No fixes were checked in yesterday, so the tests    
             must have been flaky yesterday.                                                       

Analysis 

Despite numerous problems, the tests ultimately did catch real bugs.

What Went Well 

  * Customer-impacting bugs were identified and fixed before they reached the customer.

What Went Wrong 

  * The team completed their coding milestone a week late (and worked a lot of overtime). 
  * Finding the root cause for a failing end-to-end test is painful and can take a long time. 
  * Partner failures and lab failures ruined the test results on multiple days. 
  * Many smaller bugs were hidden behind bigger bugs. 
  * End-to-end tests were flaky at times. 
  * Developers had to wait until the following day to know if a fix worked or not. 

So now that we know what went wrong with the end-to-end strategy, we need to change our approach to
testing to avoid many of these problems. But what is the right approach?

The True Value of Tests 

Typically, a tester's job ends once they have a failing test. A bug is filed, and then it's the
developer's job to fix the bug. To identify where the end-to-end strategy breaks down, however, we
need to think outside this box and approach the problem from first principles. If we "focus on the
user (and all else will follow)," we have to ask ourselves how a failing test benefits the user.
Here is the answer:

A failing test does not directly benefit the user. 

While this statement seems shocking at first, it is true. If a product works, it works, whether a
test says it works or not. If a product is broken, it is broken, whether a test says it is broken
or not. So, if failing tests do not benefit the user, then what does benefit the user?

A bug fix directly benefits the user.

The user will only be happy when that unintended behavior - the bug - goes away. Obviously, to fix
a bug, you must know the bug exists. To know the bug exists, ideally you have a test that catches
the bug (because the user will find the bug if the test does not). But in that entire process, from
failing test to bug fix, value is only added at the very last step.

Stage       Failing Test  Bug Opened Bug Fixed
Value Added No            No         Yes      

Thus, to evaluate any testing strategy, you cannot just evaluate how it finds bugs. You also must
evaluate how it enables developers to fix (and even prevent) bugs.

Building the Right Feedback Loop

Tests create a feedback loop that informs the developer whether the product is working or not. The
ideal feedback loop has several properties:

  * It's fast. No developer wants to wait hours or days to find out if their change works.
    Sometimes the change does not work - nobody is perfect - and the feedback loop needs to run
    multiple times. A faster feedback loop leads to faster fixes. If the loop is fast enough,
    developers may even run tests before checking in a change. 
  * It's reliable. No developer wants to spend hours debugging a test, only to find out it was a
    flaky test. Flaky tests reduce the developer's trust in the test, and as a result flaky tests
    are often ignored, even when they find real product issues. 
  * It isolates failures. To fix a bug, developers need to find the specific lines of code causing
    the bug. When a product contains millions of lines of codes, and the bug could be anywhere,
    it's like trying to find a needle in a haystack. 

Think Smaller, Not Larger

So how do we create that ideal feedback loop? By thinking smaller, not larger.

Unit Tests

Unit tests take a small piece of the product and test that piece in isolation. They tend to create
that ideal feedback loop:

  * Unit tests are fast. We only need to build a small unit to test it, and the tests also tend to
    be rather small. In fact, one tenth of a second is considered slow for unit tests. 
  * Unit tests are reliable. Simple systems and small units in general tend to suffer much less
    from flakiness. Furthermore, best practices for unit testing - in particular practices related
    to hermetic tests - will remove flakiness entirely. 
  * Unit tests isolate failures. Even if a product contains millions of lines of code, if a unit
    test fails, you only need to search that small unit under test to find the bug. 

Writing effective unit tests requires skills in areas such as dependency management, mocking, and
hermetic testing. I won't cover these skills here, but as a start, the typical example offered to
new Googlers (or Nooglers) is how Google builds and tests a stopwatch.

Unit Tests vs. End-to-End Tests

With end-to-end tests, you have to wait: first for the entire product to be built, then for it to
be deployed, and finally for all end-to-end tests to run. When the tests do run, flaky tests tend
to be a fact of life. And even if a test finds a bug, that bug could be anywhere in the product.

Although end-to-end tests do a better job of simulating real user scenarios, this advantage quickly
becomes outweighed by all the disadvantages of the end-to-end feedback loop:

                       Unit    End-toEnd
Fast                   [happy] [sad]    
                                        
                       [happy] [sad]    
Reliable                                
                                        
Isolates Failures      [happy] [sad]    
                                        
Simulates a Real User  [sad]   [happy]  

Integration Tests

Unit tests do have one major disadvantage: even if the units work well in isolation, you do not
know if they work well together. But even then, you do not necessarily need end-to-end tests. For
that, you can use an integration test. An integration test takes a small group of units, often two
units, and tests their behavior as a whole, verifying that they coherently work together.

If two units do not integrate properly, why write an end-to-end test when you can write a much
smaller, more focused integration test that will detect the same bug? While you do need to think
larger, you only need to think a little larger to verify that units work together.

Testing Pyramid

Even with both unit tests and integration tests, you probably still will want a small number of
end-to-end tests to verify the system as a whole. To find the right balance between all three test
types, the best visual aid to use is the testing pyramid. Here is a simplified version of the 
testing pyramid from the opening keynote of the 2014 Google Test Automation Conference:

[image02]

The bulk of your tests are unit tests at the bottom of the pyramid. As you move up the pyramid,
your tests gets larger, but at the same time the number of tests (the width of your pyramid) gets
smaller.

As a good first guess, Google often suggests a 70/20/10 split: 70% unit tests, 20% integration
tests, and 10% end-to-end tests. The exact mix will be different for each team, but in general, it
should retain that pyramid shape. Try to avoid these anti-patterns:

  * Inverted pyramid/ice cream cone. The team relies primarily on end-to-end tests, using few
    integration tests and even fewer unit tests. 
  * Hourglass. The team starts with a lot of unit tests, then uses end-to-end tests where
    integration tests should be used. The hourglass has many unit tests at the bottom and many
    end-to-end tests at the top, but few integration tests in the middle. 

Just like a regular pyramid tends to be the most stable structure in real life, the testing pyramid
also tends to be the most stable testing strategy.

Email ThisBlogThis!Share to TwitterShare to FacebookShare to Pinterest
Labels: Mike Wacker

35 comments:

 1. [b36-rounde]
    Tamas KohegyiApril 23, 2015 at 2:45:00 AM PDT
   
    Meanwhile I share the opinion, I have problem with measuring the shape - just for curiosity,
    how you suggest to measure the size of unit/integration/E2E tests?
    Comparing the coverage they have, a few E2E test can generate much higher coverage than several
    unit tests. Comparing numbers, and having n thousands of unit tests and having only <100 E2E
    tests, this would still be presented as pyramid (well in the given percentages), but the E2E
    part still may cause so many problems (time, effort, test env problems and value of the test),
    that we can say: we have the pyramid - but the goal is not achieved.
   
    ReplyDelete
    Replies
     1. [b36-rounde]
        Mike WackerApril 23, 2015 at 11:22:00 AM PDT
       
        It can be hard to directly measure the unit/integration/E2E ratio for several reasons.
        However, deviating from the test pyramid has byproducts you can measure, such as increased
        test runtime and more flakes.
       
        Let me use sorting algorithms and running time as an analogy. Quicksort can take O(n^2)
        time in the worst case, but that worst case is rare enough that the expected runtime of
        quicksort is still O(n log n). However, if you use a sorting algorithm that always hit that
        O(n^2) worst case, for example selection sort, then the expected runtime inflates from O(n
        log n) to O(n^2).
       
        Think of E2E tests as your worst case. If you have a small number E2E tests, the overall
        runtime of all your tests will still be quite reasonable. However, if you mostly use E2E
        tests, then your test runtime (and the number of test flakes) will inflate significantly.
       
        Delete
        Reply
 2. [photo]
    Rafal MotykaApril 23, 2015 at 4:51:00 AM PDT
   
    I agree with the main idea, but it's nothing new. Let's look at V-model in testing.
    I would add one thing: Before unit test it would be nice to perform a code deskcheck - statis
    testing - the first step in testing chain.
   
    ReplyDelete
    Replies
     1. [photo]
        Sebastian HeglmeierApril 25, 2015 at 3:24:00 PM PDT
       
        In my testing chain TDDing would be my first rather than a code deskcheck. If you want to
        test your code, why not simply do it beforehand? Might be quicker than pen&paper, more
        reliable, easier to reproduce, easier to extend .. and I sure find it more rewarding from a
        motivational perspective going from red to green than to write tests afterwards hoping that
        they turn green right away (and hoping that this 'green' is somewhat meaningful).
       
        Delete
        Reply
 3. [b36-rounde]
    Random KernelApril 23, 2015 at 5:18:00 AM PDT
   
    Hey Mike,
   
    Thanks for the article. I think that sentence is good to be highlighted: "The exact mix will be
    different for each team, but in general, it should retain that pyramid shape."
   
    A typical path for a test automation engineer is the following: 1) we do everything as close as
    possible to the real user's experience; 2) oh, well, those tests are too slow and unstable; 3)
    let's move to unit tests; 4) oh, well, unit tests are good and green, but we do miss some
    important bugs here; 4) both unit and end-to-end tests are important. I don't mention
    integration tests here, since it's a too general term, and they may differ in size and value
    even within one project, not to say about different projects and teams.
   
    Also, sometimes end-to-end tests are built upon API tests that may be considered as unit tests
    in some extent. So when we talk about percentage, we should take it into account, as well.
   
    With all that in mind, here is my point: yes, the pyramid makes sense, but don't pay too much
    attention to 70/20/10 or anything like that. Think in term of _your_ product, its specific, its
    challenges, and build your strategy and tactics on that.
   
    ReplyDelete
    Replies
     1. [b36-rounde]
        Mike WackerApril 23, 2015 at 11:39:00 AM PDT
       
        I tend to take the opposite approach, starting with unit tests and only using larger tests
        when unit tests clearly are not sufficient.
       
        As a useful thought experiment, pretend that you could only write 10 E2E tests, and ask
        yourself where those tests would go. As you said, each product has its own unique specifics
        and challenges, so the answer will be different for each product.
       
        The testing pyramid can generalize to any product, and the problems associated with too
        many E2E tests will affect all products, but what will be unique for each product is where
        unit tests become insufficient and larger tests are needed.
       
        Delete
     2. [b36-rounde]
        Random KernelApril 24, 2015 at 4:08:00 AM PDT
       
        Mike, I got your point. And this thought experiment seems to be useful. Let me share some
        thoughts, though.
       
        Suppose your product has fundamental web interface. In this product,
       
        1) part of UI operations can be executed without UI via API or command line interface. So
        you can write some basic unit tests for single operations, but are you going to verify UI
        operations, as well, to make sure, say, that not only core operations are successful, but
        also the changes made in the browser are delivered to the core functions? Also, some
        operations in UI may require preliminary steps. Each step may be considered as a test
        itself, but the real value comes from the whole chain of steps, because each step can be
        successful, and the chain is not. What if you guesses about necessary E2E tests for you
        products are wrong, and with all your formal unit tests coverage you miss important
        scenarios?
       
        2) part of the other operations are intended for run in UI by their nature. Say, your
        product opens RDP session to some computer in your browser and run some UI-based operations
        there. Will you be satisfied with some mocks/stubs imitating remote computer behavior, or
        will you try to handle real sessions, as well?
       
        You say that E2E tests are not fast, not reliable and hard to debug. But what if you are
        able to make them sufficiently fast, reliable, easy to implement and change when necessary,
        and you can easily understand test failures by their results? Will you say yes in that
        case?
       
        I still agree with the concept of the testing pyramid, though.
       
        Delete
        Reply
 4. [b36-rounde]
    emddudleyApril 23, 2015 at 5:47:00 AM PDT
   
    Do you guys still use the small/medium/large test nomenclature that Simon Stewart wrote about
    in 2010?
   
    ReplyDelete
    Replies
     1. [b36-rounde]
        Mike WackerApril 23, 2015 at 11:24:00 AM PDT
       
        Yes, we still do. If you're trying to sell the testing pyramid to someone, using small/
        medium/large instead of unit/integration/E2E may make it an easier sell.
       
        Delete
        Reply
 5. [photo]
    Lovro PandzicApril 24, 2015 at 11:34:00 PM PDT
   
    You should mention FIRST properties of unit tests.
    FIRST should be applied to all tests much as possible, but bigger the scope, the harder it
    gets.
   
    ReplyDelete
 6. [photo]
    Ran TavoryApril 25, 2015 at 10:47:00 PM PDT
   
    Tests, as well as monitoring of all sorts (app level monitoring, host, user, kpi) are all part
    of the immune system of your software IMO .
    I agree with the 70/20/10 approach but on top of the pyramid I would add another pyramid of
    monitoring. I argue that well thought out monitoring is more effective than tests in many
    cases, particularly in CD (continuous deployment) where MTTR (mean time to recovery) is far
    more important than MTBF (mean time bw failures)
    I'd go with 50/50 bw testing and monitoring time investment wise, at least in CD scenario.
   
    BTW having to wait for tests (any test) to run at night doesn't make sense in many cases
    anyway, CD included.
   
    ReplyDelete
 7. [photo]
    Ran TavoryApril 26, 2015 at 12:24:00 AM PDT
   
    Coming from the CD (Continuous Deployment) perspective, I think things are a little different.
    With CD the complete "immune system" means that monitoring (different types of monitors) are
    part of the immune system aside tests and they complement the tests (other components in the
    immune system are code review, static code analysis etc).
    Interestingly, monitoring resembles testing in many ways, so you'd have application level
    monitoring, which usually are similar in scope to unit tests - they usually monitor individual
    in-process complements (e.g. size of internal memory buffer, operations/sec etc), you have host
    level monitoring (CPU, disk etc), which is similar in concept to integration tests and you have
    KPI monitoring (e.g. # daily active users etc) which takes the user perspective and is similar
    to E2E tests.
    The picture would not be whole if you don't mention monitoring since, IMO monitoring come on
    the expense of testing - developers either invest time in tests or in monitoring (or split
    their efforts b/w these two)
    I would argue that, at least in CD where MTTR (Mean Time to Recovery) is far more important
    than MTBF (Mean Time Between Failures), monitoring take precedence over tests. I would draw yet
    another pyramid - a monitoring pyramid - on top of the testing pyramid such that 70% is
    application level monitoring, 20% host monitoring and 10% KPI. And the entire effort b/w tests
    and monitoring should be split 50/50 (or some other number that makes sense for your use case -
    in some cases it's 90/10).
    Again, I'm speaking from the perspective of CD - which may or may not apply to some google
    systems, but many dev organizations tend to like it.
    BTW speaking about putting the user in the center, delivering value fast and being able to
    verify the value with actual users in matter of hours - the core value of CD - fast feedback
    (including the user in the feedback loop) - *is* putting the user in the center.
   
    BTW2, a feedback loop needs to be in the order of a few hours at most (minutes sometimes),
    *including actual users* in the loop, not just automated tests. As such - running E2E tests
    during the night simply makes no sense.
   
    ReplyDelete
    Replies
     1. [b36-rounde]
        Mike WackerApril 28, 2015 at 11:35:00 AM PDT
       
        Monitoring was not in scope for this blog post, but I do agree that monitoring is
        important, and that good monitoring will catch bugs that even good tests miss. There is a
        trade-off at times between monitoring and testing as you said, but they're not always
        mutually exclusive.
       
        Monitoring is not particular useful, for example, if the code for your service doesn't even
        build. And if all your tests fail, you probably don't need monitoring to know that if you
        try to deploy that service in its current state, everything will break.
       
        Your service doesn't need to be perfect before you deploy it, but it does need to meet some
        minimal quality bar before monitoring becomes useful. And tests are how you get it to that
        bar.
       
        Delete
        Reply
 8. [b36-rounde]
    오장일April 27, 2015 at 1:32:00 AM PDT
   
    Hello
    I would like to translate the contents of this blog in Korean on My Blog.
    is it possible?
   
    Have a good day.
   
    ReplyDelete
 9. [b36-rounde]
    RecurrenceApril 27, 2015 at 1:50:00 PM PDT
   
    Sounds like Test Instability and Timeliness are your biggest beefs (Addresses basically
    everything in 'What Went Wrong')
   
    Just throw a thousand instances at the problem and have your results in (overhead +
    longest_test time). I've done something similar but with only 300 instances some years ago and
    we had E2E results in 12 minutes after EVERY commit.
   
    Benefits:
    + You can isolate the test (General cause of instability)
    + Results are quick and can be traced to a specific commit
    + Comparatively little waiting period for results
   
    That said, if your labs can't keep themselves up, you have no business in the E2E testing
    space.
   
    ReplyDelete
    Replies
     1. [b36-rounde]
        Mike WackerApril 28, 2015 at 11:27:00 AM PDT
       
        Not everybody has the resources or funding to just throw a thousand instances at the
        problem, especially as they get more and more E2E tests. And building and deploying your
        service is typically part of that process of running E2E tests. For you, that doesn't seem
        to take a long time, but I've worked on teams that couldn't even build their service in 12
        minutes, much less build, deploy, and run tests in 12 minutes. In short, I have doubts on
        whether that approach can scale beyond your specific situation.
       
        But even if you can get it down to 12 minutes (and your E2E tests are not flaky), that's
        still slow compared to < 1/10 of a second for each unit test. If you want developers
        regular running some tests before they check-in, unit tests are the way to go.
       
        Delete
     2. [b36-rounde]
        Random KernelApril 29, 2015 at 3:54:00 AM PDT
       
        Sure enough, developers would prefer running unit tests rather then E2E ones. But should
        this criteria be the most important? Please, consider two options:
       
        1) running E2E tests takes more time than unit tests, but you have an opportunity to run
        these checks because you consider them necessary;
        2) you don't run E2E tests at all, or run only small amount of them (with percentage in
        testing pyramid you consider acceptable)
       
        In both options, developers will only run unit tests, but in the first option, you will be
        able to have deeper coverage and more certainty in product quality. Well, in the worst
        case, developers will be informed on results after check-ins, but later better than never.
        In the best case (E2E tests are not long enough, and developers don't hurry with
        check-ins), you will kill two birds with one stone (better coverage and running tests
        before check-in).
       
        Delete
     3. [b36-rounde]
        UnknownApril 30, 2015 at 12:56:00 AM PDT
       
        To ignore the benefits of both end to end and unit testing is a mistake That said, this
        article ignores some of the more difficult problems with Unit Tests. For one, they can
        create a barrier to refactoring especially if that refactoring breaks many tests and it's
        now the tests that are wrong, not the code that has been refactored. More over, if you need
        a significant amount of state in order to complete the test, a unit test is unlikely to
        give you the results.
       
        With end to end tests it's likely they will not break when refactoring. If there is a
        failure in the end to end test than of course you need to isolate and that is when (smaller
        more focused) unit tests are immensely useful.
       
        Delete
     4. [b36-rounde]
        Mike WackerMay 1, 2015 at 12:44:00 PM PDT
       
        It's not just a question of coverage and quality - it's a tradeoff between quality and
        velocity.
       
        I sometimes will run my unit tests 12 times in the course of minutes, not once every 12
        minutes. If my team takes over an hour to build, waiting on E2E tests gets much worse.
       
        In my composite sketch, the problem was never that the E2E tests had bad coverage. The
        problem was relying on them delayed the released and forced developers to work overtime.
        Delayed releases and slow bug fixes are neither good for the user nor good for the
        developer.
       
        Even if the testing pyramid only gets you a B in terms of quality and coverage, while the
        E2E strategy gets you an A - I don't believe that's true, but will assume so to make a
        point - is going from a B to an A worth it if it takes you twice as long, for example?
       
        Delete
        Reply
10. [Soul]
    Jonty...April 28, 2015 at 2:35:00 AM PDT
   
    Nice article Mike -
   
    While I agree in principle of IT and Software delivery, am not sure if am board with this
    statement : "Although end-to-end tests do a better job of simulating real user scenarios, this
    advantage quickly becomes outweighed by all the disadvantages of the end-to-end feedback loop"
   
    Have we reached a maturity level, where in software building process has become so much
    standarized and defects more predictable ?
   
    I would argue there are whole lot of systems which still puts user feedback, by simulating end
    user flows high on the pedestal than faster feedback.
   
    One key reason for E2E tests is because simulating all aspects of user behavior (the
    fundamental reason of the application) is too tedious at units level
   
    It is great to see most org adopting matured and faster dev practices, but jumping into it
    without setting the house right for me is the biggest risk :)
   
    I however subscribe to your thought, building layered Architecture is the need of the hour :)
   
    ReplyDelete
11. [b36-rounde]
    Giorgi KikolashviliApril 29, 2015 at 8:03:00 AM PDT
   
    Thanks for sharing your experience.
   
    I'm new to TDD. I'm reading "Growing Object-Oriented Software, Guided by Tests" by Steve
    Freeman. The author has very interesting argument for end-to-end tests:
   
    "Running end-to-end tests tells us about the external quality of our system, and writing them
    tells us something about how well we (the whole team) understand the domain, but end-to-end
    tests don’t tell us how well we’ve written the code. Writing unit tests gives us a lot of
    feedback about the quality of our code, and running them tells us that we haven’t broken any
    classes—but, again, unit tests don’t give us enough confidence that the system as a whole
    works."
   
    So I understand this statement as end-to-end tests give us feedback and tells whether we are
    moving in the right direction. After reading your post I got feeling that end-to-end tests are
    a waste of time. Don't you think they play vital role in the early stage of development?
   
    ReplyDelete
    Replies
     1. [b36-rounde]
        Mike WackerMay 1, 2015 at 12:57:00 PM PDT
       
        You can have bad E2E tests that externally simulate things real users don't do; just
        because a test is E2E doesn't necessarily mean it represents the user. You can also have
        good unit tests driven by user scenarios, which test the specific task a unit would be
        given for a particular user scenario, as opposed to testing the unit as some abstract
        entity.
       
        Quality and user impact are measured in both visible and invisible ways. A bug where an
        implementation of equals() is broken could easily break the entire system and have a severe
        user impact. However, it's obviously harder to visibly explain the impact of that bug in
        terms of a specific user scenario or a specific E2E test.
       
        Delete
        Reply
12. [b36-rounde]
    AnandMay 3, 2015 at 7:01:00 AM PDT
   
    Got your point. I think for finance domain application stakeholders give more importance to E2E
    automated tests more as they want to ensure End User Experience or Customer Journeys meet the
    expected behavior. These tests not necessarily serve the purpose when designed badly and
    generally concentrate on proving something works. They are under a wrong pre-text that you can
    replace manual tests with these E2E tests.
   
    ReplyDelete
13. [21fc27a2ac]
    Federico RampazzoMay 5, 2015 at 9:36:00 AM PDT
   
    I feel like the title is misleading. I disagree with the title but I agree completely on the
    article
    E2E tests are important - but you can't rely ONLY on them.
    E2E tests are good for quality assurance, unit and integration tests are an aid to developers.
   
    ReplyDelete
14. [b36-rounde]
    Gaurav JoshiMay 6, 2015 at 3:29:00 AM PDT
   
    What are your suggestions for legacy systems? Benefits of automated end to end tests are much
    larger than unit testing or acceptance testing. For new functional development, I completely
    agree with your approach.
   
    At the moment, we are concentrating automating end to end regression manual tests to cut down
    our release cycle. We plan to add integration/unit testing to identified problem area. Could
    you suggest alternative approach.
   
    ReplyDelete
    Replies
     1. [b36-rounde]
        Mike WackerMay 6, 2015 at 9:18:00 AM PDT
       
        Buy a copy of Working Effectively with Legacy Code by Michael Feathers :) Beyond that, you
        should measure progress not by whether you have a pyramid or not, but relative to where you
        were before. Even if you won't have a proper pyramid for a long time, but does it look more
        like a period today than yesterday?
       
        Delete
     2. [b36-rounde]
        Gaurav JoshiMay 7, 2015 at 10:09:00 PM PDT
       
        Will do. We were not targeting for pyramid but wish to achieve that during the journey. So
        for a legacy system which has no unit test coverage, what would be your suggestion?
        1. Write E2E tests (we will use robot framework)- It would give us the most benefits
        2. Write unit tests - Faster feedback for very low coverage.
        3. Write test for subsystem which encompasses lot of classes and represent a fairly big
        unit of work - Use some thing like approval testing
       
        Please ignore if the book already answers these questions. BTW I did not understand "but
        does it look more like a period today than yesterday?" , Can you please elaborate?
       
        Delete
        Reply
15. []
    Adoniram MishraMay 6, 2015 at 8:41:00 AM PDT
   
    I too am a believer of a test pyramid and just to add I believe in not repeating the test i.e
    if something can be tested at a lower level, push it to the lower level and try not to have the
    same validation at higher level. Also, We should aim for ~100% unit test code coverage as unit
    tests are first and most strongest line of defence.
   
    ReplyDelete
16. []
    Shadab AnsariMay 7, 2015 at 8:41:00 AM PDT
   
    Can I post this article in my blog by giving you due credit? It is really an eye opener for QA
    managers.
   
    ReplyDelete
    Replies
     1. [b36-rounde]
        Mike WackerMay 7, 2015 at 10:15:00 AM PDT
       
        That's fine, as long as you both link to the original article and give due credit as you
        said.
       
        Delete
        Reply
17. [b36-rounde]
    Gaurav JoshiMay 7, 2015 at 10:03:00 PM PDT
   
    What are your thoughts on acceptance testing ? They are E2E in nature
   
    ReplyDelete
18. [b36-rounde]
    Michael McDermottMay 11, 2015 at 7:23:00 AM PDT
   
    Do you think working in a dynamically typed language (such as Python or Ruby) changes the
    arguments here in some way?
   
    ReplyDelete
    Replies
     1. [b36-rounde]
        Mike WackerMay 11, 2015 at 8:53:00 AM PDT
       
        The fundamental argument is the same. Additionally, you may need a few more unit tests to
        guard against things that normally would be caught at compile-time with a statically typed
        language.
       
        Delete
        Reply
19. [b36-rounde]
    itinsleyMay 11, 2015 at 7:52:00 PM PDT
   
    I think a lot of posters are ignoring the importance of letting your tests drive your design.
    Thinking about how you are going to test your code encourages you to design good abstractions
    in your classes and services and should allow you to test business processes at the unit or
    integration level. When the tests exist with a close relation to the function or process the
    tests are likely to stay relevant and up-to-date. Having worked on a team that had extensive
    (many 1000's) of Cucumber E2E tests we ended up in a situation where engineers were maintaining
    tests while being unsure if the tests were still actually relevant or simply legacy remains.
    Because they are E2E by definition it is hard to define ownership of these tests in relation to
    any particular codebase, library or service and they end up as poorly maintained 'common' code
    with no individual feeling they have the right to delete them. Inevitably the tests continue to
    grow and build times get out of hand. If you are doing TDD using E2E tests the results can be
    disastrous with logic scattered around all over the code base.
   
    By all means, have E2E tests but keep them broad and shallow - i.e. the 10% described in the
    article.
   
    ReplyDelete
20. [photo]
    Voky SweetJune 12, 2015 at 4:09:00 PM PDT
   
    How about this? Stop blaming on the E2E Test Methodology, but blame on you, the developers for
    now doing a good job. I think developers are not capable if they break 10 things to fix 1
    thing. Coming from defense background, I see that developers of the web technology don't
    seriously take responsibilities and accountability. If you are likely to break features that
    already worked from before, maybe it's time that go back to school.
   
    ReplyDelete

Add comment
Load more...

The comments you read and contribute here belong only to the person who posted them. We reserve the
right to remove off-topic comments.

Newer Post Older Post Home
Subscribe to: Post Comments (Atom)

Search This Blog

Loading...
#

Subscribe

Subscribe by email

follow us in feedly

[feed-icon]  Site Feed [RLXA]

Follow @googletesting
#

Tags

  * TotT (54)
  * GTAC (50)
  * James Whittaker (42)
  * Misko Hevery (32)
  * Patrick Copeland (23)
  * Anthony Vallone (20)
  * Jobs (14)
  * C++ (11)
  * Andrew Trenk (8)
  * JavaScript (7)
  * Allen Hutchison (6)
  * Zhanyong Wan (6)
  * Harry Robinson (5)
  * Java (5)
  * Julian Harty (5)
  * Alberto Savoia (4)
  * Patrik Höglund (4)
  * Philip Zembrod (4)
  * Shyam Seshadri (4)
  * Chrome (3)
  * Erik Kuefler (3)
  * John Thomas (3)
  * Marc Kaplan (3)
  * Markus Clermont (3)
  * APIs (2)
  * Alek Icev (2)
  * April Fools (2)
  * Chaitali Narla (2)
  * Chrome OS (2)
  * Diego Salas (2)
  * George Pirocanac (2)
  * Jason Arbon (2)
  * Mobile (2)
  * Simon Stewart (2)
  * Tony Voellm (2)
  * Yvette Nameth (2)
  * Zuri Kemp (2)
  * Aaron Jacobs (1)
  * Adam Porter (1)
  * Alan Faulkner (1)
  * Alan Myrvold (1)
  * Alex Eagle (1)
  * Android (1)
  * Antoine Picard (1)
  * App Engine (1)
  * Arif Sukoco (1)
  * Bruce Leban (1)
  * Christopher Semturs (1)
  * Dave Chen (1)
  * Dmitry Vyukov (1)
  * Dori Reuveni (1)
  * Eduardo Bravo Ortiz (1)
  * Ekaterina Kamenskaya (1)
  * Espresso (1)
  * Google+ (1)
  * Goranka Bjedov (1)
  * Hank Duan (1)
  * Havard Rast Blok (1)
  * Hongfei Ding (1)
  * Jason Elbaum (1)
  * Jason Huggins (1)
  * Jay Han (1)
  * Jessica Tomechak (1)
  * Jim Reardon (1)
  * Joe Allan Muharsky (1)
  * Joel Hynoski (1)
  * John Penix (1)
  * Jonathan Rockway (1)
  * Jonathan Velasquez (1)
  * Julie Ralph (1)
  * Karin Lundberg (1)
  * Kaue Silveira (1)
  * Kevin Graney (1)
  * Kirkland (1)
  * Kurt Alfred Kluever (1)
  * Mark Ivey (1)
  * Mark Striebeck (1)
  * Marko Ivanković (1)
  * Michael Bachman (1)
  * Mike Wacker (1)
  * Mona El Mahdy (1)
  * Noel Yap (1)
  * Patricia Legaspi (1)
  * Peter Arrenbrecht (1)
  * Phil Rollet (1)
  * Pooja Gupta (1)
  * Radoslav Vasilev (1)
  * Rajat Dewan (1)
  * Rajat Jain (1)
  * Rich Martin (1)
  * Richard Bustamante (1)
  * Roshan Sembacuttiaratchy (1)
  * Ruslan Khamitov (1)
  * Sean Jordan (1)
  * Sharon Zhou (1)
  * Stephen Ng (1)
  * Tejas Shah (1)
  * Test Analytics (1)
  * Vojta Jína (1)
  * WebRTC (1)

#

Archives

  * June 2015 (1)
  * May 2015 (2)
  * April 2015 (2)
  * March 2015 (1)
  * February 2015 (1)
  * January 2015 (2)
  * December 2014 (2)
  * November 2014 (1)
  * October 2014 (2)
  * September 2014 (2)
  * August 2014 (2)
  * July 2014 (3)
  * June 2014 (3)
  * May 2014 (2)
  * April 2014 (2)
  * March 2014 (2)
  * February 2014 (1)
  * January 2014 (2)
  * December 2013 (1)
  * November 2013 (1)
  * October 2013 (1)
  * August 2013 (2)
  * July 2013 (1)
  * June 2013 (2)
  * May 2013 (2)
  * April 2013 (2)
  * March 2013 (2)
  * January 2013 (2)
  * December 2012 (1)
  * November 2012 (2)
  * October 2012 (3)
  * September 2012 (1)
  * August 2012 (4)
  * November 2011 (2)
  * October 2011 (5)
  * September 2011 (2)
  * August 2011 (4)
  * July 2011 (2)
  * June 2011 (5)
  * May 2011 (4)
  * April 2011 (3)
  * March 2011 (4)
  * February 2011 (5)
  * January 2011 (3)
  * December 2010 (3)
  * November 2010 (3)
  * October 2010 (4)
  * September 2010 (8)
  * August 2010 (3)
  * July 2010 (3)
  * June 2010 (2)
  * May 2010 (2)
  * April 2010 (3)
  * March 2010 (3)
  * February 2010 (2)
  * January 2010 (1)
  * December 2009 (3)
  * November 2009 (2)
  * October 2009 (3)
  * September 2009 (5)
  * August 2009 (4)
  * July 2009 (15)
  * June 2009 (8)
  * May 2009 (3)
  * April 2009 (2)
  * February 2009 (5)
  * January 2009 (4)
  * December 2008 (6)
  * November 2008 (8)
  * October 2008 (9)
  * September 2008 (8)
  * August 2008 (9)
  * July 2008 (9)
  * June 2008 (6)
  * May 2008 (6)
  * April 2008 (4)
  * March 2008 (4)
  * February 2008 (4)
  * January 2008 (2)
  * October 2007 (6)
  * September 2007 (5)
  * August 2007 (3)
  * July 2007 (2)
  * June 2007 (2)
  * May 2007 (2)
  * April 2007 (7)
  * March 2007 (5)
  * February 2007 (5)
  * January 2007 (4)

#
   
Awesome Inc. template. Powered by Blogger.
#

#+end_example
* TODO DevOps Chef common cookbooks
| Name    | Summary |
|---------+---------|
| Jenkins |         |
| sandbox |         |
|---------+---------|
| backup  |         |
| nagios  |         |
* DONE [#B] osc sandbox-test: /root/jenkins-cli.jar download in serverspec is incorrect, jenkins is not started yet
  CLOSED: [2015-07-09 Thu 08:12]
http://50.198.76.249:443/view/All/job/KitchenDockerTestAllCookbooks/135/console
http://stackoverflow.com/questions/17344061/please-wait-while-jenkins-is-restarting-waiting-long

#+BEGIN_EXAMPLE
Please wait while Jenkins is getting ready to work...

Your browser will reload automatically when Jenkins is ready.
#+END_EXAMPLE

#+BEGIN_EXAMPLE
root@74f2364c4690:~# file /root/jenkins-cli.jar
file /root/jenkins-cli.jar
/root/jenkins-cli.jar: HTML document, UTF-8 Unicode text, with very long lines
root@74f2364c4690:~# 
root@74f2364c4690:~# java -jar /root/jenkins-cli.jar -s http://localhost:28080/ build  UpdateJenkinsItself -w 
<-s http://localhost:28080/ build  UpdateJenkinsItself -w 
Error: Invalid or corrupt jarfile /root/jenkins-cli.jar

root@74f2364c4690:~# curl --noproxy 127.0.0.1 -o /root/jenkins-cli2.jar http://127.0.0.1:28080/jnlpJars/jenkins-cli.jar
<t/jenkins-cli2.jar http://127.0.0.1:28080/jnlpJars/jenkins-cli.jar
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  769k  100  769k    0     0  75.0M      0 --:--:-- --:--:-- --:--:-- 83.4M
root@74f2364c4690:~# ls -lth /root/jenkins-cli*.jar
ls -lth /root/jenkins-cli*.jar
-rw-r--r-- 1 root root 770K Jul  7 22:25 /root/jenkins-cli2.jar
-rw-r--r-- 1 root root 5.0K Jul  7 15:38 /root/jenkins-cli.jar
root@74f2364c4690:~# cat /root/jenkins-cli.jar
cat /root/jenkins-cli.jar




    
    <!DOCTYPE html><html><head resURL="/static/bf38fb7d">
    

    <title>Jenkins [Jenkins]</title><link rel="stylesheet" href="/static/bf38fb7d/css/style.css" type="text/css" /><link rel="stylesheet" href="/static/bf38fb7d/css/color.css" type="text/css" /><link rel="stylesheet" href="/static/bf38fb7d/css/responsive-grid.css" type="text/css" /><link rel="shortcut icon" href="/static/bf38fb7d/favicon.ico" type="image/vnd.microsoft.icon" /><script>var isRunAsTest=false; var rootURL=""; var resURL="/static/bf38fb7d";</script><script src="/static/bf38fb7d/scripts/prototype.js" type="text/javascript"></script><script src="/static/bf38fb7d/scripts/behavior.js" type="text/javascript"></script><script src='/adjuncts/bf38fb7d/org/kohsuke/stapler/bind.js' type='text/javascript'></script><script src="/static/bf38fb7d/scripts/yui/yahoo/yahoo-min.js"></script><script src="/static/bf38fb7d/scripts/yui/dom/dom-min.js"></script><script src="/static/bf38fb7d/scripts/yui/event/event-min.js"></script><script src="/static/bf38fb7d/scripts/yui/animation/animation-min.js"></script><script src="/static/bf38fb7d/scripts/yui/dragdrop/dragdrop-min.js"></script><script src="/static/bf38fb7d/scripts/yui/container/container-min.js"></script><script src="/static/bf38fb7d/scripts/yui/connection/connection-min.js"></script><script src="/static/bf38fb7d/scripts/yui/datasource/datasource-min.js"></script><script src="/static/bf38fb7d/scripts/yui/autocomplete/autocomplete-min.js"></script><script src="/static/bf38fb7d/scripts/yui/menu/menu-min.js"></script><script src="/static/bf38fb7d/scripts/yui/element/element-min.js"></script><script src="/static/bf38fb7d/scripts/yui/button/button-min.js"></script><script src="/static/bf38fb7d/scripts/yui/storage/storage-min.js"></script><script src="/static/bf38fb7d/scripts/hudson-behavior.js" type="text/javascript"></script><script src="/static/bf38fb7d/scripts/sortable.js" type="text/javascript"></script><link rel="stylesheet" href="/static/bf38fb7d/scripts/yui/container/assets/container.css" type="text/css" /><link rel="stylesheet" href="/static/bf38fb7d/scripts/yui/assets/skins/sam/skin.css" type="text/css" /><link rel="stylesheet" href="/static/bf38fb7d/scripts/yui/container/assets/skins/sam/container.css" type="text/css" /><link rel="stylesheet" href="/static/bf38fb7d/scripts/yui/button/assets/skins/sam/button.css" type="text/css" /><link rel="stylesheet" href="/static/bf38fb7d/scripts/yui/menu/assets/skins/sam/menu.css" type="text/css" /><link rel="search" href="/opensearch.xml" type="application/opensearchdescription+xml" title="Jenkins" /><meta name="ROBOTS" content="INDEX,NOFOLLOW" /></head><body id="jenkins" class="yui-skin-sam jenkins-1.617" data-version="jenkins-1.617"><a href="#skip2content" class="skiplink">Skip to content</a><div id="page-head"><div id="header"><div class="logo"><a id="jenkins-home-link" href="/"><img src="/static/bf38fb7d/images/headshot.png" alt="title" id="jenkins-head-icon" /><img src="/static/bf38fb7d/images/title.png" alt="title" width="139" id="jenkins-name-icon" height="34" /></a></div><div class="login"></div><div class="searchbox hidden-xs"><form method="get" name="search" style="position:relative;" class="no-json"><div id="search-box-minWidth"></div><div id="search-box-sizer"></div><div id="searchform"><input name="q" placeholder="search" id="search-box" class="has-default-text" /> <a href="http://wiki.jenkins-ci.org/display/JENKINS/Search+Box"><img src="/static/bf38fb7d/images/16x16/help.png" style="width: 16px; height: 16px; " class="icon-help icon-sm" /></a><div id="search-box-completion"></div><script>createSearchBox("");</script></div></form></div></div><div id="breadcrumbBar"><tr id="top-nav"><td id="left-top-nav" colspan="2"><link rel='stylesheet' href='/adjuncts/bf38fb7d/lib/layout/breadcrumbs.css' type='text/css' /><script src='/adjuncts/bf38fb7d/lib/layout/breadcrumbs.js' type='text/javascript'></script><div class="top-sticker noedge"><div class="top-sticker-inner"><div id="right-top-nav"><div id="right-top-nav"><div class="smallfont"><a href="?auto_refresh=true">ENABLE AUTO REFRESH</a></div></div></div><ul id="breadcrumbs"></ul><div id="breadcrumb-menu-target"></div></div></div></td></tr></div></div><div id="page-body"><div class="row"><div id="side-panel"><div id="side-panel-content"></div></div><div id="main-panel"><div id="main-panel-content"><a name="skip2content"></a><h1 style="margin-top:4em">
        Please wait while Jenkins is getting ready to work<span id="progress">...</span></h1><p style="color:gray">Your browser will reload automatically when Jenkins is ready.</p><script>applySafeRedirector(window.location.href)</script></div></div></div></div><div id="footer-container" class="hidden-xs"><div id="footer"><span class="page_generated">
          Page generated:
          Jul 7, 2015 3:38:42 PM</span><span class="rest_api"><a href="api/">REST API</a></span><span class="jenkins_ver"><a href="http://jenkins-ci.org/">Jenkins ver. 1.617</a></span></div></div></body></html>
#+END_EXAMPLE
* TODO Bin: Deploy task take 15 min, which is too long
#+BEGIN_EXAMPLE
Started by user anonymous
Building in workspace /var/lib/jenkins/jobs/DeployGatewayAllInOne/workspace
[workspace] $ /bin/bash -ex /tmp/hudson8366937542985987921.sh
+ echo 'Deploy to 192.168.50.10:6022'
Deploy to 192.168.50.10:6022
+ git_repo_url=git@bitbucket.org:authright/iamdevops.git
+ git_repo=iamdevops
+ working_dir=/root/
+ branch_name=master
+ ssh_key_file=/var/lib/jenkins/.ssh/id_rsa
+ true
+ echo 'ps -ef | grep chef-solo || killall -9 chef-solo'
ps -ef | grep chef-solo || killall -9 chef-solo
+ ssh -i /var/lib/jenkins/.ssh/id_rsa -p 6022 -o StrictHostKeyChecking=no root@192.168.50.10 'killall -9 chef-solo || true'
chef-solo: no process found
+ code_sh=/root/iamdevops/misc/berk_update.sh
+ code_dir=/root/test
+ echo 'Update chef dependenies of berkshelf'
Update chef dependenies of berkshelf
+ ssh -i /var/lib/jenkins/.ssh/id_rsa -p 6022 -o StrictHostKeyChecking=no root@192.168.50.10 /root/iamdevops/misc/berk_update.sh /root/test git@bitbucket.org:authright/iamdevops.git iamdevops master gateway-auth
Git update code for 'git@bitbucket.org:authright/iamdevops.git' to /root/test, branch_name: master
Already on 'master'
Your branch is up-to-date with 'origin/master'.
Already up-to-date.
Generating locales...
  en_US.UTF-8... up-to-date
Generation complete.
removed ‘/root/test/master/iamdevops/cookbooks/packagecloud/Berksfile.lock’
removed ‘/root/test/master/iamdevops/cookbooks/packagecloud/Gemfile.lock’
removed ‘/root/test/master/iamdevops/cookbooks/runit/Berksfile.lock’
removed ‘/root/test/master/iamdevops/cookbooks/runit/Gemfile.lock’
removed ‘/root/test/master/iamdevops/cookbooks/runit/Cheffile.lock’
removed ‘/root/test/master/iamdevops/cookbooks/timezone-ii/Gemfile.lock’
removed ‘/root/test/master/iamdevops/cookbooks/java/Berksfile.lock’
removed ‘/root/test/master/iamdevops/cookbooks/linux-basic/Berksfile.lock’
removed ‘/root/test/master/iamdevops/cookbooks/linux-basic/Gemfile.lock’
removed ‘/root/test/master/iamdevops/cookbooks/gateway-auth/Berksfile.lock’
removed ‘/root/test/master/iamdevops/cookbooks/ssh/Berksfile.lock’
removed ‘/root/test/master/iamdevops/cookbooks/ssh/Gemfile.lock’
removed ‘/root/test/master/iamdevops/cookbooks/ssh_authorized_keys/Berksfile.lock’
removed ‘/root/test/master/iamdevops/cookbooks/ssh_authorized_keys/Gemfile.lock’
removed ‘/root/test/master/iamdevops/cookbooks/openssh/Berksfile.lock’
removed ‘/root/test/master/iamdevops/cookbooks/jenkins/Berksfile.lock’
removed ‘/root/test/master/iamdevops/cookbooks/jenkins/Gemfile.lock’
removed ‘/root/test/master/iamdevops/cookbooks/nagios3/Berksfile.lock’
removed ‘/root/test/master/iamdevops/cookbooks/logrotate/Gemfile.lock’
removed ‘/root/test/master/iamdevops/cookbooks/systempatch/Berksfile.lock’
Resolving cookbook dependencies...
Fetching 'gateway-auth' from source at .
Fetching 'nagios-auth' from source at ../nagios-auth
Fetching 'os-basic-auth' from source at ../os-basic-auth
Fetching cookbook index from https://supermarket.getchef.com...
Using 7-zip (1.0.2)
Using apache2 (3.1.0)
Using ark (0.9.0)
Using apt (2.6.1)
Using build-essential (2.2.3)
Using chef-sugar (3.1.0)
Using chef_handler (1.1.9)
Using firewall (1.1.1)
Using gateway-auth (0.0.1) from source at .
Using homebrew (1.12.0)
Using iptables (1.0.0)
Using java (1.31.0)
Using linux-basic (2.3.1)
Using locale (1.0.2)
Using nagios-auth (0.0.1) from source at ../nagios-auth
Using nagios3 (1.6.1)
Using nodejs (2.4.0)
Using ntp (1.8.6)
Using openssh (1.4.0)
Using openssl (4.1.2)
Using os-basic-auth (0.0.1) from source at ../os-basic-auth
Using poise (1.0.12)
Using selinux (0.9.0)
Using ssh_authorized_keys (0.1.0)
Using systempatch (1.1.3)
Using timezone-ii (0.2.0)
Using tomcat (0.17.3)
Using windows (1.37.0)
Using yum (3.6.1)
Using yum-epel (0.6.2)
copy cookbooks by tripping version number
+ echo 'Prepare chef configuration'
Prepare chef configuration
+ echo 'cookbook_path "/root/test/master/iamdevops/cookbooks"'
+ echo '{
"run_list": ["recipe[gateway-auth]"],
"gateway-auth":{"package_url":"http://192.168.50.10:28000/gateway-merge/"}
}'
+ scp -i /var/lib/jenkins/.ssh/id_rsa -P 6022 -o StrictHostKeyChecking=no /tmp/client.rb root@192.168.50.10:/root/client.rb
+ scp -i /var/lib/jenkins/.ssh/id_rsa -P 6022 -o StrictHostKeyChecking=no /tmp/client.json root@192.168.50.10:/root/client.json
+ echo 'Apply chef update'
Apply chef update
+ ssh -i /var/lib/jenkins/.ssh/id_rsa -p 6022 -o StrictHostKeyChecking=no root@192.168.50.10 chef-solo --config /root/client.rb -j /root/client.json
[2015-06-23T05:02:32+00:00] INFO: Forking chef instance to converge...
[2015-06-23T05:02:32+00:00] INFO: *** Chef 12.3.0 ***
[2015-06-23T05:02:32+00:00] INFO: Chef-client pid: 12203
[2015-06-23T05:08:27+00:00] INFO: Setting the run_list to ["recipe[gateway-auth]"] from CLI options
[2015-06-23T05:08:27+00:00] INFO: Run List is [recipe[gateway-auth]]
[2015-06-23T05:08:27+00:00] INFO: Run List expands to [gateway-auth]
[2015-06-23T05:08:27+00:00] INFO: Starting Chef Run for 981d09a8ece6
[2015-06-23T05:08:27+00:00] INFO: Running start handlers
[2015-06-23T05:08:27+00:00] INFO: Start handlers complete.
[2015-06-23T05:08:28+00:00] WARN: Cloning resource attributes for service[apache2] from prior resource (CHEF-3694)
[2015-06-23T05:08:28+00:00] WARN: Previous service[apache2]: /root/test/master/iamdevops/cookbooks/apache2/recipes/default.rb:206:in `from_file'
[2015-06-23T05:08:28+00:00] WARN: Current  service[apache2]: /root/test/master/iamdevops/cookbooks/nagios3/recipes/nagios_server.rb:20:in `from_file'
[2015-06-23T05:08:28+00:00] WARN: Cloning resource attributes for apt_package[tar] from prior resource (CHEF-3694)
[2015-06-23T05:08:28+00:00] WARN: Previous apt_package[tar]: /root/test/master/iamdevops/cookbooks/os-basic-auth/recipes/default.rb:14:in `block in from_file'
[2015-06-23T05:08:28+00:00] WARN: Current  apt_package[tar]: /root/test/master/iamdevops/cookbooks/nagios3/recipes/nagios_server.rb:26:in `block in from_file'
[2015-06-23T05:08:28+00:00] INFO: Processing ruby_block[Check network connectivity] action run (os-basic-auth::precheck line 18)
[2015-06-23T05:08:29+00:00] INFO: Processing apt_package[lsof] action install (os-basic-auth::default line 14)
[2015-06-23T05:08:30+00:00] INFO: Processing apt_package[tmux] action install (os-basic-auth::default line 14)
[2015-06-23T05:08:32+00:00] INFO: Processing apt_package[inotify-tools] action install (os-basic-auth::default line 14)
[2015-06-23T05:08:33+00:00] INFO: Processing apt_package[telnet] action install (os-basic-auth::default line 14)
[2015-06-23T05:08:34+00:00] INFO: Processing apt_package[tar] action install (os-basic-auth::default line 14)
[2015-06-23T05:08:35+00:00] INFO: Processing apt_package[tree] action install (os-basic-auth::default line 14)
[2015-06-23T05:08:37+00:00] INFO: Processing apt_package[vim] action install (os-basic-auth::default line 14)
[2015-06-23T05:08:38+00:00] INFO: Processing directory[/opt/authright] action create (os-basic-auth::basic line 14)
[2015-06-23T05:08:38+00:00] INFO: Processing directory[/opt/authright/download] action create (os-basic-auth::basic line 14)
[2015-06-23T05:08:38+00:00] INFO: Processing directory[/opt/authright/bin] action create (os-basic-auth::basic line 14)
[2015-06-23T05:08:38+00:00] INFO: Processing directory[/opt/authright/config] action create (os-basic-auth::basic line 14)
[2015-06-23T05:08:38+00:00] INFO: Processing directory[/opt/authright/config/env.d] action create (os-basic-auth::basic line 14)
[2015-06-23T05:08:38+00:00] INFO: Processing directory[/opt/authright/logs] action create (os-basic-auth::basic line 14)
[2015-06-23T05:08:38+00:00] INFO: Processing directory[/opt/authright/plugins] action create (os-basic-auth::basic line 14)
[2015-06-23T05:08:38+00:00] INFO: Processing directory[/data] action create (os-basic-auth::basic line 14)
[2015-06-23T05:08:38+00:00] INFO: Processing directory[/data/backup] action create (os-basic-auth::basic line 14)
[2015-06-23T05:08:38+00:00] INFO: Processing template[/etc/profile.d/profile_auth.sh] action create (os-basic-auth::basic line 22)
[2015-06-23T05:08:38+00:00] INFO: Processing link[/sbin/insserv] action create (os-basic-auth::basic line 28)
[2015-06-23T05:08:38+00:00] INFO: Processing ruby_block[set-env-java-home] action run (java::set_java_home line 19)
[2015-06-23T05:08:38+00:00] INFO: ruby_block[set-env-java-home] called
[2015-06-23T05:08:38+00:00] INFO: Processing directory[/etc/profile.d] action create (java::set_java_home line 26)
[2015-06-23T05:08:38+00:00] INFO: Processing file[/etc/profile.d/jdk.sh] action create (java::set_java_home line 30)
[2015-06-23T05:08:38+00:00] INFO: Processing java_ark[jdk] action install (java::oracle line 53)
[2015-06-23T05:08:38+00:00] INFO: Processing java_alternatives[set-java-alternatives] action set (/root/test/master/iamdevops/cookbooks/java/providers/ark.rb line 219)
[2015-06-23T05:08:40+00:00] INFO: Processing link[/usr/lib/jvm/default-java] action create (java::default_java_symlink line 16)
[2015-06-23T05:08:40+00:00] INFO: Processing apt_package[unzip] action install (java::oracle_jce line 33)
[2015-06-23T05:08:42+00:00] INFO: Processing apt_package[curl] action install (java::oracle_jce line 34)
[2015-06-23T05:08:43+00:00] INFO: Processing directory[/opt/java_jce/8] action create (java::oracle_jce line 36)
[2015-06-23T05:08:43+00:00] INFO: Processing execute[download jce] action run (java::oracle_jce line 41)
[2015-06-23T05:08:43+00:00] INFO: Processing execute[extract jce] action run (java::oracle_jce line 56)
[2015-06-23T05:08:43+00:00] INFO: Processing file[/usr/lib/jvm/java-8-oracle-amd64/jre/lib/security/local_policy.jar] action delete (java::oracle_jce line 68)
[2015-06-23T05:08:43+00:00] INFO: Processing link[/usr/lib/jvm/java-8-oracle-amd64/jre/lib/security/local_policy.jar] action create (java::oracle_jce line 72)
[2015-06-23T05:08:43+00:00] INFO: Processing file[/usr/lib/jvm/java-8-oracle-amd64/jre/lib/security/US_export_policy.jar] action delete (java::oracle_jce line 68)
[2015-06-23T05:08:43+00:00] INFO: Processing link[/usr/lib/jvm/java-8-oracle-amd64/jre/lib/security/US_export_policy.jar] action create (java::oracle_jce line 72)
[2015-06-23T05:08:43+00:00] INFO: Processing execute[Set urandom for java.security] action run (os-basic-auth::java line 33)
[2015-06-23T05:08:43+00:00] INFO: Processing execute[Guard resource] action run (dynamically defined)
[2015-06-23T05:08:43+00:00] INFO: Processing link[/usr/bin/java] action create (os-basic-auth::java line 43)
[2015-06-23T05:08:43+00:00] INFO: Processing cookbook_file[/usr/lib/jvm/java-8-oracle-amd64/jre/lib/security/jssecacerts] action create (os-basic-auth::java line 47)
[2015-06-23T05:08:43+00:00] INFO: Processing execute[Config SSHD] action run (os-basic-auth::conf_ssh line 12)
[2015-06-23T05:08:43+00:00] INFO: execute[Config SSHD] ran successfully
[2015-06-23T05:08:43+00:00] INFO: Processing directory[/root/.ssh] action create (os-basic-auth::conf_ssh line 48)
[2015-06-23T05:08:43+00:00] INFO: Processing template[/root/.ssh/authorized_keys] action create (os-basic-auth::conf_ssh line 60)
[2015-06-23T05:08:43+00:00] INFO: Processing apt_package[locales] action install (locale::default line 26)
[2015-06-23T05:08:44+00:00] INFO: Processing execute[Generate locale] action run (locale::default line 30)
[2015-06-23T05:08:44+00:00] INFO: Processing execute[Update locale] action run (locale::default line 35)
[2015-06-23T05:08:44+00:00] INFO: Processing execute[apt-get-update] action run (apt::default line 45)
[2015-06-23T05:08:44+00:00] INFO: Processing execute[apt-get update] action nothing (apt::default line 53)
[2015-06-23T05:08:44+00:00] INFO: Processing execute[apt-get autoremove] action nothing (apt::default line 61)
[2015-06-23T05:08:44+00:00] INFO: Processing execute[apt-get autoclean] action nothing (apt::default line 68)
[2015-06-23T05:08:44+00:00] INFO: Processing apt_package[update-notifier-common] action install (apt::default line 75)
[2015-06-23T05:08:46+00:00] INFO: Processing execute[apt-get-update-periodic] action run (apt::default line 80)
[2015-06-23T05:08:46+00:00] INFO: Processing directory[/var/cache/local] action create (apt::default line 91)
[2015-06-23T05:08:46+00:00] INFO: Processing directory[/var/cache/local/preseeding] action create (apt::default line 91)
[2015-06-23T05:08:46+00:00] INFO: Processing log[platform: ubuntu] action write (nagios3::nagios_server line 10)
[2015-06-23T05:08:46+00:00] INFO: platform: ubuntu
[2015-06-23T05:08:46+00:00] INFO: Processing apt_package[apache2] action install (apache2::default line 21)
[2015-06-23T05:08:47+00:00] INFO: Processing directory[/etc/apache2/sites-available] action create (apache2::default line 26)
[2015-06-23T05:08:47+00:00] INFO: Processing directory[/etc/apache2/sites-enabled] action create (apache2::default line 26)
[2015-06-23T05:08:47+00:00] INFO: Processing directory[/etc/apache2/mods-available] action create (apache2::default line 26)
[2015-06-23T05:08:47+00:00] INFO: Processing directory[/etc/apache2/mods-enabled] action create (apache2::default line 26)
[2015-06-23T05:08:47+00:00] INFO: Processing directory[/etc/apache2/conf-available] action create (apache2::default line 26)
[2015-06-23T05:08:47+00:00] INFO: Processing directory[/etc/apache2/conf-enabled] action create (apache2::default line 26)
[2015-06-23T05:08:47+00:00] INFO: Processing link[/etc/apache2/sites-enabled/default] action delete (apache2::default line 34)
[2015-06-23T05:08:47+00:00] INFO: Processing file[/etc/apache2/sites-available/default] action delete (apache2::default line 39)
[2015-06-23T05:08:47+00:00] INFO: Processing link[/etc/apache2/sites-enabled/default.conf] action delete (apache2::default line 34)
[2015-06-23T05:08:47+00:00] INFO: Processing file[/etc/apache2/sites-available/default.conf] action delete (apache2::default line 39)
[2015-06-23T05:08:47+00:00] INFO: Processing link[/etc/apache2/sites-enabled/000-default] action delete (apache2::default line 34)
[2015-06-23T05:08:47+00:00] INFO: Processing file[/etc/apache2/sites-available/000-default] action delete (apache2::default line 39)
[2015-06-23T05:08:47+00:00] INFO: Processing link[/etc/apache2/sites-enabled/000-default.conf] action delete (apache2::default line 34)
[2015-06-23T05:08:47+00:00] INFO: Processing file[/etc/apache2/sites-available/000-default.conf] action delete (apache2::default line 39)
[2015-06-23T05:08:47+00:00] INFO: Processing directory[/etc/apache2/conf.d] action delete (apache2::default line 46)
[2015-06-23T05:08:47+00:00] INFO: Processing directory[/var/log/apache2] action create (apache2::default line 51)
[2015-06-23T05:08:47+00:00] INFO: Processing apt_package[perl] action install (apache2::default line 56)
[2015-06-23T05:08:48+00:00] INFO: Processing link[/usr/sbin/a2ensite] action delete (apache2::default line 59)
[2015-06-23T05:08:48+00:00] INFO: Processing template[/usr/sbin/a2ensite] action create (apache2::default line 64)
[2015-06-23T05:08:48+00:00] INFO: Processing link[/usr/sbin/a2dissite] action delete (apache2::default line 59)
[2015-06-23T05:08:48+00:00] INFO: Processing template[/usr/sbin/a2dissite] action create (apache2::default line 64)
[2015-06-23T05:08:48+00:00] INFO: Processing link[/usr/sbin/a2enmod] action delete (apache2::default line 59)
[2015-06-23T05:08:48+00:00] INFO: Processing template[/usr/sbin/a2enmod] action create (apache2::default line 64)
[2015-06-23T05:08:48+00:00] INFO: Processing link[/usr/sbin/a2dismod] action delete (apache2::default line 59)
[2015-06-23T05:08:48+00:00] INFO: Processing template[/usr/sbin/a2dismod] action create (apache2::default line 64)
[2015-06-23T05:08:48+00:00] INFO: Processing link[/usr/sbin/a2enconf] action delete (apache2::default line 59)
[2015-06-23T05:08:48+00:00] INFO: Processing template[/usr/sbin/a2enconf] action create (apache2::default line 64)
[2015-06-23T05:08:48+00:00] INFO: Processing link[/usr/sbin/a2disconf] action delete (apache2::default line 59)
[2015-06-23T05:08:48+00:00] INFO: Processing template[/usr/sbin/a2disconf] action create (apache2::default line 64)
[2015-06-23T05:08:48+00:00] INFO: Processing directory[/etc/apache2/ssl] action create (apache2::default line 122)
[2015-06-23T05:08:48+00:00] INFO: Processing directory[/var/cache/apache2] action create (apache2::default line 122)
[2015-06-23T05:08:48+00:00] INFO: Processing directory[/var/lock/apache2] action create (apache2::default line 129)
[2015-06-23T05:08:48+00:00] INFO: Processing template[/etc/sysconfig/apache2] action create (apache2::default line 140)
[2015-06-23T05:08:48+00:00] INFO: Processing template[/etc/apache2/envvars] action create (apache2::default line 149)
[2015-06-23T05:08:48+00:00] INFO: Processing template[apache2.conf] action create (apache2::default line 158)
[2015-06-23T05:08:48+00:00] INFO: Processing file[/etc/apache2/conf-available/security] action delete (apache2::default line 26)
[2015-06-23T05:08:48+00:00] INFO: Processing template[/etc/apache2/conf-available/security.conf] action create (apache2::default line 30)
[2015-06-23T05:08:48+00:00] INFO: Processing execute[a2enconf security.conf] action run (apache2::default line 27)
[2015-06-23T05:08:48+00:00] INFO: Processing file[/etc/apache2/conf-available/charset] action delete (apache2::default line 26)
[2015-06-23T05:08:48+00:00] INFO: Processing template[/etc/apache2/conf-available/charset.conf] action create (apache2::default line 30)
[2015-06-23T05:08:48+00:00] INFO: Processing execute[a2enconf charset.conf] action run (apache2::default line 27)
[2015-06-23T05:08:48+00:00] INFO: Processing file[/etc/apache2/ports] action delete (apache2::default line 26)
[2015-06-23T05:08:48+00:00] INFO: Processing template[/etc/apache2/ports.conf] action create (apache2::default line 30)
[2015-06-23T05:08:48+00:00] INFO: Processing file[/etc/apache2/mods-available/mpm_event.load] action create (apache2::mpm_prefork line 29)
[2015-06-23T05:08:48+00:00] INFO: Processing execute[a2dismod mpm_event] action run (apache2::mpm_prefork line 48)
[2015-06-23T05:08:48+00:00] INFO: Processing file[/etc/apache2/mods-available/mpm_worker.load] action create (apache2::mpm_prefork line 29)
[2015-06-23T05:08:48+00:00] INFO: Processing execute[a2dismod mpm_worker] action run (apache2::mpm_prefork line 48)
[2015-06-23T05:08:48+00:00] INFO: Processing template[/etc/apache2/mods-available/mpm_prefork.conf] action create (apache2::mpm_prefork line 23)
[2015-06-23T05:08:48+00:00] INFO: Processing file[/etc/apache2/mods-available/mpm_prefork.load] action create (apache2::mpm_prefork line 29)
[2015-06-23T05:08:48+00:00] INFO: Processing execute[a2enmod mpm_prefork] action run (apache2::mpm_prefork line 35)
[2015-06-23T05:08:48+00:00] INFO: Processing template[/etc/apache2/mods-available/status.conf] action create (apache2::mod_status line 23)
[2015-06-23T05:08:48+00:00] INFO: Processing file[/etc/apache2/mods-available/status.load] action create (apache2::mod_status line 29)
[2015-06-23T05:08:48+00:00] INFO: Processing execute[a2enmod status] action run (apache2::mod_status line 35)
[2015-06-23T05:08:48+00:00] INFO: Processing template[/etc/apache2/mods-available/alias.conf] action create (apache2::mod_alias line 23)
[2015-06-23T05:08:48+00:00] INFO: Processing file[/etc/apache2/mods-available/alias.load] action create (apache2::mod_alias line 29)
[2015-06-23T05:08:48+00:00] INFO: Processing execute[a2enmod alias] action run (apache2::mod_alias line 35)
[2015-06-23T05:08:48+00:00] INFO: Processing file[/etc/apache2/mods-available/auth_basic.load] action create (apache2::mod_auth_basic line 29)
[2015-06-23T05:08:48+00:00] INFO: Processing execute[a2enmod auth_basic] action run (apache2::mod_auth_basic line 35)
[2015-06-23T05:08:48+00:00] INFO: Processing file[/etc/apache2/mods-available/authn_core.load] action create (apache2::mod_authn_core line 29)
[2015-06-23T05:08:48+00:00] INFO: Processing execute[a2enmod authn_core] action run (apache2::mod_authn_core line 35)
[2015-06-23T05:08:48+00:00] INFO: Processing file[/etc/apache2/mods-available/authn_file.load] action create (apache2::mod_authn_file line 29)
[2015-06-23T05:08:48+00:00] INFO: Processing execute[a2enmod authn_file] action run (apache2::mod_authn_file line 35)
[2015-06-23T05:08:48+00:00] INFO: Processing file[/etc/apache2/mods-available/authz_core.load] action create (apache2::mod_authz_core line 29)
[2015-06-23T05:08:48+00:00] INFO: Processing execute[a2enmod authz_core] action run (apache2::mod_authz_core line 35)
[2015-06-23T05:08:48+00:00] INFO: Processing file[/etc/apache2/mods-available/authz_groupfile.load] action create (apache2::mod_authz_groupfile line 29)
[2015-06-23T05:08:48+00:00] INFO: Processing execute[a2enmod authz_groupfile] action run (apache2::mod_authz_groupfile line 35)
[2015-06-23T05:08:48+00:00] INFO: Processing file[/etc/apache2/mods-available/authz_host.load] action create (apache2::mod_authz_host line 29)
[2015-06-23T05:08:48+00:00] INFO: Processing execute[a2enmod authz_host] action run (apache2::mod_authz_host line 35)
[2015-06-23T05:08:48+00:00] INFO: Processing file[/etc/apache2/mods-available/authz_user.load] action create (apache2::mod_authz_user line 29)
[2015-06-23T05:08:48+00:00] INFO: Processing execute[a2enmod authz_user] action run (apache2::mod_authz_user line 35)
[2015-06-23T05:08:48+00:00] INFO: Processing template[/etc/apache2/mods-available/autoindex.conf] action create (apache2::mod_autoindex line 23)
[2015-06-23T05:08:48+00:00] INFO: Processing file[/etc/apache2/mods-available/autoindex.load] action create (apache2::mod_autoindex line 29)
[2015-06-23T05:08:48+00:00] INFO: Processing execute[a2enmod autoindex] action run (apache2::mod_autoindex line 35)
[2015-06-23T05:08:48+00:00] INFO: Processing template[/etc/apache2/mods-available/dir.conf] action create (apache2::mod_dir line 23)
[2015-06-23T05:08:48+00:00] INFO: Processing file[/etc/apache2/mods-available/dir.load] action create (apache2::mod_dir line 29)
[2015-06-23T05:08:48+00:00] INFO: Processing execute[a2enmod dir] action run (apache2::mod_dir line 35)
[2015-06-23T05:08:48+00:00] INFO: Processing file[/etc/apache2/mods-available/env.load] action create (apache2::mod_env line 29)
[2015-06-23T05:08:48+00:00] INFO: Processing execute[a2enmod env] action run (apache2::mod_env line 35)
[2015-06-23T05:08:48+00:00] INFO: Processing template[/etc/apache2/mods-available/mime.conf] action create (apache2::mod_mime line 23)
[2015-06-23T05:08:48+00:00] INFO: Processing file[/etc/apache2/mods-available/mime.load] action create (apache2::mod_mime line 29)
[2015-06-23T05:08:48+00:00] INFO: Processing execute[a2enmod mime] action run (apache2::mod_mime line 35)
[2015-06-23T05:08:48+00:00] INFO: Processing template[/etc/apache2/mods-available/negotiation.conf] action create (apache2::mod_negotiation line 23)
[2015-06-23T05:08:48+00:00] INFO: Processing file[/etc/apache2/mods-available/negotiation.load] action create (apache2::mod_negotiation line 29)
[2015-06-23T05:08:48+00:00] INFO: Processing execute[a2enmod negotiation] action run (apache2::mod_negotiation line 35)
[2015-06-23T05:08:48+00:00] INFO: Processing template[/etc/apache2/mods-available/setenvif.conf] action create (apache2::mod_setenvif line 23)
[2015-06-23T05:08:48+00:00] INFO: Processing file[/etc/apache2/mods-available/setenvif.load] action create (apache2::mod_setenvif line 29)
[2015-06-23T05:08:48+00:00] INFO: Processing execute[a2enmod setenvif] action run (apache2::mod_setenvif line 35)
[2015-06-23T05:08:48+00:00] INFO: Processing service[apache2] action enable (apache2::default line 206)
[2015-06-23T05:08:49+00:00] INFO: Processing service[apache2] action start (apache2::default line 206)
[2015-06-23T05:08:49+00:00] INFO: Processing service[apache2] action nothing (nagios3::nagios_server line 20)
[2015-06-23T05:08:49+00:00] INFO: Processing apt_package[tar] action install (nagios3::nagios_server line 26)
[2015-06-23T05:08:50+00:00] INFO: Processing apt_package[nagios3] action install (nagios3::nagios_server line 35)
[2015-06-23T05:08:51+00:00] INFO: Processing apt_package[nagios-nrpe-plugin] action install (nagios3::nagios_server line 35)
[2015-06-23T05:08:52+00:00] INFO: Processing apt_package[librrds-perl] action install (nagios3::nagios_server line 42)
[2015-06-23T05:08:54+00:00] INFO: Processing apt_package[libgd-gd2-perl] action install (nagios3::nagios_server line 42)
[2015-06-23T05:08:55+00:00] INFO: Processing apt_package[net-tools] action install (nagios3::nagios_server line 48)
[2015-06-23T05:08:56+00:00] INFO: Processing user[nagios] action create (nagios3::nagios_server line 53)
[2015-06-23T05:08:56+00:00] INFO: Processing template[/etc/nagios3/apache2.conf] action create (nagios3::nagios_server line 58)
[2015-06-23T05:08:56+00:00] INFO: Processing template[/etc/nagios3/nagios.cfg] action create (nagios3::nagios_server line 92)
[2015-06-23T05:08:56+00:00] INFO: Processing template[/etc/nagios3/commands.cfg] action create (nagios3::nagios_server line 104)
[2015-06-23T05:08:56+00:00] INFO: Processing template[/etc/nagios3/conf.d/localhost_nagios2.cfg] action create (nagios3::nagios_server line 113)
[2015-06-23T05:08:56+00:00] INFO: Processing directory[/var/log/apache2/] action create (nagios3::nagios_server line 122)
[2015-06-23T05:08:56+00:00] INFO: Processing file[/var/log/apache2/error.log] action create (nagios3::nagios_server line 129)
[2015-06-23T05:08:56+00:00] INFO: Processing directory[/var/lib/nagios3/] action create (nagios3::nagios_server line 134)
[2015-06-23T05:08:56+00:00] INFO: Processing template[/etc/nagios3/htpasswd.users] action create (nagios3::nagios_server line 141)
[2015-06-23T05:08:56+00:00] INFO: Processing directory[/root/download] action create (nagios3::nagios_server line 156)
[2015-06-23T05:08:56+00:00] INFO: Processing remote_file[Download nagiosgraph Tarball] action create_if_missing (nagios3::nagios_server line 164)
[2015-06-23T05:08:56+00:00] INFO: Processing execute[Unpack nagiosgraph Tarball] action run (nagios3::nagios_server line 172)
[2015-06-23T05:08:56+00:00] INFO: Processing execute[Deploy nagiosgraph] action nothing (nagios3::nagios_server line 181)
[2015-06-23T05:08:56+00:00] INFO: Processing directory[/usr/local/nagiosgraph/var/rrd/] action create (nagios3::nagios_server line 199)
[2015-06-23T05:08:56+00:00] INFO: Processing directory[/usr/local/nagiosgraph/etc/] action create (nagios3::nagios_server line 207)
[2015-06-23T05:08:56+00:00] INFO: Processing template[/usr/local/nagiosgraph/etc/nagiosgraph.conf] action create (nagios3::nagios_server line 215)
[2015-06-23T05:08:56+00:00] INFO: Processing template[/etc//apache2/conf-enabled/nagiosgraph.conf] action create (nagios3::nagios_server line 223)
[2015-06-23T05:08:56+00:00] INFO: Processing template[/etc/nagios3/conf.d/services_nagios2.cfg] action create (nagios3::nagios_server line 234)
[2015-06-23T05:08:56+00:00] INFO: Processing template[/etc/nagios3/conf.d/extinfo_nagios2.cfg] action create (nagios3::nagios_server line 242)
[2015-06-23T05:08:56+00:00] INFO: Processing template[/etc/nagios3/conf.d/hostgroups_nagios2.cfg] action create (nagios3::nagios_server line 250)
[2015-06-23T05:08:56+00:00] INFO: Processing link[/etc/apache2/conf-enabled/nagios3.conf] action create (nagios3::nagios_server line 273)
[2015-06-23T05:08:56+00:00] INFO: Processing service[nagios3] action enable (nagios3::nagios_server line 280)
[2015-06-23T05:08:56+00:00] INFO: Processing service[nagios3] action start (nagios3::nagios_server line 280)
[2015-06-23T05:08:56+00:00] INFO: Processing apt_package[nagios-nrpe-server] action install (nagios3::nagios_client line 13)
[2015-06-23T05:08:58+00:00] INFO: Processing apt_package[nagios-plugins] action install (nagios3::nagios_client line 13)
[2015-06-23T05:08:59+00:00] INFO: Processing apt_package[nagios-plugins-basic] action install (nagios3::nagios_client line 13)
[2015-06-23T05:09:00+00:00] INFO: Processing apt_package[libsys-statistics-linux-perl] action install (nagios3::nagios_client line 13)
[2015-06-23T05:09:01+00:00] INFO: Processing file[/etc/sudoers.d/nagios] action create (nagios3::nagios_client line 28)
[2015-06-23T05:09:01+00:00] INFO: Processing remote_directory[/etc/nagios/log_cfg] action create (nagios3::nagios_client line 34)
[2015-06-23T05:09:01+00:00] INFO: Processing cookbook_file[/etc/nagios/log_cfg/tomcat_log.cfg] action create (dynamically defined)
[2015-06-23T05:09:01+00:00] INFO: cookbook_file[/etc/nagios/log_cfg/tomcat_log.cfg] backed up to /var/chef/backup/etc/nagios/log_cfg/tomcat_log.cfg.chef-20150623050901.954651
[2015-06-23T05:09:01+00:00] INFO: cookbook_file[/etc/nagios/log_cfg/tomcat_log.cfg] updated file contents /etc/nagios/log_cfg/tomcat_log.cfg
[2015-06-23T05:09:01+00:00] INFO: Processing cookbook_file[/etc/nagios/log_cfg/apache_log.cfg] action create (dynamically defined)
[2015-06-23T05:09:01+00:00] INFO: Processing directory[/etc/nagios/nrpe.d] action create (nagios3::nagios_client line 44)
[2015-06-23T05:09:01+00:00] INFO: Processing template[/etc/nagios/nrpe.cfg] action create (nagios3::nagios_client line 62)
[2015-06-23T05:09:01+00:00] INFO: Processing template[/etc/nagios/nrpe.d/common_nrpe.cfg] action create (nagios3::nagios_client line 73)
[2015-06-23T05:09:01+00:00] INFO: Processing template[/etc/nagios/nrpe.d/my_nrpe.cfg] action create (nagios3::nagios_client line 84)
[2015-06-23T05:09:01+00:00] INFO: Processing template[/etc/nagios/nrpe.d/check_logfile.cfg] action create (nagios3::nagios_client line 96)
[2015-06-23T05:09:01+00:00] INFO: Processing template[/etc/nagios/nrpe.d/check_port.cfg] action create (nagios3::nagios_client line 107)
[2015-06-23T05:09:01+00:00] INFO: Processing directory[/usr/lib/nagios/plugins] action create (nagios3::nagios_client line 118)
[2015-06-23T05:09:01+00:00] INFO: Processing remote_file[/usr/lib/nagios/plugins/check_proc_mem.sh] action create (nagios3::nagios_client line 127)
[2015-06-23T05:09:03+00:00] INFO: Processing remote_file[/usr/lib/nagios/plugins/check_proc_cpu.sh] action create (nagios3::nagios_client line 127)
[2015-06-23T05:09:04+00:00] INFO: Processing remote_file[/usr/lib/nagios/plugins/check_proc_fd.sh] action create (nagios3::nagios_client line 127)
[2015-06-23T05:09:05+00:00] INFO: Processing template[/usr/lib/nagios/plugins/check_linux_stats.pl] action create (nagios3::nagios_client line 137)
[2015-06-23T05:09:05+00:00] INFO: Processing template[/usr/lib/nagios/plugins/check_ip_address.sh] action create (nagios3::nagios_client line 137)
[2015-06-23T05:09:05+00:00] INFO: Processing cookbook_file[/usr/lib/nagios/plugins/check_logfiles] action create (nagios3::nagios_client line 156)
[2015-06-23T05:09:05+00:00] INFO: Processing cookbook_file[/usr/lib/nagios/plugins/check_service_status.sh] action create (nagios3::nagios_client line 156)
[2015-06-23T05:09:05+00:00] INFO: Processing service[nagios-nrpe-server] action enable (nagios3::nagios_client line 162)
[2015-06-23T05:09:05+00:00] INFO: Processing service[nagios-nrpe-server] action start (nagios3::nagios_client line 162)
[2015-06-23T05:09:05+00:00] INFO: Processing directory[/etc/nagios3/conf.d/172.17.0.5] action create (nagios-auth::server_checks line 11)
[2015-06-23T05:09:05+00:00] INFO: Processing template[/etc/nagios3/conf.d/172.17.0.5/0_nagios_host.cfg] action create (nagios-auth::server_checks line 18)
[2015-06-23T05:09:05+00:00] INFO: Processing template[/etc/nagios3/conf.d/172.17.0.5/basic_nagios.cfg] action create (nagios-auth::server_checks line 28)
[2015-06-23T05:09:05+00:00] INFO: Processing template[/etc/nagios/nrpe.d/gateway_check.cfg] action create (nagios-auth::gateway_checks line 11)
[2015-06-23T05:09:05+00:00] INFO: Processing template[/etc/nagios/log_cfg/gateway_log.cfg] action create (nagios-auth::gateway_checks line 19)
[2015-06-23T05:09:05+00:00] INFO: Processing template[/etc/nagios3/conf.d/172.17.0.5/gateway_nagios.cfg] action create (nagios-auth::gateway_checks line 28)
[2015-06-23T05:09:05+00:00] INFO: Processing template[/etc/nagios/nrpe.d/tomcat_check.cfg] action create (nagios-auth::tomcat_checks line 11)
[2015-06-23T05:09:05+00:00] INFO: Processing template[/etc/nagios/log_cfg/tomcat_log.cfg] action create (nagios-auth::tomcat_checks line 19)
[2015-06-23T05:09:05+00:00] INFO: template[/etc/nagios/log_cfg/tomcat_log.cfg] backed up to /var/chef/backup/etc/nagios/log_cfg/tomcat_log.cfg.chef-20150623050905.716777
[2015-06-23T05:09:05+00:00] INFO: template[/etc/nagios/log_cfg/tomcat_log.cfg] updated file contents /etc/nagios/log_cfg/tomcat_log.cfg
[2015-06-23T05:09:05+00:00] INFO: Processing template[/etc/nagios3/conf.d/172.17.0.5/tomcat_nagios.cfg] action create (nagios-auth::tomcat_checks line 28)
[2015-06-23T05:09:05+00:00] INFO: Processing apt_package[libtomcat7-java] action install (os-basic-auth::tomcat line 18)
[2015-06-23T05:09:06+00:00] INFO: Processing apt_package[tomcat7-common] action install (os-basic-auth::tomcat line 18)
[2015-06-23T05:09:08+00:00] INFO: Processing apt_package[tomcat7] action install (tomcat::default line 31)
[2015-06-23T05:09:09+00:00] INFO: Processing apt_package[tomcat7-admin] action install (tomcat::default line 37)
[2015-06-23T05:09:10+00:00] INFO: Processing tomcat_instance[base] action configure (tomcat::default line 63)
[2015-06-23T05:09:10+00:00] WARN: Cloning resource attributes for service[tomcat7] from prior resource (CHEF-3694)
[2015-06-23T05:09:10+00:00] WARN: Previous service[tomcat7]: /root/test/master/iamdevops/cookbooks/os-basic-auth/recipes/tomcat.rb:69:in `from_file'
[2015-06-23T05:09:10+00:00] WARN: Current  service[tomcat7]: /root/test/master/iamdevops/cookbooks/tomcat/providers/instance.rb:259:in `block in class_from_file'
[2015-06-23T05:09:10+00:00] INFO: Processing directory[/usr/share/tomcat6/lib/endorsed] action create (/root/test/master/iamdevops/cookbooks/tomcat/providers/instance.rb line 109)
[2015-06-23T05:09:10+00:00] INFO: Processing template[/etc/default/tomcat7] action create (/root/test/master/iamdevops/cookbooks/tomcat/providers/instance.rb line 150)
[2015-06-23T05:09:10+00:00] INFO: Processing template[/etc/tomcat7/server.xml] action create (/root/test/master/iamdevops/cookbooks/tomcat/providers/instance.rb line 171)
[2015-06-23T05:09:10+00:00] INFO: template[/etc/tomcat7/server.xml] backed up to /var/chef/backup/etc/tomcat7/server.xml.chef-20150623050910.768709
[2015-06-23T05:09:10+00:00] INFO: template[/etc/tomcat7/server.xml] updated file contents /etc/tomcat7/server.xml
[2015-06-23T05:09:10+00:00] INFO: Processing template[/etc/tomcat7/logging.properties] action create (/root/test/master/iamdevops/cookbooks/tomcat/providers/instance.rb line 193)
[2015-06-23T05:09:10+00:00] INFO: Processing execute[Create Tomcat SSL certificate] action run (/root/test/master/iamdevops/cookbooks/tomcat/providers/instance.rb line 202)
[2015-06-23T05:09:10+00:00] INFO: Processing service[tomcat7] action start (/root/test/master/iamdevops/cookbooks/tomcat/providers/instance.rb line 259)
[2015-06-23T05:09:15+00:00] INFO: Retrying execution of service[tomcat7], 3 attempt(s) left
[2015-06-23T05:09:50+00:00] INFO: Retrying execution of service[tomcat7], 2 attempt(s) left
[2015-06-23T05:10:25+00:00] INFO: Retrying execution of service[tomcat7], 1 attempt(s) left
[2015-06-23T05:11:01+00:00] INFO: Retrying execution of service[tomcat7], 0 attempt(s) left
[2015-06-23T05:11:36+00:00] INFO: service[tomcat7] started
[2015-06-23T05:11:36+00:00] INFO: service[tomcat7] sending run action to execute[wait for tomcat7] (immediate)
[2015-06-23T05:11:36+00:00] INFO: Processing execute[wait for tomcat7] action run (/root/test/master/iamdevops/cookbooks/tomcat/providers/instance.rb line 280)
[2015-06-23T05:11:41+00:00] INFO: execute[wait for tomcat7] ran successfully
[2015-06-23T05:11:41+00:00] INFO: Processing service[tomcat7] action enable (/root/test/master/iamdevops/cookbooks/tomcat/providers/instance.rb line 259)
[2015-06-23T05:11:41+00:00] INFO: Processing execute[wait for tomcat7] action nothing (/root/test/master/iamdevops/cookbooks/tomcat/providers/instance.rb line 280)
[2015-06-23T05:11:41+00:00] INFO: Processing link[/etc/alternatives/java] action create (os-basic-auth::tomcat line 56)
[2015-06-23T05:11:41+00:00] INFO: link[/etc/alternatives/java] created
[2015-06-23T05:11:41+00:00] INFO: Processing directory[/var/lib/tomcat7/webapps] action create (os-basic-auth::tomcat line 61)
[2015-06-23T05:11:41+00:00] INFO: directory[/var/lib/tomcat7/webapps] mode changed to 755
[2015-06-23T05:11:41+00:00] INFO: Processing service[tomcat7] action enable (os-basic-auth::tomcat line 69)
[2015-06-23T05:11:41+00:00] INFO: Processing remote_file[Download gateway war] action create (gateway-auth::deploy line 19)
[2015-06-23T05:13:07+00:00] INFO: remote_file[Download gateway war] created file /opt/authright/download/gateway-war-1.0-SNAPSHOT.war
[2015-06-23T05:13:07+00:00] INFO: remote_file[Download gateway war] updated file contents /opt/authright/download/gateway-war-1.0-SNAPSHOT.war
[2015-06-23T05:13:08+00:00] INFO: remote_file[Download gateway war] sending run action to execute[Deploy gateway war] (immediate)
[2015-06-23T05:13:08+00:00] INFO: Processing execute[Deploy gateway war] action run (gateway-auth::deploy line 27)
[2015-06-23T05:13:08+00:00] INFO: execute[Deploy gateway war] ran successfully
[2015-06-23T05:13:08+00:00] INFO: Processing execute[Deploy gateway war] action nothing (gateway-auth::deploy line 27)
[2015-06-23T05:13:08+00:00] INFO: template[/etc/nagios/log_cfg/tomcat_log.cfg] sending restart action to service[nagios-nrpe-server] (delayed)
[2015-06-23T05:13:08+00:00] INFO: Processing service[nagios-nrpe-server] action restart (nagios3::nagios_client line 162)
[2015-06-23T05:13:09+00:00] INFO: service[nagios-nrpe-server] restarted
[2015-06-23T05:13:09+00:00] INFO: template[/etc/tomcat7/server.xml] sending restart action to service[tomcat7] (delayed)
[2015-06-23T05:13:09+00:00] INFO: Processing service[tomcat7] action restart (/root/test/master/iamdevops/cookbooks/tomcat/providers/instance.rb line 259)
[2015-06-23T05:13:15+00:00] INFO: Retrying execution of service[tomcat7], 3 attempt(s) left
[2015-06-23T05:13:50+00:00] INFO: Retrying execution of service[tomcat7], 2 attempt(s) left
[2015-06-23T05:14:25+00:00] INFO: Retrying execution of service[tomcat7], 1 attempt(s) left
[2015-06-23T05:15:00+00:00] INFO: Retrying execution of service[tomcat7], 0 attempt(s) left
[0m
================================================================================[0m
[31mError executing action `restart` on resource 'service[tomcat7]'[0m
================================================================================[0m

[0mMixlib::ShellOut::ShellCommandFailed[0m
------------------------------------[0m
Expected process to exit with [0], but received '1'
[0m---- Begin output of /etc/init.d/tomcat7 restart ----
[0mSTDOUT: * Starting Tomcat servlet engine tomcat7
[0m   ...fail!
[0mSTDERR:
[0m---- End output of /etc/init.d/tomcat7 restart ----
[0mRan /etc/init.d/tomcat7 restart returned 1[0m

[0mResource Declaration:[0m
---------------------[0m
# In /root/test/master/iamdevops/cookbooks/tomcat/providers/instance.rb
[0m
[0m259:   service "#{instance}" do
[0m260:     case node['platform_family']
[0m261:     when 'rhel', 'fedora'
[0m262:       service_name "#{instance}"
[0m263:       supports :restart => true, :status => true
[0m264:     when 'debian'
[0m265:       service_name "#{instance}"
[0m266:       supports :restart => true, :reload => false, :status => true
[0m267:     when 'smartos'
[0m268:       # SmartOS doesn't support multiple instances
[0m269:       service_name 'tomcat'
[0m270:       supports :restart => false, :reload => false, :status => true
[0m271:     else
[0m272:       service_name "#{instance}"
[0m273:     end
[0m274:     action [:start, :enable]
[0m275:     notifies :run, "execute[wait for #{instance}]", :immediately
[0m276:     retries 4
[0m277:     retry_delay 30
[0m278:   end
[0m279:
[0m
[0mCompiled Resource:[0m
------------------[0m
# Declared in /root/test/master/iamdevops/cookbooks/tomcat/providers/instance.rb:259:in `block in class_from_file'
[0m
[0mservice("tomcat7") do
[0m  action [:start, :enable]
[0m  updated true
[0m  supports {:restart=>true, :reload=>false, :status=>true}
[0m  retries 4
[0m  retry_delay 30
[0m  default_guard_interpreter :default
[0m  service_name "tomcat7"
[0m  enabled true
[0m  running true
[0m  pattern "tomcat7"
[0m  declared_type :service
[0m  cookbook_name :tomcat
[0mend
[0m
[0m[2015-06-23T05:15:35+00:00] INFO: execute[Deploy gateway war] sending restart action to service[tomcat7] (delayed)
[2015-06-23T05:15:35+00:00] INFO: Processing service[tomcat7] action restart (os-basic-auth::tomcat line 69)
[0m
================================================================================[0m
[31mError executing action `restart` on resource 'service[tomcat7]'[0m
================================================================================[0m

[0mMixlib::ShellOut::ShellCommandFailed[0m
------------------------------------[0m
Expected process to exit with [0], but received '1'
[0m---- Begin output of /etc/init.d/tomcat7 start ----
[0mSTDOUT: * Starting Tomcat servlet engine tomcat7
[0m   ...fail!
[0mSTDERR:
[0m---- End output of /etc/init.d/tomcat7 start ----
[0mRan /etc/init.d/tomcat7 start returned 1[0m

[0mResource Declaration:[0m
---------------------[0m
# In /root/test/master/iamdevops/cookbooks/os-basic-auth/recipes/tomcat.rb
[0m
[0m 69: service 'tomcat7' do
[0m 70:   supports status: true
[0m 71:
[0m 72:   # init_command "/etc/init.d/tomcat7" # Need for redhat OS
[0m 73:   action [:enable]
[0m 74: end
[0m
[0mCompiled Resource:[0m
------------------[0m
# Declared in /root/test/master/iamdevops/cookbooks/os-basic-auth/recipes/tomcat.rb:69:in `from_file'
[0m
[0mservice("tomcat7") do
[0m  action [:enable]
[0m  supports {:status=>true}
[0m  retries 0
[0m  retry_delay 2
[0m  default_guard_interpreter :default
[0m  service_name "tomcat7"
[0m  enabled true
[0m  pattern "tomcat7"
[0m  declared_type :service
[0m  cookbook_name :"os-basic-auth"
[0m  recipe_name "tomcat"
[0mend
[0m
[0m[2015-06-23T05:15:41+00:00] ERROR: Running exception handlers
[2015-06-23T05:15:41+00:00] ERROR: Exception handlers complete
[2015-06-23T05:15:41+00:00] FATAL: Stacktrace dumped to /var/chef/cache/chef-stacktrace.out
[2015-06-23T05:15:41+00:00] ERROR: Chef::Exceptions::MultipleFailures
[2015-06-23T05:15:41+00:00] FATAL: Chef::Exceptions::ChildConvergeError: Chef run process exited unsuccessfully (exit code 1)
Build step 'Execute shell' marked build as failure
Finished: FAILURE
#+END_EXAMPLE
* TODO DevOps Education effort
#+BEGIN_EXAMPLE
[7/13/15, 11:45:33 AM] Jason Zheng: Do I have the permission to upload my public key?
[7/13/15, 11:45:51 AM] denny: Yes, you have.
[7/13/15, 11:46:02 AM] Jason Zheng: what is the page link?
[7/13/15, 11:46:08 AM] Jason Zheng: I cannot find it
[7/13/15, 11:46:09 AM] denny: It’s standard behavior of bitbucket or github.

Nothing to do with aim
[7/13/15, 11:46:27 AM] denny: Let me check it
[7/13/15, 11:47:34 AM] denny: Image
[7/13/15, 11:47:46 AM] denny: Manage account —> SSH Keys
[7/13/15, 11:48:47 AM] Jason Zheng: what is URL?
[7/13/15, 11:48:54 AM] Jason Zheng: please paste the URL
[7/13/15, 11:49:22 AM] Jason Zheng: where you have the “manage account” button
[7/13/15, 11:49:34 AM] denny: The url is not changed.

Go to your profile, by clicking right upper button.
#+END_EXAMPLE
* #  --8<-------------------------- separator ------------------------>8--
* TODO [#A] docker-registry stopped by itself
#+BEGIN_EXAMPLE
root@7a8ebeacae0b:/var/log/docker-registry# tail -n 100 ./server.log
tail -n 100 ./server.log
[2015-07-18 07:14:33 +0000] [21586] [INFO] Booting worker with pid: 21586
[2015-07-18 07:14:34 +0000] [21590] [INFO] Booting worker with pid: 21590
[2015-07-18 07:14:34 +0000] [21592] [INFO] Booting worker with pid: 21592
[2015-07-18 07:14:34 +0000] [21596] [INFO] Booting worker with pid: 21596
[2015-07-18 07:14:37 +0000] [21575] [INFO] Handling signal: term
[2015-07-18 07:14:37 +0000] [21584] [INFO] Worker exiting (pid: 21584)
[2015-07-18 07:14:37 +0000] [21587] [INFO] Worker exiting (pid: 21587)
[2015-07-18 07:14:37 +0000] [21585] [INFO] Worker exiting (pid: 21585)
[2015-07-18 07:14:37 +0000] [21590] [INFO] Worker exiting (pid: 21590)
[2015-07-18 07:14:37 +0000] [21592] [INFO] Worker exiting (pid: 21592)
[2015-07-18 07:14:37 +0000] [21596] [INFO] Worker exiting (pid: 21596)
[2015-07-18 07:14:38 +0000] [21583] [INFO] Worker exiting (pid: 21583)
[2015-07-18 07:14:38 +0000] [21586] [INFO] Worker exiting (pid: 21586)
[2015-07-18 07:14:38 +0000] [21575] [INFO] Shutting down: Master
[2015-07-18 07:14:40 +0000] [21697] [INFO] Starting gunicorn 19.1.1
[2015-07-18 07:14:40 +0000] [21697] [INFO] Listening at: http://127.0.0.1:5000 (21697)
[2015-07-18 07:14:40 +0000] [21697] [INFO] Using worker: gevent
[2015-07-18 07:14:40 +0000] [21705] [INFO] Booting worker with pid: 21705
[2015-07-18 07:14:40 +0000] [21706] [INFO] Booting worker with pid: 21706
[2015-07-18 07:14:40 +0000] [21707] [INFO] Booting worker with pid: 21707
[2015-07-18 07:14:40 +0000] [21708] [INFO] Booting worker with pid: 21708
[2015-07-18 07:14:41 +0000] [21709] [INFO] Booting worker with pid: 21709
[2015-07-18 07:14:41 +0000] [21712] [INFO] Booting worker with pid: 21712
[2015-07-18 07:14:41 +0000] [21719] [INFO] Booting worker with pid: 21719
[2015-07-18 07:14:41 +0000] [21720] [INFO] Booting worker with pid: 21720
[2015-07-19 08:25:43 +0000] [21706] [INFO] Autorestarting worker after current request.
[2015-07-19 08:25:43 +0000] [21706] [INFO] Worker exiting (pid: 21706)
[2015-07-19 08:25:43 +0000] [21946] [INFO] Booting worker with pid: 21946
[2015-07-19 15:35:22 +0000] [21720] [INFO] Autorestarting worker after current request.
[2015-07-19 15:35:23 +0000] [21720] [INFO] Worker exiting (pid: 21720)
[2015-07-19 15:35:23 +0000] [21963] [INFO] Booting worker with pid: 21963
[2015-07-19 23:50:06 +0000] [21719] [INFO] Autorestarting worker after current request.
[2015-07-19 23:50:07 +0000] [21719] [INFO] Worker exiting (pid: 21719)
[2015-07-19 23:50:07 +0000] [21966] [INFO] Booting worker with pid: 21966
[2015-07-19 23:50:10 +0000] [21946] [INFO] Autorestarting worker after current request.
[2015-07-19 23:50:10 +0000] [21946] [INFO] Worker exiting (pid: 21946)
[2015-07-19 23:50:10 +0000] [21967] [INFO] Booting worker with pid: 21967
[2015-07-19 23:50:30 +0000] [21967] [ERROR] Exception in worker process:
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/gunicorn/arbiter.py", line 507, in spawn_worker
    worker.init_process()
  File "/usr/local/lib/python2.7/dist-packages/gunicorn/workers/ggevent.py", line 193, in init_process
    super(GeventWorker, self).init_process()
  File "/usr/local/lib/python2.7/dist-packages/gunicorn/workers/base.py", line 114, in init_process
    self.wsgi = self.app.wsgi()
  File "/usr/local/lib/python2.7/dist-packages/gunicorn/app/base.py", line 66, in wsgi
    self.callable = self.load()
  File "/usr/local/lib/python2.7/dist-packages/gunicorn/app/wsgiapp.py", line 65, in load
    return self.load_wsgiapp()
  File "/usr/local/lib/python2.7/dist-packages/gunicorn/app/wsgiapp.py", line 52, in load_wsgiapp
    return util.import_app(self.app_uri)
  File "/usr/local/lib/python2.7/dist-packages/gunicorn/util.py", line 356, in import_app
    __import__(module)
  File "/usr/local/lib/python2.7/dist-packages/docker_registry/wsgi.py", line 27, in <module>
    from .search import *  # noqa
  File "/usr/local/lib/python2.7/dist-packages/docker_registry/search.py", line 14, in <module>
    INDEX = index.load(cfg.search_backend.lower())
  File "/usr/local/lib/python2.7/dist-packages/docker_registry/lib/index/__init__.py", line 82, in load
    return db.SQLAlchemyIndex()
  File "/usr/local/lib/python2.7/dist-packages/docker_registry/lib/index/db.py", line 86, in __init__
    self._setup_database()
  File "/usr/local/lib/python2.7/dist-packages/docker_registry/toolkit.py", line 330, in wrapper
    os.remove(lock_path)
OSError: [Errno 2] No such file or directory: './registry._setup_database.lock'
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/gunicorn/arbiter.py", line 507, in spawn_worker
    worker.init_process()
  File "/usr/local/lib/python2.7/dist-packages/gunicorn/workers/ggevent.py", line 193, in init_process
    super(GeventWorker, self).init_process()
  File "/usr/local/lib/python2.7/dist-packages/gunicorn/workers/base.py", line 114, in init_process
    self.wsgi = self.app.wsgi()
  File "/usr/local/lib/python2.7/dist-packages/gunicorn/app/base.py", line 66, in wsgi
    self.callable = self.load()
  File "/usr/local/lib/python2.7/dist-packages/gunicorn/app/wsgiapp.py", line 65, in load
    return self.load_wsgiapp()
  File "/usr/local/lib/python2.7/dist-packages/gunicorn/app/wsgiapp.py", line 52, in load_wsgiapp
    return util.import_app(self.app_uri)
  File "/usr/local/lib/python2.7/dist-packages/gunicorn/util.py", line 356, in import_app
    __import__(module)
  File "/usr/local/lib/python2.7/dist-packages/docker_registry/wsgi.py", line 27, in <module>
    from .search import *  # noqa
  File "/usr/local/lib/python2.7/dist-packages/docker_registry/search.py", line 14, in <module>
    INDEX = index.load(cfg.search_backend.lower())
  File "/usr/local/lib/python2.7/dist-packages/docker_registry/lib/index/__init__.py", line 82, in load
    return db.SQLAlchemyIndex()
  File "/usr/local/lib/python2.7/dist-packages/docker_registry/lib/index/db.py", line 86, in __init__
    self._setup_database()
  File "/usr/local/lib/python2.7/dist-packages/docker_registry/toolkit.py", line 330, in wrapper
    os.remove(lock_path)
OSError: [Errno 2] No such file or directory: './registry._setup_database.lock'
[2015-07-19 23:50:30 +0000] [21967] [INFO] Worker exiting (pid: 21967)
[2015-07-19 23:50:31 +0000] [21707] [INFO] Worker exiting (pid: 21707)
[2015-07-19 23:50:31 +0000] [21963] [INFO] Worker exiting (pid: 21963)
[2015-07-19 23:50:31 +0000] [21712] [INFO] Worker exiting (pid: 21712)
[2015-07-19 23:50:31 +0000] [21708] [INFO] Worker exiting (pid: 21708)
[2015-07-19 23:50:31 +0000] [21709] [INFO] Worker exiting (pid: 21709)
[2015-07-19 23:50:31 +0000] [21705] [INFO] Worker exiting (pid: 21705)
[2015-07-19 23:50:31 +0000] [21966] [INFO] Worker exiting (pid: 21966)
[2015-07-19 23:50:31 +0000] [21697] [INFO] Shutting down: Master
[2015-07-19 23:50:31 +0000] [21697] [INFO] Reason: Worker failed to boot.
root@7a8ebeacae0b:/var/log/docker-registry# service docker-registry status
service docker-registry status
 * docker-registry not running
root@7a8ebeacae0b:/var/log/docker-registry# 
#+END_EXAMPLE
* TODO [#A] squid start issue: start-stop-daemon doesn't write correct pid to pidfile
https://github.com/inveneo/hub-linux-ubuntu/blob/master/install/overlay/etc/init.d/squid3
#+BEGIN_EXAMPLE
root@bd4af69974ab:~# ps -ef | grep squid
ps -ef | grep squid
root@bd4af69974ab:~# bash -xe /etc/init.d/squid3 start
bash -xe /etc/init.d/squid3 start
+ '[' -f /etc/sysconfig/network ']'
+ . /lib/lsb/init-functions
+++ run-parts --lsbsysinit --list /lib/lsb/init-functions.d
++ for hook in '$(run-parts --lsbsysinit --list /lib/lsb/init-functions.d 2>/dev/null)'
++ '[' -r /lib/lsb/init-functions.d/20-left-info-blocks ']'
++ . /lib/lsb/init-functions.d/20-left-info-blocks
++ for hook in '$(run-parts --lsbsysinit --list /lib/lsb/init-functions.d 2>/dev/null)'
++ '[' -r /lib/lsb/init-functions.d/50-ubuntu-logging ']'
++ . /lib/lsb/init-functions.d/50-ubuntu-logging
+++ LOG_DAEMON_MSG=
++ FANCYTTY=
++ '[' -e /etc/lsb-base-logging.sh ']'
++ true
+ '[' '' = no ']'
+ . /etc/profile
++ '[' '' ']'
++ '[' -d /etc/profile.d ']'
++ for i in '/etc/profile.d/*.sh'
++ '[' -r /etc/profile.d/jdk.sh ']'
++ . /etc/profile.d/jdk.sh
+++cat /var/run/squid.pid export JAVA_HOME=/usr/lib/jvm/java-8-oracle-amd64
+++ JAVA_HOME=/usr/lib/jvm/java-8-oracle-amd64
++ for i in '/etc/profile.d/*.sh'
++ '[' -r /etc/profile.d/no_proxy.sh ']'
++ . /etc/profile.d/no_proxy.sh
+++ no_proxy='localhost,127.0.0.1,172.17.0.*'
++ for i in '/etc/profile.d/*.sh'
++ '[' -r /etc/profile.d/profile_auth.sh ']'
++ . /etc/profile.d/profile_auth.sh
+++ export LC_ALL=C
+++ LC_ALL=C
+++ export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/authright/bin/:/opt/authright/bin/
+++ PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/authright/bin/:/opt/authright/bin/
+++ export CLASSPATH=/usr/lib/jvm/java-8-oracle-amd64/lib:/opt/authright/:/usr/lib/jvm/java-8-oracle-amd64/lib:/opt/authright/:
+++ CLASSPATH=/usr/lib/jvm/java-8-oracle-amd64/lib:/opt/authright/:/usr/lib/jvm/java-8-oracle-amd64/lib:/opt/authright/:
++ unset i
++ export VISIBLE=now
++ VISIBLE=now
+ export LC_ALL=C
+ LC_ALL=C
+ SERVICE_NAME=squid3
++ ps ax
++ grep 'squid3.*/etc/squid3/squid.conf'
++ grep -v grep
++ sed 's/^\s*\([0-9]*\)\s.*/\1/'
+ CHECK_PID_RUNNING=
+ MONITOR_TCP_PORT=3128
+ PIDFILE=/var/run/squid.pid
+ MAX_START_TIMEOUT=100
+ MAX_STOP_TIMEOUT=30
+ case "$1" in
+ start
+ '[' -f /var/run/squid.pid ']'
+ echo -en ' * \033[1mStarting squid3...\033[0m'
 * Starting squid3...+ touch /var/run/squid.pid
+ start-stop-daemon --start --quiet --background --make-pidfile --pidfile /var/run/squid.pid --exec /usr/sbin/squid3 -- -D -sYC
+ log_end_msg 0
+ '[' -z 0 ']'
+ '[' '' ']'
+ '[' 0 -eq 0 ']'
+ echo '   ...done.'
   ...done.
+ return 0
+ '[' 0 ']'
+ timeout=0
+ lsof -i tcp:3128
+ grep -i listen
+ echo -n .
.+ ((  timeout ++ ))
root@bd4af69974ab:~# cat /var/run/squid.pd
cat /var/run/squid.pd
cat: /var/run/squid.pd: No such file or directory
root@bd4af69974ab:~# cat /var/run/squid.pid
cat /var/run/squid.pid
1460
root@bd4af69974ab:~# ps -ef | grep squid
ps -ef | grep squid
root      1463     1  0 01:45 ?        00:00:00 /usr/sbin/squid3 -D -sYC
proxy     1465  1463  0 01:45 ?        00:00:00 (squid-1) -D -sYC
root      1471  1398  0 01:45 pts/1    00:00:00 grep --color=auto squid
root@bd4af69974ab:~# 
#+END_EXAMPLE
* enforce Jenkins code build
#+BEGIN_EXAMPLE
Hi Wyman & Dehui

Code build for audit project fails.
Have you received the notification email in your inbox?
http://50.198.76.249:443/view/CodeBuild/job/BuildAuditCode/38/console

I understand we’re on rapid development cycle.

Please update the email loop, if the job fails but will be fixed soon.

Otherwise I will have to keep being annoying like this.
Normally people avoid this by two means:
1. Dev in one branch and continuously merge to the branch which daily build will be triggered
   https://github.com/Kunena/Kunena-Forum/wiki/Create-a-new-branch-with-git-and-manage-branches
2. Developers test locally, before push to repo.
#+END_EXAMPLE
* #  --8<-------------------------- separator ------------------------>8--
* Interview for DevOps
** configuration management
- chef, puppet
** nagios monitor system
- monitor critical logfiles
- selenium test
- enable history
** Request to Webservice fails from time to time
- Check network traffic for Internet
- shell loop check: bash
- What logfiles
- What if application layer's logfile is too big, like over 10G?
- What network debugs tools you use: tcpdump, losf, ps
** linux tools: sed, awk, wc, sort, uniq; $$, id; nohup, fg, bg;
** How to identity FD problem of a process
- Find out the file handle limits of a given process
- Monitor the history
- How to identity this issue happen again?
* TODO DevOps interview
** ask the painpoints: what's the painpoints
** shining points: totvs in two months, decide to cut off half of the devops team
** facial interactive: look audience directly
* Common problems of Deployment
- Changes that often result in failures and are difficult to diagnose and fix.
- Dev, test, and staging environments that are different from production environments, causing failures when builds are promoted across environments.
- Lots of manual work required to deploy.
- Lots of handoffs between teams, resulting in slow, inefficient deployments.
* six organizational risk factors that predict burnout:16
- Work overload. Job demands exceed human limits.
- Lack of control. Inability to influence decisions that affect your job.
- Insufficient rewards. Insufficient financial, institutional or social rewards.
- Breakdown of community. Unsupportive workplace environment.
- Absence of fairness. Lack of fairness in decision-making processes.
- Value conflicts. Mismatch in organizational values and the individual’s values.
* TODO [#A] osc kitchen verify fails: availaibity of taobao ruby gem source
#+BEGIN_EXAMPLE
Fetching: rspec-core-3.3.2.gem ( 83%)
Fetching: rspec-core-3.3.2.gem ( 94%)
Fetching: rspec-core-3.3.2.gem (100%)
Fetching: rspec-core-3.3.2.gem (100%)
       /opt/chef/embedded/lib/ruby/site_ruby/2.1.0/rubygems/remote_fetcher.rb:249:in `fetch_http': bad response Service Unavailable 503 (https://rubygems-china.oss.aliyuncs.com/quick/Marshal.4.8/rspec-its-1.2.0.gemspec.rz) (Gem::RemoteFetcher::FetchError)
       	from /opt/chef/embedded/lib/ruby/site_ruby/2.1.0/rubygems/remote_fetcher.rb:247:in `fetch_http'
       	from /opt/chef/embedded/lib/ruby/site_ruby/2.1.0/rubygems/remote_fetcher.rb:267:in `fetch_path'
       	from /opt/chef/embedded/lib/ruby/site_ruby/2.1.0/rubygems/source.rb:148:in `fetch_spec'
       	from /opt/chef/embedded/lib/ruby/site_ruby/2.1.0/rubygems/resolver/api_specification.rb:76:in `spec'
       	from /opt/chef/embedded/lib/ruby/site_ruby/2.1.0/rubygems/resolver/activation_request.rb:74:in `full_spec'
       	from /opt/chef/embedded/lib/ruby/site_ruby/2.1.0/rubygems/resolver/activation_request.rb:104:in `installed?'
       	from /opt/chef/embedded/lib/ruby/site_ruby/2.1.0/rubygems/request_set.rb:151:in `block in install'
       	from /opt/chef/embedded/lib/ruby/site_ruby/2.1.0/rubygems/request_set.rb:150:in `each'
       	from /opt/chef/embedded/lib/ruby/site_ruby/2.1.0/rubygems/request_set.rb:150:in `install'
       	from /opt/chef/embedded/lib/ruby/site_ruby/2.1.0/rubygems/dependency_installer.rb:394:in `install'
       	from /tmp/verifier/gems/gems/busser-0.7.1/lib/busser/rubygems.rb:44:in `install_gem'
       	from /tmp/verifier/gems/gems/busser-0.7.1/lib/busser/helpers.rb:57:in `install_gem'
       	from /tmp/verifier/gems/gems/busser-serverspec-0.5.7/lib/busser/runner_plugin/serverspec.rb:60:in `install_serverspec'
       	from /tmp/verifier/gems/gems/busser-serverspec-0.5.7/lib/busser/runner_plugin/serverspec.rb:33:in `test'
       	from /tmp/verifier/gems/gems/thor-0.19.0/lib/thor/command.rb:27:in `run'
       	from /tmp/verifier/gems/gems/thor-0.19.0/lib/thor/invocation.rb:126:in `invoke_command'
       	from /tmp/verifier/gems/gems/thor-0.19.0/lib/thor/invocation.rb:133:in `block in invoke_all'
       	from /tmp/verifier/gems/gems/thor-0.19.0/lib/thor/invocation.rb:133:in `each'
       	from /tmp/verifier/gems/gems/thor-0.19.0/lib/thor/invocation.rb:133:in `map'
       	from /tmp/verifier/gems/gems/thor-0.19.0/lib/thor/invocation.rb:133:in `invoke_all'
       from /tmp/verifier/gems/gems/thor-0.19.0/lib/thor/group.rb:232:in `dispatch'
       	from /tmp/verifier/gems/gems/thor-0.19.0/lib/thor/invocation.rb:115:in `invoke'
       	from /tmp/verifier/gems/gems/busser-0.7.1/lib/busser/command/test.rb:43:in `block in perform'
       	from /tmp/verifier/gems/gems/busser-0.7.1/lib/busser/command/test.rb:35:in `each'
       	from /tmp/verifier/gems/gems/busser-0.7.1/lib/busser/command/test.rb:35:in `perform'
       	from /tmp/verifier/gems/gems/thor-0.19.0/lib/thor/command.rb:27:in `run'
       
       	from /tmp/verifier/gems/gems/thor-0.19.0/lib/thor/invocation.rb:133:in `block in invoke_all'
       	from /tmp/verifier/gems/gems/thor-0.19.0/lib/thor/invocation.rb:133:in `each'
       	from /tmp/verifier/gems/gems/thor-0.19.0/lib/thor/invocation.rb:133:in `map'
       	from /tmp/verifier/gems/gems/thor-0.19.0/lib/thor/invocation.rb:133:in `invoke_all'
       from /tmp/verifier/gems/gems/thor-0.19.0/lib/thor/group.rb:232:in `dispatch'
       
       	from /tmp/verifier/gems/gems/thor-0.19.0/lib/thor.rb:40:in `block in register'
       	from /tmp/verifier/gems/gems/thor-0.19.0/lib/thor/command.rb:27:in `run'
       from /tmp/verifier/gems/gems/thor-0.19.0/lib/thor/invocation.rb:126:in `invoke_command'
       from /tmp/verifier/gems/gems/thor-0.19.0/lib/thor.rb:359:in `dispatch'
       	from /tmp/verifier/gems/gems/thor-0.19.0/lib/thor/base.rb:440:in `start'
       	from /tmp/verifier/gems/gems/busser-0.7.1/bin/busser:8:in `<top (required)>'
       	from /tmp/verifier/gems/bin/busser:23:in `load'
       	from /tmp/verifier/gems/bin/busser:23:in `<main>'
>>>>>> Verify failed on instance <default-ubuntu-1404>.
>>>>>> Please see .kitchen/logs/default-ubuntu-1404.log for more details
>>>>>> ------Exception-------
>>>>>> Class: Kitchen::ActionFailed
>>>>>> Message: SSH exited (1) for command: [env http_proxy=http://172.17.42.1:3128 https_proxy=https://172.17.42.1:3128 sh -c '
http_proxy="http://172.17.42.1:3128"; export http_proxy
HTTP_PROXY="http://172.17.42.1:3128"; export HTTP_PROXY
https_proxy="https://172.17.42.1:3128"; export https_proxy
HTTPS_PROXY="https://172.17.42.1:3128"; export HTTPS_PROXY
BUSSER_ROOT="/tmp/verifier"; export BUSSER_ROOT
#+END_EXAMPLE

* CANCELED sandbox jenkins update: need to pull the data
  CLOSED: [2015-08-12 Wed 16:27]
root@a3471a4bd6ae:~/test/master/iamdevops/cookbooks/gateway-auth# git pull
git pull
remote: Counting objects: 49, done.        
remote: Compressing objects: 100% (45/45), done.        
remote: Total 49 (delta 32), reused 0 (delta 0)        
Unpacking objects: 100% (49/49), done.
From bitbucket.org:authright/iamdevops
   8a53f17..f4c7478  dev        -> origin/dev
Already up-to-date.
* #  --8<-------------------------- separator ------------------------>8--
* TODO berks cookbook stuck
http://50.198.76.249:443/job/DockerDeployBasicCookbooks/245/console
#+BEGIN_EXAMPLE
jenkins@3aa89f131a3a:/home/denny/iamdevops$ lsof -p 18448
lsof: WARNING: can't stat() aufs file system /var/lib/docker/devicemapper
      Output information may be incomplete.
COMMAND   PID    USER   FD   TYPE   DEVICE SIZE/OFF     NODE NAME
ruby    18448 jenkins  cwd    DIR     0,33     4096   344772 /var/lib/jenkins/code/dockerbasic/dev/iamdevops/cookbooks/elk-auth
ruby    18448 jenkins  rtd    DIR     0,33     4096        2 /
ruby    18448 jenkins  txt    REG     0,33 12932939   131545 /usr/local/bin/ruby
ruby    18448 jenkins  mem    REG     0,33   101240     1813 /lib/x86_64-linux-gnu/libresolv-2.19.so
ruby    18448 jenkins  mem    REG     0,33    22952     1811 /lib/x86_64-linux-gnu/libnss_dns-2.19.so
ruby    18448 jenkins  mem    REG     0,33    47712       45 /lib/x86_64-linux-gnu/libnss_files-2.19.so
ruby    18448 jenkins  mem    REG     0,33 61052099   153485 /usr/local/lib/ruby/gems/2.0.0/gems/dep-selector-libgecode-1.0.2/lib/dep-selector-libgecode/vendored-gecode/lib/libgecodeset.so.32.0
ruby    18448 jenkins  mem    REG     0,33    90080      376 /lib/x86_64-linux-gnu/libgcc_s.so.1
ruby    18448 jenkins  mem    REG     0,33   979056    32709 /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.19
ruby    18448 jenkins  mem    REG     0,33    70361   153499 /usr/local/lib/ruby/gems/2.0.0/gems/dep-selector-libgecode-1.0.2/lib/dep-selector-libgecode/vendored-gecode/lib/libgecodesupport.so.32.0
ruby    18448 jenkins  mem    REG     0,33   299726   153492 /usr/local/lib/ruby/gems/2.0.0/gems/dep-selector-libgecode-1.0.2/lib/dep-selector-libgecode/vendored-gecode/lib/libgecodekernel.so.32.0
ruby    18448 jenkins  mem    REG     0,33 81788181   153488 /usr/local/lib/ruby/gems/2.0.0/gems/dep-selector-libgecode-1.0.2/lib/dep-selector-libgecode/vendored-gecode/lib/libgecodeint.so.32.0
ruby    18448 jenkins  mem    REG     0,33  1473823   153495 /usr/local/lib/ruby/gems/2.0.0/gems/dep-selector-libgecode-1.0.2/lib/dep-selector-libgecode/vendored-gecode/lib/libgecodeminimodel.so.32.0
ruby    18448 jenkins  mem    REG     0,33   773795   153490 /usr/local/lib/ruby/gems/2.0.0/gems/dep-selector-libgecode-1.0.2/lib/dep-selector-libgecode/vendored-gecode/lib/libgecodesearch.so.32.0
ruby    18448 jenkins  mem    REG     0,33   145228   152130 /usr/local/lib/ruby/gems/2.0.0/gems/dep_selector-1.0.3/lib/dep_gecode.so
ruby    18448 jenkins  mem    REG     0,33    30944    32723 /usr/lib/x86_64-linux-gnu/libffi.so.6.0.1
ruby    18448 jenkins  mem    REG     0,33   954794   213905 /usr/local/lib/ruby/gems/2.0.0/gems/ffi-1.9.10/lib/ffi_c.so
ruby    18448 jenkins  mem    REG     0,33   106384   131651 /usr/local/lib/ruby/2.0.0/x86_64-linux/digest/sha1.so
ruby    18448 jenkins  mem    REG     0,33   409420   151496 /usr/local/lib/ruby/gems/2.0.0/gems/nio4r-1.1.0/lib/nio4r_ext.so
ruby    18448 jenkins  mem    REG     0,33   149150   151397 /usr/local/lib/ruby/gems/2.0.0/gems/hitimes-1.2.2/lib/hitimes/2.0/hitimes.so
ruby    18448 jenkins  mem    REG     0,33    16835   131619 /usr/local/lib/ruby/2.0.0/x86_64-linux/fiber.so
ruby    18448 jenkins  mem    REG     0,33   103216   131653 /usr/local/lib/ruby/2.0.0/x86_64-linux/digest/md5.so
ruby    18448 jenkins  mem    REG     0,33   304685   151996 /usr/local/lib/ruby/gems/2.0.0/gems/json-1.8.3/lib/json/ext/generator.so
ruby    18448 jenkins  mem    REG     0,33    66266   131572 /usr/local/lib/ruby/2.0.0/x86_64-linux/enc/utf_32le.so
ruby    18448 jenkins  mem    REG     0,33    66218   131563 /usr/local/lib/ruby/2.0.0/x86_64-linux/enc/utf_32be.so
ruby    18448 jenkins  mem    REG     0,33   195172   151995 /usr/local/lib/ruby/gems/2.0.0/gems/json-1.8.3/lib/json/ext/parser.so
ruby    18448 jenkins  mem    REG     0,33    72210   131610 /usr/local/lib/ruby/2.0.0/x86_64-linux/enc/utf_16be.so
ruby    18448 jenkins  mem    REG     0,33    72274   131565 /usr/local/lib/ruby/2.0.0/x86_64-linux/enc/utf_16le.so
ruby    18448 jenkins  mem    REG     0,33   213783   131657 /usr/local/lib/ruby/2.0.0/x86_64-linux/io/console.so
ruby    18448 jenkins  mem    REG     0,33   100728      316 /lib/x86_64-linux-gnu/libz.so.1.2.8
ruby    18448 jenkins  mem    REG     0,33   387207   131646 /usr/local/lib/ruby/2.0.0/x86_64-linux/zlib.so
ruby    18448 jenkins  mem    REG     0,33   139542   131612 /usr/local/lib/ruby/2.0.0/x86_64-linux/digest.so
ruby    18448 jenkins  mem    REG     0,33  1930528   109274 /lib/x86_64-linux-gnu/libcrypto.so.1.0.0
ruby    18448 jenkins  mem    REG     0,33   383112   109273 /lib/x86_64-linux-gnu/libssl.so.1.0.0
ruby    18448 jenkins  mem    REG     0,33  2345722   131628 /usr/local/lib/ruby/2.0.0/x86_64-linux/openssl.so
ruby    18448 jenkins  mem    REG     0,33   838631   131647 /usr/local/lib/ruby/2.0.0/x86_64-linux/socket.so
ruby    18448 jenkins  mem    REG     0,33  1184182   131631 /usr/local/lib/ruby/2.0.0/x86_64-linux/date_core.so
ruby    18448 jenkins  mem    REG     0,33   237026   131643 /usr/local/lib/ruby/2.0.0/x86_64-linux/stringio.so
ruby    18448 jenkins  mem    REG     0,33   129104    32270 /usr/lib/x86_64-linux-gnu/libyaml-0.so.2.0.2
ruby    18448 jenkins  mem    REG     0,33   223216   131556 /usr/local/lib/ruby/2.0.0/x86_64-linux/psych.so
ruby    18448 jenkins  mem    REG     0,33   220359   131636 /usr/local/lib/ruby/2.0.0/x86_64-linux/strscan.so
ruby    18448 jenkins  mem    REG     0,33   104071   131622 /usr/local/lib/ruby/2.0.0/x86_64-linux/fcntl.so
ruby    18448 jenkins  mem    REG     0,33   167603   131627 /usr/local/lib/ruby/2.0.0/x86_64-linux/etc.so
ruby    18448 jenkins  mem    REG     0,33   214561   131630 /usr/local/lib/ruby/2.0.0/x86_64-linux/pathname.so
ruby    18448 jenkins  mem    REG     0,33   167096       29 /lib/x86_64-linux-gnu/libtinfo.so.5.9
ruby    18448 jenkins  mem    REG     0,33   282352     4900 /lib/x86_64-linux-gnu/libreadline.so.6.3
ruby    18448 jenkins  mem    REG     0,33   232917   131642 /usr/local/lib/ruby/2.0.0/x86_64-linux/readline.so
ruby    18448 jenkins  mem    REG     0,33    36656   131591 /usr/local/lib/ruby/2.0.0/x86_64-linux/enc/trans/transdb.so
ruby    18448 jenkins  mem    REG     0,33    29141   131609 /usr/local/lib/ruby/2.0.0/x86_64-linux/enc/encdb.so
ruby    18448 jenkins  mem    REG     0,33  1840928       33 /lib/x86_64-linux-gnu/libc-2.19.so
ruby    18448 jenkins  mem    REG     0,33  1071552      207 /lib/x86_64-linux-gnu/libm-2.19.so
ruby    18448 jenkins  mem    REG     0,33    43368      150 /lib/x86_64-linux-gnu/libcrypt-2.19.so
ruby    18448 jenkins  mem    REG     0,33    14664       31 /lib/x86_64-linux-gnu/libdl-2.19.so
ruby    18448 jenkins  mem    REG     0,33    31792      169 /lib/x86_64-linux-gnu/librt-2.19.so
ruby    18448 jenkins  mem    REG     0,33   141574      108 /lib/x86_64-linux-gnu/libpthread-2.19.so
ruby    18448 jenkins  mem    REG     0,33   149120       26 /lib/x86_64-linux-gnu/ld-2.19.so
ruby    18448 jenkins  mem    REG     0,33  1607664       81 /usr/lib/locale/locale-archive
ruby    18448 jenkins    0r  FIFO      0,8      0t0 20073561 pipe
ruby    18448 jenkins    1w  FIFO      0,8      0t0 20073508 pipe
ruby    18448 jenkins    2w  FIFO      0,8      0t0 20073508 pipe
ruby    18448 jenkins    3r  FIFO      0,8      0t0 20081836 pipe
ruby    18448 jenkins    4w  FIFO      0,8      0t0 20081836 pipe
ruby    18448 jenkins    5r  FIFO      0,8      0t0 20081837 pipe
ruby    18448 jenkins    6w  FIFO      0,8      0t0 20081837 pipe
ruby    18448 jenkins    7w   REG     0,33      190   368285 /var/lib/jenkins/code/dockerbasic/dev/iamdevops/cookbooks/elk-auth/.kitchen/logs/kitchen.log
ruby    18448 jenkins    8w   REG     0,33      536   372297 /var/lib/jenkins/code/dockerbasic/dev/iamdevops/cookbooks/elk-auth/.kitchen/logs/default-ubuntu-1404.log
ruby    18448 jenkins    9u  IPv4 20080048      0t0      TCP 3aa89f131a3a:47444->ec2-54-201-170-234.us-west-2.compute.amazonaws.com:https (CLOSE_WAIT)
ruby    18448 jenkins   10u  IPv4 20083085      0t0      TCP 3aa89f131a3a:59332->ec2-52-26-220-83.us-west-2.compute.amazonaws.com:https (SYN_SENT)
jenkins@3aa89f131a3a:/home/denny/iamdevops$ telnet ec2-52-26-220-83.us-west-2.compute.amazonaws.com 443
Trying 52.26.220.83...
root@3aa89f131a3a:~# lsof | grep CLOSE_WAIT| wc -l
403
root@3aa89f131a3a:~# reboot^C
root@3aa89f131a3a:~# lsof | grep CLOSE_WAIT| tail 
sshd    16795 root  399u  IPv4 19021766      0t0      TCP 3aa89f131a3a:55608->192.168.1.184:18080 (CLOSE_WAIT)
sshd    16795 root  400u  IPv4 19021382      0t0      TCP 3aa89f131a3a:55595->192.168.1.184:18080 (CLOSE_WAIT)
sshd    16795 root  401u  IPv4 19028622      0t0      TCP 3aa89f131a3a:55754->192.168.1.184:18080 (CLOSE_WAIT)
sshd    16795 root  402u  IPv4 19024118      0t0      TCP 3aa89f131a3a:55650->192.168.1.184:18080 (CLOSE_WAIT)
sshd    16795 root  403u  IPv4 19028982      0t0      TCP 3aa89f131a3a:55759->192.168.1.184:18080 (CLOSE_WAIT)
sshd    16795 root  404u  IPv4 19029407      0t0      TCP 3aa89f131a3a:55770->192.168.1.184:18080 (CLOSE_WAIT)
sshd    16795 root  405u  IPv4 19179149      0t0      TCP 3aa89f131a3a:58202->192.168.1.184:18080 (CLOSE_WAIT)
sshd    16795 root  406u  IPv4 19192188      0t0      TCP 3aa89f131a3a:58274->192.168.1.184:18080 (CLOSE_WAIT)
sshd    16795 root  407u  IPv4 19334258      0t0      TCP 3aa89f131a3a:32903->192.168.1.184:18080 (CLOSE_WAIT)
sshd    16795 root  410u  IPv4 20086704      0t0      TCP 3aa89f131a3a:46590->192.168.1.184:18080 (CLOSE_WAIT)
root@3aa89f131a3a:~# 

#+END_EXAMPLE
* TODO jenkins docker: fail to reboot
* TODO Fail to stop jenkins docker container
ssh -p 4022 root@50.198.76.249
ssh -i /home/denny/denny root@192.168.1.184

root@authright-internal-it:~# docker ps
CONTAINER ID        IMAGE                                COMMAND             CREATED             STATUS              PORTS                                                                      NAMES
6c399d6d450e        denny/osc_authright_aio:latest       "/bin/bash"         10 weeks ago        Up 10 weeks         0.0.0.0:9200->9200/tcp, 0.0.0.0:5022->22/tcp, 0.0.0.0:8080->80/tcp         authright_aio       
3aa89f131a3a        denny/osc_authright_jenkins:latest   "/bin/bash"         10 weeks ago        Up 10 weeks         0.0.0.0:18000->18000/tcp, 0.0.0.0:18080->18080/tcp, 0.0.0.0:4022->22/tcp   authright_jenkins   
root@authright-internal-it:~# docker stop  authright_jenkins  

* TODO DevOps: code build fail, due to scm conflict
http://123.57.240.189:28080/job/BuildRepoCode/347/console

+ echo -ne '[2015-08-14' '13:15:22] Git update code for '\''git@bitbucket.org:authright/iam.git'\'' to /var/lib/jenkins/code, branch_name: dev\n'
[2015-08-14 13:15:22] Git update code for 'git@bitbucket.org:authright/iam.git' to /var/lib/jenkins/code, branch_name: dev
+ '[' '!' -d /var/lib/jenkins/code/dev/iam ']'
+ cd /var/lib/jenkins/code/dev/iam
+ git config remote.origin.url git@bitbucket.org:authright/iam.git
+ cd /var/lib/jenkins/code/dev/iam
+ git checkout dev
Already on 'dev'
Your branch is up-to-date with 'origin/dev'.
+ git pull
From bitbucket.org:authright/iam
   b351247..bb40af1  dev        -> origin/dev
error: The following untracked working tree files would be overwritten by merge:
	portal-platform-admin/backend/src/main/resources/static/images/logo_nav.png
	portal-platform-admin/backend/src/main/resources/static/images/logo_nav1.png
Please move or remove them before you can merge.
Aborting
Updating b351247..bb40af1
+ shell_exit
+ errcode=1
+ rm -rf /tmp/env//14963
+ '[' 1 -eq 0 ']'
+ echo ERROR
+ exit 1
Build step 'Execute shell' marked build as failure
Finished: FAILURE

#+BEGIN_EXAMPLE
[8/14/15, 9:24:06 PM] denny: http://123.57.240.189:28080/job/BuildRepoCode/347/console
我想问题是这样的
[8/14/15, 9:24:42 PM] denny: 1. 这两个文件在git仓库里
2. 这两个文件在build过程中，会被更新。

所以conflict了。
[8/14/15, 9:24:55 PM] jacobzeng-曾瑞林ruilin: 这2个文件不应该在这个目录
[8/14/15, 9:25:02 PM] jacobzeng-曾瑞林ruilin: 删了的
[8/14/15, 9:25:22 PM] jacobzeng-曾瑞林ruilin: 我来处理下
[8/14/15, 9:25:23 PM] jacobzeng-曾瑞林ruilin: 稍等
[8/14/15, 9:25:26 PM] denny: 曾经存在过？
[8/14/15, 9:26:08 PM] jacobzeng-曾瑞林ruilin: 恩，曾经在过，现在又出现了
[8/14/15, 9:26:15 PM] jacobzeng-曾瑞林ruilin: 我刚提交了删除，稍等
#+END_EXAMPLE

* TODO Deal with customers who need detail update everyday
#+BEGIN_EXAMPLE
[8/18/15, 9:15:07 PM] kungchaowang: let me add the format, and please add details to them
[8/18/15, 9:18:25 PM] kungchaowang: please see ticket MDM-328 and MDM-624 to fill up the status for each task in the table.
[8/18/15, 9:23:04 PM] kungchaowang: please don’t use comments, please add sub-tasks to ticket like MDM-624, and give every subtask points and also days of work. so we can keep better tracking of the things got done
[8/18/15, 9:26:43 PM] denny: ok
[8/18/15, 9:30:22 PM] kungchaowang: Denny, we will need you to give us update more frequent. So, it will be, send to totvslabs emails to give everyone in office your update every monday/wed/friday. Detail describe what you do and what you have completed.
[8/18/15, 9:31:11 PM] kungchaowang: meanwhile, I will have to start code review on your works after I come back from vacation, which is Aug 31 and on.
[8/18/15, 9:32:12 PM] kungchaowang: so I will start to pick up my chef and docker skills, so I can better understand what you do.
[8/18/15, 9:32:55 PM] kungchaowang: that’s for now, ping me when you have questions for me.
[8/18/15, 11:00:00 PM] denny: ok
[8/18/15, 11:01:03 PM] kungchaowang: thank you, let’s do that and see if we can make people more visualize your work
[8/18/15, 11:01:23 PM] denny: yes, let’s try this approach.
#+END_EXAMPLE

* TODO devops consultant: Pepole demand request
#+BEGIN_EXAMPLE
[8/18/15, 10:34:24 PM] Robson Thanael Poffo: Another question, about the VM... Is possible for me see the Fluig Data log in sandbox?
[8/18/15, 10:53:40 PM] denny: Hi Robson

Thanks for bringing this to table.

Technically speaking, we definitely can, like allow people to ssh or export log by web ui.

We will have concern, if we have people more access, will it damage the code security.

To support this, we need a solution which people will agree.

So could you send me an email and cc Kung, so that I can start this discussion
[8/18/15, 11:56:26 PM] Robson Thanael Poffo: Ok..
[8/18/15, 11:56:33 PM] Robson Thanael Poffo: I am going to send the email to you
[8/18/15, 11:56:38 PM] denny: thanks
[8/18/15, 11:56:54 PM] Robson Thanael Poffo: I agree that is not good for us enable ssh (security code)
[8/18/15, 11:57:10 PM] Robson Thanael Poffo: I liked your suggestion about allow web access to the log
[8/18/15, 11:57:18 PM] Robson Thanael Poffo: thanks
[8/18/15, 11:58:49 PM] denny: Yes, let’s start the topic in email, so that I can propose solution on this..

It’s not a very small fix. So I need to convince Kung/Vicente first, only after then I can put effort on that.
#+END_EXAMPLE
* web page: Monitoring Linux Remote Hosts with nagios NRPE...          
http://blog.roozbehk.com/post/25059446631/nrpe-monitoring-linux-remote-hosts-nagios
** webcontent                     :noexport:
#+begin_example
Location: http://blog.roozbehk.com/post/25059446631/nrpe-monitoring-linux-remote-hosts-nagios                                 
Roozbeh Kavian

Roozbehk.com Logo Life Runs on Code

  * Home
  * Blog
  * Snippets
  * Archive
  * Contact
  * Subscribe via RSS

Monitoring Linux Remote Hosts with nagios NRPE daemon

---------------------------------------------------------------------------------------------------

This guide will walk through the steps to properly configure your NRPE daemon. we will show how to
install NRPE in Red Hat Enterprise Linux / Cent OS to monitor server health. This has been test in
Red Hat Enterprise Linux 4 and 5.

1 - Summary

NRPE (Nagios Remote Plugin Executor) plugin allows you to monitor any number of remote network
devices and services using Nagios. Installing and Configuring a Nagios Server is not part of this
HowTo. You will need a nagios machine already in place on your internal network to monitor the host
we install the nrpe daemon on.

2 - installation nrpe, nagios-plugins-all

you will need to have yum EPEL repository enabled for your Redhat/CentsOs machine. Check out this
guide: Enable EPEL Repository

sudo yum install nrpe
sudo yum install nagios-plugins-all

3 - edit nrpe.cfg to allow your nagios server

Edit nrpe configuration file:

vim /etc/nagios/nrpe.cfg

find line allowed_hosts . it is a comma separated list. add your nagios server ip to the list

allowed_hosts=127.0.0.1,192.168.1.100

4 - IPTables

nrpe daemon binds to port 5666. edit your iptables filter to accept connection from your nagios
server

-A RH-Firewall-1-INPUT -s 192.168.1.100 -p tcp --dport 5666 -j ACCEPT

5 - Hosts.allow

Now, open the /etc/hosts.allow file and add an entry for the IP address of your remote monitoring
server.

nrpe: 192.168.1.100   nagios.example.edu

6 - Start nrpe service

Start nrpe service 

sudo /sbin/service nrpe start

7 - Test Connection 

test the connection from your nagios box and see if you can connect to nrpe daemon

telnet 192.168.1.100 5666

If the connection immediately closes you’ve got a problem and something isn’t right. If the socket
opens and you are met with the following:

Escape character is '^]'.

Then y ou’re ready to move on. If you’ve got problems at this point, go back through each of the
steps above and check for any errors in configuration.

9 - Start nrpe service on system start up

Enable the nrpe service so that it will start when the system starts up.

sudo /sbin/chkconfig nrpe on 
sudo /sbin/chkconfig --list nrpe 
nrpe 0:off 1:off 2:on 3:on 4:on 5:on 6:off

8 - Define Command Definition for check_nrpe

now that the nrpe service is installed and running, lets make sure there is command definition for
check_nrpe if there is no command please add the below code. open your checkcommands.cfgfile.These
are specified in the $NAGIOSHOME/etc/checkcommands.cfg file. Where there are parameters available
for a command, these can be passed through from services.cfg. my checkcommands.cfg is located in /
usr/local/nagios/etc/objects/checkcommands.cfg

When monitoring remote services, we first issue a check_nrpe command followed by a ! and the
command on the remote machine to run. This means that we are going to need an instance of
check_nrpe on our Nagios Server. check_nrpe should be under /usr/local/nagios/libexec if you can’t
find it. you will need to compile or install it for your nagios

define command{
        command_name check_nrpe
        command_line $USER10$/check_nrpe -H $HOSTADDRESS$ -t 30 -c $ARG1$
}

8 - Add New Host & Service

We are now ready to add our new host to our primary Nagios installation. This is very straight
forward and should only take a moment.

Back on the primary Nagios installation server we need to edit our hosts.cfg configuration file.
The file is located in /usr/local/nagios/etc/hosts.cfg. This may change depending on your
installation and organization of configuration files. Read the first part of this whitepaper for
organization advise.

In the hosts.cfg file, add your new host object:

define host{
        use generic-host
        #Hostname of remote system
        host_name host.domain.com
        # A friendly name for this server
        alias Friendly  name 
        # Remote host IP address
        address 127.0.0.1
        check_command check-host-alive
        max_check_attempts 10
        notification_interval 30
        notification_period 24x7
        notification_options d,r
        # Your defined contact group name
        contact_groups admins
}

At this time our hosts.cfg file contains two hosts objects, the localhost which is running the
Nagios application and our remote host which we will be monitoring.

We now want to add the service objects to our services.cfg file located in the same directory. Add
the following single service to your services.cfg file:

define service{
        use generic-service
        # Hostname of remote system
        host_name host.domain.com
        service_description Primary Disk Usage
        is_volatile 0
        check_period 24x7
        max_check_attempts 3
        normal_check_interval 5
        retry_check_interval 1
        # Change to your contact group
        contact_groups admins
        notification_options w,u,c,r
        notification_interval 10
        notification_period 24x7
        check_command check_nrpe!check_disk1
}

9 - reload nagios configuration

 /etc/init.d/nagios reload 

once nagios is reloaded without errors check nagios web for the added check and make sure it is
recieving information from nrpe service on the host.

---------------------------------------------------------------------------------------------------

Wednesday, June 13th, 2012

View the discussion thread
[                    ]  Search 
Blog (*) Snippets ( )

Roozbeh Kavian

[roozbeh_ka]

  * Linkedin
  * Github

Published

Wednesday, June 13th, 2012

Tags

  * HowTo
  * NRPE
  * nagios
  * Monitoring
  * redhat

Recent Posts [rss_feed]

Recent Snippets [rss_feed]

Archive
Mobile

Recent Tweets

Tag Cloud

[impixu][impixu]

#+end_example
